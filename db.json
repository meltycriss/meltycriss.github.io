{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":1,"renderable":0},{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":1,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/hook-duoshuo.js","path":"js/src/hook-duoshuo.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","path":"lib/algolia-instant-search/instantsearch.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","path":"lib/canvas-nest/canvas-nest.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/LICENSE","path":"lib/fastclick/LICENSE","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/README.md","path":"lib/fastclick/README.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/bower.json","path":"lib/fastclick/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","path":"lib/jquery_lazyload/CONTRIBUTING.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","path":"lib/jquery_lazyload/README.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","path":"lib/jquery_lazyload/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","path":"lib/jquery_lazyload/jquery.lazyload.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","path":"lib/jquery_lazyload/jquery.scrollstop.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/bower.json","path":"lib/velocity/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","path":"lib/fancybox/source/blank.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","path":"lib/fancybox/source/fancybox_loading.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","path":"lib/fancybox/source/fancybox_loading@2x.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","path":"lib/fancybox/source/fancybox_overlay.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","path":"lib/fancybox/source/fancybox_sprite.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","path":"lib/fancybox/source/fancybox_sprite@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","path":"lib/fancybox/source/jquery.fancybox.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","path":"lib/fancybox/source/jquery.fancybox.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","path":"lib/fastclick/lib/fastclick.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","path":"lib/fastclick/lib/fastclick.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","path":"lib/fancybox/source/jquery.fancybox.pack.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","path":"lib/fancybox/source/helpers/fancybox_buttons.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","path":"lib/fancybox/source/helpers/jquery.fancybox-media.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","path":"lib/algolia-instant-search/instantsearch.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":1,"renderable":1}],"Cache":[{"_id":"source/CNAME","hash":"4ee9f53b2f454d366c75978ad3c8dd83ca7614b2","modified":1723565027848},{"_id":"themes/next/.bowerrc","hash":"3228a58ed0ece9f85e1e3136352094080b8dece1","modified":1723565027896},{"_id":"themes/next/.editorconfig","hash":"792fd2bd8174ece1a75d5fd24ab16594886f3a7f","modified":1723565027896},{"_id":"themes/next/.gitignore","hash":"5f09fca02e030b7676c1d312cd88ce8fbccf381c","modified":1723565027896},{"_id":"themes/next/.hound.yml","hash":"b76daa84c9ca3ad292c78412603370a367cc2bc3","modified":1723565027896},{"_id":"themes/next/.javascript_ignore","hash":"f9ea3c5395f8feb225a24e2c32baa79afda30c16","modified":1723565027896},{"_id":"themes/next/.jshintrc","hash":"9928f81bd822f6a8d67fdbc909b517178533bca9","modified":1723565027896},{"_id":"themes/next/README.en.md","hash":"3b0c7998cf17f9cf9e1a5bfcd65679a43a00c817","modified":1723565027896},{"_id":"themes/next/README.md","hash":"500b5606eb6a09c979d16128f8b00f4bf9bc95ac","modified":1723565027896},{"_id":"themes/next/_config.yml","hash":"da0c38f7d5ee14ed7dcc0a7299f79250fc532a55","modified":1723734428764},{"_id":"themes/next/bower.json","hash":"5abc236d9cc2512f5457ed57c1fba76669eb7399","modified":1723565027896},{"_id":"themes/next/gulpfile.coffee","hash":"61ef0606a8134894d7ac796bc8d0fa4ba6a94483","modified":1723565027896},{"_id":"themes/next/package.json","hash":"877cb98025e59015532c4c9a04a33e2af4ad56f9","modified":1723565027904},{"_id":"source/_posts/caffe-configuration.md","hash":"8daca41d462aafd288a0a3c13c690ae7dce17d63","modified":1723565027848},{"_id":"source/_posts/caffe_1_layer.md","hash":"265f14e638460bdbbace98b7c2d5b3bc57be0bde","modified":1723565027848},{"_id":"source/_posts/caffe_2_rnn.md","hash":"4ef886a5b1b770a3b78b679669e5a90abaf01829","modified":1723565027848},{"_id":"source/_posts/caffe_3_s2vt_data_process.md","hash":"fd4b46c89bff90952839d5e5aa15adff5a9b7dd1","modified":1723565027848},{"_id":"source/_posts/caffe_4_lstm.md","hash":"8c8b083764de39e570d507480fb535bc9827040b","modified":1723565027848},{"_id":"source/_posts/caffe_5_s2vt_captioner.md","hash":"b5427b7ae7a6a456a986b4e2a8e8de888f5a65e2","modified":1723565027848},{"_id":"source/_posts/imagenet.md","hash":"8bb948100ee41b5c6ed6437f3de227d9fa9a808e","modified":1723565027848},{"_id":"source/_posts/mindmap-goutongdeyishu.md","hash":"cc494412d7fb21e8c9f8b250a9a891f7f9c1154d","modified":1723565027848},{"_id":"source/_posts/mindmap-jingjin.md","hash":"64667d55001c323e09277d9924c25f5acdfaef78","modified":1723565027848},{"_id":"source/_posts/mindmap-zhexuejiamendouganlexieshenme.md","hash":"ab7e1e29e78f782cbb3a14a9c78ea3075a01b45a","modified":1723565027848},{"_id":"source/_posts/note-a-tour-of-cpp-1.md","hash":"4a8316be9b313f8e7ea180eb7c9e45d134034f41","modified":1723565027848},{"_id":"source/_posts/note-essence-of-linear-algrbra.md","hash":"88b47159c4953973ec2d84af470e3d5ec77d7da5","modified":1723565027848},{"_id":"source/_posts/note-learning-how-to-learn.md","hash":"a7d3f9421f1ab83892310fc48752bf0da77b07dc","modified":1723565027852},{"_id":"source/_posts/note-linear-algebra.md","hash":"2fae61a9039de51214223bf6d12c4f8b023a8d00","modified":1723565027852},{"_id":"source/_posts/note-reinforcement-learning.md","hash":"e47e621703b7572c0373fae19d9390bbf381b6c9","modified":1723565027856},{"_id":"source/_posts/paper-acktr.md","hash":"007a14db1bd305f965c0d7f7fee900ba5639947a","modified":1723565027864},{"_id":"source/_posts/paper-orca.md","hash":"45a7f4491102fd14cf5546f079288a146dff719e","modified":1723565027864},{"_id":"source/_posts/paper-prioritized-experience-replay.md","hash":"b9db96892cb64b4085fbcb01b9b72956a6462ac9","modified":1723565027864},{"_id":"source/_posts/paper-rvo.md","hash":"1ec8523135848e2677cb767e96e7ed92cdaecc38","modified":1723565027868},{"_id":"source/_posts/paper_rcnn.md","hash":"6dc2e9f10392312fcdc46d994f0eb51cc0173035","modified":1723565027872},{"_id":"source/_posts/source-carlaue5-architecture.md","hash":"99a66726009e89f775c0fde11ed8c86dcfce1f64","modified":1723642678881},{"_id":"source/_posts/source-ppo.md","hash":"8644688cfcb748ab53d3cb2779bcfd9c8f317c1b","modified":1723565027872},{"_id":"source/_posts/summary-derivative.md","hash":"14d1d751d94a00ff3629ac1599596c53d707209c","modified":1723565027872},{"_id":"source/_posts/summary-gps.md","hash":"a72bf7255121079f224a5dfda9c47373996995ca","modified":1723565027876},{"_id":"source/_posts/summary-rl-drl.md","hash":"8305b58e791c82e16ec60e53e2348b046986f0c1","modified":1723565027884},{"_id":"source/_posts/tech-gym.md","hash":"69a28c70ca0a33892f57e2f11cd46a945282987f","modified":1723565027884},{"_id":"source/_posts/tech-ubuntu-bluetooth.md","hash":"4ad63afa5e8bf8c8f3a38ea9b168720507bd4cd2","modified":1723565027884},{"_id":"source/_posts/tech-ubuntu-to-go.md","hash":"b02de5dd54175a750057bb25aa20036d550a3c82","modified":1723565027884},{"_id":"source/_posts/tech-vimrc.md","hash":"9fdfe2b078a9ec35c97de806c47bca84cee6c3e7","modified":1723565027884},{"_id":"source/_posts/tech-windows-ue5-carla-build.md","hash":"7182baf7593eeb78d58fc8cf278b89a42b467b8b","modified":1723565027884},{"_id":"source/about/index.md","hash":"cbe8f118960b17c526c1ebdf0761c9d53fd65157","modified":1723565027884},{"_id":"source/tags/index.md","hash":"94bbb384e5e284787dbcef35f9ea0208409c2527","modified":1723565027884},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"5ab257af816986cd0e53f9527a92d5934ac70ae9","modified":1723565027896},{"_id":"themes/next/.github/ISSUE_TEMPLATE.md","hash":"c2024ded82143807c28a299c5fe6b927ef3525ff","modified":1723565027896},{"_id":"themes/next/languages/de.yml","hash":"1fdea1f84b7f691f5b4dd4d2b43eeb27b10fa0c8","modified":1723565027896},{"_id":"themes/next/languages/default.yml","hash":"767470a80dc257e23e14c3a78e8c52a46c9d6209","modified":1723565027896},{"_id":"themes/next/languages/en.yml","hash":"40057d6608e825d06e0864bac4dcd27ed88ada87","modified":1723565027896},{"_id":"themes/next/languages/fr-FR.yml","hash":"9fca01ef917d33ae2ae6bc04561ec6799dff5351","modified":1723565027896},{"_id":"themes/next/languages/id.yml","hash":"34396bef27c4ab9e9a3c5d3e3aa94b0e3b3a7b0d","modified":1723565027896},{"_id":"themes/next/languages/ja.yml","hash":"49f12149edcc1892b26a6207328cda64da20116d","modified":1723565027896},{"_id":"themes/next/languages/ko.yml","hash":"b6bc5d6b0c000deb44099b42d3aebb8c49dbfca9","modified":1723565027896},{"_id":"themes/next/languages/pt-BR.yml","hash":"7742ba4c0d682cbe1d38305332ebc928abd754b5","modified":1723565027896},{"_id":"themes/next/languages/pt.yml","hash":"6b660b117314cad93f08757601df3adb04c68beb","modified":1723565027896},{"_id":"themes/next/languages/ru.yml","hash":"257d11e626cbe4b9b78785a764190b9278f95c28","modified":1723565027896},{"_id":"themes/next/languages/zh-Hans.yml","hash":"f6c9fafa0f5f0050cd07ca2cf5e38fbae3e28145","modified":1723565027896},{"_id":"themes/next/languages/zh-hk.yml","hash":"34c84c6d04447a25bd5eac576922a13947c000e2","modified":1723565027896},{"_id":"themes/next/languages/zh-tw.yml","hash":"c97a5c41149de9b17f33439b0ecf0eff6fdae50e","modified":1723565027896},{"_id":"themes/next/layout/_layout.swig","hash":"2fa3c74066843a859fac77803324a1de51044da9","modified":1723565027900},{"_id":"themes/next/layout/archive.swig","hash":"b5b59d70fc1563f482fa07afd435752774ad5981","modified":1723565027904},{"_id":"themes/next/layout/category.swig","hash":"6422d196ceaff4220d54b8af770e7e957f3364ad","modified":1723565027904},{"_id":"themes/next/layout/index.swig","hash":"427d0b95b854e311ae363088ab39a393bf8fdc8b","modified":1723565027904},{"_id":"themes/next/layout/page.swig","hash":"3727fab9dadb967e9c2204edca787dc72264674a","modified":1723565027904},{"_id":"themes/next/layout/post.swig","hash":"e2e512142961ddfe77eba29eaa88f4a2ee43ae18","modified":1723565027904},{"_id":"themes/next/layout/schedule.swig","hash":"1f1cdc268f4ef773fd3ae693bbdf7d0b2f45c3a3","modified":1723565027904},{"_id":"themes/next/layout/tag.swig","hash":"07cf49c49c39a14dfbe9ce8e7d7eea3d4d0a4911","modified":1723565027904},{"_id":"themes/next/scripts/merge-configs.js","hash":"0c56be2e85c694247cfa327ea6d627b99ca265e8","modified":1723565027904},{"_id":"themes/next/test/.jshintrc","hash":"19f93d13d1689fe033c82eb2d5f3ce30b6543cc0","modified":1723565027936},{"_id":"themes/next/test/helpers.js","hash":"a1f5de25154c3724ffc24a91ddc576cdbd60864f","modified":1723565027936},{"_id":"themes/next/test/intern.js","hash":"11fa8a4f5c3b4119a179ae0a2584c8187f907a73","modified":1723565027936},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1723565027916},{"_id":"source/_posts/note-essence-of-linear-algrbra/combination.png","hash":"7fff8d00a0245e19564c05b2037f3f7d836a6e36","modified":1723565027848},{"_id":"source/_posts/note-essence-of-linear-algrbra/dot_product_order.png","hash":"7e98037126903e36880c30bacc83b6232787f9ca","modified":1723565027848},{"_id":"source/_posts/note-essence-of-linear-algrbra/dot_product_projection.png","hash":"d85a3e7b264bb1bff7624a85a6f9f6ef2de727f3","modified":1723565027848},{"_id":"source/_posts/note-essence-of-linear-algrbra/representation.png","hash":"19ad51b9238092074ec0b0dae6c47aaf3940c7b7","modified":1723565027848},{"_id":"source/_posts/note-essence-of-linear-algrbra/transformation.png","hash":"0bf2d5acd0d7e7a81df341aca79c9082a2b194a6","modified":1723565027852},{"_id":"source/_posts/note-reinforcement-learning/lec1_Intro_to_RL.png","hash":"7ea12e992a3e1286dab7a50b1868db90399f9033","modified":1723565027856},{"_id":"source/_posts/note-reinforcement-learning/lec3_Planning_by_DP.png","hash":"3768d82b093bc44890435da2da314704c5d92485","modified":1723565027860},{"_id":"source/_posts/note-reinforcement-learning/lec9_Exploration_and_Exploitation.png","hash":"a5b60b7951e0aaf8a1be5fdbda7dfa14b63739f6","modified":1723565027864},{"_id":"source/_posts/paper-orca/orca_sol.png","hash":"18e1ed3a4bd3ca056c1a1944e866c224f4d5be62","modified":1723565027864},{"_id":"source/_posts/paper-prioritized-experience-replay/env.png","hash":"6bb91e717c7802f102ec72005a930cdc605bd17e","modified":1723565027868},{"_id":"source/_posts/paper-prioritized-experience-replay/fig.png","hash":"0811b241f509eeb147e0682fdb9b2036155d5e64","modified":1723565027868},{"_id":"source/_posts/paper-rvo/left_right.png","hash":"4c42a652cdc5dea16e432cebfea3edf9a8c32189","modified":1723565027868},{"_id":"source/_posts/paper-rvo/oscillation.png","hash":"fb6232bb65cb8c3550060247c48d2aa9283547d6","modified":1723565027868},{"_id":"source/_posts/paper-rvo/prob_disc.png","hash":"3580292f8e4e853a79dff930bf07be0d6752350f","modified":1723565027868},{"_id":"source/_posts/paper-rvo/prob_sol.png","hash":"021f98d1225200335f37a63881d7733986ea7264","modified":1723565027868},{"_id":"source/_posts/summary-derivative/bp1.png","hash":"e3aad72351087efdf3ef6e6fbdb99792039a46b4","modified":1723565027872},{"_id":"source/_posts/summary-derivative/bp2.png","hash":"6d19f03c276c7aaaee4911eea9f8d37796a478ae","modified":1723565027872},{"_id":"source/_posts/summary-derivative/bp3.png","hash":"00d38a54775dfd8015fd45b0afceefa7975b1ccf","modified":1723565027872},{"_id":"source/_posts/summary-derivative/rnn.png","hash":"2b658f64d3db195da40fe5cf80674687055196ea","modified":1723565027876},{"_id":"source/_posts/summary-derivative/softmax.png","hash":"477d7fe77499f6d01202edc3e34350f24680ddd1","modified":1723565027876},{"_id":"source/_posts/summary-gps/1.png","hash":"ab590897eac804ae593beb48bca2aea1fb329050","modified":1723565027876},{"_id":"source/_posts/summary-gps/lqr.png","hash":"50a5d0e7f7291e8099ad4f808fef69b58c4eb003","modified":1723565027884},{"_id":"source/_posts/summary-rl-drl/ppo_objective.png","hash":"88efe85eba5758c768b118156f73da9872e6c31e","modified":1723565027884},{"_id":"themes/next/layout/_custom/header.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1723565027900},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1723565027900},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"5864f5567ba5efeabcf6ea355013c0b603ee07f2","modified":1723565027900},{"_id":"themes/next/layout/_macro/post.swig","hash":"e6016def9b512188f4c2725399c9adc7bc41cdae","modified":1723565027900},{"_id":"themes/next/layout/_macro/reward.swig","hash":"37e5b7c42ec17b9b6b786c5512bcc481a21c974e","modified":1723565027900},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"43d8830bb19da4fc7a5773866be19fa066b62645","modified":1723565027900},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"14e785adeb0e671ba0ff9a553e6f0d8def6c670c","modified":1723565027900},{"_id":"themes/next/layout/_partials/comments.swig","hash":"78ccfc1dc915247c1fec3c86d742e0f4c2f6d99c","modified":1723565027900},{"_id":"themes/next/layout/_partials/duoshuo-hot-articles.swig","hash":"5d4638c46aef65bf32a01681495b62416ccc98db","modified":1723565027900},{"_id":"themes/next/layout/_partials/footer.swig","hash":"7172c6053118b7c291a56a7860128a652ae66b83","modified":1723565027900},{"_id":"themes/next/layout/_partials/head.swig","hash":"ca56f92e2fa82b03853869f5073ee1a5626a4796","modified":1723565027900},{"_id":"themes/next/layout/_partials/header.swig","hash":"adab5c3f7b173f1b45454787f39dde07aea03483","modified":1723565027900},{"_id":"themes/next/layout/_partials/page-header.swig","hash":"39d613e5a9f8389d4ea52d6082502af8e833b9f2","modified":1723565027900},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"9e8e21d194ef44d271b1cca0bc1448c14d7edf4f","modified":1723565027900},{"_id":"themes/next/layout/_partials/search.swig","hash":"1431719d1dbba3f5ee385eebc46376d1a960b2d5","modified":1723565027900},{"_id":"themes/next/layout/_scripts/baidu-push.swig","hash":"c057b17f79e8261680fbae8dc4e81317a127c799","modified":1723565027900},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"03aaebe9d50f6acb007ec38cc04acd1cfceb404d","modified":1723565027900},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"766b2bdda29523ed6cd8d7aa197f996022f8fd94","modified":1723565027900},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"4512867d80d9eddfc3a0f5fea3c456f33aa9d522","modified":1723565027904},{"_id":"themes/next/scripts/tags/button.js","hash":"62e6dbeb53d07627a048132c79630b45d9a8f2cc","modified":1723565027904},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"535fc542781021c4326dec24d8495cbb1387634a","modified":1723565027904},{"_id":"themes/next/scripts/tags/full-image.js","hash":"8eeb3fb89540299bdbb799edfdfdac3743b50596","modified":1723565027904},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"49252824cd53184dc9b97b2f2d87ff28e1b3ef27","modified":1723565027904},{"_id":"themes/next/scripts/tags/note.js","hash":"6752925eedbdb939d8ec4d11bdfb75199f18dd70","modified":1723565027904},{"_id":"themes/next/source/css/main.styl","hash":"f4d6504b783a4944d8d456dd7acb7ba21b64f8c7","modified":1723565027916},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"90035272fa31a3f65b3c0e2cb8a633876ef457dc","modified":1723565027916},{"_id":"themes/next/source/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1723565027916},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1723565027916},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1723565027916},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1723565027916},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1723565027916},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1723565027916},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1723565027916},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1723565027916},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1723565027916},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1723565027916},{"_id":"themes/next/source/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1723565027916},{"_id":"themes/next/source/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1723565027916},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1723565027920},{"_id":"source/_posts/note-essence-of-linear-algrbra/det.png","hash":"ebb7e873f5987d657e4fc7121eb7f8800604278f","modified":1723565027848},{"_id":"source/_posts/note-reinforcement-learning/lec2_MDP.png","hash":"89c39e318abdc30fc5c65db7d79453488ff6e975","modified":1723565027856},{"_id":"source/_posts/note-reinforcement-learning/lec4_Model_Free_Prediction.png","hash":"71162a00429564ceef6dfd329d58748d01006286","modified":1723565027860},{"_id":"source/_posts/note-reinforcement-learning/lec6_Value_Function_Approximation.png","hash":"50434bdb5c6c0ba3d3a80f3ecb786b599e0d1267","modified":1723565027860},{"_id":"source/_posts/note-reinforcement-learning/lec7_Policy_Gradient.png","hash":"e6b33b6be0d0c2de7aea59fcb75e83b5c241a03f","modified":1723565027860},{"_id":"source/_posts/note-reinforcement-learning/lec8_Integrating_Learning_and_Planning.png","hash":"fb387a3f2e67a1d08f0d892cf56111e363d47d67","modified":1723565027864},{"_id":"source/_posts/paper-orca/opt.png","hash":"92aef50ae799ffc7ad40a672c6ac824f2ed81342","modified":1723565027864},{"_id":"source/_posts/paper-orca/orca_app.png","hash":"ebcca0d12534dbc566480dbd7184cbd6ee6722dd","modified":1723565027864},{"_id":"source/_posts/paper-orca/time_interval.png","hash":"0421ecf30741ed973344ce3728d9674c87efe308","modified":1723565027864},{"_id":"source/_posts/paper-rvo/rvo.png","hash":"d22c1078da30825c16b942a4f2aff8155c32181b","modified":1723565027872},{"_id":"source/_posts/paper-rvo/vo.png","hash":"84b84f74b4f83c979842f181b632cc314b30b611","modified":1723565027872},{"_id":"source/_posts/source-carlaue5-architecture/carla.png","hash":"fefb964d9474203661579196432c5601ffdae48e","modified":1723642725985},{"_id":"source/_posts/summary-gps/2.png","hash":"c8e52031e86c63255ee374f6736911fbbdec7a20","modified":1723565027876},{"_id":"source/_posts/summary-gps/3_1.png","hash":"7fb5f326336b0c51974306654728a7403853167a","modified":1723565027880},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1723565027900},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1723565027900},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1723565027912},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1723565027912},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1723565027912},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1723565027916},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1723565027916},{"_id":"source/_posts/source-carlaue5-architecture/pythonapi.png","hash":"10822010b0d821c2060c1be84302e27bc819bd60","modified":1723598425928},{"_id":"source/_posts/summary-derivative/cnn1.png","hash":"71a300c340c5e933cd009fe54462a2d9de4f8d11","modified":1723565027876},{"_id":"source/_posts/summary-gps/3.png","hash":"3b3ed866a498942542c3bc79c27d3d42ec836c2a","modified":1723565027880},{"_id":"source/_posts/summary-gps/3_2.png","hash":"6383a5ce8de41f471675edc6a1d398b68135444f","modified":1723565027880},{"_id":"source/_posts/summary-gps/4.png","hash":"ea3dc37746b8b154fc5ff72a4921ee8158829c45","modified":1723565027884},{"_id":"themes/next/layout/_components/algolia-search/assets.swig","hash":"28ff4ed6714c59124569ffcbd10f1173d53ca923","modified":1723565027896},{"_id":"themes/next/layout/_components/algolia-search/dom.swig","hash":"636f1181dd5887a70b4a08ca8f655d4e46635792","modified":1723565027900},{"_id":"themes/next/layout/_partials/head/custom-head.swig","hash":"9e1b9666efa77f4cf8d8261bcfa445a9ac608e53","modified":1723565027900},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"7ce76358411184482bb0934e70037949dd0da8ca","modified":1723565027900},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"ff5523d5dacaa77a55a24e50e6e6530c3b98bfad","modified":1723565027900},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"959b7e04a96a5596056e4009b73b6489c117597e","modified":1723565027900},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"eefe2388ff3d424694045eda21346989b123977c","modified":1723565027900},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"23e23dc0f76ef3c631f24c65277adf7ea517b383","modified":1723565027900},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"1f1107468aaf03f7d0dcd7eb2b653e2813a675b4","modified":1723565027900},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"89c5a5240ecb223acfe1d12377df5562a943fd5d","modified":1723565027900},{"_id":"themes/next/layout/_partials/share/jiathis.swig","hash":"63315fcf210799f894208c9f512737096df84962","modified":1723565027900},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"069d1357c717572256e5cdee09574ebce529cbae","modified":1723565027900},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1723565027900},{"_id":"themes/next/layout/_scripts/third-party/analytics.swig","hash":"394d9fff7951287cc90f52acc2d4cbfd1bae079d","modified":1723565027900},{"_id":"themes/next/layout/_scripts/third-party/comments.swig","hash":"4abc01bc870e1d7a783cdbd26166edc782a6a4f4","modified":1723565027900},{"_id":"themes/next/layout/_scripts/third-party/lean-analytics.swig","hash":"92dc60821307fc9769bea9b2d60adaeb798342af","modified":1723565027904},{"_id":"themes/next/layout/_scripts/third-party/localsearch.swig","hash":"b460e27db3dcd4ab40b17d8926a5c4e624f293a9","modified":1723565027904},{"_id":"themes/next/layout/_scripts/third-party/mathjax.swig","hash":"6d25596d6a7c57700d37b607f8d9a62d89708683","modified":1723565027904},{"_id":"themes/next/layout/_scripts/third-party/schedule.swig","hash":"22369026c87fc23893c35a7f250b42f3bb1b60f1","modified":1723565027904},{"_id":"themes/next/layout/_scripts/third-party/tinysou.swig","hash":"cb3a5d36dbe1630bab84e03a52733a46df7c219b","modified":1723565027904},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"328d9a9696cc2ccf59c67d3c26000d569f46344c","modified":1723565027912},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"715d5b40dc52f319fe4bff0325beb874774d9bd9","modified":1723565027912},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"78a83c38f69a8747bb74e420e6c9eeef1ea76525","modified":1723565027912},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"c8d35a6b9e3bff6d8fdb66de853065af9d37562d","modified":1723565027916},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"c459aa6d607d8bcb747544e74f6ad0b8374aa3b1","modified":1723565027916},{"_id":"themes/next/source/css/_variables/base.styl","hash":"fc185c6cec79593775d1c2440dbe2a71cfbe2e99","modified":1723565027916},{"_id":"themes/next/source/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1723565027920},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"96b29f69b8b916b22f62c9959a117b5a968200a5","modified":1723565027920},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"39bf93769d9080fa01a9a875183b43198f79bc19","modified":1723565027920},{"_id":"themes/next/source/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1723565027920},{"_id":"themes/next/source/js/src/motion.js","hash":"269414e84df544a4ccb88519f6abae4943db3c67","modified":1723565027920},{"_id":"themes/next/source/js/src/post-details.js","hash":"2038f54e289b6da5def09689e69f623187147be5","modified":1723565027920},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1723565027920},{"_id":"themes/next/source/js/src/utils.js","hash":"384e17ff857f073060f5bf8c6e4f4b7353236331","modified":1723565027920},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1723565027920},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1723565027924},{"_id":"themes/next/source/lib/fastclick/.bower.json","hash":"93ebd5b35e632f714dcf1753e1f6db77ec74449b","modified":1723565027928},{"_id":"themes/next/source/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1723565027928},{"_id":"themes/next/source/lib/fastclick/README.md","hash":"1decd8e1adad2cd6db0ab50cf56de6035156f4ea","modified":1723565027928},{"_id":"themes/next/source/lib/fastclick/bower.json","hash":"13379463c7463b4b96d13556b46faa4cc38d81e6","modified":1723565027928},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"c1072942459fa0880e8a33a1bd929176b62b4171","modified":1723565027928},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"69d152fa46b517141ec3b1114dd6134724494d83","modified":1723565027928},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"dcf470ab3a358103bb896a539cc03caeda10fa8b","modified":1723565027928},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1723565027928},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"279a8a718ab6c930a67c41237f0aac166c1b9440","modified":1723565027928},{"_id":"themes/next/source/lib/jquery/.bower.json","hash":"91745c2cc6c946c7275f952b2b0760b880cea69e","modified":1723565027932},{"_id":"themes/next/source/lib/jquery_lazyload/.bower.json","hash":"b7638afc93e9cd350d0783565ee9a7da6805ad8e","modified":1723565027932},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","hash":"4891864c24c28efecd81a6a8d3f261145190f901","modified":1723565027932},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","hash":"895d50fa29759af7835256522e9dd7dac597765c","modified":1723565027932},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","hash":"65bc85d12197e71c40a55c0cd7f6823995a05222","modified":1723565027932},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1723565027932},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1723565027932},{"_id":"themes/next/source/lib/velocity/.bower.json","hash":"05f960846f1c7a93dab1d3f9a1121e86812e8c88","modified":1723565027936},{"_id":"themes/next/source/lib/velocity/bower.json","hash":"2ec99573e84c7117368beccb9e94b6bf35d2db03","modified":1723565027936},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1723565027936},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1723565027936},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1723565027936},{"_id":"source/_posts/note-learning-how-to-learn/learning_how_to_learn.png","hash":"a059657d99823762027a024dc3f7b8bff72278a8","modified":1723565027852},{"_id":"source/_posts/note-reinforcement-learning/lec5_Model_Free_Control.png","hash":"b5bb0f24c087f240a8d349ea72f542f6ffd06b83","modified":1723565027860},{"_id":"source/_posts/summary-derivative/cnn2.png","hash":"6667442bd7b0a5de38e00cc55abf117eb8644bdb","modified":1723565027876},{"_id":"themes/next/source/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1723565027932},{"_id":"themes/next/layout/_scripts/third-party/analytics/application-insights.swig","hash":"60426bf73f8a89ba61fb1be2df3ad5398e32c4ef","modified":1723565027900},{"_id":"themes/next/layout/_scripts/third-party/analytics/baidu-analytics.swig","hash":"deda6a814ed48debc694c4e0c466f06c127163d0","modified":1723565027900},{"_id":"themes/next/layout/_scripts/third-party/analytics/busuanzi-counter.swig","hash":"3e1cc3c3461a2a85812c4b05c8430c21084e5e8a","modified":1723565027900},{"_id":"themes/next/layout/_scripts/third-party/analytics/cnzz-analytics.swig","hash":"8160b27bee0aa372c7dc7c8476c05bae57f58d0f","modified":1723565027900},{"_id":"themes/next/layout/_scripts/third-party/analytics/facebook-sdk.swig","hash":"394d008e5e94575280407ad8a1607a028026cbc3","modified":1723565027900},{"_id":"themes/next/layout/_scripts/third-party/analytics/google-analytics.swig","hash":"b5e3820ef3ed7ab6d06933661516d92bba8e8c3a","modified":1723730786064},{"_id":"themes/next/layout/_scripts/third-party/analytics/tencent-analytics.swig","hash":"3658414379e0e8a34c45c40feadc3edc8dc55f88","modified":1723565027900},{"_id":"themes/next/layout/_scripts/third-party/comments/disqus.swig","hash":"fb1d04ede838b52ca7541973f86c3810f1ad396e","modified":1723565027904},{"_id":"themes/next/layout/_scripts/third-party/comments/duoshuo.swig","hash":"a356b2185d40914447fde817eb3d358ab6b3e4c3","modified":1723565027904},{"_id":"themes/next/layout/_scripts/third-party/comments/gentie.swig","hash":"03592d1d731592103a41ebb87437fe4b0a4c78ca","modified":1723565027904},{"_id":"themes/next/layout/_scripts/third-party/comments/hypercomments.swig","hash":"3e8dc5c6c912628a37e3b5f886bec7b2e5ed14ea","modified":1723565027904},{"_id":"themes/next/layout/_scripts/third-party/comments/youyan.swig","hash":"ea8078fa9e10be2bb042749d8b6a97adc38f914c","modified":1723565027904},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"b49efc66bd055a2d0be7deabfcb02ee72a9a28c8","modified":1723565027904},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"0dfb4b3ba3180d7285e66f270e1d3fa0f132c3d2","modified":1723565027904},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"471f1627891aca5c0e1973e09fbcb01e1510d193","modified":1723565027904},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"10994990d6e0b4d965a728a22cf7f6ee29cae9f6","modified":1723565027904},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"711c8830886619d4f4a0598b0cde5499dce50c62","modified":1723565027908},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"dd8a3b22fc2f222ac6e6c05bd8a773fb039169c0","modified":1723565027912},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"2186be20e317505cd31886f1291429cc21f76703","modified":1723565027912},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"5304f99581da3a31de3ecec959b7adf9002fde83","modified":1723565027912},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"54c90cf7bdbf5c596179d8dae6e671bad1292662","modified":1723565027912},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"ece571f38180febaf02ace8187ead8318a300ea7","modified":1723565027912},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"013619c472c7e4b08311c464fcbe9fcf5edde603","modified":1723565027912},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"64f5d56c08d74a338813df1265580ca0cbf0190b","modified":1723565027912},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"c2d079788d6fc2e9a191ccdae94e50d55bf849dc","modified":1723565027912},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"5ae7906dc7c1d9468c7f4b4a6feddddc555797a1","modified":1723565027912},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"38e5df90c8689a71c978fd83ba74af3d4e4e5386","modified":1723565027912},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"b0dcca862cd0cc6e732e33d975b476d744911742","modified":1723565027912},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"bbc82c34b5815ff32974f9675e2e9aeff67ac50f","modified":1723565027912},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl.bak","hash":"bbc82c34b5815ff32974f9675e2e9aeff67ac50f","modified":1723565027912},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1723565027912},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"9a5581a770af8964064fef7afd3e16963e45547f","modified":1723565027912},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"0efa036a15c18f5abb058b7c0fad1dd9ac5eed4c","modified":1723565027912},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"8829bc556ca38bfec4add4f15a2f028092ac6d46","modified":1723565027912},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"82bbaa6322764779a1ac2e2c8390ce901c7972e2","modified":1723565027916},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1723565027916},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"a0e2030a606c934fb2c5c7373aaae04a1caac4c5","modified":1723565027916},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"ff9f163bb05c0709577040a875924d36c9ab99d6","modified":1723565027916},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"dcf9fe43b2ef78b923118ba39efedb38760e76b1","modified":1723565027916},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"1408209dfb9a22a0982a30bdbd14842c2b53f264","modified":1723565027916},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"2f878213cb24c5ddc18877f6d15ec5c5f57745ac","modified":1723565027916},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"9b63bd8effc7cf4b96acdea4d73add7df934a222","modified":1723565027916},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"69ecd6c97e7cdfd822ac8102b45ad0ede85050db","modified":1723565027916},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"9ccee9189c910b8a264802d7b2ec305d12dedcd0","modified":1723565027920},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1723565027924},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1723565027924},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1723565027924},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1723565027924},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1723565027924},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1723565027924},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1723565027924},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1723565027924},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1723565027928},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1723565027928},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"4eda182cbcc046dbf449aef97c02c230cf80a494","modified":1723565027928},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1723565027928},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"fb5b49426dee7f1508500e698d1b3c6b04c8fcce","modified":1723565027928},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1723565027932},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1723565027936},{"_id":"source/_posts/source-carlaue5-architecture/client.png","hash":"e9973bfe8bca081bdaef6536156924b41bd6cff5","modified":1723634925782},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1723565027928},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"965ce8f688fedbeed504efd498bc9c1622d12362","modified":1723565027928},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"6d7e6a5fc802b13694d8820fc0138037c0977d2e","modified":1723565027932},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"97e438cc545714309882fbceadbf344fcaddcec5","modified":1723565027932},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"8994ffcce84deac0471532f270f97c44fea54dc0","modified":1723565027904},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"ae1ca14e51de67b07dba8f61ec79ee0e2e344574","modified":1723565027904},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d27448f199fc2f9980b601bc22b87f08b5d64dd1","modified":1723565027904},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"c890ce7fe933abad7baf39764a01894924854e92","modified":1723565027904},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"6c00f6e0978f4d8f9a846a15579963728aaa6a17","modified":1723565027904},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"49c2b2c14a1e7fcc810c6be4b632975d0204c281","modified":1723565027904},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"96f32ea6c3265a3889e6abe57587f6e2a2a40dfb","modified":1723565027904},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"4b7f81e1006e7acee3d1c840ccba155239f830cc","modified":1723565027904},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"b76387934fb6bb75212b23c1a194486892cc495e","modified":1723565027908},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"7778920dd105fa4de3a7ab206eeba30b1a7bac45","modified":1723565027908},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"4eff5b252d7b614e500fc7d52c97ce325e57d3ab","modified":1723565027908},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"2039590632bba3943c39319d80ef630af7928185","modified":1723565027908},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"9bf4362a4d0ae151ada84b219d39fbe5bb8c790e","modified":1723565027908},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"a82afbb72d83ee394aedc7b37ac0008a9823b4f4","modified":1723565027908},{"_id":"themes/next/source/css/_common/components/post/post-button.styl","hash":"fdfadbb4483043c7e0afd541ee9712389e633517","modified":1723565027908},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"8fae54591877a73dff0b29b2be2e8935e3c63575","modified":1723565027908},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"2cdc094ecf907a02fce25ad4a607cd5c40da0f2b","modified":1723565027908},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"b25132fe6a7ad67059a2c3afc60feabb479bdd75","modified":1723565027908},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"387ce23bba52b22a586b2dfb4ec618fe1ffd3926","modified":1723565027908},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"7f1aab694caf603809e33cff82beea84cd0128fd","modified":1723565027908},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"c6dab7661a6b8c678b21b7eb273cef7100f970f6","modified":1723565027908},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"e792c8dc41561c96d128e9b421187f1c3dc978a0","modified":1723565027908},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"a352ae5b1f8857393bf770d2e638bf15f0c9585d","modified":1723565027908},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"963105a531403d7aad6d9e5e23e3bfabb8ec065a","modified":1723565027908},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"10251257aceecb117233c9554dcf8ecfef8e2104","modified":1723565027908},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"bfd806d0a9f21446a22df82ac02e37d0075cc3b5","modified":1723565027908},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"2e7ec9aaa3293941106b1bdd09055246aa3c3dc6","modified":1723565027908},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"920343e41c124221a17f050bbb989494d44f7a24","modified":1723565027908},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"c44f6a553ec7ea5508f2054a13be33a62a15d3a9","modified":1723565027908},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"9486ddd2cb255227db102d09a7df4cae0fabad72","modified":1723565027908},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"45fa7193435a8eae9960267438750b4c9fa9587f","modified":1723565027908},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"7690b9596ec3a49befbe529a5a2649abec0faf76","modified":1723565027908},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"2d3abbc85b979a648e0e579e45f16a6eba49d1e7","modified":1723565027908},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"234facd038f144bd0fe09a31ed1357c5d74c517f","modified":1723565027908},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"3623e7fa4324ec1307370f33d8f287a9e20a5578","modified":1723565027908},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"c2abe4d87148e23e15d49ee225bc650de60baf46","modified":1723565027912},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"b8969e1654eec89a0fd10d88b337fee9cb03cd44","modified":1723565027912},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"4851b981020c5cbc354a1af9b831a2dcb3cf9d39","modified":1723565027912},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"74d0ba86f698165d13402670382a822c8736a556","modified":1723565027912},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"3eb73cee103b810fa56901577ecb9c9bb1793cff","modified":1723565027912},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"eba491ae624b4c843c8be4c94a044085dad4ba0f","modified":1723565027912},{"_id":"themes/next/source/css/_common/components/third-party/baidushare.styl","hash":"93b08815c4d17e2b96fef8530ec1f1064dede6ef","modified":1723565027912},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"b03f891883446f3a5548b7cc90d29c77e62f1053","modified":1723565027912},{"_id":"themes/next/source/css/_common/components/third-party/duoshuo.styl","hash":"2340dd9b3202c61d73cc708b790fac5adddbfc7f","modified":1723565027912},{"_id":"themes/next/source/css/_common/components/third-party/gentie.styl","hash":"586a3ec0f1015e7207cd6a2474362e068c341744","modified":1723565027912},{"_id":"themes/next/source/css/_common/components/third-party/jiathis.styl","hash":"327b5f63d55ec26f7663185c1a778440588d9803","modified":1723565027912},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"637c6b32c58ecf40041be6e911471cd82671919b","modified":1723565027912},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"42348219db93a85d2ee23cb06cebd4d8ab121726","modified":1723565027912},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"5dc4859c66305f871e56cba78f64bfe3bf1b5f01","modified":1723565027912},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"8b8e8cbce98a9296c8fd77f512ae85d945f65d40","modified":1723565027912},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"8b8e8cbce98a9296c8fd77f512ae85d945f65d40","modified":1723565027916},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1723565027924},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1723565027924},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1723565027924},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1723565027924},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1723565027924},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1723565027924},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"1b22f17fdc38070de50e6d1ab3a32da71aa2d819","modified":1723565027928},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1723565027936},{"_id":"source/_posts/note-linear-algebra/linear_algebra.png","hash":"f88d5ce92c3b630755fc4c945f1f1bfaf6d2a10b","modified":1723565027856},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"61d8d967807ef12598d81582fa95b9f600c3ee01","modified":1723565027932},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1723565027924},{"_id":"source/_posts/source-carlaue5-architecture/server.png","hash":"1b91793c57619b052e4e9f9308fa3dc9495bce45","modified":1723636528697},{"_id":"source/_posts/paper-rvo/five_agents.gif","hash":"808251205f52fe3f90dc17cb14e7a5da62d86bc4","modified":1723565027868},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"c0522272bbaef2acb3d341912754d6ea2d0ecfc0","modified":1723565027932},{"_id":"public/sitemap.xml","hash":"a5a737beb900a2d6131750f50c5a96faa81f9d24","modified":1723734536649},{"_id":"public/CNAME","hash":"4ee9f53b2f454d366c75978ad3c8dd83ca7614b2","modified":1723734536951},{"_id":"public/images/algolia_logo.svg","hash":"90035272fa31a3f65b3c0e2cb8a633876ef457dc","modified":1723734536951},{"_id":"public/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1723734536952},{"_id":"public/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1723734536952},{"_id":"public/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1723734536952},{"_id":"public/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1723734536952},{"_id":"public/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1723734536952},{"_id":"public/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1723734536952},{"_id":"public/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1723734536952},{"_id":"public/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1723734536952},{"_id":"public/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1723734536952},{"_id":"public/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1723734536952},{"_id":"public/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1723734536952},{"_id":"public/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1723734536952},{"_id":"public/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1723734536953},{"_id":"public/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1723734536953},{"_id":"public/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1723734536953},{"_id":"public/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1723734536953},{"_id":"public/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1723734536953},{"_id":"public/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1723734536953},{"_id":"public/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1723734536953},{"_id":"public/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1723734536953},{"_id":"public/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1723734536953},{"_id":"public/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1723734536953},{"_id":"public/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1723734536953},{"_id":"public/2018/02/03/summary-rl-drl/ppo_objective.png","hash":"88efe85eba5758c768b118156f73da9872e6c31e","modified":1723734536953},{"_id":"public/2018/03/18/paper-prioritized-experience-replay/env.png","hash":"6bb91e717c7802f102ec72005a930cdc605bd17e","modified":1723734536953},{"_id":"public/2018/03/18/paper-prioritized-experience-replay/fig.png","hash":"0811b241f509eeb147e0682fdb9b2036155d5e64","modified":1723734536954},{"_id":"public/2017/01/14/paper-orca/opt.png","hash":"92aef50ae799ffc7ad40a672c6ac824f2ed81342","modified":1723734536954},{"_id":"public/2017/01/14/paper-orca/orca_sol.png","hash":"18e1ed3a4bd3ca056c1a1944e866c224f4d5be62","modified":1723734536954},{"_id":"public/2017/09/09/note-essence-of-linear-algrbra/combination.png","hash":"7fff8d00a0245e19564c05b2037f3f7d836a6e36","modified":1723734536954},{"_id":"public/2017/09/09/note-essence-of-linear-algrbra/dot_product_order.png","hash":"7e98037126903e36880c30bacc83b6232787f9ca","modified":1723734536954},{"_id":"public/2017/09/09/note-essence-of-linear-algrbra/representation.png","hash":"19ad51b9238092074ec0b0dae6c47aaf3940c7b7","modified":1723734536954},{"_id":"public/2017/09/09/note-essence-of-linear-algrbra/transformation.png","hash":"0bf2d5acd0d7e7a81df341aca79c9082a2b194a6","modified":1723734536954},{"_id":"public/2017/01/13/paper-rvo/left_right.png","hash":"4c42a652cdc5dea16e432cebfea3edf9a8c32189","modified":1723734536954},{"_id":"public/2017/01/13/paper-rvo/oscillation.png","hash":"fb6232bb65cb8c3550060247c48d2aa9283547d6","modified":1723734536954},{"_id":"public/2017/01/13/paper-rvo/prob_disc.png","hash":"3580292f8e4e853a79dff930bf07be0d6752350f","modified":1723734536954},{"_id":"public/2017/01/13/paper-rvo/prob_sol.png","hash":"021f98d1225200335f37a63881d7733986ea7264","modified":1723734536954},{"_id":"public/2018/03/31/summary-derivative/bp1.png","hash":"e3aad72351087efdf3ef6e6fbdb99792039a46b4","modified":1723734536955},{"_id":"public/2018/03/31/summary-derivative/bp3.png","hash":"00d38a54775dfd8015fd45b0afceefa7975b1ccf","modified":1723734536955},{"_id":"public/2018/03/31/summary-derivative/rnn.png","hash":"2b658f64d3db195da40fe5cf80674687055196ea","modified":1723734536955},{"_id":"public/2018/03/31/summary-derivative/softmax.png","hash":"477d7fe77499f6d01202edc3e34350f24680ddd1","modified":1723734536955},{"_id":"public/2018/05/17/summary-gps/1.png","hash":"ab590897eac804ae593beb48bca2aea1fb329050","modified":1723734536955},{"_id":"public/2017/09/09/note-reinforcement-learning/lec2_MDP.png","hash":"89c39e318abdc30fc5c65db7d79453488ff6e975","modified":1723734536955},{"_id":"public/2017/09/09/note-reinforcement-learning/lec3_Planning_by_DP.png","hash":"3768d82b093bc44890435da2da314704c5d92485","modified":1723734536955},{"_id":"public/2017/09/09/note-reinforcement-learning/lec9_Exploration_and_Exploitation.png","hash":"a5b60b7951e0aaf8a1be5fdbda7dfa14b63739f6","modified":1723734536955},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"965ce8f688fedbeed504efd498bc9c1622d12362","modified":1723734537659},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"6d7e6a5fc802b13694d8820fc0138037c0977d2e","modified":1723734537662},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"97e438cc545714309882fbceadbf344fcaddcec5","modified":1723734537665},{"_id":"public/lib/font-awesome/fonts/FontAwesome.otf","hash":"1b22f17fdc38070de50e6d1ab3a32da71aa2d819","modified":1723734537665},{"_id":"public/2017/01/14/paper-orca/orca_app.png","hash":"ebcca0d12534dbc566480dbd7184cbd6ee6722dd","modified":1723734537665},{"_id":"public/2017/01/14/paper-orca/time_interval.png","hash":"0421ecf30741ed973344ce3728d9674c87efe308","modified":1723734537665},{"_id":"public/2024/08/13/source-carlaue5-architecture/carla.png","hash":"fefb964d9474203661579196432c5601ffdae48e","modified":1723734537666},{"_id":"public/2017/09/09/note-essence-of-linear-algrbra/det.png","hash":"ebb7e873f5987d657e4fc7121eb7f8800604278f","modified":1723734537666},{"_id":"public/2017/09/09/note-essence-of-linear-algrbra/dot_product_projection.png","hash":"d85a3e7b264bb1bff7624a85a6f9f6ef2de727f3","modified":1723734537666},{"_id":"public/2017/01/13/paper-rvo/rvo.png","hash":"d22c1078da30825c16b942a4f2aff8155c32181b","modified":1723734537666},{"_id":"public/2017/01/13/paper-rvo/vo.png","hash":"84b84f74b4f83c979842f181b632cc314b30b611","modified":1723734537666},{"_id":"public/2018/03/31/summary-derivative/bp2.png","hash":"6d19f03c276c7aaaee4911eea9f8d37796a478ae","modified":1723734537666},{"_id":"public/2018/05/17/summary-gps/2.png","hash":"c8e52031e86c63255ee374f6736911fbbdec7a20","modified":1723734537666},{"_id":"public/2018/05/17/summary-gps/lqr.png","hash":"50a5d0e7f7291e8099ad4f808fef69b58c4eb003","modified":1723734537667},{"_id":"public/2017/09/09/note-reinforcement-learning/lec1_Intro_to_RL.png","hash":"7ea12e992a3e1286dab7a50b1868db90399f9033","modified":1723734537667},{"_id":"public/2017/09/09/note-reinforcement-learning/lec4_Model_Free_Prediction.png","hash":"71162a00429564ceef6dfd329d58748d01006286","modified":1723734537667},{"_id":"public/2017/09/09/note-reinforcement-learning/lec6_Value_Function_Approximation.png","hash":"50434bdb5c6c0ba3d3a80f3ecb786b599e0d1267","modified":1723734537667},{"_id":"public/2017/09/09/note-reinforcement-learning/lec7_Policy_Gradient.png","hash":"e6b33b6be0d0c2de7aea59fcb75e83b5c241a03f","modified":1723734537667},{"_id":"public/2017/09/09/note-reinforcement-learning/lec8_Integrating_Learning_and_Planning.png","hash":"fb387a3f2e67a1d08f0d892cf56111e363d47d67","modified":1723734537667},{"_id":"public/tags/index.html","hash":"258f390c28b9fba2160fad52295152b2c70f580a","modified":1723734537695},{"_id":"public/2016/07/07/mindmap-jingjin/index.html","hash":"71acd5f11b0674d6f39a01fc29b24b2ebbf3c011","modified":1723734537695},{"_id":"public/archives/2016/page/2/index.html","hash":"b758258a7447790bb307ea7f430a5492ff1cdfd7","modified":1723734537695},{"_id":"public/archives/2016/06/index.html","hash":"f079a3cea94c7ddfca7e34555f07b3b329c4dd93","modified":1723734537695},{"_id":"public/archives/2016/07/index.html","hash":"9341ddf081012eb70fe4b45139d0ddc5ee8e1252","modified":1723734537695},{"_id":"public/archives/2016/08/index.html","hash":"2b291eaa067f42d11e67b90f7cc982b2e5e822e6","modified":1723734537696},{"_id":"public/archives/2016/09/index.html","hash":"4e096d2687ef2b4021151ec80f9e1f8a72838d74","modified":1723734537696},{"_id":"public/archives/2017/index.html","hash":"b609aefb4df0cfa95019f1c7b1fc4ee3560652c7","modified":1723734537696},{"_id":"public/archives/2017/01/index.html","hash":"8f59a02b689a408169fb6d6b674a088b5b454378","modified":1723734537696},{"_id":"public/archives/2017/09/index.html","hash":"7b784e19bcba200c7d55f7a4158d095429088300","modified":1723734537696},{"_id":"public/archives/2018/02/index.html","hash":"044516b3566a2c2b67d454de6892bdf539c08505","modified":1723734537696},{"_id":"public/archives/2018/03/index.html","hash":"f0cc3c6a15157ab3d8451e6c52e48371836713bb","modified":1723734537696},{"_id":"public/archives/2018/05/index.html","hash":"439c28f8843f8d9a1f4963a4c0e1194721ad853a","modified":1723734537696},{"_id":"public/archives/2018/09/index.html","hash":"8229f17486acd638176c061ad97d27d17de62d20","modified":1723734537696},{"_id":"public/archives/2018/10/index.html","hash":"56e97097162f75a6f3900801c34e61d32136aa3c","modified":1723734537696},{"_id":"public/archives/2021/index.html","hash":"0bb56fdf2eb2cafe4564d02a00c5b677e6757129","modified":1723734537696},{"_id":"public/archives/2021/12/index.html","hash":"8df4a214605bf2356c016a97ec3acd7ee1a1b4f4","modified":1723734537697},{"_id":"public/archives/2024/index.html","hash":"281690a453ee99e4542ea05a4c7f3cc7e112527e","modified":1723734537697},{"_id":"public/archives/2024/08/index.html","hash":"489b2c38d8da847792a4d876dab61c2d1d0d7124","modified":1723734537697},{"_id":"public/categories/环境配置/index.html","hash":"04c59c19ca4cf37401a95da5681e24479b47e3ed","modified":1723734537697},{"_id":"public/categories/caffe/index.html","hash":"a6010b4a0973aa1c67d9c2644fb31d04f90164e0","modified":1723734537697},{"_id":"public/categories/论文笔记/index.html","hash":"10c8f7abdf14fab1cff2fe5219baa90a04d3aa6d","modified":1723734537697},{"_id":"public/categories/思维导图/index.html","hash":"284d492b9c990e818998a1762cc78a8bee666f3e","modified":1723734537697},{"_id":"public/categories/学习笔记/index.html","hash":"bb0834214b1ed6e33f743a2cfbfe167b06b98fd0","modified":1723734537697},{"_id":"public/categories/课程笔记/index.html","hash":"6db2d83e847d29b0aa5c10858da2a955d344426d","modified":1723734537697},{"_id":"public/categories/源码阅读/index.html","hash":"e44ea6cccbb3896eebd549ab041625707ffbfdcf","modified":1723734537697},{"_id":"public/categories/学习总结/index.html","hash":"be4e8bfd9eb2f74e5daf90a011f80c07a67a28aa","modified":1723734537697},{"_id":"public/categories/技术总结/index.html","hash":"1b3a7abafb54999d683a61121c2f6801ef111801","modified":1723734537697},{"_id":"public/tags/caffe配置/index.html","hash":"1f8cad4a5892f28ef593f1aa9df76de8a0157cb8","modified":1723734537697},{"_id":"public/tags/caffe学习/index.html","hash":"68d9884dd274ff9fd71734847a8607743a2dfc32","modified":1723734537698},{"_id":"public/tags/rnn/index.html","hash":"88216c74319fa728878903615061010a7f6603d4","modified":1723734537698},{"_id":"public/tags/s2vt-data/index.html","hash":"5a1f2d4769b8bb5ffc83592c96100dd54a245399","modified":1723734537698},{"_id":"public/tags/lstm/index.html","hash":"fbe65416cf58618da8558f94f57e730d628024a4","modified":1723734537698},{"_id":"public/tags/s2vt-captioner/index.html","hash":"985acac974f16a999c9a9010a07055a35582d036","modified":1723734537698},{"_id":"public/tags/AlexNet/index.html","hash":"3dd5a71d15a9b1dda303680606c388e03d9d75de","modified":1723734537698},{"_id":"public/tags/沟通的艺术/index.html","hash":"33a7bbd0e10d072d465371984cfd5dd7c522db6a","modified":1723734537698},{"_id":"public/tags/精进/index.html","hash":"7993c90d57ec4e1ac9d52a803a77cc5753528b97","modified":1723734537698},{"_id":"public/tags/哲学家们都干了些什么/index.html","hash":"b3f6cfb9dcdec19d85bf17ea6c686198201bfb28","modified":1723734537698},{"_id":"public/tags/A-Tour-of-C/index.html","hash":"b97188d8873a1dd7f812ce711607d43f0052a61c","modified":1723734537698},{"_id":"public/tags/线性代数的本质/index.html","hash":"1f28fa128bf521dabfe5d06b934f64c944ef83ea","modified":1723734537698},{"_id":"public/tags/学习方法/index.html","hash":"10024e53d9bcc8e6bcda0999ebac4413cd58cc9c","modified":1723734537698},{"_id":"public/tags/线性代数/index.html","hash":"01ae70b9aa8d39f4ba4027d80e69efd9a58f535d","modified":1723734537698},{"_id":"public/tags/强化学习/index.html","hash":"12e810c04e39b4ce58e8a258d61a37b0e418a437","modified":1723734537699},{"_id":"public/tags/K-FAC/index.html","hash":"6711e256af92a76881f148cd23ede709b53a8fc9","modified":1723734537699},{"_id":"public/tags/ACKTR/index.html","hash":"8acfaa82f86ced6a96607eb22a0d5f716fd4ab6d","modified":1723734537699},{"_id":"public/tags/ORCA/index.html","hash":"6d2419d0dd0d7730b45e26cf1213e2c0cb61b3ac","modified":1723734537699},{"_id":"public/tags/Prioritized-Experience-Replay/index.html","hash":"0073a84b7b0516edac8910588a431295014d0ca0","modified":1723734537699},{"_id":"public/tags/VO-Velocity-Obstacle/index.html","hash":"701955da1d98b82b5603d8ab09b50bc1245f8705","modified":1723734537699},{"_id":"public/tags/RVO-Reciprocal-Velocity-Obstacle/index.html","hash":"ff79166c5ab882d0562627663e7220a44a0381c5","modified":1723734537699},{"_id":"public/tags/rcnn/index.html","hash":"d9040c3be51c882d8664895946826fc05af39b85","modified":1723734537700},{"_id":"public/tags/CarlaUE5/index.html","hash":"496664ee244810545baa2e2a3d8e39548193c43a","modified":1723734537700},{"_id":"public/tags/pytorch-ppo/index.html","hash":"5b4ee71915b02425ecf84bba1ef740f5c0907d3e","modified":1723734537700},{"_id":"public/tags/derivative/index.html","hash":"2ebb751ff7cae94a0f593229ca0d5e587432ff67","modified":1723734537700},{"_id":"public/tags/softmax/index.html","hash":"c53b45c7b312bffeaa2b66004602344a6dd99ea4","modified":1723734537700},{"_id":"public/tags/backpropagation/index.html","hash":"20e2aad701de4a21743a5cec292a5b7f93cf6d49","modified":1723734537700},{"_id":"public/tags/cnn/index.html","hash":"fc48acf6090ea0dea61f0dd3517dc88775af93a0","modified":1723734537700},{"_id":"public/tags/bptt/index.html","hash":"8ae98591b63d84662e3252f532721b3ea482ffe4","modified":1723734537700},{"_id":"public/tags/max-pooling/index.html","hash":"6c6f7dd7f28a613fe567aa8951a19d334ddea4e6","modified":1723734537700},{"_id":"public/tags/Guided-Policy-Search/index.html","hash":"72c9b8c77908153e14150ca3ad6b56aeba22c250","modified":1723734537701},{"_id":"public/tags/GPS/index.html","hash":"6f24ebb71618e540588b9c1359b50b5805447fab","modified":1723734537701},{"_id":"public/tags/深度强化学习/index.html","hash":"00c2e3ceb009983b654bd61a208ae6a1d28c1561","modified":1723734537701},{"_id":"public/tags/GAE/index.html","hash":"65df50f43ccf4ec62831235d6970b0eea1bac9d3","modified":1723734537701},{"_id":"public/tags/A3C/index.html","hash":"9e1fe7d556ba3175a8f289bf1056d6fdc445a5a0","modified":1723734537701},{"_id":"public/tags/DPG/index.html","hash":"5876baca8d3f78d7996a56fec4500330ff516a5c","modified":1723734537701},{"_id":"public/tags/DDPG/index.html","hash":"049499eb579fd9c41889adee0620d5babcbe4941","modified":1723734537701},{"_id":"public/tags/TRPO/index.html","hash":"df87b8428ad07c2680afcaff49a9abb2c6bbb3df","modified":1723734537701},{"_id":"public/tags/PPO/index.html","hash":"1e3685247f50d9b98b8f88369fc211a828e64080","modified":1723734537701},{"_id":"public/tags/Gym/index.html","hash":"6940c2087facce561c41eee35c1ce265086ca018","modified":1723734537705},{"_id":"public/tags/Ubuntu-USB蓝牙适配器/index.html","hash":"fc0a633064c678743d82e0fdda90d0665d3ed0b5","modified":1723734537705},{"_id":"public/tags/Ubuntu-to-Go/index.html","hash":"2d3b308e2dedbc91bb51d4aadffb948ce84c5f11","modified":1723734537705},{"_id":"public/tags/Vim/index.html","hash":"20514ad2aa4f021e4112d96c8bf4d0a86b4242d8","modified":1723734537706},{"_id":"public/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1723734537706},{"_id":"public/js/src/algolia-search.js","hash":"96b29f69b8b916b22f62c9959a117b5a968200a5","modified":1723734537706},{"_id":"public/js/src/bootstrap.js","hash":"39bf93769d9080fa01a9a875183b43198f79bc19","modified":1723734537706},{"_id":"public/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1723734537706},{"_id":"public/js/src/motion.js","hash":"269414e84df544a4ccb88519f6abae4943db3c67","modified":1723734537706},{"_id":"public/js/src/post-details.js","hash":"2038f54e289b6da5def09689e69f623187147be5","modified":1723734537706},{"_id":"public/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1723734537706},{"_id":"public/js/src/utils.js","hash":"384e17ff857f073060f5bf8c6e4f4b7353236331","modified":1723734537706},{"_id":"public/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1723734537706},{"_id":"public/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1723734537706},{"_id":"public/lib/fastclick/bower.json","hash":"4dcecf83afddba148464d5339c93f6d0aa9f42e9","modified":1723734537706},{"_id":"public/lib/font-awesome/bower.json","hash":"64394a2a9aa00f8e321d8daa5e51a420f0e96dad","modified":1723734537706},{"_id":"public/lib/jquery_lazyload/bower.json","hash":"ae3c3b61e6e7f9e1d7e3585ad854380ecc04cf53","modified":1723734537706},{"_id":"public/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1723734537707},{"_id":"public/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1723734537707},{"_id":"public/lib/velocity/bower.json","hash":"0ef14e7ccdfba5db6eb3f8fc6aa3b47282c36409","modified":1723734537707},{"_id":"public/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1723734537707},{"_id":"public/js/src/schemes/pisces.js","hash":"9ccee9189c910b8a264802d7b2ec305d12dedcd0","modified":1723734537707},{"_id":"public/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1723734537707},{"_id":"public/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1723734537707},{"_id":"public/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1723734537707},{"_id":"public/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1723734537707},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1723734537707},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1723734537707},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1723734537707},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1723734537707},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1723734537707},{"_id":"public/lib/fastclick/README.html","hash":"c52d599f3a276053019fc41af2759ce6491ef581","modified":1723734537707},{"_id":"public/lib/jquery_lazyload/CONTRIBUTING.html","hash":"a6358170d346af13b1452ac157b60505bec7015c","modified":1723734537708},{"_id":"public/lib/jquery_lazyload/README.html","hash":"bde24335f6bc09d8801c0dcd7274f71b466552bd","modified":1723734537708},{"_id":"public/2024/08/13/source-carlaue5-architecture/index.html","hash":"c1c5740445152381d64def79d4270b849bc0dfb6","modified":1723734537708},{"_id":"public/2024/08/11/note-a-tour-of-cpp-1/index.html","hash":"4fc37ea14aa626824db4a167201b6b6d86969633","modified":1723734537708},{"_id":"public/2024/08/04/tech-windows-ue5-carla-build/index.html","hash":"b50693f5580707067f985d7153083a9d0c03d2ae","modified":1723734537708},{"_id":"public/2021/12/29/tech-ubuntu-bluetooth/index.html","hash":"656d46b2821a7f0f8abdaf90f96d920425f520c3","modified":1723734537708},{"_id":"public/2021/12/11/tech-ubuntu-to-go/index.html","hash":"9c09d70bdb54c5f8ddbb8fbeb67585cb9984bd74","modified":1723734537708},{"_id":"public/2018/10/09/source-ppo/index.html","hash":"c0f54be857c8ced5c38a3b38c34241c4e92b61e4","modified":1723734537708},{"_id":"public/2018/09/27/tech-vimrc/index.html","hash":"f845a8753c5f705e360f894488ee4c054b8d131d","modified":1723734537708},{"_id":"public/2018/05/17/summary-gps/index.html","hash":"aebfad0d1a518dfc2f69a8a7a7d430319cc80aef","modified":1723734537709},{"_id":"public/2018/03/31/summary-derivative/index.html","hash":"c2bb46fbc178ac751bb502e686fd860ddeb18d1b","modified":1723734537709},{"_id":"public/2018/03/26/tech-gym/index.html","hash":"26c4b911bcb0ae69f82a45b9903d266124ddb238","modified":1723734537709},{"_id":"public/2018/03/18/paper-prioritized-experience-replay/index.html","hash":"c2ed47135dcfb7fee3de09de661ca2c833908591","modified":1723734537709},{"_id":"public/2018/02/26/paper-acktr/index.html","hash":"1766b902613685e632003f57e2905acd6613d125","modified":1723734537709},{"_id":"public/2018/02/03/summary-rl-drl/index.html","hash":"30761973d7621fcf740f477cee635308c1a1033d","modified":1723734537709},{"_id":"public/2017/09/09/note-reinforcement-learning/index.html","hash":"70500d508e1fabc4cc005efb300d5fa31d9f2dda","modified":1723734537709},{"_id":"public/2017/09/09/note-learning-how-to-learn/index.html","hash":"83308a335f082c2958cf86f3d141ed74f5623286","modified":1723734537709},{"_id":"public/2017/09/09/note-linear-algebra/index.html","hash":"0382b0637f6d76ebdc3cb78536517e920094b0e9","modified":1723734537709},{"_id":"public/2017/09/09/note-essence-of-linear-algrbra/index.html","hash":"5125faa9a63da59a760716549e387990d45d80e3","modified":1723734537709},{"_id":"public/2017/01/14/paper-orca/index.html","hash":"b1482d81ccaa41397272e19fbfc2302b62b97ed4","modified":1723734537710},{"_id":"public/2017/01/13/paper-rvo/index.html","hash":"ad889cf55fb63d492ad6a3efa89c9c0482a50573","modified":1723734537710},{"_id":"public/2016/09/02/mindmap-zhexuejiamendouganlexieshenme/index.html","hash":"1ebca925dba71250aa90f399412d1f6f50fed398","modified":1723734537710},{"_id":"public/2016/08/29/mindmap-goutongdeyishu/index.html","hash":"2a499c19868b0d0c7d53ac14214554a6dd56eea2","modified":1723734537710},{"_id":"public/2016/08/17/caffe_5_s2vt_captioner/index.html","hash":"1623a312f353b351cabc7b89c5adaeec1bbb887d","modified":1723734537710},{"_id":"public/2016/08/05/caffe_4_lstm/index.html","hash":"420c18c9d3d2153c4d8d7238fb1dbbb31b0ed91e","modified":1723734537710},{"_id":"public/2016/07/22/caffe_3_s2vt_data_process/index.html","hash":"8e65743805ef5e7080c692827ac1767a40875a9a","modified":1723734537710},{"_id":"public/2016/07/13/caffe_2_rnn/index.html","hash":"f6b621b9da4ed8cfe20c54f7e4effc656563127c","modified":1723734537710},{"_id":"public/2016/07/08/paper_rcnn/index.html","hash":"8609b87224d2836f36b477c2cfbd7363137bacec","modified":1723734537710},{"_id":"public/2016/07/04/caffe_1_layer/index.html","hash":"1dd6545738d50ea6809069ee6ad2a1018b35e4a7","modified":1723734537710},{"_id":"public/2016/07/01/imagenet/index.html","hash":"a264dcde761e851ef1858564d7259afc24854356","modified":1723734537710},{"_id":"public/2016/06/28/caffe-configuration/index.html","hash":"134c1ffe3b5981c2c6a5515d3058b54becc6c48b","modified":1723734537710},{"_id":"public/archives/index.html","hash":"b2ca0f1486b156a4ddf2317d3339d7afad68ce3d","modified":1723734537711},{"_id":"public/archives/page/2/index.html","hash":"dcc08984e248488f3420b122a26ca0dcef046df8","modified":1723734537711},{"_id":"public/archives/page/3/index.html","hash":"51ff40ccc03862799262ba12b378a53d44adff60","modified":1723734537711},{"_id":"public/archives/2016/index.html","hash":"85b7fc79dd1913ec77bb8eecdb6b2f29a3b5bff1","modified":1723734537711},{"_id":"public/archives/2018/index.html","hash":"4b7c8c643e11e714c824d884730ec95e322225d6","modified":1723734537711},{"_id":"public/index.html","hash":"c853298484a540db742a070ac4f6fe91e5e9cf72","modified":1723734537711},{"_id":"public/page/2/index.html","hash":"f8438f1102a628f3b26640393c124b833e2f41bd","modified":1723734537711},{"_id":"public/page/3/index.html","hash":"410dd0cb6a059371b69075a2bf70afa2e12291f1","modified":1723734537711},{"_id":"public/css/main.css","hash":"d298599ba6cfd63829e133307bbc9ab941c05c31","modified":1723734537711},{"_id":"public/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1723734537711},{"_id":"public/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1723734537712},{"_id":"public/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1723734537712},{"_id":"public/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1723734537712},{"_id":"public/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1723734537712},{"_id":"public/lib/font-awesome/css/font-awesome.css","hash":"4eda182cbcc046dbf449aef97c02c230cf80a494","modified":1723734537712},{"_id":"public/lib/font-awesome/css/font-awesome.min.css","hash":"fb5b49426dee7f1508500e698d1b3c6b04c8fcce","modified":1723734537712},{"_id":"public/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1723734537712},{"_id":"public/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1723734537712},{"_id":"public/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1723734537712},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"61d8d967807ef12598d81582fa95b9f600c3ee01","modified":1723734537713},{"_id":"public/2017/09/09/note-reinforcement-learning/lec5_Model_Free_Control.png","hash":"b5bb0f24c087f240a8d349ea72f542f6ffd06b83","modified":1723734537713},{"_id":"public/2018/03/31/summary-derivative/cnn2.png","hash":"6667442bd7b0a5de38e00cc55abf117eb8644bdb","modified":1723734537713},{"_id":"public/2017/09/09/note-learning-how-to-learn/learning_how_to_learn.png","hash":"a059657d99823762027a024dc3f7b8bff72278a8","modified":1723734537725},{"_id":"public/2024/08/13/source-carlaue5-architecture/pythonapi.png","hash":"10822010b0d821c2060c1be84302e27bc819bd60","modified":1723734537725},{"_id":"public/2018/03/31/summary-derivative/cnn1.png","hash":"71a300c340c5e933cd009fe54462a2d9de4f8d11","modified":1723734537725},{"_id":"public/2018/05/17/summary-gps/3.png","hash":"3b3ed866a498942542c3bc79c27d3d42ec836c2a","modified":1723734537725},{"_id":"public/2018/05/17/summary-gps/3_1.png","hash":"7fb5f326336b0c51974306654728a7403853167a","modified":1723734537726},{"_id":"public/2018/05/17/summary-gps/3_2.png","hash":"6383a5ce8de41f471675edc6a1d398b68135444f","modified":1723734537726},{"_id":"public/2018/05/17/summary-gps/4.png","hash":"ea3dc37746b8b154fc5ff72a4921ee8158829c45","modified":1723734537737},{"_id":"public/2024/08/13/source-carlaue5-architecture/client.png","hash":"e9973bfe8bca081bdaef6536156924b41bd6cff5","modified":1723734537776},{"_id":"public/2017/09/09/note-linear-algebra/linear_algebra.png","hash":"f88d5ce92c3b630755fc4c945f1f1bfaf6d2a10b","modified":1723734537819},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"c0522272bbaef2acb3d341912754d6ea2d0ecfc0","modified":1723734537835},{"_id":"public/2017/01/13/paper-rvo/five_agents.gif","hash":"808251205f52fe3f90dc17cb14e7a5da62d86bc4","modified":1723734537874},{"_id":"public/2024/08/13/source-carlaue5-architecture/server.png","hash":"1b91793c57619b052e4e9f9308fa3dc9495bce45","modified":1723734537880}],"Category":[{"name":"环境配置","_id":"clzvf190v0003eqwovgfzelqr"},{"name":"caffe","_id":"clzvf19170008eqwo4qjdk8wq"},{"name":"论文笔记","_id":"clzvf1920000xeqwof1lqngvg"},{"name":"思维导图","_id":"clzvf19240013eqwoestr1vom"},{"name":"学习笔记","_id":"clzvf192g001neqwopkn8vv7k"},{"name":"课程笔记","_id":"clzvf192j001veqwob3q8wppv"},{"name":"源码阅读","_id":"clzvf192v002ieqwoeg8wgjhp"},{"name":"学习总结","_id":"clzvf192y002peqwo8cf339nl"},{"name":"技术总结","_id":"clzvf19360030eqwozsf9bhwy"}],"Data":[],"Page":[{"title":"tags","date":"2016-06-29T11:14:59.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2016-06-29 19:14:59\ntype: \"tags\"\n---\n","updated":"2024-08-13T16:03:47.884Z","path":"tags/index.html","comments":1,"layout":"page","_id":"clzvf190o0001eqwo3dloqxx7","content":"","excerpt":"","more":""}],"Post":[{"title":"Ubuntu 16.04配置Caffe环境","date":"2016-06-28T11:21:42.000Z","description":["Ubuntu 16.04配置Caffe环境"],"_content":"\n## 基本配置流程\n1. 从官网克隆到本地 [caffe官网](https://github.com/BVLC/caffe)\n> git clone git@github.com:BVLC/caffe.git\n\n2. 按照官方教程安装 [官方安装教程](http://caffe.berkeleyvision.org/installation.html) \n\t1. 配置依赖文件 [依赖文件](http://caffe.berkeleyvision.org/install_apt.html)\n\t> sudo apt-get install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compiler\n\tsudo apt-get install --no-install-recommends libboost-all-dev  \n\tsudo apt-get install libatlas-base-dev  \n\tsudo apt-get install libgflags-dev libgoogle-glog-dev liblmdb-dev\n\n\t2. 编译(**默认含GPU，可以用-j4多核加速编译**) [编译](http://caffe.berkeleyvision.org/installation.html#compilation)\n\t> cp Makefile.config.example Makefile.config  \n\tmake all  \n\tmake test  \n\tmake runtest\n\n## 踩过的坑\n- **can't find hdf5.h when build caffe**: 用以下sh改变include路径 [source](https://github.com/NVIDIA/DIGITS/issues/156)\n```\n#!/bin/bash\n# manipulate header path, before building caffe on debian jessie\n# usage:\n# 1. cd root of caffe\n# 2. bash <this_script>\n# 3. build\n\n# transformations :\n#  #include \"hdf5/serial/hdf5.h\" -> #include \"hdf5/serial/hdf5.h\"\n#  #include \"hdf5_hl.h\" -> #include \"hdf5/serial/hdf5_hl.h\"\n\nfind . -type f -exec sed -i -e 's^\"hdf5.h\"^\"hdf5/serial/hdf5.h\"^g' -e 's^\"hdf5_hl.h\"^\"hdf5/serial/hdf5_hl.h\"^g' '{}' \\;\n```\n\n- **/usr/bin/ld: cannot find -lhdf5_hl**: 修改文件名字 [source](https://github.com/NVIDIA/DIGITS/issues/156)  \n> cd /usr/lib/x86_64-linux-gnu  \nsudo ln -s libhdf5_serial.so.10.1.0 libhdf5.so  \nsudo ln -s libhdf5_serial_hl.so.10.0.2 libhdf5_hl.so\n\n- **‘memcpy’ was not declared in this scope**: 修改Makefile.config [source](https://github.com/BVLC/caffe/issues/4046)\n> 将Makefile.config中的  \nNVCCFLAGS += -ccbin=$(CXX) -Xcompiler -fPIC $(COMMON_FLAGS)  \n修改为  \nNVCCFLAGS += -D_FORCE_INLINES -ccbin=$(CXX) -Xcompiler -fPIC $(COMMON_FLAGS)  \n\n- **安装Cuda**:  Cuda官网只有给出14.04和15.04的Cuda7.5版本，但实际上可以直接通过apt-get获取16.04的Cuda7.5\n\t1. 安装cuda\n\t> sudo apt-get install nvidia-cuda-toolkit\n\t2. 修改caffe/Makefile.config中的CUDA_DIR\n\n\n- **安装显卡驱动**: 系统设置-软件和更新-附加驱动，选择最新的显卡驱动，应用。\n\t* 安装驱动后屏幕无法调节亮度的解决办法 [调节亮度](http://askubuntu.com/questions/76081/brightness-not-working-after-installing-nvidia-driver)\n\t* 使用`nvidia-setttings`查看gpu使用情况\n\n\n\n\n","source":"_posts/caffe-configuration.md","raw":"---\ntitle: Ubuntu 16.04配置Caffe环境\ndate: 2016-06-28 19:21:42\ntags: \n  - caffe配置\ndescription:\n  - Ubuntu 16.04配置Caffe环境\ncategories:\n  - 环境配置\n---\n\n## 基本配置流程\n1. 从官网克隆到本地 [caffe官网](https://github.com/BVLC/caffe)\n> git clone git@github.com:BVLC/caffe.git\n\n2. 按照官方教程安装 [官方安装教程](http://caffe.berkeleyvision.org/installation.html) \n\t1. 配置依赖文件 [依赖文件](http://caffe.berkeleyvision.org/install_apt.html)\n\t> sudo apt-get install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compiler\n\tsudo apt-get install --no-install-recommends libboost-all-dev  \n\tsudo apt-get install libatlas-base-dev  \n\tsudo apt-get install libgflags-dev libgoogle-glog-dev liblmdb-dev\n\n\t2. 编译(**默认含GPU，可以用-j4多核加速编译**) [编译](http://caffe.berkeleyvision.org/installation.html#compilation)\n\t> cp Makefile.config.example Makefile.config  \n\tmake all  \n\tmake test  \n\tmake runtest\n\n## 踩过的坑\n- **can't find hdf5.h when build caffe**: 用以下sh改变include路径 [source](https://github.com/NVIDIA/DIGITS/issues/156)\n```\n#!/bin/bash\n# manipulate header path, before building caffe on debian jessie\n# usage:\n# 1. cd root of caffe\n# 2. bash <this_script>\n# 3. build\n\n# transformations :\n#  #include \"hdf5/serial/hdf5.h\" -> #include \"hdf5/serial/hdf5.h\"\n#  #include \"hdf5_hl.h\" -> #include \"hdf5/serial/hdf5_hl.h\"\n\nfind . -type f -exec sed -i -e 's^\"hdf5.h\"^\"hdf5/serial/hdf5.h\"^g' -e 's^\"hdf5_hl.h\"^\"hdf5/serial/hdf5_hl.h\"^g' '{}' \\;\n```\n\n- **/usr/bin/ld: cannot find -lhdf5_hl**: 修改文件名字 [source](https://github.com/NVIDIA/DIGITS/issues/156)  \n> cd /usr/lib/x86_64-linux-gnu  \nsudo ln -s libhdf5_serial.so.10.1.0 libhdf5.so  \nsudo ln -s libhdf5_serial_hl.so.10.0.2 libhdf5_hl.so\n\n- **‘memcpy’ was not declared in this scope**: 修改Makefile.config [source](https://github.com/BVLC/caffe/issues/4046)\n> 将Makefile.config中的  \nNVCCFLAGS += -ccbin=$(CXX) -Xcompiler -fPIC $(COMMON_FLAGS)  \n修改为  \nNVCCFLAGS += -D_FORCE_INLINES -ccbin=$(CXX) -Xcompiler -fPIC $(COMMON_FLAGS)  \n\n- **安装Cuda**:  Cuda官网只有给出14.04和15.04的Cuda7.5版本，但实际上可以直接通过apt-get获取16.04的Cuda7.5\n\t1. 安装cuda\n\t> sudo apt-get install nvidia-cuda-toolkit\n\t2. 修改caffe/Makefile.config中的CUDA_DIR\n\n\n- **安装显卡驱动**: 系统设置-软件和更新-附加驱动，选择最新的显卡驱动，应用。\n\t* 安装驱动后屏幕无法调节亮度的解决办法 [调节亮度](http://askubuntu.com/questions/76081/brightness-not-working-after-installing-nvidia-driver)\n\t* 使用`nvidia-setttings`查看gpu使用情况\n\n\n\n\n","slug":"caffe-configuration","published":1,"updated":"2024-08-13T16:03:47.848Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clzvf190j0000eqwo4x5rnktz","content":"<h2 id=\"基本配置流程\"><a href=\"#基本配置流程\" class=\"headerlink\" title=\"基本配置流程\"></a>基本配置流程</h2><ol>\n<li><p>从官网克隆到本地 <a href=\"https://github.com/BVLC/caffe\" target=\"_blank\" rel=\"external\">caffe官网</a></p>\n<blockquote>\n<p>git clone git@github.com:BVLC/caffe.git</p>\n</blockquote>\n</li>\n<li><p>按照官方教程安装 <a href=\"http://caffe.berkeleyvision.org/installation.html\" target=\"_blank\" rel=\"external\">官方安装教程</a> </p>\n<ol>\n<li><p>配置依赖文件 <a href=\"http://caffe.berkeleyvision.org/install_apt.html\" target=\"_blank\" rel=\"external\">依赖文件</a></p>\n<blockquote>\n<p>sudo apt-get install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compiler<br>sudo apt-get install –no-install-recommends libboost-all-dev<br>sudo apt-get install libatlas-base-dev<br>sudo apt-get install libgflags-dev libgoogle-glog-dev liblmdb-dev</p>\n</blockquote>\n</li>\n<li><p>编译(<strong>默认含GPU，可以用-j4多核加速编译</strong>) <a href=\"http://caffe.berkeleyvision.org/installation.html#compilation\" target=\"_blank\" rel=\"external\">编译</a></p>\n<blockquote>\n<p>cp Makefile.config.example Makefile.config<br>make all<br>make test<br>make runtest</p>\n</blockquote>\n</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"踩过的坑\"><a href=\"#踩过的坑\" class=\"headerlink\" title=\"踩过的坑\"></a>踩过的坑</h2><ul>\n<li><p><strong>can’t find hdf5.h when build caffe</strong>: 用以下sh改变include路径 <a href=\"https://github.com/NVIDIA/DIGITS/issues/156\" target=\"_blank\" rel=\"external\">source</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\">#!/bin/bash</div><div class=\"line\"># manipulate header path, before building caffe on debian jessie</div><div class=\"line\"># usage:</div><div class=\"line\"># 1. cd root of caffe</div><div class=\"line\"># 2. bash &lt;this_script&gt;</div><div class=\"line\"># 3. build</div><div class=\"line\"></div><div class=\"line\"># transformations :</div><div class=\"line\">#  #include &quot;hdf5/serial/hdf5.h&quot; -&gt; #include &quot;hdf5/serial/hdf5.h&quot;</div><div class=\"line\">#  #include &quot;hdf5_hl.h&quot; -&gt; #include &quot;hdf5/serial/hdf5_hl.h&quot;</div><div class=\"line\"></div><div class=\"line\">find . -type f -exec sed -i -e &apos;s^&quot;hdf5.h&quot;^&quot;hdf5/serial/hdf5.h&quot;^g&apos; -e &apos;s^&quot;hdf5_hl.h&quot;^&quot;hdf5/serial/hdf5_hl.h&quot;^g&apos; &apos;&#123;&#125;&apos; \\;</div></pre></td></tr></table></figure>\n</li>\n<li><p><strong>/usr/bin/ld: cannot find -lhdf5_hl</strong>: 修改文件名字 <a href=\"https://github.com/NVIDIA/DIGITS/issues/156\" target=\"_blank\" rel=\"external\">source</a>  </p>\n<blockquote>\n<p>cd /usr/lib/x86_64-linux-gnu<br>sudo ln -s libhdf5_serial.so.10.1.0 libhdf5.so<br>sudo ln -s libhdf5_serial_hl.so.10.0.2 libhdf5_hl.so</p>\n</blockquote>\n</li>\n<li><p><strong>‘memcpy’ was not declared in this scope</strong>: 修改Makefile.config <a href=\"https://github.com/BVLC/caffe/issues/4046\" target=\"_blank\" rel=\"external\">source</a></p>\n<blockquote>\n<p>将Makefile.config中的<br>NVCCFLAGS += -ccbin=$(CXX) -Xcompiler -fPIC $(COMMON_FLAGS)<br>修改为<br>NVCCFLAGS += -D_FORCE_INLINES -ccbin=$(CXX) -Xcompiler -fPIC $(COMMON_FLAGS)  </p>\n</blockquote>\n</li>\n<li><p><strong>安装Cuda</strong>:  Cuda官网只有给出14.04和15.04的Cuda7.5版本，但实际上可以直接通过apt-get获取16.04的Cuda7.5</p>\n<ol>\n<li>安装cuda<blockquote>\n<p>sudo apt-get install nvidia-cuda-toolkit</p>\n</blockquote>\n</li>\n<li>修改caffe/Makefile.config中的CUDA_DIR</li>\n</ol>\n</li>\n</ul>\n<ul>\n<li><strong>安装显卡驱动</strong>: 系统设置-软件和更新-附加驱动，选择最新的显卡驱动，应用。<ul>\n<li>安装驱动后屏幕无法调节亮度的解决办法 <a href=\"http://askubuntu.com/questions/76081/brightness-not-working-after-installing-nvidia-driver\" target=\"_blank\" rel=\"external\">调节亮度</a></li>\n<li>使用<code>nvidia-setttings</code>查看gpu使用情况</li>\n</ul>\n</li>\n</ul>\n","excerpt":"","more":"<h2 id=\"基本配置流程\"><a href=\"#基本配置流程\" class=\"headerlink\" title=\"基本配置流程\"></a>基本配置流程</h2><ol>\n<li><p>从官网克隆到本地 <a href=\"https://github.com/BVLC/caffe\">caffe官网</a></p>\n<blockquote>\n<p>git clone git@github.com:BVLC/caffe.git</p>\n</blockquote>\n</li>\n<li><p>按照官方教程安装 <a href=\"http://caffe.berkeleyvision.org/installation.html\">官方安装教程</a> </p>\n<ol>\n<li><p>配置依赖文件 <a href=\"http://caffe.berkeleyvision.org/install_apt.html\">依赖文件</a></p>\n<blockquote>\n<p>sudo apt-get install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compiler<br>sudo apt-get install –no-install-recommends libboost-all-dev<br>sudo apt-get install libatlas-base-dev<br>sudo apt-get install libgflags-dev libgoogle-glog-dev liblmdb-dev</p>\n</blockquote>\n</li>\n<li><p>编译(<strong>默认含GPU，可以用-j4多核加速编译</strong>) <a href=\"http://caffe.berkeleyvision.org/installation.html#compilation\">编译</a></p>\n<blockquote>\n<p>cp Makefile.config.example Makefile.config<br>make all<br>make test<br>make runtest</p>\n</blockquote>\n</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"踩过的坑\"><a href=\"#踩过的坑\" class=\"headerlink\" title=\"踩过的坑\"></a>踩过的坑</h2><ul>\n<li><p><strong>can’t find hdf5.h when build caffe</strong>: 用以下sh改变include路径 <a href=\"https://github.com/NVIDIA/DIGITS/issues/156\">source</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\">#!/bin/bash</div><div class=\"line\"># manipulate header path, before building caffe on debian jessie</div><div class=\"line\"># usage:</div><div class=\"line\"># 1. cd root of caffe</div><div class=\"line\"># 2. bash &lt;this_script&gt;</div><div class=\"line\"># 3. build</div><div class=\"line\"></div><div class=\"line\"># transformations :</div><div class=\"line\">#  #include &quot;hdf5/serial/hdf5.h&quot; -&gt; #include &quot;hdf5/serial/hdf5.h&quot;</div><div class=\"line\">#  #include &quot;hdf5_hl.h&quot; -&gt; #include &quot;hdf5/serial/hdf5_hl.h&quot;</div><div class=\"line\"></div><div class=\"line\">find . -type f -exec sed -i -e &apos;s^&quot;hdf5.h&quot;^&quot;hdf5/serial/hdf5.h&quot;^g&apos; -e &apos;s^&quot;hdf5_hl.h&quot;^&quot;hdf5/serial/hdf5_hl.h&quot;^g&apos; &apos;&#123;&#125;&apos; \\;</div></pre></td></tr></table></figure>\n</li>\n<li><p><strong>/usr/bin/ld: cannot find -lhdf5_hl</strong>: 修改文件名字 <a href=\"https://github.com/NVIDIA/DIGITS/issues/156\">source</a>  </p>\n<blockquote>\n<p>cd /usr/lib/x86_64-linux-gnu<br>sudo ln -s libhdf5_serial.so.10.1.0 libhdf5.so<br>sudo ln -s libhdf5_serial_hl.so.10.0.2 libhdf5_hl.so</p>\n</blockquote>\n</li>\n<li><p><strong>‘memcpy’ was not declared in this scope</strong>: 修改Makefile.config <a href=\"https://github.com/BVLC/caffe/issues/4046\">source</a></p>\n<blockquote>\n<p>将Makefile.config中的<br>NVCCFLAGS += -ccbin=$(CXX) -Xcompiler -fPIC $(COMMON_FLAGS)<br>修改为<br>NVCCFLAGS += -D_FORCE_INLINES -ccbin=$(CXX) -Xcompiler -fPIC $(COMMON_FLAGS)  </p>\n</blockquote>\n</li>\n<li><p><strong>安装Cuda</strong>:  Cuda官网只有给出14.04和15.04的Cuda7.5版本，但实际上可以直接通过apt-get获取16.04的Cuda7.5</p>\n<ol>\n<li>安装cuda<blockquote>\n<p>sudo apt-get install nvidia-cuda-toolkit</p>\n</blockquote>\n</li>\n<li>修改caffe/Makefile.config中的CUDA_DIR</li>\n</ol>\n</li>\n</ul>\n<ul>\n<li><strong>安装显卡驱动</strong>: 系统设置-软件和更新-附加驱动，选择最新的显卡驱动，应用。<ul>\n<li>安装驱动后屏幕无法调节亮度的解决办法 <a href=\"http://askubuntu.com/questions/76081/brightness-not-working-after-installing-nvidia-driver\">调节亮度</a></li>\n<li>使用<code>nvidia-setttings</code>查看gpu使用情况</li>\n</ul>\n</li>\n</ul>\n"},{"title":"Caffe学习：自定义数据读取","date":"2016-07-04T11:23:42.000Z","description":["Caffe基本框架，阅读和修改image_data_layer源码，使用Caffe的基本流程"],"_content":"\n## Caffe架构\n\n### 简介\nCaffe将层的实现（输入层，卷积层，全连接层），整体网络的定义（AlexNet，LeNet），以及超参数的定义（步长，迭代次数）解耦。用c++实现各层，并使用protocol buffer来定义网络和传入参数\n\n### 基础构件\n\n.cpp文件实现一个个层，作为基础构件供上层调用\n\n- **CAFFE_ROOT/include/caffe/layers**: .hpp为层的头文件\n- **CAFFE_ROOT/src/caffe/layers**: .cpp为层的实现文件\n- **CAFFE_ROOT/src/caffe/proto**: .proto为传参数用的protocol buffer文件\n\n### 自定义网络\n\n- **MODEL_ROOT/train_val.prototxt**: 用作定义整体网络\n- **MODEL_ROOT/solver.prototxt**: 为网络传递超参数\n- **MODEL_ROOT/train.sh**: 开始训练的脚本\n- **MODEL_ROOT/test.sh**: 开始测试的脚本\n\n## 自定义数据读取层\n\n### 数据描述\n[MSRA 10K Salient Object Database](http://mmcheng.net/msra10k/)。含有1w个数据，.jpg结尾的是原图，.png结尾的是标注了的图。用9k张作为训练集，用1k张作为测试集\n\n### image_data_layer总览\n\nimage_data_layer实现了三个函数和调用了两个宏\n\n- **DataLayerSetUp**: 把容器的规格设置好（设好N, K, H, W)\n- **ShuffleImages**: 打乱顺序\n- **load_batch**: 真正把图片读入内存\n- **INSTANTIATE_CLASS**和**REGISTER_LAYER_CLASS**: 注册创建的层\n\n\n### DataLayerSetUp\n\n- **读取图片规格**: 从protocol buffer中读取目标图片的k,h,w（有可能原图800\\*600，但想要256\\*256，这时就需要压缩）\n```cpp\n  const int new_height = this->layer_param_.image_data_param().new_height();\n  const int new_width  = this->layer_param_.image_data_param().new_width();\n  const bool is_color  = this->layer_param_.image_data_param().is_color();\n  string root_folder = this->layer_param_.image_data_param().root_folder();\n\n```\n- **读取图片列表**: 从一个txt文件中读取图片名及其对应label，写进lines_\n```cpp\n  while (std::getline(infile, line)) {\n    pos = line.find_last_of(' ');\n    label = atoi(line.substr(pos + 1).c_str());\n    lines_.push_back(std::make_pair(line.substr(0, pos), label));\n  }\n```\n- **shuffle & skip**\n- **设置容器规格**: 读一张图进来，并用它的规格来设置容器的规格\n```cpp\n  // Read an image, and use it to initialize the top blob.\n  cv::Mat cv_img = ReadImageToCVMat(root_folder + lines_[lines_id_].first,\n                                    new_height, new_width, is_color);\n  CHECK(cv_img.data) << \"Could not load \" << lines_[lines_id_].first;\n  // Use data_transformer to infer the expected blob shape from a cv_image.\n  vector<int> top_shape = this->data_transformer_->InferBlobShape(cv_img);\n  this->transformed_data_.Reshape(top_shape);\n  // Reshape prefetch_data and top[0] according to the batch_size.\n  const int batch_size = this->layer_param_.image_data_param().batch_size();\n  CHECK_GT(batch_size, 0) << \"Positive batch size required\";\n  top_shape[0] = batch_size;\n  for (int i = 0; i < this->PREFETCH_COUNT; ++i) {\n    this->prefetch_[i].data_.Reshape(top_shape);\n  }\n  top[0]->Reshape(top_shape);\n\n```\n\n### load_batch\n\n- **读取图片规格**\n- **设置容器规格**\n- **读入图片**: prefetch\\_data为起始地址，offset根据容器的规格来求，然后在prefetch\\_data+offset的位置设置一个容器transformed\\_data\\_，并将图片写到容器里面\n```cpp\n    cv::Mat cv_img = ReadImageToCVMat(root_folder + lines_[lines_id_].first,\n        new_height, new_width, is_color);\n    CHECK(cv_img.data) << \"Could not load \" << lines_[lines_id_].first;\n    read_time += timer.MicroSeconds();\n    timer.Start();\n    // Apply transformations (mirror, crop...) to the image\n    int offset = batch->data_.offset(item_id);\n    this->transformed_data_.set_cpu_data(prefetch_data + offset);\n    this->data_transformer_->Transform(cv_img, &(this->transformed_data_));\n    trans_time += timer.MicroSeconds();\n```\n\n### 自定义image_data_layer_disc\n\n复现的模型为[DISC](http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7372470&tag=1)，label不是一个简单的int，而是一张图片，所以要对数据输入层进行修改，来产生一个图片label\n\n- **image_data_layer_disc.hpp**: 修改lines_的定义，改成两个string的pair\n- **image_data_layer_disc.cpp**: 参考读入data的方式处理label\n- **caffe.proto**: 添加一个disc_image_data_para来添加关于label的参数\n\n## 训练和测试\n\n- **train_val.prototxt**: 赋值models里面的AlexNet，将data层改成我们的image_data_layer_disc，将loss层改成欧式距离，删除accuracy层\n- **solver.prototxt**: 网络指定为train_val.prototxt，学习率指定为1e-9\n- **train.sh**: \n```shell\n#!/usr/bin/env sh\n\n./build/tools/caffe train --solver=models/disc/solver.prototxt\n\n```\n- **test.sh**:\n```shell\n#!/usr/bin/env sh\n\n./build/tools/caffe.bin test -model=models/disc/train_val.prototxt -weights=models/disc/caffe_alexnet_train_iter_370000.caffemodel -gpu=1\n```\n## Protocol Buffer\n给出一些介绍Protocol Buffer的网站\n- [IMB](https://www.ibm.com/developerworks/cn/linux/l-cn-gpb/)\n- [Google](https://developers.google.com/protocol-buffers/docs/encoding#optional)\n- [pb1](http://www.iloveandroid.net/2015/10/08/studyPtorobuf/)\n- [pb2](http://www.cnblogs.com/royenhome/archive/2010/10/29/1864860.html)","source":"_posts/caffe_1_layer.md","raw":"---\ntitle: Caffe学习：自定义数据读取\ndate: 2016-07-04 19:23:42\ntags: \n  - caffe学习\ndescription:\n  - Caffe基本框架，阅读和修改image_data_layer源码，使用Caffe的基本流程\ncategories:\n  - caffe\n---\n\n## Caffe架构\n\n### 简介\nCaffe将层的实现（输入层，卷积层，全连接层），整体网络的定义（AlexNet，LeNet），以及超参数的定义（步长，迭代次数）解耦。用c++实现各层，并使用protocol buffer来定义网络和传入参数\n\n### 基础构件\n\n.cpp文件实现一个个层，作为基础构件供上层调用\n\n- **CAFFE_ROOT/include/caffe/layers**: .hpp为层的头文件\n- **CAFFE_ROOT/src/caffe/layers**: .cpp为层的实现文件\n- **CAFFE_ROOT/src/caffe/proto**: .proto为传参数用的protocol buffer文件\n\n### 自定义网络\n\n- **MODEL_ROOT/train_val.prototxt**: 用作定义整体网络\n- **MODEL_ROOT/solver.prototxt**: 为网络传递超参数\n- **MODEL_ROOT/train.sh**: 开始训练的脚本\n- **MODEL_ROOT/test.sh**: 开始测试的脚本\n\n## 自定义数据读取层\n\n### 数据描述\n[MSRA 10K Salient Object Database](http://mmcheng.net/msra10k/)。含有1w个数据，.jpg结尾的是原图，.png结尾的是标注了的图。用9k张作为训练集，用1k张作为测试集\n\n### image_data_layer总览\n\nimage_data_layer实现了三个函数和调用了两个宏\n\n- **DataLayerSetUp**: 把容器的规格设置好（设好N, K, H, W)\n- **ShuffleImages**: 打乱顺序\n- **load_batch**: 真正把图片读入内存\n- **INSTANTIATE_CLASS**和**REGISTER_LAYER_CLASS**: 注册创建的层\n\n\n### DataLayerSetUp\n\n- **读取图片规格**: 从protocol buffer中读取目标图片的k,h,w（有可能原图800\\*600，但想要256\\*256，这时就需要压缩）\n```cpp\n  const int new_height = this->layer_param_.image_data_param().new_height();\n  const int new_width  = this->layer_param_.image_data_param().new_width();\n  const bool is_color  = this->layer_param_.image_data_param().is_color();\n  string root_folder = this->layer_param_.image_data_param().root_folder();\n\n```\n- **读取图片列表**: 从一个txt文件中读取图片名及其对应label，写进lines_\n```cpp\n  while (std::getline(infile, line)) {\n    pos = line.find_last_of(' ');\n    label = atoi(line.substr(pos + 1).c_str());\n    lines_.push_back(std::make_pair(line.substr(0, pos), label));\n  }\n```\n- **shuffle & skip**\n- **设置容器规格**: 读一张图进来，并用它的规格来设置容器的规格\n```cpp\n  // Read an image, and use it to initialize the top blob.\n  cv::Mat cv_img = ReadImageToCVMat(root_folder + lines_[lines_id_].first,\n                                    new_height, new_width, is_color);\n  CHECK(cv_img.data) << \"Could not load \" << lines_[lines_id_].first;\n  // Use data_transformer to infer the expected blob shape from a cv_image.\n  vector<int> top_shape = this->data_transformer_->InferBlobShape(cv_img);\n  this->transformed_data_.Reshape(top_shape);\n  // Reshape prefetch_data and top[0] according to the batch_size.\n  const int batch_size = this->layer_param_.image_data_param().batch_size();\n  CHECK_GT(batch_size, 0) << \"Positive batch size required\";\n  top_shape[0] = batch_size;\n  for (int i = 0; i < this->PREFETCH_COUNT; ++i) {\n    this->prefetch_[i].data_.Reshape(top_shape);\n  }\n  top[0]->Reshape(top_shape);\n\n```\n\n### load_batch\n\n- **读取图片规格**\n- **设置容器规格**\n- **读入图片**: prefetch\\_data为起始地址，offset根据容器的规格来求，然后在prefetch\\_data+offset的位置设置一个容器transformed\\_data\\_，并将图片写到容器里面\n```cpp\n    cv::Mat cv_img = ReadImageToCVMat(root_folder + lines_[lines_id_].first,\n        new_height, new_width, is_color);\n    CHECK(cv_img.data) << \"Could not load \" << lines_[lines_id_].first;\n    read_time += timer.MicroSeconds();\n    timer.Start();\n    // Apply transformations (mirror, crop...) to the image\n    int offset = batch->data_.offset(item_id);\n    this->transformed_data_.set_cpu_data(prefetch_data + offset);\n    this->data_transformer_->Transform(cv_img, &(this->transformed_data_));\n    trans_time += timer.MicroSeconds();\n```\n\n### 自定义image_data_layer_disc\n\n复现的模型为[DISC](http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7372470&tag=1)，label不是一个简单的int，而是一张图片，所以要对数据输入层进行修改，来产生一个图片label\n\n- **image_data_layer_disc.hpp**: 修改lines_的定义，改成两个string的pair\n- **image_data_layer_disc.cpp**: 参考读入data的方式处理label\n- **caffe.proto**: 添加一个disc_image_data_para来添加关于label的参数\n\n## 训练和测试\n\n- **train_val.prototxt**: 赋值models里面的AlexNet，将data层改成我们的image_data_layer_disc，将loss层改成欧式距离，删除accuracy层\n- **solver.prototxt**: 网络指定为train_val.prototxt，学习率指定为1e-9\n- **train.sh**: \n```shell\n#!/usr/bin/env sh\n\n./build/tools/caffe train --solver=models/disc/solver.prototxt\n\n```\n- **test.sh**:\n```shell\n#!/usr/bin/env sh\n\n./build/tools/caffe.bin test -model=models/disc/train_val.prototxt -weights=models/disc/caffe_alexnet_train_iter_370000.caffemodel -gpu=1\n```\n## Protocol Buffer\n给出一些介绍Protocol Buffer的网站\n- [IMB](https://www.ibm.com/developerworks/cn/linux/l-cn-gpb/)\n- [Google](https://developers.google.com/protocol-buffers/docs/encoding#optional)\n- [pb1](http://www.iloveandroid.net/2015/10/08/studyPtorobuf/)\n- [pb2](http://www.cnblogs.com/royenhome/archive/2010/10/29/1864860.html)","slug":"caffe_1_layer","published":1,"updated":"2024-08-13T16:03:47.848Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clzvf190s0002eqwoq82gsteh","content":"<h2 id=\"Caffe架构\"><a href=\"#Caffe架构\" class=\"headerlink\" title=\"Caffe架构\"></a>Caffe架构</h2><h3 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h3><p>Caffe将层的实现（输入层，卷积层，全连接层），整体网络的定义（AlexNet，LeNet），以及超参数的定义（步长，迭代次数）解耦。用c++实现各层，并使用protocol buffer来定义网络和传入参数</p>\n<h3 id=\"基础构件\"><a href=\"#基础构件\" class=\"headerlink\" title=\"基础构件\"></a>基础构件</h3><p>.cpp文件实现一个个层，作为基础构件供上层调用</p>\n<ul>\n<li><strong>CAFFE_ROOT/include/caffe/layers</strong>: .hpp为层的头文件</li>\n<li><strong>CAFFE_ROOT/src/caffe/layers</strong>: .cpp为层的实现文件</li>\n<li><strong>CAFFE_ROOT/src/caffe/proto</strong>: .proto为传参数用的protocol buffer文件</li>\n</ul>\n<h3 id=\"自定义网络\"><a href=\"#自定义网络\" class=\"headerlink\" title=\"自定义网络\"></a>自定义网络</h3><ul>\n<li><strong>MODEL_ROOT/train_val.prototxt</strong>: 用作定义整体网络</li>\n<li><strong>MODEL_ROOT/solver.prototxt</strong>: 为网络传递超参数</li>\n<li><strong>MODEL_ROOT/train.sh</strong>: 开始训练的脚本</li>\n<li><strong>MODEL_ROOT/test.sh</strong>: 开始测试的脚本</li>\n</ul>\n<h2 id=\"自定义数据读取层\"><a href=\"#自定义数据读取层\" class=\"headerlink\" title=\"自定义数据读取层\"></a>自定义数据读取层</h2><h3 id=\"数据描述\"><a href=\"#数据描述\" class=\"headerlink\" title=\"数据描述\"></a>数据描述</h3><p><a href=\"http://mmcheng.net/msra10k/\" target=\"_blank\" rel=\"external\">MSRA 10K Salient Object Database</a>。含有1w个数据，.jpg结尾的是原图，.png结尾的是标注了的图。用9k张作为训练集，用1k张作为测试集</p>\n<h3 id=\"image-data-layer总览\"><a href=\"#image-data-layer总览\" class=\"headerlink\" title=\"image_data_layer总览\"></a>image_data_layer总览</h3><p>image_data_layer实现了三个函数和调用了两个宏</p>\n<ul>\n<li><strong>DataLayerSetUp</strong>: 把容器的规格设置好（设好N, K, H, W)</li>\n<li><strong>ShuffleImages</strong>: 打乱顺序</li>\n<li><strong>load_batch</strong>: 真正把图片读入内存</li>\n<li><strong>INSTANTIATE_CLASS</strong>和<strong>REGISTER_LAYER_CLASS</strong>: 注册创建的层</li>\n</ul>\n<h3 id=\"DataLayerSetUp\"><a href=\"#DataLayerSetUp\" class=\"headerlink\" title=\"DataLayerSetUp\"></a>DataLayerSetUp</h3><ul>\n<li><p><strong>读取图片规格</strong>: 从protocol buffer中读取目标图片的k,h,w（有可能原图800*600，但想要256*256，这时就需要压缩）</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> new_height = <span class=\"keyword\">this</span>-&gt;layer_param_.image_data_param().new_height();</div><div class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> new_width  = <span class=\"keyword\">this</span>-&gt;layer_param_.image_data_param().new_width();</div><div class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">bool</span> is_color  = <span class=\"keyword\">this</span>-&gt;layer_param_.image_data_param().is_color();</div><div class=\"line\"><span class=\"built_in\">string</span> root_folder = <span class=\"keyword\">this</span>-&gt;layer_param_.image_data_param().root_folder();</div></pre></td></tr></table></figure>\n</li>\n<li><p><strong>读取图片列表</strong>: 从一个txt文件中读取图片名及其对应label，写进lines_</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">while</span> (<span class=\"built_in\">std</span>::getline(infile, line)) &#123;</div><div class=\"line\">  pos = line.find_last_of(<span class=\"string\">' '</span>);</div><div class=\"line\">  label = atoi(line.substr(pos + <span class=\"number\">1</span>).c_str());</div><div class=\"line\">  lines_.push_back(<span class=\"built_in\">std</span>::make_pair(line.substr(<span class=\"number\">0</span>, pos), label));</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n</li>\n<li><p><strong>shuffle &amp; skip</strong></p>\n</li>\n<li><strong>设置容器规格</strong>: 读一张图进来，并用它的规格来设置容器的规格<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">// Read an image, and use it to initialize the top blob.</span></div><div class=\"line\">cv::Mat cv_img = ReadImageToCVMat(root_folder + lines_[lines_id_].first,</div><div class=\"line\">                                  new_height, new_width, is_color);</div><div class=\"line\">CHECK(cv_img.data) &lt;&lt; <span class=\"string\">\"Could not load \"</span> &lt;&lt; lines_[lines_id_].first;</div><div class=\"line\"><span class=\"comment\">// Use data_transformer to infer the expected blob shape from a cv_image.</span></div><div class=\"line\"><span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; top_shape = <span class=\"keyword\">this</span>-&gt;data_transformer_-&gt;InferBlobShape(cv_img);</div><div class=\"line\"><span class=\"keyword\">this</span>-&gt;transformed_data_.Reshape(top_shape);</div><div class=\"line\"><span class=\"comment\">// Reshape prefetch_data and top[0] according to the batch_size.</span></div><div class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> batch_size = <span class=\"keyword\">this</span>-&gt;layer_param_.image_data_param().batch_size();</div><div class=\"line\">CHECK_GT(batch_size, <span class=\"number\">0</span>) &lt;&lt; <span class=\"string\">\"Positive batch size required\"</span>;</div><div class=\"line\">top_shape[<span class=\"number\">0</span>] = batch_size;</div><div class=\"line\"><span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"keyword\">this</span>-&gt;PREFETCH_COUNT; ++i) &#123;</div><div class=\"line\">  <span class=\"keyword\">this</span>-&gt;prefetch_[i].data_.Reshape(top_shape);</div><div class=\"line\">&#125;</div><div class=\"line\">top[<span class=\"number\">0</span>]-&gt;Reshape(top_shape);</div></pre></td></tr></table></figure>\n</li>\n</ul>\n<h3 id=\"load-batch\"><a href=\"#load-batch\" class=\"headerlink\" title=\"load_batch\"></a>load_batch</h3><ul>\n<li><strong>读取图片规格</strong></li>\n<li><strong>设置容器规格</strong></li>\n<li><strong>读入图片</strong>: prefetch_data为起始地址，offset根据容器的规格来求，然后在prefetch_data+offset的位置设置一个容器transformed_data_，并将图片写到容器里面<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">cv::Mat cv_img = ReadImageToCVMat(root_folder + lines_[lines_id_].first,</div><div class=\"line\">    new_height, new_width, is_color);</div><div class=\"line\">CHECK(cv_img.data) &lt;&lt; <span class=\"string\">\"Could not load \"</span> &lt;&lt; lines_[lines_id_].first;</div><div class=\"line\">read_time += timer.MicroSeconds();</div><div class=\"line\">timer.Start();</div><div class=\"line\"><span class=\"comment\">// Apply transformations (mirror, crop...) to the image</span></div><div class=\"line\"><span class=\"keyword\">int</span> offset = batch-&gt;data_.offset(item_id);</div><div class=\"line\"><span class=\"keyword\">this</span>-&gt;transformed_data_.set_cpu_data(prefetch_data + offset);</div><div class=\"line\"><span class=\"keyword\">this</span>-&gt;data_transformer_-&gt;Transform(cv_img, &amp;(<span class=\"keyword\">this</span>-&gt;transformed_data_));</div><div class=\"line\">trans_time += timer.MicroSeconds();</div></pre></td></tr></table></figure>\n</li>\n</ul>\n<h3 id=\"自定义image-data-layer-disc\"><a href=\"#自定义image-data-layer-disc\" class=\"headerlink\" title=\"自定义image_data_layer_disc\"></a>自定义image_data_layer_disc</h3><p>复现的模型为<a href=\"http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7372470&amp;tag=1\" target=\"_blank\" rel=\"external\">DISC</a>，label不是一个简单的int，而是一张图片，所以要对数据输入层进行修改，来产生一个图片label</p>\n<ul>\n<li><strong>image_data_layer_disc.hpp</strong>: 修改lines_的定义，改成两个string的pair</li>\n<li><strong>image_data_layer_disc.cpp</strong>: 参考读入data的方式处理label</li>\n<li><strong>caffe.proto</strong>: 添加一个disc_image_data_para来添加关于label的参数</li>\n</ul>\n<h2 id=\"训练和测试\"><a href=\"#训练和测试\" class=\"headerlink\" title=\"训练和测试\"></a>训练和测试</h2><ul>\n<li><strong>train_val.prototxt</strong>: 赋值models里面的AlexNet，将data层改成我们的image_data_layer_disc，将loss层改成欧式距离，删除accuracy层</li>\n<li><strong>solver.prototxt</strong>: 网络指定为train_val.prototxt，学习率指定为1e-9</li>\n<li><p><strong>train.sh</strong>: </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">#!/usr/bin/env sh</div><div class=\"line\"></div><div class=\"line\">./build/tools/caffe train --solver=models/disc/solver.prototxt</div></pre></td></tr></table></figure>\n</li>\n<li><p><strong>test.sh</strong>:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">#!/usr/bin/env sh</div><div class=\"line\"></div><div class=\"line\">./build/tools/caffe.bin test -model=models/disc/train_val.prototxt -weights=models/disc/caffe_alexnet_train_iter_370000.caffemodel -gpu=1</div></pre></td></tr></table></figure>\n</li>\n</ul>\n<h2 id=\"Protocol-Buffer\"><a href=\"#Protocol-Buffer\" class=\"headerlink\" title=\"Protocol Buffer\"></a>Protocol Buffer</h2><p>给出一些介绍Protocol Buffer的网站</p>\n<ul>\n<li><a href=\"https://www.ibm.com/developerworks/cn/linux/l-cn-gpb/\" target=\"_blank\" rel=\"external\">IMB</a></li>\n<li><a href=\"https://developers.google.com/protocol-buffers/docs/encoding#optional\" target=\"_blank\" rel=\"external\">Google</a></li>\n<li><a href=\"http://www.iloveandroid.net/2015/10/08/studyPtorobuf/\" target=\"_blank\" rel=\"external\">pb1</a></li>\n<li><a href=\"http://www.cnblogs.com/royenhome/archive/2010/10/29/1864860.html\" target=\"_blank\" rel=\"external\">pb2</a></li>\n</ul>\n","excerpt":"","more":"<h2 id=\"Caffe架构\"><a href=\"#Caffe架构\" class=\"headerlink\" title=\"Caffe架构\"></a>Caffe架构</h2><h3 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h3><p>Caffe将层的实现（输入层，卷积层，全连接层），整体网络的定义（AlexNet，LeNet），以及超参数的定义（步长，迭代次数）解耦。用c++实现各层，并使用protocol buffer来定义网络和传入参数</p>\n<h3 id=\"基础构件\"><a href=\"#基础构件\" class=\"headerlink\" title=\"基础构件\"></a>基础构件</h3><p>.cpp文件实现一个个层，作为基础构件供上层调用</p>\n<ul>\n<li><strong>CAFFE_ROOT/include/caffe/layers</strong>: .hpp为层的头文件</li>\n<li><strong>CAFFE_ROOT/src/caffe/layers</strong>: .cpp为层的实现文件</li>\n<li><strong>CAFFE_ROOT/src/caffe/proto</strong>: .proto为传参数用的protocol buffer文件</li>\n</ul>\n<h3 id=\"自定义网络\"><a href=\"#自定义网络\" class=\"headerlink\" title=\"自定义网络\"></a>自定义网络</h3><ul>\n<li><strong>MODEL_ROOT/train_val.prototxt</strong>: 用作定义整体网络</li>\n<li><strong>MODEL_ROOT/solver.prototxt</strong>: 为网络传递超参数</li>\n<li><strong>MODEL_ROOT/train.sh</strong>: 开始训练的脚本</li>\n<li><strong>MODEL_ROOT/test.sh</strong>: 开始测试的脚本</li>\n</ul>\n<h2 id=\"自定义数据读取层\"><a href=\"#自定义数据读取层\" class=\"headerlink\" title=\"自定义数据读取层\"></a>自定义数据读取层</h2><h3 id=\"数据描述\"><a href=\"#数据描述\" class=\"headerlink\" title=\"数据描述\"></a>数据描述</h3><p><a href=\"http://mmcheng.net/msra10k/\">MSRA 10K Salient Object Database</a>。含有1w个数据，.jpg结尾的是原图，.png结尾的是标注了的图。用9k张作为训练集，用1k张作为测试集</p>\n<h3 id=\"image-data-layer总览\"><a href=\"#image-data-layer总览\" class=\"headerlink\" title=\"image_data_layer总览\"></a>image_data_layer总览</h3><p>image_data_layer实现了三个函数和调用了两个宏</p>\n<ul>\n<li><strong>DataLayerSetUp</strong>: 把容器的规格设置好（设好N, K, H, W)</li>\n<li><strong>ShuffleImages</strong>: 打乱顺序</li>\n<li><strong>load_batch</strong>: 真正把图片读入内存</li>\n<li><strong>INSTANTIATE_CLASS</strong>和<strong>REGISTER_LAYER_CLASS</strong>: 注册创建的层</li>\n</ul>\n<h3 id=\"DataLayerSetUp\"><a href=\"#DataLayerSetUp\" class=\"headerlink\" title=\"DataLayerSetUp\"></a>DataLayerSetUp</h3><ul>\n<li><p><strong>读取图片规格</strong>: 从protocol buffer中读取目标图片的k,h,w（有可能原图800*600，但想要256*256，这时就需要压缩）</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> new_height = <span class=\"keyword\">this</span>-&gt;layer_param_.image_data_param().new_height();</div><div class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> new_width  = <span class=\"keyword\">this</span>-&gt;layer_param_.image_data_param().new_width();</div><div class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">bool</span> is_color  = <span class=\"keyword\">this</span>-&gt;layer_param_.image_data_param().is_color();</div><div class=\"line\"><span class=\"built_in\">string</span> root_folder = <span class=\"keyword\">this</span>-&gt;layer_param_.image_data_param().root_folder();</div></pre></td></tr></table></figure>\n</li>\n<li><p><strong>读取图片列表</strong>: 从一个txt文件中读取图片名及其对应label，写进lines_</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">while</span> (<span class=\"built_in\">std</span>::getline(infile, line)) &#123;</div><div class=\"line\">  pos = line.find_last_of(<span class=\"string\">' '</span>);</div><div class=\"line\">  label = atoi(line.substr(pos + <span class=\"number\">1</span>).c_str());</div><div class=\"line\">  lines_.push_back(<span class=\"built_in\">std</span>::make_pair(line.substr(<span class=\"number\">0</span>, pos), label));</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n</li>\n<li><p><strong>shuffle &amp; skip</strong></p>\n</li>\n<li><strong>设置容器规格</strong>: 读一张图进来，并用它的规格来设置容器的规格<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">// Read an image, and use it to initialize the top blob.</span></div><div class=\"line\">cv::Mat cv_img = ReadImageToCVMat(root_folder + lines_[lines_id_].first,</div><div class=\"line\">                                  new_height, new_width, is_color);</div><div class=\"line\">CHECK(cv_img.data) &lt;&lt; <span class=\"string\">\"Could not load \"</span> &lt;&lt; lines_[lines_id_].first;</div><div class=\"line\"><span class=\"comment\">// Use data_transformer to infer the expected blob shape from a cv_image.</span></div><div class=\"line\"><span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; top_shape = <span class=\"keyword\">this</span>-&gt;data_transformer_-&gt;InferBlobShape(cv_img);</div><div class=\"line\"><span class=\"keyword\">this</span>-&gt;transformed_data_.Reshape(top_shape);</div><div class=\"line\"><span class=\"comment\">// Reshape prefetch_data and top[0] according to the batch_size.</span></div><div class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> batch_size = <span class=\"keyword\">this</span>-&gt;layer_param_.image_data_param().batch_size();</div><div class=\"line\">CHECK_GT(batch_size, <span class=\"number\">0</span>) &lt;&lt; <span class=\"string\">\"Positive batch size required\"</span>;</div><div class=\"line\">top_shape[<span class=\"number\">0</span>] = batch_size;</div><div class=\"line\"><span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"keyword\">this</span>-&gt;PREFETCH_COUNT; ++i) &#123;</div><div class=\"line\">  <span class=\"keyword\">this</span>-&gt;prefetch_[i].data_.Reshape(top_shape);</div><div class=\"line\">&#125;</div><div class=\"line\">top[<span class=\"number\">0</span>]-&gt;Reshape(top_shape);</div></pre></td></tr></table></figure>\n</li>\n</ul>\n<h3 id=\"load-batch\"><a href=\"#load-batch\" class=\"headerlink\" title=\"load_batch\"></a>load_batch</h3><ul>\n<li><strong>读取图片规格</strong></li>\n<li><strong>设置容器规格</strong></li>\n<li><strong>读入图片</strong>: prefetch_data为起始地址，offset根据容器的规格来求，然后在prefetch_data+offset的位置设置一个容器transformed_data_，并将图片写到容器里面<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">cv::Mat cv_img = ReadImageToCVMat(root_folder + lines_[lines_id_].first,</div><div class=\"line\">    new_height, new_width, is_color);</div><div class=\"line\">CHECK(cv_img.data) &lt;&lt; <span class=\"string\">\"Could not load \"</span> &lt;&lt; lines_[lines_id_].first;</div><div class=\"line\">read_time += timer.MicroSeconds();</div><div class=\"line\">timer.Start();</div><div class=\"line\"><span class=\"comment\">// Apply transformations (mirror, crop...) to the image</span></div><div class=\"line\"><span class=\"keyword\">int</span> offset = batch-&gt;data_.offset(item_id);</div><div class=\"line\"><span class=\"keyword\">this</span>-&gt;transformed_data_.set_cpu_data(prefetch_data + offset);</div><div class=\"line\"><span class=\"keyword\">this</span>-&gt;data_transformer_-&gt;Transform(cv_img, &amp;(<span class=\"keyword\">this</span>-&gt;transformed_data_));</div><div class=\"line\">trans_time += timer.MicroSeconds();</div></pre></td></tr></table></figure>\n</li>\n</ul>\n<h3 id=\"自定义image-data-layer-disc\"><a href=\"#自定义image-data-layer-disc\" class=\"headerlink\" title=\"自定义image_data_layer_disc\"></a>自定义image_data_layer_disc</h3><p>复现的模型为<a href=\"http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7372470&amp;tag=1\">DISC</a>，label不是一个简单的int，而是一张图片，所以要对数据输入层进行修改，来产生一个图片label</p>\n<ul>\n<li><strong>image_data_layer_disc.hpp</strong>: 修改lines_的定义，改成两个string的pair</li>\n<li><strong>image_data_layer_disc.cpp</strong>: 参考读入data的方式处理label</li>\n<li><strong>caffe.proto</strong>: 添加一个disc_image_data_para来添加关于label的参数</li>\n</ul>\n<h2 id=\"训练和测试\"><a href=\"#训练和测试\" class=\"headerlink\" title=\"训练和测试\"></a>训练和测试</h2><ul>\n<li><strong>train_val.prototxt</strong>: 赋值models里面的AlexNet，将data层改成我们的image_data_layer_disc，将loss层改成欧式距离，删除accuracy层</li>\n<li><strong>solver.prototxt</strong>: 网络指定为train_val.prototxt，学习率指定为1e-9</li>\n<li><p><strong>train.sh</strong>: </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">#!/usr/bin/env sh</div><div class=\"line\"></div><div class=\"line\">./build/tools/caffe train --solver=models/disc/solver.prototxt</div></pre></td></tr></table></figure>\n</li>\n<li><p><strong>test.sh</strong>:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">#!/usr/bin/env sh</div><div class=\"line\"></div><div class=\"line\">./build/tools/caffe.bin test -model=models/disc/train_val.prototxt -weights=models/disc/caffe_alexnet_train_iter_370000.caffemodel -gpu=1</div></pre></td></tr></table></figure>\n</li>\n</ul>\n<h2 id=\"Protocol-Buffer\"><a href=\"#Protocol-Buffer\" class=\"headerlink\" title=\"Protocol Buffer\"></a>Protocol Buffer</h2><p>给出一些介绍Protocol Buffer的网站</p>\n<ul>\n<li><a href=\"https://www.ibm.com/developerworks/cn/linux/l-cn-gpb/\">IMB</a></li>\n<li><a href=\"https://developers.google.com/protocol-buffers/docs/encoding#optional\">Google</a></li>\n<li><a href=\"http://www.iloveandroid.net/2015/10/08/studyPtorobuf/\">pb1</a></li>\n<li><a href=\"http://www.cnblogs.com/royenhome/archive/2010/10/29/1864860.html\">pb2</a></li>\n</ul>\n"},{"title":"Caffe学习：RNN源码阅读","date":"2016-07-13T07:20:42.000Z","description":["Caffe中的RNN源码阅读"],"_content":"\n## 简介\nRNN(Recurrent Neural Network)是一种能考虑上下文信息的神经网络，在求解的时候不止考虑当前的输入是什么，还考虑上一次的输出是什么，有种马尔可夫链的感觉，比较适用于包含上下文语义的任务。这里选了标准RNN源码入手，学习RNN的实现。\n\n## 源码框架\n\n### 目录结构\n- **sequence_layers.hpp:**  抽象类RecurrentLayer，子类RNN和LSTM的头文件\n- **recurrent_layer.cpp:** 抽象类RecurrentLayer的定义文件\n- **rnn_layer.cpp:** 子类RNN的定义文件\n\n### 逻辑结构\n- 使用了**模板方法设计模式**\n- **RecurrentLayer:** 定义了网络的通用框架，包括输入，输出，循环部分的入口输入\n- **RNNLayer:** 定义了循环部分的网络结构\n- **bottom:**\n\t* bottom[0]: T，帧数\n\t* bottom[1]: N，视频数\n\t* ...: 真正的data\n- **top:** 同bottom\n\n## sequence_layers.hpp\n\n### 成员变量\n- **shared\\_ptr< Net< Dtype> \\> unrolled\\_net\\_:** 最终生成的网络\n- **int N\\_:** 视频流的数量\n- **int T\\_:** 视频帧数\n- **bool static\\_input\\_:** 输入是否静态\n- **vector< Blob< Dtype\\>* \\> recur\\_input\\_blobs\\_:** 子类循环部分的入口输入($h_0$)\n- **vector< Blob< Dtype\\>* \\> recur\\_output\\_blobs\\_:** 子类循环部分的出口输出($h_T$)\n- **vector< Blob< Dtype\\>* \\> output\\_blobs\\_:** 总输出(top)\n- **Blob< Dtype\\>* x\\_input\\_blob\\_:** 总视频输入(bottom[0])\n- **Blob< Dtype\\>* x\\_static\\_input\\_blob\\_:** 总静态输入(bottom[2])\n- **Blob< Dtype\\>* cont\\_input\\_blob\\_:** 总标识输入(bottom[1])。cont为0表示应该新开一个序列，不用再参照上一次的输出结果\n\n### 成员函数\n- **FillUnrolledNet(NetParameter* net\\_param):** \t\n\t* 子类根据自己的内部网络修改net\\_param\n\t* 原理同我们在外面写prototxt生成网络\n\t* 类比安卓开发中动态生成按钮选项，都是因为数量经常变化，写死在xml文件中不便于改动\n- **xxxBlobNames:** \n\t* 返回与主控部分交互的blob名字，主控部分根据名字找到对应的blob\n\t* 类比安卓开发中findViewByID将控件和变量绑定\n\n## recurrent_layer.cpp\n\n### Reshape\n适配blob，以及绑定blob，使得操作变量等价于修改bottom与top\n\n1. **Reshape:** 将x\\_input\\_blob\\_, cont\\_input\\_blob\\_和x\\_static\\_input\\_blob\\_几个输入blob的shape适配bottom\n2. **Reshape:** 将recur\\_input\\_blobs\\_适配子类的入口输出blob(即$h_0$)\n3. **Share:** 将x\\_input\\_blob\\_, cont\\_input\\_blob\\_和x\\_static\\_input\\_blob\\_与bottom的data及diff进行绑定\n4. **Share:** 将output\\_blobs\\_与top的data及diff进行绑定\n\n### LayerSetUp\n等价于将prototxt转为代码，核心为：初始化net\\_param来生成一个Net\n\n1. **检查bottom是否规范**\n\t- bottom[0]: 各帧，各视频的数据 (T \\* N \\* ...)\n\t- bottom[1]: 各帧，各视频的标识，0为开始，1为继续 (T \\* N \\* 1)\n\t- bottom[2]: 静态输入\n2. **为网络接入总输入，并为各输入命名**\n\t- x: bottom[0]\n\t- cont: bottom[1]\n\t- x_static: bottom[2]\n3. **进一步构建网络**，调用FillUnrolledNet修改net\\_param\n4. **用net\\_param生成最终的网络**\n```cpp\n  unrolled_net_.reset(new Net<Dtype>(net_param));\n```\n5. **将变量与网络对应部分绑定**\n\t- 在上一步中网络已经生成完毕，但为了操作方便，将要用到的网络部分跟变量绑定，以后直接用变量进行操作\n\t- 绑定的时候使用net->blob\\_by\\_name(\"xxx\")，类似findViewById。找blob的key是名字，这就是为什么要有xxxBlobNames这样的函数\n6. **设置辅助参数**\n\t- blobs\\_: 这个参数应该要记录本层所有的blob，但由于我们的网络定义不仅是prototxt，还有中途动态生成的部分，所以不能依赖caffe帮我们自动生成的blobs\\_，要手动将所有参数添加\n\t- param\\_propagate\\_down\\_: 记录是否要bp\n\t- recur\\_output\\_blobs\\_全部置0**（不懂）**\n\n## rnn_layer.cpp\n\n### 跟主控交接部分\n\n- **循环输入入口:** $h_0$，1 \\* N \\* num\\_output（循环输入跟循环输出shape一致，所以这里既说明了输入由说明了输出，即对于每一帧，生成num\\_output维的向量）\n- **循环输出出口:** $h_t$\n- **总输出:** o\n\n### FillUnrolledNet\n\n核心部分，实现网络的定义。实际效果近似于这样的prototxt\n\n``` \n################################\n#            input             #\n################################\nlayer{\n\t#sliced x\n\tbottom: x\n\ttop: x_1\n\ttop: x_2\n\t.\n\t.\n\t.\n\ttop: x_t\n}\nlayer{\n\t#sliced cont\n\tbottom: cont\n\ttop: cont_1\n\ttop: cont_2\n\t.\n\t.\n\t.\n\ttop: cont_t\n}\n################################\n#          recur layer         #\n################################\nlayer{\n\t#recur_unit_1\n\tbottom: x_1, cont_1, h_0\n\ttop: o_1, h_1\n}\nlayer{\n\t#recur_unit_2\n\tbottom: x_2, cont_2, h_1\n\ttop: o_2, h_2\n}\n\t\t.\n\t\t.\n\t\t.\n\nlayer{\n\t#recur_unit_t\n\tbottom: x_t, cont_t, h_t-1\n\ttop: o_t, h_t\n}\n################################\n#           output             #\n################################\nlayer{\n\t#concated output\n\tbottom: o_1\n\tbottom: o_2\n\t.\n\t.\n\t.\n\tbottom: o_t\n\ttop: o\n}\n```\n\n## 收获\n\n- 阅读源码前前思考代码的**输入**是什么，**输出**是什么，给你这样的任务**你会怎么做**\n- 然后在阅读的时候合理地进行**假设**，一步步验证并修改\n- 先看**数据结构**再看算法，**粒度**从粗到细（类级，函数级，块级，行级）\n\n\n## Reference\n- 论文地址：[s2vt](https://github.com/vsubhashini/caffe/tree/recurrent/examples/s2vt)\n- 项目地址：[Sequence to Sequence -- Video to Text](https://arxiv.org/abs/1505.00487)\n- 参考资料：[LSTM](http://colah.github.io/posts/2015-08-Understanding-LSTMs/), [Sequences in Caffe](http://tutorial.caffe.berkeleyvision.org/caffe-cvpr15-sequences.pdf)\n","source":"_posts/caffe_2_rnn.md","raw":"---\ntitle: Caffe学习：RNN源码阅读\ndate: 2016-07-13 15:20:42\ntags: \n  - rnn\ndescription:\n  - Caffe中的RNN源码阅读\ncategories:\n  - caffe\n---\n\n## 简介\nRNN(Recurrent Neural Network)是一种能考虑上下文信息的神经网络，在求解的时候不止考虑当前的输入是什么，还考虑上一次的输出是什么，有种马尔可夫链的感觉，比较适用于包含上下文语义的任务。这里选了标准RNN源码入手，学习RNN的实现。\n\n## 源码框架\n\n### 目录结构\n- **sequence_layers.hpp:**  抽象类RecurrentLayer，子类RNN和LSTM的头文件\n- **recurrent_layer.cpp:** 抽象类RecurrentLayer的定义文件\n- **rnn_layer.cpp:** 子类RNN的定义文件\n\n### 逻辑结构\n- 使用了**模板方法设计模式**\n- **RecurrentLayer:** 定义了网络的通用框架，包括输入，输出，循环部分的入口输入\n- **RNNLayer:** 定义了循环部分的网络结构\n- **bottom:**\n\t* bottom[0]: T，帧数\n\t* bottom[1]: N，视频数\n\t* ...: 真正的data\n- **top:** 同bottom\n\n## sequence_layers.hpp\n\n### 成员变量\n- **shared\\_ptr< Net< Dtype> \\> unrolled\\_net\\_:** 最终生成的网络\n- **int N\\_:** 视频流的数量\n- **int T\\_:** 视频帧数\n- **bool static\\_input\\_:** 输入是否静态\n- **vector< Blob< Dtype\\>* \\> recur\\_input\\_blobs\\_:** 子类循环部分的入口输入($h_0$)\n- **vector< Blob< Dtype\\>* \\> recur\\_output\\_blobs\\_:** 子类循环部分的出口输出($h_T$)\n- **vector< Blob< Dtype\\>* \\> output\\_blobs\\_:** 总输出(top)\n- **Blob< Dtype\\>* x\\_input\\_blob\\_:** 总视频输入(bottom[0])\n- **Blob< Dtype\\>* x\\_static\\_input\\_blob\\_:** 总静态输入(bottom[2])\n- **Blob< Dtype\\>* cont\\_input\\_blob\\_:** 总标识输入(bottom[1])。cont为0表示应该新开一个序列，不用再参照上一次的输出结果\n\n### 成员函数\n- **FillUnrolledNet(NetParameter* net\\_param):** \t\n\t* 子类根据自己的内部网络修改net\\_param\n\t* 原理同我们在外面写prototxt生成网络\n\t* 类比安卓开发中动态生成按钮选项，都是因为数量经常变化，写死在xml文件中不便于改动\n- **xxxBlobNames:** \n\t* 返回与主控部分交互的blob名字，主控部分根据名字找到对应的blob\n\t* 类比安卓开发中findViewByID将控件和变量绑定\n\n## recurrent_layer.cpp\n\n### Reshape\n适配blob，以及绑定blob，使得操作变量等价于修改bottom与top\n\n1. **Reshape:** 将x\\_input\\_blob\\_, cont\\_input\\_blob\\_和x\\_static\\_input\\_blob\\_几个输入blob的shape适配bottom\n2. **Reshape:** 将recur\\_input\\_blobs\\_适配子类的入口输出blob(即$h_0$)\n3. **Share:** 将x\\_input\\_blob\\_, cont\\_input\\_blob\\_和x\\_static\\_input\\_blob\\_与bottom的data及diff进行绑定\n4. **Share:** 将output\\_blobs\\_与top的data及diff进行绑定\n\n### LayerSetUp\n等价于将prototxt转为代码，核心为：初始化net\\_param来生成一个Net\n\n1. **检查bottom是否规范**\n\t- bottom[0]: 各帧，各视频的数据 (T \\* N \\* ...)\n\t- bottom[1]: 各帧，各视频的标识，0为开始，1为继续 (T \\* N \\* 1)\n\t- bottom[2]: 静态输入\n2. **为网络接入总输入，并为各输入命名**\n\t- x: bottom[0]\n\t- cont: bottom[1]\n\t- x_static: bottom[2]\n3. **进一步构建网络**，调用FillUnrolledNet修改net\\_param\n4. **用net\\_param生成最终的网络**\n```cpp\n  unrolled_net_.reset(new Net<Dtype>(net_param));\n```\n5. **将变量与网络对应部分绑定**\n\t- 在上一步中网络已经生成完毕，但为了操作方便，将要用到的网络部分跟变量绑定，以后直接用变量进行操作\n\t- 绑定的时候使用net->blob\\_by\\_name(\"xxx\")，类似findViewById。找blob的key是名字，这就是为什么要有xxxBlobNames这样的函数\n6. **设置辅助参数**\n\t- blobs\\_: 这个参数应该要记录本层所有的blob，但由于我们的网络定义不仅是prototxt，还有中途动态生成的部分，所以不能依赖caffe帮我们自动生成的blobs\\_，要手动将所有参数添加\n\t- param\\_propagate\\_down\\_: 记录是否要bp\n\t- recur\\_output\\_blobs\\_全部置0**（不懂）**\n\n## rnn_layer.cpp\n\n### 跟主控交接部分\n\n- **循环输入入口:** $h_0$，1 \\* N \\* num\\_output（循环输入跟循环输出shape一致，所以这里既说明了输入由说明了输出，即对于每一帧，生成num\\_output维的向量）\n- **循环输出出口:** $h_t$\n- **总输出:** o\n\n### FillUnrolledNet\n\n核心部分，实现网络的定义。实际效果近似于这样的prototxt\n\n``` \n################################\n#            input             #\n################################\nlayer{\n\t#sliced x\n\tbottom: x\n\ttop: x_1\n\ttop: x_2\n\t.\n\t.\n\t.\n\ttop: x_t\n}\nlayer{\n\t#sliced cont\n\tbottom: cont\n\ttop: cont_1\n\ttop: cont_2\n\t.\n\t.\n\t.\n\ttop: cont_t\n}\n################################\n#          recur layer         #\n################################\nlayer{\n\t#recur_unit_1\n\tbottom: x_1, cont_1, h_0\n\ttop: o_1, h_1\n}\nlayer{\n\t#recur_unit_2\n\tbottom: x_2, cont_2, h_1\n\ttop: o_2, h_2\n}\n\t\t.\n\t\t.\n\t\t.\n\nlayer{\n\t#recur_unit_t\n\tbottom: x_t, cont_t, h_t-1\n\ttop: o_t, h_t\n}\n################################\n#           output             #\n################################\nlayer{\n\t#concated output\n\tbottom: o_1\n\tbottom: o_2\n\t.\n\t.\n\t.\n\tbottom: o_t\n\ttop: o\n}\n```\n\n## 收获\n\n- 阅读源码前前思考代码的**输入**是什么，**输出**是什么，给你这样的任务**你会怎么做**\n- 然后在阅读的时候合理地进行**假设**，一步步验证并修改\n- 先看**数据结构**再看算法，**粒度**从粗到细（类级，函数级，块级，行级）\n\n\n## Reference\n- 论文地址：[s2vt](https://github.com/vsubhashini/caffe/tree/recurrent/examples/s2vt)\n- 项目地址：[Sequence to Sequence -- Video to Text](https://arxiv.org/abs/1505.00487)\n- 参考资料：[LSTM](http://colah.github.io/posts/2015-08-Understanding-LSTMs/), [Sequences in Caffe](http://tutorial.caffe.berkeleyvision.org/caffe-cvpr15-sequences.pdf)\n","slug":"caffe_2_rnn","published":1,"updated":"2024-08-13T16:03:47.848Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clzvf190z0005eqwoib78amfq","content":"<h2 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h2><p>RNN(Recurrent Neural Network)是一种能考虑上下文信息的神经网络，在求解的时候不止考虑当前的输入是什么，还考虑上一次的输出是什么，有种马尔可夫链的感觉，比较适用于包含上下文语义的任务。这里选了标准RNN源码入手，学习RNN的实现。</p>\n<h2 id=\"源码框架\"><a href=\"#源码框架\" class=\"headerlink\" title=\"源码框架\"></a>源码框架</h2><h3 id=\"目录结构\"><a href=\"#目录结构\" class=\"headerlink\" title=\"目录结构\"></a>目录结构</h3><ul>\n<li><strong>sequence_layers.hpp:</strong>  抽象类RecurrentLayer，子类RNN和LSTM的头文件</li>\n<li><strong>recurrent_layer.cpp:</strong> 抽象类RecurrentLayer的定义文件</li>\n<li><strong>rnn_layer.cpp:</strong> 子类RNN的定义文件</li>\n</ul>\n<h3 id=\"逻辑结构\"><a href=\"#逻辑结构\" class=\"headerlink\" title=\"逻辑结构\"></a>逻辑结构</h3><ul>\n<li>使用了<strong>模板方法设计模式</strong></li>\n<li><strong>RecurrentLayer:</strong> 定义了网络的通用框架，包括输入，输出，循环部分的入口输入</li>\n<li><strong>RNNLayer:</strong> 定义了循环部分的网络结构</li>\n<li><strong>bottom:</strong><ul>\n<li>bottom[0]: T，帧数</li>\n<li>bottom[1]: N，视频数</li>\n<li>…: 真正的data</li>\n</ul>\n</li>\n<li><strong>top:</strong> 同bottom</li>\n</ul>\n<h2 id=\"sequence-layers-hpp\"><a href=\"#sequence-layers-hpp\" class=\"headerlink\" title=\"sequence_layers.hpp\"></a>sequence_layers.hpp</h2><h3 id=\"成员变量\"><a href=\"#成员变量\" class=\"headerlink\" title=\"成员变量\"></a>成员变量</h3><ul>\n<li><strong>shared_ptr&lt; Net&lt; Dtype&gt; > unrolled_net_:</strong> 最终生成的网络</li>\n<li><strong>int N_:</strong> 视频流的数量</li>\n<li><strong>int T_:</strong> 视频帧数</li>\n<li><strong>bool static_input_:</strong> 输入是否静态</li>\n<li><strong>vector&lt; Blob&lt; Dtype>* > recur_input_blobs_:</strong> 子类循环部分的入口输入($h_0$)</li>\n<li><strong>vector&lt; Blob&lt; Dtype>* > recur_output_blobs_:</strong> 子类循环部分的出口输出($h_T$)</li>\n<li><strong>vector&lt; Blob&lt; Dtype>* > output_blobs_:</strong> 总输出(top)</li>\n<li><strong>Blob&lt; Dtype>* x_input_blob_:</strong> 总视频输入(bottom[0])</li>\n<li><strong>Blob&lt; Dtype>* x_static_input_blob_:</strong> 总静态输入(bottom[2])</li>\n<li><strong>Blob&lt; Dtype>* cont_input_blob_:</strong> 总标识输入(bottom[1])。cont为0表示应该新开一个序列，不用再参照上一次的输出结果</li>\n</ul>\n<h3 id=\"成员函数\"><a href=\"#成员函数\" class=\"headerlink\" title=\"成员函数\"></a>成员函数</h3><ul>\n<li><strong>FillUnrolledNet(NetParameter* net_param):</strong>     <ul>\n<li>子类根据自己的内部网络修改net_param</li>\n<li>原理同我们在外面写prototxt生成网络</li>\n<li>类比安卓开发中动态生成按钮选项，都是因为数量经常变化，写死在xml文件中不便于改动</li>\n</ul>\n</li>\n<li><strong>xxxBlobNames:</strong> <ul>\n<li>返回与主控部分交互的blob名字，主控部分根据名字找到对应的blob</li>\n<li>类比安卓开发中findViewByID将控件和变量绑定</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"recurrent-layer-cpp\"><a href=\"#recurrent-layer-cpp\" class=\"headerlink\" title=\"recurrent_layer.cpp\"></a>recurrent_layer.cpp</h2><h3 id=\"Reshape\"><a href=\"#Reshape\" class=\"headerlink\" title=\"Reshape\"></a>Reshape</h3><p>适配blob，以及绑定blob，使得操作变量等价于修改bottom与top</p>\n<ol>\n<li><strong>Reshape:</strong> 将x_input_blob_, cont_input_blob_和x_static_input_blob_几个输入blob的shape适配bottom</li>\n<li><strong>Reshape:</strong> 将recur_input_blobs_适配子类的入口输出blob(即$h_0$)</li>\n<li><strong>Share:</strong> 将x_input_blob_, cont_input_blob_和x_static_input_blob_与bottom的data及diff进行绑定</li>\n<li><strong>Share:</strong> 将output_blobs_与top的data及diff进行绑定</li>\n</ol>\n<h3 id=\"LayerSetUp\"><a href=\"#LayerSetUp\" class=\"headerlink\" title=\"LayerSetUp\"></a>LayerSetUp</h3><p>等价于将prototxt转为代码，核心为：初始化net_param来生成一个Net</p>\n<ol>\n<li><strong>检查bottom是否规范</strong><ul>\n<li>bottom[0]: 各帧，各视频的数据 (T * N * …)</li>\n<li>bottom[1]: 各帧，各视频的标识，0为开始，1为继续 (T * N * 1)</li>\n<li>bottom[2]: 静态输入</li>\n</ul>\n</li>\n<li><strong>为网络接入总输入，并为各输入命名</strong><ul>\n<li>x: bottom[0]</li>\n<li>cont: bottom[1]</li>\n<li>x_static: bottom[2]</li>\n</ul>\n</li>\n<li><strong>进一步构建网络</strong>，调用FillUnrolledNet修改net_param</li>\n<li><p><strong>用net_param生成最终的网络</strong></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">unrolled_net_.reset(<span class=\"keyword\">new</span> Net&lt;Dtype&gt;(net_param));</div></pre></td></tr></table></figure>\n</li>\n<li><p><strong>将变量与网络对应部分绑定</strong></p>\n<ul>\n<li>在上一步中网络已经生成完毕，但为了操作方便，将要用到的网络部分跟变量绑定，以后直接用变量进行操作</li>\n<li>绑定的时候使用net-&gt;blob_by_name(“xxx”)，类似findViewById。找blob的key是名字，这就是为什么要有xxxBlobNames这样的函数</li>\n</ul>\n</li>\n<li><strong>设置辅助参数</strong><ul>\n<li>blobs_: 这个参数应该要记录本层所有的blob，但由于我们的网络定义不仅是prototxt，还有中途动态生成的部分，所以不能依赖caffe帮我们自动生成的blobs_，要手动将所有参数添加</li>\n<li>param_propagate_down_: 记录是否要bp</li>\n<li>recur_output_blobs_全部置0<strong>（不懂）</strong></li>\n</ul>\n</li>\n</ol>\n<h2 id=\"rnn-layer-cpp\"><a href=\"#rnn-layer-cpp\" class=\"headerlink\" title=\"rnn_layer.cpp\"></a>rnn_layer.cpp</h2><h3 id=\"跟主控交接部分\"><a href=\"#跟主控交接部分\" class=\"headerlink\" title=\"跟主控交接部分\"></a>跟主控交接部分</h3><ul>\n<li><strong>循环输入入口:</strong> $h_0$，1 * N * num_output（循环输入跟循环输出shape一致，所以这里既说明了输入由说明了输出，即对于每一帧，生成num_output维的向量）</li>\n<li><strong>循环输出出口:</strong> $h_t$</li>\n<li><strong>总输出:</strong> o</li>\n</ul>\n<h3 id=\"FillUnrolledNet\"><a href=\"#FillUnrolledNet\" class=\"headerlink\" title=\"FillUnrolledNet\"></a>FillUnrolledNet</h3><p>核心部分，实现网络的定义。实际效果近似于这样的prototxt</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div></pre></td><td class=\"code\"><pre><div class=\"line\">################################</div><div class=\"line\">#            input             #</div><div class=\"line\">################################</div><div class=\"line\">layer&#123;</div><div class=\"line\">\t#sliced x</div><div class=\"line\">\tbottom: x</div><div class=\"line\">\ttop: x_1</div><div class=\"line\">\ttop: x_2</div><div class=\"line\">\t.</div><div class=\"line\">\t.</div><div class=\"line\">\t.</div><div class=\"line\">\ttop: x_t</div><div class=\"line\">&#125;</div><div class=\"line\">layer&#123;</div><div class=\"line\">\t#sliced cont</div><div class=\"line\">\tbottom: cont</div><div class=\"line\">\ttop: cont_1</div><div class=\"line\">\ttop: cont_2</div><div class=\"line\">\t.</div><div class=\"line\">\t.</div><div class=\"line\">\t.</div><div class=\"line\">\ttop: cont_t</div><div class=\"line\">&#125;</div><div class=\"line\">################################</div><div class=\"line\">#          recur layer         #</div><div class=\"line\">################################</div><div class=\"line\">layer&#123;</div><div class=\"line\">\t#recur_unit_1</div><div class=\"line\">\tbottom: x_1, cont_1, h_0</div><div class=\"line\">\ttop: o_1, h_1</div><div class=\"line\">&#125;</div><div class=\"line\">layer&#123;</div><div class=\"line\">\t#recur_unit_2</div><div class=\"line\">\tbottom: x_2, cont_2, h_1</div><div class=\"line\">\ttop: o_2, h_2</div><div class=\"line\">&#125;</div><div class=\"line\">\t\t.</div><div class=\"line\">\t\t.</div><div class=\"line\">\t\t.</div><div class=\"line\"></div><div class=\"line\">layer&#123;</div><div class=\"line\">\t#recur_unit_t</div><div class=\"line\">\tbottom: x_t, cont_t, h_t-1</div><div class=\"line\">\ttop: o_t, h_t</div><div class=\"line\">&#125;</div><div class=\"line\">################################</div><div class=\"line\">#           output             #</div><div class=\"line\">################################</div><div class=\"line\">layer&#123;</div><div class=\"line\">\t#concated output</div><div class=\"line\">\tbottom: o_1</div><div class=\"line\">\tbottom: o_2</div><div class=\"line\">\t.</div><div class=\"line\">\t.</div><div class=\"line\">\t.</div><div class=\"line\">\tbottom: o_t</div><div class=\"line\">\ttop: o</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h2 id=\"收获\"><a href=\"#收获\" class=\"headerlink\" title=\"收获\"></a>收获</h2><ul>\n<li>阅读源码前前思考代码的<strong>输入</strong>是什么，<strong>输出</strong>是什么，给你这样的任务<strong>你会怎么做</strong></li>\n<li>然后在阅读的时候合理地进行<strong>假设</strong>，一步步验证并修改</li>\n<li>先看<strong>数据结构</strong>再看算法，<strong>粒度</strong>从粗到细（类级，函数级，块级，行级）</li>\n</ul>\n<h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><ul>\n<li>论文地址：<a href=\"https://github.com/vsubhashini/caffe/tree/recurrent/examples/s2vt\" target=\"_blank\" rel=\"external\">s2vt</a></li>\n<li>项目地址：<a href=\"https://arxiv.org/abs/1505.00487\" target=\"_blank\" rel=\"external\">Sequence to Sequence – Video to Text</a></li>\n<li>参考资料：<a href=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/\" target=\"_blank\" rel=\"external\">LSTM</a>, <a href=\"http://tutorial.caffe.berkeleyvision.org/caffe-cvpr15-sequences.pdf\" target=\"_blank\" rel=\"external\">Sequences in Caffe</a></li>\n</ul>\n","excerpt":"","more":"<h2 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h2><p>RNN(Recurrent Neural Network)是一种能考虑上下文信息的神经网络，在求解的时候不止考虑当前的输入是什么，还考虑上一次的输出是什么，有种马尔可夫链的感觉，比较适用于包含上下文语义的任务。这里选了标准RNN源码入手，学习RNN的实现。</p>\n<h2 id=\"源码框架\"><a href=\"#源码框架\" class=\"headerlink\" title=\"源码框架\"></a>源码框架</h2><h3 id=\"目录结构\"><a href=\"#目录结构\" class=\"headerlink\" title=\"目录结构\"></a>目录结构</h3><ul>\n<li><strong>sequence_layers.hpp:</strong>  抽象类RecurrentLayer，子类RNN和LSTM的头文件</li>\n<li><strong>recurrent_layer.cpp:</strong> 抽象类RecurrentLayer的定义文件</li>\n<li><strong>rnn_layer.cpp:</strong> 子类RNN的定义文件</li>\n</ul>\n<h3 id=\"逻辑结构\"><a href=\"#逻辑结构\" class=\"headerlink\" title=\"逻辑结构\"></a>逻辑结构</h3><ul>\n<li>使用了<strong>模板方法设计模式</strong></li>\n<li><strong>RecurrentLayer:</strong> 定义了网络的通用框架，包括输入，输出，循环部分的入口输入</li>\n<li><strong>RNNLayer:</strong> 定义了循环部分的网络结构</li>\n<li><strong>bottom:</strong><ul>\n<li>bottom[0]: T，帧数</li>\n<li>bottom[1]: N，视频数</li>\n<li>…: 真正的data</li>\n</ul>\n</li>\n<li><strong>top:</strong> 同bottom</li>\n</ul>\n<h2 id=\"sequence-layers-hpp\"><a href=\"#sequence-layers-hpp\" class=\"headerlink\" title=\"sequence_layers.hpp\"></a>sequence_layers.hpp</h2><h3 id=\"成员变量\"><a href=\"#成员变量\" class=\"headerlink\" title=\"成员变量\"></a>成员变量</h3><ul>\n<li><strong>shared_ptr&lt; Net&lt; Dtype&gt; > unrolled_net_:</strong> 最终生成的网络</li>\n<li><strong>int N_:</strong> 视频流的数量</li>\n<li><strong>int T_:</strong> 视频帧数</li>\n<li><strong>bool static_input_:</strong> 输入是否静态</li>\n<li><strong>vector&lt; Blob&lt; Dtype>* > recur_input_blobs_:</strong> 子类循环部分的入口输入($h_0$)</li>\n<li><strong>vector&lt; Blob&lt; Dtype>* > recur_output_blobs_:</strong> 子类循环部分的出口输出($h_T$)</li>\n<li><strong>vector&lt; Blob&lt; Dtype>* > output_blobs_:</strong> 总输出(top)</li>\n<li><strong>Blob&lt; Dtype>* x_input_blob_:</strong> 总视频输入(bottom[0])</li>\n<li><strong>Blob&lt; Dtype>* x_static_input_blob_:</strong> 总静态输入(bottom[2])</li>\n<li><strong>Blob&lt; Dtype>* cont_input_blob_:</strong> 总标识输入(bottom[1])。cont为0表示应该新开一个序列，不用再参照上一次的输出结果</li>\n</ul>\n<h3 id=\"成员函数\"><a href=\"#成员函数\" class=\"headerlink\" title=\"成员函数\"></a>成员函数</h3><ul>\n<li><strong>FillUnrolledNet(NetParameter* net_param):</strong>     <ul>\n<li>子类根据自己的内部网络修改net_param</li>\n<li>原理同我们在外面写prototxt生成网络</li>\n<li>类比安卓开发中动态生成按钮选项，都是因为数量经常变化，写死在xml文件中不便于改动</li>\n</ul>\n</li>\n<li><strong>xxxBlobNames:</strong> <ul>\n<li>返回与主控部分交互的blob名字，主控部分根据名字找到对应的blob</li>\n<li>类比安卓开发中findViewByID将控件和变量绑定</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"recurrent-layer-cpp\"><a href=\"#recurrent-layer-cpp\" class=\"headerlink\" title=\"recurrent_layer.cpp\"></a>recurrent_layer.cpp</h2><h3 id=\"Reshape\"><a href=\"#Reshape\" class=\"headerlink\" title=\"Reshape\"></a>Reshape</h3><p>适配blob，以及绑定blob，使得操作变量等价于修改bottom与top</p>\n<ol>\n<li><strong>Reshape:</strong> 将x_input_blob_, cont_input_blob_和x_static_input_blob_几个输入blob的shape适配bottom</li>\n<li><strong>Reshape:</strong> 将recur_input_blobs_适配子类的入口输出blob(即$h_0$)</li>\n<li><strong>Share:</strong> 将x_input_blob_, cont_input_blob_和x_static_input_blob_与bottom的data及diff进行绑定</li>\n<li><strong>Share:</strong> 将output_blobs_与top的data及diff进行绑定</li>\n</ol>\n<h3 id=\"LayerSetUp\"><a href=\"#LayerSetUp\" class=\"headerlink\" title=\"LayerSetUp\"></a>LayerSetUp</h3><p>等价于将prototxt转为代码，核心为：初始化net_param来生成一个Net</p>\n<ol>\n<li><strong>检查bottom是否规范</strong><ul>\n<li>bottom[0]: 各帧，各视频的数据 (T * N * …)</li>\n<li>bottom[1]: 各帧，各视频的标识，0为开始，1为继续 (T * N * 1)</li>\n<li>bottom[2]: 静态输入</li>\n</ul>\n</li>\n<li><strong>为网络接入总输入，并为各输入命名</strong><ul>\n<li>x: bottom[0]</li>\n<li>cont: bottom[1]</li>\n<li>x_static: bottom[2]</li>\n</ul>\n</li>\n<li><strong>进一步构建网络</strong>，调用FillUnrolledNet修改net_param</li>\n<li><p><strong>用net_param生成最终的网络</strong></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">unrolled_net_.reset(<span class=\"keyword\">new</span> Net&lt;Dtype&gt;(net_param));</div></pre></td></tr></table></figure>\n</li>\n<li><p><strong>将变量与网络对应部分绑定</strong></p>\n<ul>\n<li>在上一步中网络已经生成完毕，但为了操作方便，将要用到的网络部分跟变量绑定，以后直接用变量进行操作</li>\n<li>绑定的时候使用net-&gt;blob_by_name(“xxx”)，类似findViewById。找blob的key是名字，这就是为什么要有xxxBlobNames这样的函数</li>\n</ul>\n</li>\n<li><strong>设置辅助参数</strong><ul>\n<li>blobs_: 这个参数应该要记录本层所有的blob，但由于我们的网络定义不仅是prototxt，还有中途动态生成的部分，所以不能依赖caffe帮我们自动生成的blobs_，要手动将所有参数添加</li>\n<li>param_propagate_down_: 记录是否要bp</li>\n<li>recur_output_blobs_全部置0<strong>（不懂）</strong></li>\n</ul>\n</li>\n</ol>\n<h2 id=\"rnn-layer-cpp\"><a href=\"#rnn-layer-cpp\" class=\"headerlink\" title=\"rnn_layer.cpp\"></a>rnn_layer.cpp</h2><h3 id=\"跟主控交接部分\"><a href=\"#跟主控交接部分\" class=\"headerlink\" title=\"跟主控交接部分\"></a>跟主控交接部分</h3><ul>\n<li><strong>循环输入入口:</strong> $h_0$，1 * N * num_output（循环输入跟循环输出shape一致，所以这里既说明了输入由说明了输出，即对于每一帧，生成num_output维的向量）</li>\n<li><strong>循环输出出口:</strong> $h_t$</li>\n<li><strong>总输出:</strong> o</li>\n</ul>\n<h3 id=\"FillUnrolledNet\"><a href=\"#FillUnrolledNet\" class=\"headerlink\" title=\"FillUnrolledNet\"></a>FillUnrolledNet</h3><p>核心部分，实现网络的定义。实际效果近似于这样的prototxt</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div></pre></td><td class=\"code\"><pre><div class=\"line\">################################</div><div class=\"line\">#            input             #</div><div class=\"line\">################################</div><div class=\"line\">layer&#123;</div><div class=\"line\">\t#sliced x</div><div class=\"line\">\tbottom: x</div><div class=\"line\">\ttop: x_1</div><div class=\"line\">\ttop: x_2</div><div class=\"line\">\t.</div><div class=\"line\">\t.</div><div class=\"line\">\t.</div><div class=\"line\">\ttop: x_t</div><div class=\"line\">&#125;</div><div class=\"line\">layer&#123;</div><div class=\"line\">\t#sliced cont</div><div class=\"line\">\tbottom: cont</div><div class=\"line\">\ttop: cont_1</div><div class=\"line\">\ttop: cont_2</div><div class=\"line\">\t.</div><div class=\"line\">\t.</div><div class=\"line\">\t.</div><div class=\"line\">\ttop: cont_t</div><div class=\"line\">&#125;</div><div class=\"line\">################################</div><div class=\"line\">#          recur layer         #</div><div class=\"line\">################################</div><div class=\"line\">layer&#123;</div><div class=\"line\">\t#recur_unit_1</div><div class=\"line\">\tbottom: x_1, cont_1, h_0</div><div class=\"line\">\ttop: o_1, h_1</div><div class=\"line\">&#125;</div><div class=\"line\">layer&#123;</div><div class=\"line\">\t#recur_unit_2</div><div class=\"line\">\tbottom: x_2, cont_2, h_1</div><div class=\"line\">\ttop: o_2, h_2</div><div class=\"line\">&#125;</div><div class=\"line\">\t\t.</div><div class=\"line\">\t\t.</div><div class=\"line\">\t\t.</div><div class=\"line\"></div><div class=\"line\">layer&#123;</div><div class=\"line\">\t#recur_unit_t</div><div class=\"line\">\tbottom: x_t, cont_t, h_t-1</div><div class=\"line\">\ttop: o_t, h_t</div><div class=\"line\">&#125;</div><div class=\"line\">################################</div><div class=\"line\">#           output             #</div><div class=\"line\">################################</div><div class=\"line\">layer&#123;</div><div class=\"line\">\t#concated output</div><div class=\"line\">\tbottom: o_1</div><div class=\"line\">\tbottom: o_2</div><div class=\"line\">\t.</div><div class=\"line\">\t.</div><div class=\"line\">\t.</div><div class=\"line\">\tbottom: o_t</div><div class=\"line\">\ttop: o</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h2 id=\"收获\"><a href=\"#收获\" class=\"headerlink\" title=\"收获\"></a>收获</h2><ul>\n<li>阅读源码前前思考代码的<strong>输入</strong>是什么，<strong>输出</strong>是什么，给你这样的任务<strong>你会怎么做</strong></li>\n<li>然后在阅读的时候合理地进行<strong>假设</strong>，一步步验证并修改</li>\n<li>先看<strong>数据结构</strong>再看算法，<strong>粒度</strong>从粗到细（类级，函数级，块级，行级）</li>\n</ul>\n<h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><ul>\n<li>论文地址：<a href=\"https://github.com/vsubhashini/caffe/tree/recurrent/examples/s2vt\">s2vt</a></li>\n<li>项目地址：<a href=\"https://arxiv.org/abs/1505.00487\">Sequence to Sequence – Video to Text</a></li>\n<li>参考资料：<a href=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/\">LSTM</a>, <a href=\"http://tutorial.caffe.berkeleyvision.org/caffe-cvpr15-sequences.pdf\">Sequences in Caffe</a></li>\n</ul>\n"},{"title":"Caffe学习：s2vt数据处理部分源码阅读","date":"2016-07-22T03:32:32.000Z","description":["s2vt数据预处理部分源码，即txt转hdf5格式的python脚本"],"_content":"\n## 任务简介\ns2vt做的是从视频生成文字，输入端的数据量较于传统任务庞大很多，对数据流的输入速率提出了要求。传统的以txt方式保存数据的读取方式不再适用，转而使用了更大但是更快的hdf5格式。于是就需要实现两种功能，分别是将数据从**txt格式转换成hdf5格式的脚本**，以及能够**读取hdf5的数据输入层**。\n\n## 源码框架\n\n### txt转hdf5的python脚本\n\n- 采用了**模板方法**的设计模式\n- **hdf5\\_npstreamsequence\\_generator.py**: 其下定义了两个类，分别是\n\t* **SequenceGenerator: **txt转hdf5类的父类，定义了获取下一个batch内容的算法框架\n\t* **HDF5SequenceWriter: **I/O类，给定一个SequenceGenerator，将其内容输出到.h5文件\n- **framefc7\\_stream\\_text\\_to\\_hdf5\\_data.py**: 子类，定义了获取最小粒度数据的方法\n\n### 读取hdf5数据的输入层\n\n- **hdf5\\_data\\_layer.cpp**\n\n### 核心调用关系(从上往下调用)\n\n- **HDF5SequenceWriter::write\\_to\\_exhaustion**\n\t* 调用write\\_batch，直到所有数据读完\n- **HDF5SequenceWriter::write\\_batch**\n\t* **input:** get\\_next\\_batch获取的batch\n\t* **output:** 将batch内容输出为.h5文件\n- **SequenceGenerator::get\\_next\\_batch**\n\t* **intput:** 流数据\n\t* **output:** batch\\[Name]\\[T]\\[N]\n- **SequenceGenerator::reset\\_stream**\n\t* **input:** 最小粒度流数据\n\t* **output:** 重设batch中第i条流为下一条输入流\n- **fc7FrameSequenceGenerator::get_streams**\n\t* **input:** txt文件\n\t* **output:** 由下段line及其对应视频的frames所生成的数据\n\n## hdf5\\_npstreamsequence\\_generator.py\n\n### HDF5SequenceWriter::write\\_to\\_exhaustion\n\n不停地调用write\\_batch，直到所有输入的流（即line）都读完\n\n```python\ndef write_to_exhaustion(self):\n    while not self.generator.streams_exhausted():\n      self.write_batch(stop_at_exhaustion=True)\n```\n\n### HDF5SequenceWriter::write\\_batch\n\n将batch的内容以hdf5的格式保存为.h5文件，hdf5的基本操作流程如下（基本复用了NumPy的表示方式），详情参考[h5py.doc](http://docs.h5py.org/en/latest/high/dataset.html#creating-datasets)\n\n```python\nh5file = h5py.File(filename, 'w')\n# return the container\ndataset = h5file.create_dataset('cont', shape=cont_indicators.shape, dtype=cont_indicators.dtype)\n# write data intot the container\ndataset[:] = cont_indicators\nh5file.close()\n```\n\n### SequenceGenerator::get\\_next\\_batch\n\n变量解释：\n\n- **batch:** batch\\[Name]\\[T]\\[N]\n\t* 存放数据内容\n\t* **Name:** 是指framefc7, intput_sentence之类的\n\t* **T:** 是时间，注意到batch的T是1000，而每一个输入的T是80，所以说在相通的N下，T=80的流跟T=81的流不是同一个流，而是相隔了N的两个流\n- **batch\\_indicators:** batch\\_indicators\\[T]\\[N]\n\t* 指示对应流的开始和结束，0是开始，1是延续\n- **self.substream\\_names:** batch中Name维的值域，即framefc7, input_sentence\n- **self.array\\_type\\_inputs:** 类型是数组的name，比如framefc7\\[num_frames]\\[4096]\n- **exhausted:** vector<bool>(N)\n\t* 指示batch中第N个流是否已经结束（80的倍数或者轮到第N个流时输入已经结束）\n- **all\\_exhausted:** true if all exahusted are true\n- **reached\\_exhaustion:** 基本同streams_exhausted()\n- **self.stream\\_indices:** 标识当前第N个流读到T几\n\n过程解释：\n\n初始化batch和batch\\_indicator的shape，以及各种辅助变量\n```python\nif not self.streams_initialized:\n\tself.init_streams()\n# format: len0: [s0, s2, num of streams, s_n]\n#         len1: [s0, s2, num of streams, s_n]\n#         len2: [s0, s2, num of streams, s_n]\nbatch_size = self.batch_num_streams * self.batch_stream_length\nbatch = {}\nbatch_indicators = np.zeros((self.batch_stream_length, self.batch_num_streams))\n# reshape batch[name] like batch_indicators\n# and set value to pad value\nfor name in self.substream_names:\n\t# if value is high dimension\n\tif name in self.array_type_inputs.keys():\n    \tdim = self.array_type_inputs[name]\n        batch[name] = self.get_pad_value(name) * np.ones((self.batch_stream_length, self.batch_num_streams, dim))\n\t# if value is 1d\n\telse:\n        # each batch[name] is a T * N * dim blob\n        batch[name] = self.get_pad_value(name) * np.ones_like(batch_indicators)\n```\n假如第i个流从来没有用过或者上一个位于i位置的流已经读完，就reset\\_stream(i)\n```python\n# never been initialized or come to the end of a stream\nif self.streams[i] is None or \\\n\tself.stream_indices[i] == len(self.streams[i][self.substream_names[0]]): \n\tself.stream_indices[i] = 0\n\t# Q: self.streams_exhausted() always return false, so the expression is meaningless?\n\t# A: derived class will override function streams_exhausted\n\t# reached_exhaustion is forever True after pass through all lines\n\treached_exhaustion = reached_exhaustion or self.streams_exhausted()\n\t# exhausted[i] indicates the end of ith stream i.e. all lines in ith stream are read\n\tif reached_exhaustion: exhausted[i] = True\n\t# Q: why reset stream i? self.streams is the same data for all stream i\n\t# A: get_streams() in reset_stream() is wrapped around\n\tif not reached_exhaustion or not truncate_at_exhaustion:\n\t\tself.reset_stream(i)\n\telse:\n\t\tcontinue\n```\n\n将各个name的t, i写到对应的batch\\[name]\\[t][i]\n```python\nfor name in self.substream_names:\n    if isinstance(self.streams[i][name], np.ndarray) and self.streams[i][name].ndim > 1:\n        batch[name].resize((batch_size, self.streams[i][name].shape[1],1))\n        batch[name][(t*self.batch_num_streams + i), :,0] = self.streams[i][name][self.stream_indices[i],:]\n    elif name in self.array_type_inputs.keys():\n        batch[name][t, i] = self.streams[i][name][self.stream_indices[i]][0,:]\n    else:\n        batch[name][t, i] = self.streams[i][name][self.stream_indices[i]]\n```\n\n### SequenceGenerator::reset\\_stream\n\n1. 通过get_streams()得到下一个数据流（即下一个line对应的input, framefc7 ...)\n2. 修改实例变量streams[stream_index]为下一个数据流\n\n## framefc7\\_stream\\_text\\_to\\_hdf5\\_data.py\n\n### fc7FrameSequenceGenerator::\\__init__\n\n从txt中读取数据并将数据存入以下变量\n\n- self.vid\\_framefeats[video\\_id]: 存放video_id对应的frames(frame1, frame2)的feats(4096)\n- self.lines: pair< vid, line >\n\n### fc7FrameSequenceGenerator::get_streams\n\n将下一条line对应的frames feats及其他数据规范化为MAX_WORD长度的out，out的示意如下\n\n```\n\t\t     MAX_WORD\ncont_sentence\tx x x x ... x x x x\ninput_sentence  x x x x ... x x x x \nframe_fc7\tx x x x ... x x x x\n\t\t| | | |     | | | |  \n\t\t| | | |     | | | |  4096\n\n```\n\n## 收获\n\n- 在看源码前大概**交流**一下各个函数是干嘛用的，把握整体思路\n- 在纸上画出**核心函数调用链**\n- 像python这样的弱类型语言，可以看**被调函数返回数据**的数据结构\n\n## resource\n- [含注释的hdf5\\_npstreamsequence\\_generator.py](https://github.com/meltycriss/commented_src/blob/master/s2vt_data/hdf5_npstreamsequence_generator.py)\n\n## reference\n\n- 项目地址：[Sequence to Sequence -- Video to Text](https://arxiv.org/abs/1505.00487)\n\n","source":"_posts/caffe_3_s2vt_data_process.md","raw":"---\ntitle: Caffe学习：s2vt数据处理部分源码阅读\ndate: 2016-07-22 11:32:32\ntags: \n  - s2vt data\ndescription:\n  - s2vt数据预处理部分源码，即txt转hdf5格式的python脚本\ncategories:\n  - caffe\n---\n\n## 任务简介\ns2vt做的是从视频生成文字，输入端的数据量较于传统任务庞大很多，对数据流的输入速率提出了要求。传统的以txt方式保存数据的读取方式不再适用，转而使用了更大但是更快的hdf5格式。于是就需要实现两种功能，分别是将数据从**txt格式转换成hdf5格式的脚本**，以及能够**读取hdf5的数据输入层**。\n\n## 源码框架\n\n### txt转hdf5的python脚本\n\n- 采用了**模板方法**的设计模式\n- **hdf5\\_npstreamsequence\\_generator.py**: 其下定义了两个类，分别是\n\t* **SequenceGenerator: **txt转hdf5类的父类，定义了获取下一个batch内容的算法框架\n\t* **HDF5SequenceWriter: **I/O类，给定一个SequenceGenerator，将其内容输出到.h5文件\n- **framefc7\\_stream\\_text\\_to\\_hdf5\\_data.py**: 子类，定义了获取最小粒度数据的方法\n\n### 读取hdf5数据的输入层\n\n- **hdf5\\_data\\_layer.cpp**\n\n### 核心调用关系(从上往下调用)\n\n- **HDF5SequenceWriter::write\\_to\\_exhaustion**\n\t* 调用write\\_batch，直到所有数据读完\n- **HDF5SequenceWriter::write\\_batch**\n\t* **input:** get\\_next\\_batch获取的batch\n\t* **output:** 将batch内容输出为.h5文件\n- **SequenceGenerator::get\\_next\\_batch**\n\t* **intput:** 流数据\n\t* **output:** batch\\[Name]\\[T]\\[N]\n- **SequenceGenerator::reset\\_stream**\n\t* **input:** 最小粒度流数据\n\t* **output:** 重设batch中第i条流为下一条输入流\n- **fc7FrameSequenceGenerator::get_streams**\n\t* **input:** txt文件\n\t* **output:** 由下段line及其对应视频的frames所生成的数据\n\n## hdf5\\_npstreamsequence\\_generator.py\n\n### HDF5SequenceWriter::write\\_to\\_exhaustion\n\n不停地调用write\\_batch，直到所有输入的流（即line）都读完\n\n```python\ndef write_to_exhaustion(self):\n    while not self.generator.streams_exhausted():\n      self.write_batch(stop_at_exhaustion=True)\n```\n\n### HDF5SequenceWriter::write\\_batch\n\n将batch的内容以hdf5的格式保存为.h5文件，hdf5的基本操作流程如下（基本复用了NumPy的表示方式），详情参考[h5py.doc](http://docs.h5py.org/en/latest/high/dataset.html#creating-datasets)\n\n```python\nh5file = h5py.File(filename, 'w')\n# return the container\ndataset = h5file.create_dataset('cont', shape=cont_indicators.shape, dtype=cont_indicators.dtype)\n# write data intot the container\ndataset[:] = cont_indicators\nh5file.close()\n```\n\n### SequenceGenerator::get\\_next\\_batch\n\n变量解释：\n\n- **batch:** batch\\[Name]\\[T]\\[N]\n\t* 存放数据内容\n\t* **Name:** 是指framefc7, intput_sentence之类的\n\t* **T:** 是时间，注意到batch的T是1000，而每一个输入的T是80，所以说在相通的N下，T=80的流跟T=81的流不是同一个流，而是相隔了N的两个流\n- **batch\\_indicators:** batch\\_indicators\\[T]\\[N]\n\t* 指示对应流的开始和结束，0是开始，1是延续\n- **self.substream\\_names:** batch中Name维的值域，即framefc7, input_sentence\n- **self.array\\_type\\_inputs:** 类型是数组的name，比如framefc7\\[num_frames]\\[4096]\n- **exhausted:** vector<bool>(N)\n\t* 指示batch中第N个流是否已经结束（80的倍数或者轮到第N个流时输入已经结束）\n- **all\\_exhausted:** true if all exahusted are true\n- **reached\\_exhaustion:** 基本同streams_exhausted()\n- **self.stream\\_indices:** 标识当前第N个流读到T几\n\n过程解释：\n\n初始化batch和batch\\_indicator的shape，以及各种辅助变量\n```python\nif not self.streams_initialized:\n\tself.init_streams()\n# format: len0: [s0, s2, num of streams, s_n]\n#         len1: [s0, s2, num of streams, s_n]\n#         len2: [s0, s2, num of streams, s_n]\nbatch_size = self.batch_num_streams * self.batch_stream_length\nbatch = {}\nbatch_indicators = np.zeros((self.batch_stream_length, self.batch_num_streams))\n# reshape batch[name] like batch_indicators\n# and set value to pad value\nfor name in self.substream_names:\n\t# if value is high dimension\n\tif name in self.array_type_inputs.keys():\n    \tdim = self.array_type_inputs[name]\n        batch[name] = self.get_pad_value(name) * np.ones((self.batch_stream_length, self.batch_num_streams, dim))\n\t# if value is 1d\n\telse:\n        # each batch[name] is a T * N * dim blob\n        batch[name] = self.get_pad_value(name) * np.ones_like(batch_indicators)\n```\n假如第i个流从来没有用过或者上一个位于i位置的流已经读完，就reset\\_stream(i)\n```python\n# never been initialized or come to the end of a stream\nif self.streams[i] is None or \\\n\tself.stream_indices[i] == len(self.streams[i][self.substream_names[0]]): \n\tself.stream_indices[i] = 0\n\t# Q: self.streams_exhausted() always return false, so the expression is meaningless?\n\t# A: derived class will override function streams_exhausted\n\t# reached_exhaustion is forever True after pass through all lines\n\treached_exhaustion = reached_exhaustion or self.streams_exhausted()\n\t# exhausted[i] indicates the end of ith stream i.e. all lines in ith stream are read\n\tif reached_exhaustion: exhausted[i] = True\n\t# Q: why reset stream i? self.streams is the same data for all stream i\n\t# A: get_streams() in reset_stream() is wrapped around\n\tif not reached_exhaustion or not truncate_at_exhaustion:\n\t\tself.reset_stream(i)\n\telse:\n\t\tcontinue\n```\n\n将各个name的t, i写到对应的batch\\[name]\\[t][i]\n```python\nfor name in self.substream_names:\n    if isinstance(self.streams[i][name], np.ndarray) and self.streams[i][name].ndim > 1:\n        batch[name].resize((batch_size, self.streams[i][name].shape[1],1))\n        batch[name][(t*self.batch_num_streams + i), :,0] = self.streams[i][name][self.stream_indices[i],:]\n    elif name in self.array_type_inputs.keys():\n        batch[name][t, i] = self.streams[i][name][self.stream_indices[i]][0,:]\n    else:\n        batch[name][t, i] = self.streams[i][name][self.stream_indices[i]]\n```\n\n### SequenceGenerator::reset\\_stream\n\n1. 通过get_streams()得到下一个数据流（即下一个line对应的input, framefc7 ...)\n2. 修改实例变量streams[stream_index]为下一个数据流\n\n## framefc7\\_stream\\_text\\_to\\_hdf5\\_data.py\n\n### fc7FrameSequenceGenerator::\\__init__\n\n从txt中读取数据并将数据存入以下变量\n\n- self.vid\\_framefeats[video\\_id]: 存放video_id对应的frames(frame1, frame2)的feats(4096)\n- self.lines: pair< vid, line >\n\n### fc7FrameSequenceGenerator::get_streams\n\n将下一条line对应的frames feats及其他数据规范化为MAX_WORD长度的out，out的示意如下\n\n```\n\t\t     MAX_WORD\ncont_sentence\tx x x x ... x x x x\ninput_sentence  x x x x ... x x x x \nframe_fc7\tx x x x ... x x x x\n\t\t| | | |     | | | |  \n\t\t| | | |     | | | |  4096\n\n```\n\n## 收获\n\n- 在看源码前大概**交流**一下各个函数是干嘛用的，把握整体思路\n- 在纸上画出**核心函数调用链**\n- 像python这样的弱类型语言，可以看**被调函数返回数据**的数据结构\n\n## resource\n- [含注释的hdf5\\_npstreamsequence\\_generator.py](https://github.com/meltycriss/commented_src/blob/master/s2vt_data/hdf5_npstreamsequence_generator.py)\n\n## reference\n\n- 项目地址：[Sequence to Sequence -- Video to Text](https://arxiv.org/abs/1505.00487)\n\n","slug":"caffe_3_s2vt_data_process","published":1,"updated":"2024-08-13T16:03:47.848Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clzvf19120006eqwoa5tsl4g7","content":"<h2 id=\"任务简介\"><a href=\"#任务简介\" class=\"headerlink\" title=\"任务简介\"></a>任务简介</h2><p>s2vt做的是从视频生成文字，输入端的数据量较于传统任务庞大很多，对数据流的输入速率提出了要求。传统的以txt方式保存数据的读取方式不再适用，转而使用了更大但是更快的hdf5格式。于是就需要实现两种功能，分别是将数据从<strong>txt格式转换成hdf5格式的脚本</strong>，以及能够<strong>读取hdf5的数据输入层</strong>。</p>\n<h2 id=\"源码框架\"><a href=\"#源码框架\" class=\"headerlink\" title=\"源码框架\"></a>源码框架</h2><h3 id=\"txt转hdf5的python脚本\"><a href=\"#txt转hdf5的python脚本\" class=\"headerlink\" title=\"txt转hdf5的python脚本\"></a>txt转hdf5的python脚本</h3><ul>\n<li>采用了<strong>模板方法</strong>的设计模式</li>\n<li><strong>hdf5_npstreamsequence_generator.py</strong>: 其下定义了两个类，分别是<ul>\n<li><strong>SequenceGenerator: </strong>txt转hdf5类的父类，定义了获取下一个batch内容的算法框架</li>\n<li><strong>HDF5SequenceWriter: </strong>I/O类，给定一个SequenceGenerator，将其内容输出到.h5文件</li>\n</ul>\n</li>\n<li><strong>framefc7_stream_text_to_hdf5_data.py</strong>: 子类，定义了获取最小粒度数据的方法</li>\n</ul>\n<h3 id=\"读取hdf5数据的输入层\"><a href=\"#读取hdf5数据的输入层\" class=\"headerlink\" title=\"读取hdf5数据的输入层\"></a>读取hdf5数据的输入层</h3><ul>\n<li><strong>hdf5_data_layer.cpp</strong></li>\n</ul>\n<h3 id=\"核心调用关系-从上往下调用\"><a href=\"#核心调用关系-从上往下调用\" class=\"headerlink\" title=\"核心调用关系(从上往下调用)\"></a>核心调用关系(从上往下调用)</h3><ul>\n<li><strong>HDF5SequenceWriter::write_to_exhaustion</strong><ul>\n<li>调用write_batch，直到所有数据读完</li>\n</ul>\n</li>\n<li><strong>HDF5SequenceWriter::write_batch</strong><ul>\n<li><strong>input:</strong> get_next_batch获取的batch</li>\n<li><strong>output:</strong> 将batch内容输出为.h5文件</li>\n</ul>\n</li>\n<li><strong>SequenceGenerator::get_next_batch</strong><ul>\n<li><strong>intput:</strong> 流数据</li>\n<li><strong>output:</strong> batch[Name][T][N]</li>\n</ul>\n</li>\n<li><strong>SequenceGenerator::reset_stream</strong><ul>\n<li><strong>input:</strong> 最小粒度流数据</li>\n<li><strong>output:</strong> 重设batch中第i条流为下一条输入流</li>\n</ul>\n</li>\n<li><strong>fc7FrameSequenceGenerator::get_streams</strong><ul>\n<li><strong>input:</strong> txt文件</li>\n<li><strong>output:</strong> 由下段line及其对应视频的frames所生成的数据</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"hdf5-npstreamsequence-generator-py\"><a href=\"#hdf5-npstreamsequence-generator-py\" class=\"headerlink\" title=\"hdf5_npstreamsequence_generator.py\"></a>hdf5_npstreamsequence_generator.py</h2><h3 id=\"HDF5SequenceWriter-write-to-exhaustion\"><a href=\"#HDF5SequenceWriter-write-to-exhaustion\" class=\"headerlink\" title=\"HDF5SequenceWriter::write_to_exhaustion\"></a>HDF5SequenceWriter::write_to_exhaustion</h3><p>不停地调用write_batch，直到所有输入的流（即line）都读完</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">write_to_exhaustion</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">while</span> <span class=\"keyword\">not</span> self.generator.streams_exhausted():</div><div class=\"line\">      self.write_batch(stop_at_exhaustion=<span class=\"keyword\">True</span>)</div></pre></td></tr></table></figure>\n<h3 id=\"HDF5SequenceWriter-write-batch\"><a href=\"#HDF5SequenceWriter-write-batch\" class=\"headerlink\" title=\"HDF5SequenceWriter::write_batch\"></a>HDF5SequenceWriter::write_batch</h3><p>将batch的内容以hdf5的格式保存为.h5文件，hdf5的基本操作流程如下（基本复用了NumPy的表示方式），详情参考<a href=\"http://docs.h5py.org/en/latest/high/dataset.html#creating-datasets\" target=\"_blank\" rel=\"external\">h5py.doc</a></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">h5file = h5py.File(filename, <span class=\"string\">'w'</span>)</div><div class=\"line\"><span class=\"comment\"># return the container</span></div><div class=\"line\">dataset = h5file.create_dataset(<span class=\"string\">'cont'</span>, shape=cont_indicators.shape, dtype=cont_indicators.dtype)</div><div class=\"line\"><span class=\"comment\"># write data intot the container</span></div><div class=\"line\">dataset[:] = cont_indicators</div><div class=\"line\">h5file.close()</div></pre></td></tr></table></figure>\n<h3 id=\"SequenceGenerator-get-next-batch\"><a href=\"#SequenceGenerator-get-next-batch\" class=\"headerlink\" title=\"SequenceGenerator::get_next_batch\"></a>SequenceGenerator::get_next_batch</h3><p>变量解释：</p>\n<ul>\n<li><strong>batch:</strong> batch[Name][T][N]<ul>\n<li>存放数据内容</li>\n<li><strong>Name:</strong> 是指framefc7, intput_sentence之类的</li>\n<li><strong>T:</strong> 是时间，注意到batch的T是1000，而每一个输入的T是80，所以说在相通的N下，T=80的流跟T=81的流不是同一个流，而是相隔了N的两个流</li>\n</ul>\n</li>\n<li><strong>batch_indicators:</strong> batch_indicators[T][N]<ul>\n<li>指示对应流的开始和结束，0是开始，1是延续</li>\n</ul>\n</li>\n<li><strong>self.substream_names:</strong> batch中Name维的值域，即framefc7, input_sentence</li>\n<li><strong>self.array_type_inputs:</strong> 类型是数组的name，比如framefc7[num_frames][4096]</li>\n<li><strong>exhausted:</strong> vector<bool>(N)<ul>\n<li>指示batch中第N个流是否已经结束（80的倍数或者轮到第N个流时输入已经结束）</li>\n</ul>\n</bool></li>\n<li><strong>all_exhausted:</strong> true if all exahusted are true</li>\n<li><strong>reached_exhaustion:</strong> 基本同streams_exhausted()</li>\n<li><strong>self.stream_indices:</strong> 标识当前第N个流读到T几</li>\n</ul>\n<p>过程解释：</p>\n<p>初始化batch和batch_indicator的shape，以及各种辅助变量<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">if</span> <span class=\"keyword\">not</span> self.streams_initialized:</div><div class=\"line\">\tself.init_streams()</div><div class=\"line\"><span class=\"comment\"># format: len0: [s0, s2, num of streams, s_n]</span></div><div class=\"line\"><span class=\"comment\">#         len1: [s0, s2, num of streams, s_n]</span></div><div class=\"line\"><span class=\"comment\">#         len2: [s0, s2, num of streams, s_n]</span></div><div class=\"line\">batch_size = self.batch_num_streams * self.batch_stream_length</div><div class=\"line\">batch = &#123;&#125;</div><div class=\"line\">batch_indicators = np.zeros((self.batch_stream_length, self.batch_num_streams))</div><div class=\"line\"><span class=\"comment\"># reshape batch[name] like batch_indicators</span></div><div class=\"line\"><span class=\"comment\"># and set value to pad value</span></div><div class=\"line\"><span class=\"keyword\">for</span> name <span class=\"keyword\">in</span> self.substream_names:</div><div class=\"line\">\t<span class=\"comment\"># if value is high dimension</span></div><div class=\"line\">\t<span class=\"keyword\">if</span> name <span class=\"keyword\">in</span> self.array_type_inputs.keys():</div><div class=\"line\">    \tdim = self.array_type_inputs[name]</div><div class=\"line\">        batch[name] = self.get_pad_value(name) * np.ones((self.batch_stream_length, self.batch_num_streams, dim))</div><div class=\"line\">\t<span class=\"comment\"># if value is 1d</span></div><div class=\"line\">\t<span class=\"keyword\">else</span>:</div><div class=\"line\">        <span class=\"comment\"># each batch[name] is a T * N * dim blob</span></div><div class=\"line\">        batch[name] = self.get_pad_value(name) * np.ones_like(batch_indicators)</div></pre></td></tr></table></figure></p>\n<p>假如第i个流从来没有用过或者上一个位于i位置的流已经读完，就reset_stream(i)<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># never been initialized or come to the end of a stream</span></div><div class=\"line\"><span class=\"keyword\">if</span> self.streams[i] <span class=\"keyword\">is</span> <span class=\"keyword\">None</span> <span class=\"keyword\">or</span> \\</div><div class=\"line\">\tself.stream_indices[i] == len(self.streams[i][self.substream_names[<span class=\"number\">0</span>]]): </div><div class=\"line\">\tself.stream_indices[i] = <span class=\"number\">0</span></div><div class=\"line\">\t<span class=\"comment\"># Q: self.streams_exhausted() always return false, so the expression is meaningless?</span></div><div class=\"line\">\t<span class=\"comment\"># A: derived class will override function streams_exhausted</span></div><div class=\"line\">\t<span class=\"comment\"># reached_exhaustion is forever True after pass through all lines</span></div><div class=\"line\">\treached_exhaustion = reached_exhaustion <span class=\"keyword\">or</span> self.streams_exhausted()</div><div class=\"line\">\t<span class=\"comment\"># exhausted[i] indicates the end of ith stream i.e. all lines in ith stream are read</span></div><div class=\"line\">\t<span class=\"keyword\">if</span> reached_exhaustion: exhausted[i] = <span class=\"keyword\">True</span></div><div class=\"line\">\t<span class=\"comment\"># Q: why reset stream i? self.streams is the same data for all stream i</span></div><div class=\"line\">\t<span class=\"comment\"># A: get_streams() in reset_stream() is wrapped around</span></div><div class=\"line\">\t<span class=\"keyword\">if</span> <span class=\"keyword\">not</span> reached_exhaustion <span class=\"keyword\">or</span> <span class=\"keyword\">not</span> truncate_at_exhaustion:</div><div class=\"line\">\t\tself.reset_stream(i)</div><div class=\"line\">\t<span class=\"keyword\">else</span>:</div><div class=\"line\">\t\t<span class=\"keyword\">continue</span></div></pre></td></tr></table></figure></p>\n<p>将各个name的t, i写到对应的batch[name][t][i]<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">for</span> name <span class=\"keyword\">in</span> self.substream_names:</div><div class=\"line\">    <span class=\"keyword\">if</span> isinstance(self.streams[i][name], np.ndarray) <span class=\"keyword\">and</span> self.streams[i][name].ndim &gt; <span class=\"number\">1</span>:</div><div class=\"line\">        batch[name].resize((batch_size, self.streams[i][name].shape[<span class=\"number\">1</span>],<span class=\"number\">1</span>))</div><div class=\"line\">        batch[name][(t*self.batch_num_streams + i), :,<span class=\"number\">0</span>] = self.streams[i][name][self.stream_indices[i],:]</div><div class=\"line\">    <span class=\"keyword\">elif</span> name <span class=\"keyword\">in</span> self.array_type_inputs.keys():</div><div class=\"line\">        batch[name][t, i] = self.streams[i][name][self.stream_indices[i]][<span class=\"number\">0</span>,:]</div><div class=\"line\">    <span class=\"keyword\">else</span>:</div><div class=\"line\">        batch[name][t, i] = self.streams[i][name][self.stream_indices[i]]</div></pre></td></tr></table></figure></p>\n<h3 id=\"SequenceGenerator-reset-stream\"><a href=\"#SequenceGenerator-reset-stream\" class=\"headerlink\" title=\"SequenceGenerator::reset_stream\"></a>SequenceGenerator::reset_stream</h3><ol>\n<li>通过get_streams()得到下一个数据流（即下一个line对应的input, framefc7 …)</li>\n<li>修改实例变量streams[stream_index]为下一个数据流</li>\n</ol>\n<h2 id=\"framefc7-stream-text-to-hdf5-data-py\"><a href=\"#framefc7-stream-text-to-hdf5-data-py\" class=\"headerlink\" title=\"framefc7_stream_text_to_hdf5_data.py\"></a>framefc7_stream_text_to_hdf5_data.py</h2><h3 id=\"fc7FrameSequenceGenerator-init\"><a href=\"#fc7FrameSequenceGenerator-init\" class=\"headerlink\" title=\"fc7FrameSequenceGenerator::__init__\"></a>fc7FrameSequenceGenerator::__init__</h3><p>从txt中读取数据并将数据存入以下变量</p>\n<ul>\n<li>self.vid_framefeats[video_id]: 存放video_id对应的frames(frame1, frame2)的feats(4096)</li>\n<li>self.lines: pair&lt; vid, line &gt;</li>\n</ul>\n<h3 id=\"fc7FrameSequenceGenerator-get-streams\"><a href=\"#fc7FrameSequenceGenerator-get-streams\" class=\"headerlink\" title=\"fc7FrameSequenceGenerator::get_streams\"></a>fc7FrameSequenceGenerator::get_streams</h3><p>将下一条line对应的frames feats及其他数据规范化为MAX_WORD长度的out，out的示意如下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">\t\t     MAX_WORD</div><div class=\"line\">cont_sentence\tx x x x ... x x x x</div><div class=\"line\">input_sentence  x x x x ... x x x x </div><div class=\"line\">frame_fc7\tx x x x ... x x x x</div><div class=\"line\">\t\t| | | |     | | | |  </div><div class=\"line\">\t\t| | | |     | | | |  4096</div></pre></td></tr></table></figure>\n<h2 id=\"收获\"><a href=\"#收获\" class=\"headerlink\" title=\"收获\"></a>收获</h2><ul>\n<li>在看源码前大概<strong>交流</strong>一下各个函数是干嘛用的，把握整体思路</li>\n<li>在纸上画出<strong>核心函数调用链</strong></li>\n<li>像python这样的弱类型语言，可以看<strong>被调函数返回数据</strong>的数据结构</li>\n</ul>\n<h2 id=\"resource\"><a href=\"#resource\" class=\"headerlink\" title=\"resource\"></a>resource</h2><ul>\n<li><a href=\"https://github.com/meltycriss/commented_src/blob/master/s2vt_data/hdf5_npstreamsequence_generator.py\" target=\"_blank\" rel=\"external\">含注释的hdf5_npstreamsequence_generator.py</a></li>\n</ul>\n<h2 id=\"reference\"><a href=\"#reference\" class=\"headerlink\" title=\"reference\"></a>reference</h2><ul>\n<li>项目地址：<a href=\"https://arxiv.org/abs/1505.00487\" target=\"_blank\" rel=\"external\">Sequence to Sequence – Video to Text</a></li>\n</ul>\n","excerpt":"","more":"<h2 id=\"任务简介\"><a href=\"#任务简介\" class=\"headerlink\" title=\"任务简介\"></a>任务简介</h2><p>s2vt做的是从视频生成文字，输入端的数据量较于传统任务庞大很多，对数据流的输入速率提出了要求。传统的以txt方式保存数据的读取方式不再适用，转而使用了更大但是更快的hdf5格式。于是就需要实现两种功能，分别是将数据从<strong>txt格式转换成hdf5格式的脚本</strong>，以及能够<strong>读取hdf5的数据输入层</strong>。</p>\n<h2 id=\"源码框架\"><a href=\"#源码框架\" class=\"headerlink\" title=\"源码框架\"></a>源码框架</h2><h3 id=\"txt转hdf5的python脚本\"><a href=\"#txt转hdf5的python脚本\" class=\"headerlink\" title=\"txt转hdf5的python脚本\"></a>txt转hdf5的python脚本</h3><ul>\n<li>采用了<strong>模板方法</strong>的设计模式</li>\n<li><strong>hdf5_npstreamsequence_generator.py</strong>: 其下定义了两个类，分别是<ul>\n<li><strong>SequenceGenerator: </strong>txt转hdf5类的父类，定义了获取下一个batch内容的算法框架</li>\n<li><strong>HDF5SequenceWriter: </strong>I/O类，给定一个SequenceGenerator，将其内容输出到.h5文件</li>\n</ul>\n</li>\n<li><strong>framefc7_stream_text_to_hdf5_data.py</strong>: 子类，定义了获取最小粒度数据的方法</li>\n</ul>\n<h3 id=\"读取hdf5数据的输入层\"><a href=\"#读取hdf5数据的输入层\" class=\"headerlink\" title=\"读取hdf5数据的输入层\"></a>读取hdf5数据的输入层</h3><ul>\n<li><strong>hdf5_data_layer.cpp</strong></li>\n</ul>\n<h3 id=\"核心调用关系-从上往下调用\"><a href=\"#核心调用关系-从上往下调用\" class=\"headerlink\" title=\"核心调用关系(从上往下调用)\"></a>核心调用关系(从上往下调用)</h3><ul>\n<li><strong>HDF5SequenceWriter::write_to_exhaustion</strong><ul>\n<li>调用write_batch，直到所有数据读完</li>\n</ul>\n</li>\n<li><strong>HDF5SequenceWriter::write_batch</strong><ul>\n<li><strong>input:</strong> get_next_batch获取的batch</li>\n<li><strong>output:</strong> 将batch内容输出为.h5文件</li>\n</ul>\n</li>\n<li><strong>SequenceGenerator::get_next_batch</strong><ul>\n<li><strong>intput:</strong> 流数据</li>\n<li><strong>output:</strong> batch[Name][T][N]</li>\n</ul>\n</li>\n<li><strong>SequenceGenerator::reset_stream</strong><ul>\n<li><strong>input:</strong> 最小粒度流数据</li>\n<li><strong>output:</strong> 重设batch中第i条流为下一条输入流</li>\n</ul>\n</li>\n<li><strong>fc7FrameSequenceGenerator::get_streams</strong><ul>\n<li><strong>input:</strong> txt文件</li>\n<li><strong>output:</strong> 由下段line及其对应视频的frames所生成的数据</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"hdf5-npstreamsequence-generator-py\"><a href=\"#hdf5-npstreamsequence-generator-py\" class=\"headerlink\" title=\"hdf5_npstreamsequence_generator.py\"></a>hdf5_npstreamsequence_generator.py</h2><h3 id=\"HDF5SequenceWriter-write-to-exhaustion\"><a href=\"#HDF5SequenceWriter-write-to-exhaustion\" class=\"headerlink\" title=\"HDF5SequenceWriter::write_to_exhaustion\"></a>HDF5SequenceWriter::write_to_exhaustion</h3><p>不停地调用write_batch，直到所有输入的流（即line）都读完</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">write_to_exhaustion</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">while</span> <span class=\"keyword\">not</span> self.generator.streams_exhausted():</div><div class=\"line\">      self.write_batch(stop_at_exhaustion=<span class=\"keyword\">True</span>)</div></pre></td></tr></table></figure>\n<h3 id=\"HDF5SequenceWriter-write-batch\"><a href=\"#HDF5SequenceWriter-write-batch\" class=\"headerlink\" title=\"HDF5SequenceWriter::write_batch\"></a>HDF5SequenceWriter::write_batch</h3><p>将batch的内容以hdf5的格式保存为.h5文件，hdf5的基本操作流程如下（基本复用了NumPy的表示方式），详情参考<a href=\"http://docs.h5py.org/en/latest/high/dataset.html#creating-datasets\">h5py.doc</a></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">h5file = h5py.File(filename, <span class=\"string\">'w'</span>)</div><div class=\"line\"><span class=\"comment\"># return the container</span></div><div class=\"line\">dataset = h5file.create_dataset(<span class=\"string\">'cont'</span>, shape=cont_indicators.shape, dtype=cont_indicators.dtype)</div><div class=\"line\"><span class=\"comment\"># write data intot the container</span></div><div class=\"line\">dataset[:] = cont_indicators</div><div class=\"line\">h5file.close()</div></pre></td></tr></table></figure>\n<h3 id=\"SequenceGenerator-get-next-batch\"><a href=\"#SequenceGenerator-get-next-batch\" class=\"headerlink\" title=\"SequenceGenerator::get_next_batch\"></a>SequenceGenerator::get_next_batch</h3><p>变量解释：</p>\n<ul>\n<li><strong>batch:</strong> batch[Name][T][N]<ul>\n<li>存放数据内容</li>\n<li><strong>Name:</strong> 是指framefc7, intput_sentence之类的</li>\n<li><strong>T:</strong> 是时间，注意到batch的T是1000，而每一个输入的T是80，所以说在相通的N下，T=80的流跟T=81的流不是同一个流，而是相隔了N的两个流</li>\n</ul>\n</li>\n<li><strong>batch_indicators:</strong> batch_indicators[T][N]<ul>\n<li>指示对应流的开始和结束，0是开始，1是延续</li>\n</ul>\n</li>\n<li><strong>self.substream_names:</strong> batch中Name维的值域，即framefc7, input_sentence</li>\n<li><strong>self.array_type_inputs:</strong> 类型是数组的name，比如framefc7[num_frames][4096]</li>\n<li><strong>exhausted:</strong> vector<bool>(N)<ul>\n<li>指示batch中第N个流是否已经结束（80的倍数或者轮到第N个流时输入已经结束）</li>\n</ul>\n</li>\n<li><strong>all_exhausted:</strong> true if all exahusted are true</li>\n<li><strong>reached_exhaustion:</strong> 基本同streams_exhausted()</li>\n<li><strong>self.stream_indices:</strong> 标识当前第N个流读到T几</li>\n</ul>\n<p>过程解释：</p>\n<p>初始化batch和batch_indicator的shape，以及各种辅助变量<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">if</span> <span class=\"keyword\">not</span> self.streams_initialized:</div><div class=\"line\">\tself.init_streams()</div><div class=\"line\"><span class=\"comment\"># format: len0: [s0, s2, num of streams, s_n]</span></div><div class=\"line\"><span class=\"comment\">#         len1: [s0, s2, num of streams, s_n]</span></div><div class=\"line\"><span class=\"comment\">#         len2: [s0, s2, num of streams, s_n]</span></div><div class=\"line\">batch_size = self.batch_num_streams * self.batch_stream_length</div><div class=\"line\">batch = &#123;&#125;</div><div class=\"line\">batch_indicators = np.zeros((self.batch_stream_length, self.batch_num_streams))</div><div class=\"line\"><span class=\"comment\"># reshape batch[name] like batch_indicators</span></div><div class=\"line\"><span class=\"comment\"># and set value to pad value</span></div><div class=\"line\"><span class=\"keyword\">for</span> name <span class=\"keyword\">in</span> self.substream_names:</div><div class=\"line\">\t<span class=\"comment\"># if value is high dimension</span></div><div class=\"line\">\t<span class=\"keyword\">if</span> name <span class=\"keyword\">in</span> self.array_type_inputs.keys():</div><div class=\"line\">    \tdim = self.array_type_inputs[name]</div><div class=\"line\">        batch[name] = self.get_pad_value(name) * np.ones((self.batch_stream_length, self.batch_num_streams, dim))</div><div class=\"line\">\t<span class=\"comment\"># if value is 1d</span></div><div class=\"line\">\t<span class=\"keyword\">else</span>:</div><div class=\"line\">        <span class=\"comment\"># each batch[name] is a T * N * dim blob</span></div><div class=\"line\">        batch[name] = self.get_pad_value(name) * np.ones_like(batch_indicators)</div></pre></td></tr></table></figure></p>\n<p>假如第i个流从来没有用过或者上一个位于i位置的流已经读完，就reset_stream(i)<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># never been initialized or come to the end of a stream</span></div><div class=\"line\"><span class=\"keyword\">if</span> self.streams[i] <span class=\"keyword\">is</span> <span class=\"keyword\">None</span> <span class=\"keyword\">or</span> \\</div><div class=\"line\">\tself.stream_indices[i] == len(self.streams[i][self.substream_names[<span class=\"number\">0</span>]]): </div><div class=\"line\">\tself.stream_indices[i] = <span class=\"number\">0</span></div><div class=\"line\">\t<span class=\"comment\"># Q: self.streams_exhausted() always return false, so the expression is meaningless?</span></div><div class=\"line\">\t<span class=\"comment\"># A: derived class will override function streams_exhausted</span></div><div class=\"line\">\t<span class=\"comment\"># reached_exhaustion is forever True after pass through all lines</span></div><div class=\"line\">\treached_exhaustion = reached_exhaustion <span class=\"keyword\">or</span> self.streams_exhausted()</div><div class=\"line\">\t<span class=\"comment\"># exhausted[i] indicates the end of ith stream i.e. all lines in ith stream are read</span></div><div class=\"line\">\t<span class=\"keyword\">if</span> reached_exhaustion: exhausted[i] = <span class=\"keyword\">True</span></div><div class=\"line\">\t<span class=\"comment\"># Q: why reset stream i? self.streams is the same data for all stream i</span></div><div class=\"line\">\t<span class=\"comment\"># A: get_streams() in reset_stream() is wrapped around</span></div><div class=\"line\">\t<span class=\"keyword\">if</span> <span class=\"keyword\">not</span> reached_exhaustion <span class=\"keyword\">or</span> <span class=\"keyword\">not</span> truncate_at_exhaustion:</div><div class=\"line\">\t\tself.reset_stream(i)</div><div class=\"line\">\t<span class=\"keyword\">else</span>:</div><div class=\"line\">\t\t<span class=\"keyword\">continue</span></div></pre></td></tr></table></figure></p>\n<p>将各个name的t, i写到对应的batch[name][t][i]<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">for</span> name <span class=\"keyword\">in</span> self.substream_names:</div><div class=\"line\">    <span class=\"keyword\">if</span> isinstance(self.streams[i][name], np.ndarray) <span class=\"keyword\">and</span> self.streams[i][name].ndim &gt; <span class=\"number\">1</span>:</div><div class=\"line\">        batch[name].resize((batch_size, self.streams[i][name].shape[<span class=\"number\">1</span>],<span class=\"number\">1</span>))</div><div class=\"line\">        batch[name][(t*self.batch_num_streams + i), :,<span class=\"number\">0</span>] = self.streams[i][name][self.stream_indices[i],:]</div><div class=\"line\">    <span class=\"keyword\">elif</span> name <span class=\"keyword\">in</span> self.array_type_inputs.keys():</div><div class=\"line\">        batch[name][t, i] = self.streams[i][name][self.stream_indices[i]][<span class=\"number\">0</span>,:]</div><div class=\"line\">    <span class=\"keyword\">else</span>:</div><div class=\"line\">        batch[name][t, i] = self.streams[i][name][self.stream_indices[i]]</div></pre></td></tr></table></figure></p>\n<h3 id=\"SequenceGenerator-reset-stream\"><a href=\"#SequenceGenerator-reset-stream\" class=\"headerlink\" title=\"SequenceGenerator::reset_stream\"></a>SequenceGenerator::reset_stream</h3><ol>\n<li>通过get_streams()得到下一个数据流（即下一个line对应的input, framefc7 …)</li>\n<li>修改实例变量streams[stream_index]为下一个数据流</li>\n</ol>\n<h2 id=\"framefc7-stream-text-to-hdf5-data-py\"><a href=\"#framefc7-stream-text-to-hdf5-data-py\" class=\"headerlink\" title=\"framefc7_stream_text_to_hdf5_data.py\"></a>framefc7_stream_text_to_hdf5_data.py</h2><h3 id=\"fc7FrameSequenceGenerator-init\"><a href=\"#fc7FrameSequenceGenerator-init\" class=\"headerlink\" title=\"fc7FrameSequenceGenerator::__init__\"></a>fc7FrameSequenceGenerator::__init__</h3><p>从txt中读取数据并将数据存入以下变量</p>\n<ul>\n<li>self.vid_framefeats[video_id]: 存放video_id对应的frames(frame1, frame2)的feats(4096)</li>\n<li>self.lines: pair&lt; vid, line &gt;</li>\n</ul>\n<h3 id=\"fc7FrameSequenceGenerator-get-streams\"><a href=\"#fc7FrameSequenceGenerator-get-streams\" class=\"headerlink\" title=\"fc7FrameSequenceGenerator::get_streams\"></a>fc7FrameSequenceGenerator::get_streams</h3><p>将下一条line对应的frames feats及其他数据规范化为MAX_WORD长度的out，out的示意如下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">\t\t     MAX_WORD</div><div class=\"line\">cont_sentence\tx x x x ... x x x x</div><div class=\"line\">input_sentence  x x x x ... x x x x </div><div class=\"line\">frame_fc7\tx x x x ... x x x x</div><div class=\"line\">\t\t| | | |     | | | |  </div><div class=\"line\">\t\t| | | |     | | | |  4096</div></pre></td></tr></table></figure>\n<h2 id=\"收获\"><a href=\"#收获\" class=\"headerlink\" title=\"收获\"></a>收获</h2><ul>\n<li>在看源码前大概<strong>交流</strong>一下各个函数是干嘛用的，把握整体思路</li>\n<li>在纸上画出<strong>核心函数调用链</strong></li>\n<li>像python这样的弱类型语言，可以看<strong>被调函数返回数据</strong>的数据结构</li>\n</ul>\n<h2 id=\"resource\"><a href=\"#resource\" class=\"headerlink\" title=\"resource\"></a>resource</h2><ul>\n<li><a href=\"https://github.com/meltycriss/commented_src/blob/master/s2vt_data/hdf5_npstreamsequence_generator.py\">含注释的hdf5_npstreamsequence_generator.py</a></li>\n</ul>\n<h2 id=\"reference\"><a href=\"#reference\" class=\"headerlink\" title=\"reference\"></a>reference</h2><ul>\n<li>项目地址：<a href=\"https://arxiv.org/abs/1505.00487\">Sequence to Sequence – Video to Text</a></li>\n</ul>\n"},{"title":"Caffe学习：LSTM源码阅读","date":"2016-08-05T02:00:46.000Z","description":["LSTM源码阅读，主要针对几个比较tricky的点展开"],"_content":"\n## 简介\n由于之前已经有一篇RNN的源码阅读文章，这里就不再从超类讲起了，而且整体思路上LSTM跟RNN比较相似，所以本文主要是将某些比较tricky的点提出来，而不再像往常的源码阅读一样对整份源码解析。\n\n## 源码框架\n\n### 目录结构\n- **sequence_layers.hpp:**  抽象类RecurrentLayer，子类RNN和LSTM的头文件\n- **recurrent_layer.cpp:** 抽象类RecurrentLayer的定义文件\n- **lstm_layer.cpp:** 子类LSTM的定义文件\n- **lstm\\_unit\\_layer.cpp:** 子类LSTM的辅助层定义文件\n\n### 逻辑结构\n首先要说明的是这里的LSTM不是[标准LSTM](http://www.jianshu.com/p/9dc9f41f0b29/)，而是一种变种，具体参考论文[Sequence to Sequence - Video to Text](https://github.com/vsubhashini/caffe/tree/recurrent/examples/s2vt)，最关键的区别在于x和h的处理，不再是拼接，而是求和。\n\n每个for循环生成了一个像这样的net（省略cont）\n\n```\n     |---|         |---|\n c_0 |   |   c_0   |   |  c_1\n-----|   |---------|   |-----\n h_0 |   | Wh+Wx+b |   |  h_1\n-----|   |---------|   |-----\n     |---|         |---|\n   lstm_layer  lstm_unit_layer\n\n```\n\n## num_output * 4\n可以看到在lstm\\_layer.cpp中的内积层都是将num\\_output设置成num_output * 4\n\n```cpp\n  LayerParameter hidden_param;\n  hidden_param.set_type(\"InnerProduct\");\n  hidden_param.mutable_inner_product_param()->set_num_output(num_output * 4);\n  hidden_param.mutable_inner_product_param()->set_bias_term(false);\n  hidden_param.mutable_inner_product_param()->set_axis(2);\n  hidden_param.mutable_inner_product_param()->\n      mutable_weight_filler()->CopyFrom(weight_filler);\n```\n\n而这个内积层后面用作将h全连接成一个num_output * 4维的向量\n\n```cpp\n  LayerParameter* w_param = net_param->add_layer();\n  w_param->CopyFrom(hidden_param);\n  w_param->set_name(\"transform_\" + ts);\n  w_param->add_param()->set_name(\"W_hc\");\n  w_param->add_bottom(\"h_conted_\" + tm1s);\n  w_param->add_top(\"W_hc_h_\" + tm1s);\n  w_param->mutable_inner_product_param()->set_axis(2);\n```\n\n最后又可以看到，在lstm\\_unit\\_layer.cpp中，当使用到这个num_output * 4维的向量时，是把它当作4个不同意义的向量来用的\n\n\n```cpp\n  const Dtype i = sigmoid(X[d]);\n  const Dtype f = (*flush == 0) ? 0 :\n      (*flush * sigmoid(X[1 * hidden_dim_ + d]));\n  const Dtype o = sigmoid(X[2 * hidden_dim_ + d]);\n  const Dtype g = tanh(X[3 * hidden_dim_ + d]);\n```\n\n那为什么要用一种这么不直观的方式来写呢？一般来说，有违直观理解的编码方式都是**出于提高效率**考虑的。下面讨论具体原因\n\n- 创建一个layer有**开销**\n- 一个大矩阵的优化会比拆开的几个小矩阵的优化效果好，因为\n\t* 拆开的几个小矩阵相当于用**循环**\n\t* 在有**优化矩阵计算**的情况下，直接用矩阵计算会比用循环来计算快很多[（为什么矩阵计算比循环快）](https://www.zhihu.com/question/19706331)\n\n## gate_input\n\n源码里面给到lstm\\_unit\\_layer.cpp的输入是通过h和x求完内积的gate_input，而不是比较直观地将h和x输入，然后在lstm\\_unit\\_layer.cpp里面求内积。\n\n```cpp\n // Add LSTMUnit layer to compute the cell & hidden vectors c_t and h_t.\n // Inputs: c_{t-1}, gate_input_t = (i_t, f_t, o_t, g_t), cont_t\n // Outputs: c_t, h_t\n //     [ i_t' ]\n //     [ f_t' ] := gate_input_t\n //     [ o_t' ]\n //     [ g_t' ]\n //         i_t := \\sigmoid[i_t']\n //         f_t := \\sigmoid[f_t']\n //         o_t := \\sigmoid[o_t']\n //         g_t := \\tanh[g_t']\n //         c_t := cont_t * (f_t .* c_{t-1}) + (i_t .* g_t)\n //         h_t := o_t .* \\tanh[c_t]\n {\n   LayerParameter* lstm_unit_param = net_param->add_layer();\n   lstm_unit_param->set_type(\"LSTMUnit\");\n   lstm_unit_param->add_bottom(\"c_\" + tm1s);\n   lstm_unit_param->add_bottom(\"gate_input_\" + ts);\n   lstm_unit_param->add_bottom(\"cont_\" + ts);\n   lstm_unit_param->add_top(\"c_\" + ts);\n   lstm_unit_param->add_top(\"h_\" + ts);\n   lstm_unit_param->set_name(\"unit_\" + ts);\n }\n\n```\n\nX先在外面统一求，再通过切片的方式传给unit可以理解成为了提高效率。但是为什么要将h也在外面求完内积，和x求和后以一个统一的gate_input传给unit就是出于**实现方便**的角度考虑。\n\n- 试想将求内积的操作放在unit里面，那么在**求回传梯度**的时候，由于有一个内积层，就变得非常不好求\n- 而现在的实现方式，将所有内积操作放在unit外面，使得unit求梯度回传与内积层无关，变得简单\n\n## tanh与sigmoid\n\n之前都没发现原来tanh和sigmoid之间的关系是这样的\n\n```cpp\n  template <typename Dtype>\n  inline Dtype sigmoid(Dtype x) {\n    return 1. / (1. + exp(-x));\n  }\n\n  template <typename Dtype>\n  inline Dtype tanh(Dtype x) {\n    return 2. * sigmoid(2. * x) - 1.;\n  }\n\n```\n\n进而他们的导数为\n\n$$\nsigmoid' = sigmoid * (1 - sigmoid)\\\\\\\\\ntanh' = 1 - tanh^{2}\n$$\n\n## 对cont的处理\n\ncont为0的时候需要截断操作，具体的表现为\n\n- 作为输入的h为0\n\n```cpp\n  // Add layers to flush the hidden state when beginning a new\n  // sequence, as indicated by cont_t.\n  //     h_conted_{t-1} := cont_t * h_{t-1}\n  //\n  // Normally, cont_t is binary (i.e., 0 or 1), so:\n  //     h_conted_{t-1} := h_{t-1} if cont_t == 1\n  //                       0   otherwise\n  {\n    LayerParameter* cont_h_param = net_param->add_layer();\n    cont_h_param->CopyFrom(scalar_param);\n    cont_h_param->set_name(\"h_conted_\" + tm1s);\n    cont_h_param->add_bottom(\"h_\" + tm1s);\n    cont_h_param->add_bottom(\"cont_\" + ts);\n    cont_h_param->add_top(\"h_conted_\" + tm1s);\n  }\n```\n\n- 对c不进行遗忘操作\n\n```cpp\n    //         c_t := cont_t * (f_t .* c_{t-1}) + (i_t .* g_t)\n    const Dtype f = (*flush == 0) ? 0 :\n        (*flush * sigmoid(X[1 * hidden_dim_ + d]));\n\n```\n\n同时也可以看出来，当$h_0$和$c_0$的初始值设为多少不会有影响，因为\n\n- 在时刻0的时候cont为0，$h_0$会被归0\n- 且由于f\\_t=0，c\\_{t-1}对c_{t}没影响\n\n## 收获\n\n- 看源码的时候先确定模型是**标准模型**还是**变种**\n- 实现有违直观逻辑时，考虑\n\t* **效率**\n\t* **实现便利度**","source":"_posts/caffe_4_lstm.md","raw":"---\ntitle: Caffe学习：LSTM源码阅读\ndate: 2016-08-05 10:00:46\ntags: \n  - lstm\ndescription:\n  - LSTM源码阅读，主要针对几个比较tricky的点展开\ncategories:\n  - caffe\n---\n\n## 简介\n由于之前已经有一篇RNN的源码阅读文章，这里就不再从超类讲起了，而且整体思路上LSTM跟RNN比较相似，所以本文主要是将某些比较tricky的点提出来，而不再像往常的源码阅读一样对整份源码解析。\n\n## 源码框架\n\n### 目录结构\n- **sequence_layers.hpp:**  抽象类RecurrentLayer，子类RNN和LSTM的头文件\n- **recurrent_layer.cpp:** 抽象类RecurrentLayer的定义文件\n- **lstm_layer.cpp:** 子类LSTM的定义文件\n- **lstm\\_unit\\_layer.cpp:** 子类LSTM的辅助层定义文件\n\n### 逻辑结构\n首先要说明的是这里的LSTM不是[标准LSTM](http://www.jianshu.com/p/9dc9f41f0b29/)，而是一种变种，具体参考论文[Sequence to Sequence - Video to Text](https://github.com/vsubhashini/caffe/tree/recurrent/examples/s2vt)，最关键的区别在于x和h的处理，不再是拼接，而是求和。\n\n每个for循环生成了一个像这样的net（省略cont）\n\n```\n     |---|         |---|\n c_0 |   |   c_0   |   |  c_1\n-----|   |---------|   |-----\n h_0 |   | Wh+Wx+b |   |  h_1\n-----|   |---------|   |-----\n     |---|         |---|\n   lstm_layer  lstm_unit_layer\n\n```\n\n## num_output * 4\n可以看到在lstm\\_layer.cpp中的内积层都是将num\\_output设置成num_output * 4\n\n```cpp\n  LayerParameter hidden_param;\n  hidden_param.set_type(\"InnerProduct\");\n  hidden_param.mutable_inner_product_param()->set_num_output(num_output * 4);\n  hidden_param.mutable_inner_product_param()->set_bias_term(false);\n  hidden_param.mutable_inner_product_param()->set_axis(2);\n  hidden_param.mutable_inner_product_param()->\n      mutable_weight_filler()->CopyFrom(weight_filler);\n```\n\n而这个内积层后面用作将h全连接成一个num_output * 4维的向量\n\n```cpp\n  LayerParameter* w_param = net_param->add_layer();\n  w_param->CopyFrom(hidden_param);\n  w_param->set_name(\"transform_\" + ts);\n  w_param->add_param()->set_name(\"W_hc\");\n  w_param->add_bottom(\"h_conted_\" + tm1s);\n  w_param->add_top(\"W_hc_h_\" + tm1s);\n  w_param->mutable_inner_product_param()->set_axis(2);\n```\n\n最后又可以看到，在lstm\\_unit\\_layer.cpp中，当使用到这个num_output * 4维的向量时，是把它当作4个不同意义的向量来用的\n\n\n```cpp\n  const Dtype i = sigmoid(X[d]);\n  const Dtype f = (*flush == 0) ? 0 :\n      (*flush * sigmoid(X[1 * hidden_dim_ + d]));\n  const Dtype o = sigmoid(X[2 * hidden_dim_ + d]);\n  const Dtype g = tanh(X[3 * hidden_dim_ + d]);\n```\n\n那为什么要用一种这么不直观的方式来写呢？一般来说，有违直观理解的编码方式都是**出于提高效率**考虑的。下面讨论具体原因\n\n- 创建一个layer有**开销**\n- 一个大矩阵的优化会比拆开的几个小矩阵的优化效果好，因为\n\t* 拆开的几个小矩阵相当于用**循环**\n\t* 在有**优化矩阵计算**的情况下，直接用矩阵计算会比用循环来计算快很多[（为什么矩阵计算比循环快）](https://www.zhihu.com/question/19706331)\n\n## gate_input\n\n源码里面给到lstm\\_unit\\_layer.cpp的输入是通过h和x求完内积的gate_input，而不是比较直观地将h和x输入，然后在lstm\\_unit\\_layer.cpp里面求内积。\n\n```cpp\n // Add LSTMUnit layer to compute the cell & hidden vectors c_t and h_t.\n // Inputs: c_{t-1}, gate_input_t = (i_t, f_t, o_t, g_t), cont_t\n // Outputs: c_t, h_t\n //     [ i_t' ]\n //     [ f_t' ] := gate_input_t\n //     [ o_t' ]\n //     [ g_t' ]\n //         i_t := \\sigmoid[i_t']\n //         f_t := \\sigmoid[f_t']\n //         o_t := \\sigmoid[o_t']\n //         g_t := \\tanh[g_t']\n //         c_t := cont_t * (f_t .* c_{t-1}) + (i_t .* g_t)\n //         h_t := o_t .* \\tanh[c_t]\n {\n   LayerParameter* lstm_unit_param = net_param->add_layer();\n   lstm_unit_param->set_type(\"LSTMUnit\");\n   lstm_unit_param->add_bottom(\"c_\" + tm1s);\n   lstm_unit_param->add_bottom(\"gate_input_\" + ts);\n   lstm_unit_param->add_bottom(\"cont_\" + ts);\n   lstm_unit_param->add_top(\"c_\" + ts);\n   lstm_unit_param->add_top(\"h_\" + ts);\n   lstm_unit_param->set_name(\"unit_\" + ts);\n }\n\n```\n\nX先在外面统一求，再通过切片的方式传给unit可以理解成为了提高效率。但是为什么要将h也在外面求完内积，和x求和后以一个统一的gate_input传给unit就是出于**实现方便**的角度考虑。\n\n- 试想将求内积的操作放在unit里面，那么在**求回传梯度**的时候，由于有一个内积层，就变得非常不好求\n- 而现在的实现方式，将所有内积操作放在unit外面，使得unit求梯度回传与内积层无关，变得简单\n\n## tanh与sigmoid\n\n之前都没发现原来tanh和sigmoid之间的关系是这样的\n\n```cpp\n  template <typename Dtype>\n  inline Dtype sigmoid(Dtype x) {\n    return 1. / (1. + exp(-x));\n  }\n\n  template <typename Dtype>\n  inline Dtype tanh(Dtype x) {\n    return 2. * sigmoid(2. * x) - 1.;\n  }\n\n```\n\n进而他们的导数为\n\n$$\nsigmoid' = sigmoid * (1 - sigmoid)\\\\\\\\\ntanh' = 1 - tanh^{2}\n$$\n\n## 对cont的处理\n\ncont为0的时候需要截断操作，具体的表现为\n\n- 作为输入的h为0\n\n```cpp\n  // Add layers to flush the hidden state when beginning a new\n  // sequence, as indicated by cont_t.\n  //     h_conted_{t-1} := cont_t * h_{t-1}\n  //\n  // Normally, cont_t is binary (i.e., 0 or 1), so:\n  //     h_conted_{t-1} := h_{t-1} if cont_t == 1\n  //                       0   otherwise\n  {\n    LayerParameter* cont_h_param = net_param->add_layer();\n    cont_h_param->CopyFrom(scalar_param);\n    cont_h_param->set_name(\"h_conted_\" + tm1s);\n    cont_h_param->add_bottom(\"h_\" + tm1s);\n    cont_h_param->add_bottom(\"cont_\" + ts);\n    cont_h_param->add_top(\"h_conted_\" + tm1s);\n  }\n```\n\n- 对c不进行遗忘操作\n\n```cpp\n    //         c_t := cont_t * (f_t .* c_{t-1}) + (i_t .* g_t)\n    const Dtype f = (*flush == 0) ? 0 :\n        (*flush * sigmoid(X[1 * hidden_dim_ + d]));\n\n```\n\n同时也可以看出来，当$h_0$和$c_0$的初始值设为多少不会有影响，因为\n\n- 在时刻0的时候cont为0，$h_0$会被归0\n- 且由于f\\_t=0，c\\_{t-1}对c_{t}没影响\n\n## 收获\n\n- 看源码的时候先确定模型是**标准模型**还是**变种**\n- 实现有违直观逻辑时，考虑\n\t* **效率**\n\t* **实现便利度**","slug":"caffe_4_lstm","published":1,"updated":"2024-08-13T16:03:47.848Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clzvf19160007eqwo6za4exy6","content":"<h2 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h2><p>由于之前已经有一篇RNN的源码阅读文章，这里就不再从超类讲起了，而且整体思路上LSTM跟RNN比较相似，所以本文主要是将某些比较tricky的点提出来，而不再像往常的源码阅读一样对整份源码解析。</p>\n<h2 id=\"源码框架\"><a href=\"#源码框架\" class=\"headerlink\" title=\"源码框架\"></a>源码框架</h2><h3 id=\"目录结构\"><a href=\"#目录结构\" class=\"headerlink\" title=\"目录结构\"></a>目录结构</h3><ul>\n<li><strong>sequence_layers.hpp:</strong>  抽象类RecurrentLayer，子类RNN和LSTM的头文件</li>\n<li><strong>recurrent_layer.cpp:</strong> 抽象类RecurrentLayer的定义文件</li>\n<li><strong>lstm_layer.cpp:</strong> 子类LSTM的定义文件</li>\n<li><strong>lstm_unit_layer.cpp:</strong> 子类LSTM的辅助层定义文件</li>\n</ul>\n<h3 id=\"逻辑结构\"><a href=\"#逻辑结构\" class=\"headerlink\" title=\"逻辑结构\"></a>逻辑结构</h3><p>首先要说明的是这里的LSTM不是<a href=\"http://www.jianshu.com/p/9dc9f41f0b29/\" target=\"_blank\" rel=\"external\">标准LSTM</a>，而是一种变种，具体参考论文<a href=\"https://github.com/vsubhashini/caffe/tree/recurrent/examples/s2vt\" target=\"_blank\" rel=\"external\">Sequence to Sequence - Video to Text</a>，最关键的区别在于x和h的处理，不再是拼接，而是求和。</p>\n<p>每个for循环生成了一个像这样的net（省略cont）</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">     |---|         |---|</div><div class=\"line\"> c_0 |   |   c_0   |   |  c_1</div><div class=\"line\">-----|   |---------|   |-----</div><div class=\"line\"> h_0 |   | Wh+Wx+b |   |  h_1</div><div class=\"line\">-----|   |---------|   |-----</div><div class=\"line\">     |---|         |---|</div><div class=\"line\">   lstm_layer  lstm_unit_layer</div></pre></td></tr></table></figure>\n<h2 id=\"num-output-4\"><a href=\"#num-output-4\" class=\"headerlink\" title=\"num_output * 4\"></a>num_output * 4</h2><p>可以看到在lstm_layer.cpp中的内积层都是将num_output设置成num_output * 4</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">LayerParameter hidden_param;</div><div class=\"line\">hidden_param.set_type(<span class=\"string\">\"InnerProduct\"</span>);</div><div class=\"line\">hidden_param.mutable_inner_product_param()-&gt;set_num_output(num_output * <span class=\"number\">4</span>);</div><div class=\"line\">hidden_param.mutable_inner_product_param()-&gt;set_bias_term(<span class=\"literal\">false</span>);</div><div class=\"line\">hidden_param.mutable_inner_product_param()-&gt;set_axis(<span class=\"number\">2</span>);</div><div class=\"line\">hidden_param.mutable_inner_product_param()-&gt;</div><div class=\"line\">    mutable_weight_filler()-&gt;CopyFrom(weight_filler);</div></pre></td></tr></table></figure>\n<p>而这个内积层后面用作将h全连接成一个num_output * 4维的向量</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">LayerParameter* w_param = net_param-&gt;add_layer();</div><div class=\"line\">w_param-&gt;CopyFrom(hidden_param);</div><div class=\"line\">w_param-&gt;set_name(<span class=\"string\">\"transform_\"</span> + ts);</div><div class=\"line\">w_param-&gt;add_param()-&gt;set_name(<span class=\"string\">\"W_hc\"</span>);</div><div class=\"line\">w_param-&gt;add_bottom(<span class=\"string\">\"h_conted_\"</span> + tm1s);</div><div class=\"line\">w_param-&gt;add_top(<span class=\"string\">\"W_hc_h_\"</span> + tm1s);</div><div class=\"line\">w_param-&gt;mutable_inner_product_param()-&gt;set_axis(<span class=\"number\">2</span>);</div></pre></td></tr></table></figure>\n<p>最后又可以看到，在lstm_unit_layer.cpp中，当使用到这个num_output * 4维的向量时，是把它当作4个不同意义的向量来用的</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">const</span> Dtype i = sigmoid(X[d]);</div><div class=\"line\"><span class=\"keyword\">const</span> Dtype f = (*flush == <span class=\"number\">0</span>) ? <span class=\"number\">0</span> :</div><div class=\"line\">    (*flush * sigmoid(X[<span class=\"number\">1</span> * hidden_dim_ + d]));</div><div class=\"line\"><span class=\"keyword\">const</span> Dtype o = sigmoid(X[<span class=\"number\">2</span> * hidden_dim_ + d]);</div><div class=\"line\"><span class=\"keyword\">const</span> Dtype g = <span class=\"built_in\">tanh</span>(X[<span class=\"number\">3</span> * hidden_dim_ + d]);</div></pre></td></tr></table></figure>\n<p>那为什么要用一种这么不直观的方式来写呢？一般来说，有违直观理解的编码方式都是<strong>出于提高效率</strong>考虑的。下面讨论具体原因</p>\n<ul>\n<li>创建一个layer有<strong>开销</strong></li>\n<li>一个大矩阵的优化会比拆开的几个小矩阵的优化效果好，因为<ul>\n<li>拆开的几个小矩阵相当于用<strong>循环</strong></li>\n<li>在有<strong>优化矩阵计算</strong>的情况下，直接用矩阵计算会比用循环来计算快很多<a href=\"https://www.zhihu.com/question/19706331\" target=\"_blank\" rel=\"external\">（为什么矩阵计算比循环快）</a></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"gate-input\"><a href=\"#gate-input\" class=\"headerlink\" title=\"gate_input\"></a>gate_input</h2><p>源码里面给到lstm_unit_layer.cpp的输入是通过h和x求完内积的gate_input，而不是比较直观地将h和x输入，然后在lstm_unit_layer.cpp里面求内积。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">// Add LSTMUnit layer to compute the cell &amp; hidden vectors c_t and h_t.</span></div><div class=\"line\"><span class=\"comment\">// Inputs: c_&#123;t-1&#125;, gate_input_t = (i_t, f_t, o_t, g_t), cont_t</span></div><div class=\"line\"><span class=\"comment\">// Outputs: c_t, h_t</span></div><div class=\"line\"><span class=\"comment\">//     [ i_t' ]</span></div><div class=\"line\"><span class=\"comment\">//     [ f_t' ] := gate_input_t</span></div><div class=\"line\"><span class=\"comment\">//     [ o_t' ]</span></div><div class=\"line\"><span class=\"comment\">//     [ g_t' ]</span></div><div class=\"line\"><span class=\"comment\">//         i_t := \\sigmoid[i_t']</span></div><div class=\"line\"><span class=\"comment\">//         f_t := \\sigmoid[f_t']</span></div><div class=\"line\"><span class=\"comment\">//         o_t := \\sigmoid[o_t']</span></div><div class=\"line\"><span class=\"comment\">//         g_t := \\tanh[g_t']</span></div><div class=\"line\"><span class=\"comment\">//         c_t := cont_t * (f_t .* c_&#123;t-1&#125;) + (i_t .* g_t)</span></div><div class=\"line\"><span class=\"comment\">//         h_t := o_t .* \\tanh[c_t]</span></div><div class=\"line\">&#123;</div><div class=\"line\">  LayerParameter* lstm_unit_param = net_param-&gt;add_layer();</div><div class=\"line\">  lstm_unit_param-&gt;set_type(<span class=\"string\">\"LSTMUnit\"</span>);</div><div class=\"line\">  lstm_unit_param-&gt;add_bottom(<span class=\"string\">\"c_\"</span> + tm1s);</div><div class=\"line\">  lstm_unit_param-&gt;add_bottom(<span class=\"string\">\"gate_input_\"</span> + ts);</div><div class=\"line\">  lstm_unit_param-&gt;add_bottom(<span class=\"string\">\"cont_\"</span> + ts);</div><div class=\"line\">  lstm_unit_param-&gt;add_top(<span class=\"string\">\"c_\"</span> + ts);</div><div class=\"line\">  lstm_unit_param-&gt;add_top(<span class=\"string\">\"h_\"</span> + ts);</div><div class=\"line\">  lstm_unit_param-&gt;set_name(<span class=\"string\">\"unit_\"</span> + ts);</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>X先在外面统一求，再通过切片的方式传给unit可以理解成为了提高效率。但是为什么要将h也在外面求完内积，和x求和后以一个统一的gate_input传给unit就是出于<strong>实现方便</strong>的角度考虑。</p>\n<ul>\n<li>试想将求内积的操作放在unit里面，那么在<strong>求回传梯度</strong>的时候，由于有一个内积层，就变得非常不好求</li>\n<li>而现在的实现方式，将所有内积操作放在unit外面，使得unit求梯度回传与内积层无关，变得简单</li>\n</ul>\n<h2 id=\"tanh与sigmoid\"><a href=\"#tanh与sigmoid\" class=\"headerlink\" title=\"tanh与sigmoid\"></a>tanh与sigmoid</h2><p>之前都没发现原来tanh和sigmoid之间的关系是这样的</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> Dtype&gt;</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">inline</span> Dtype <span class=\"title\">sigmoid</span><span class=\"params\">(Dtype x)</span> </span>&#123;</div><div class=\"line\">  <span class=\"keyword\">return</span> <span class=\"number\">1.</span> / (<span class=\"number\">1.</span> + <span class=\"built_in\">exp</span>(-x));</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> Dtype&gt;</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">inline</span> Dtype <span class=\"title\">tanh</span><span class=\"params\">(Dtype x)</span> </span>&#123;</div><div class=\"line\">  <span class=\"keyword\">return</span> <span class=\"number\">2.</span> * sigmoid(<span class=\"number\">2.</span> * x) - <span class=\"number\">1.</span>;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>进而他们的导数为</p>\n<p>$$<br>sigmoid’ = sigmoid * (1 - sigmoid)\\\\\\\\<br>tanh’ = 1 - tanh^{2}<br>$$</p>\n<h2 id=\"对cont的处理\"><a href=\"#对cont的处理\" class=\"headerlink\" title=\"对cont的处理\"></a>对cont的处理</h2><p>cont为0的时候需要截断操作，具体的表现为</p>\n<ul>\n<li>作为输入的h为0</li>\n</ul>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">// Add layers to flush the hidden state when beginning a new</span></div><div class=\"line\"><span class=\"comment\">// sequence, as indicated by cont_t.</span></div><div class=\"line\"><span class=\"comment\">//     h_conted_&#123;t-1&#125; := cont_t * h_&#123;t-1&#125;</span></div><div class=\"line\"><span class=\"comment\">//</span></div><div class=\"line\"><span class=\"comment\">// Normally, cont_t is binary (i.e., 0 or 1), so:</span></div><div class=\"line\"><span class=\"comment\">//     h_conted_&#123;t-1&#125; := h_&#123;t-1&#125; if cont_t == 1</span></div><div class=\"line\"><span class=\"comment\">//                       0   otherwise</span></div><div class=\"line\">&#123;</div><div class=\"line\">  LayerParameter* cont_h_param = net_param-&gt;add_layer();</div><div class=\"line\">  cont_h_param-&gt;CopyFrom(scalar_param);</div><div class=\"line\">  cont_h_param-&gt;set_name(<span class=\"string\">\"h_conted_\"</span> + tm1s);</div><div class=\"line\">  cont_h_param-&gt;add_bottom(<span class=\"string\">\"h_\"</span> + tm1s);</div><div class=\"line\">  cont_h_param-&gt;add_bottom(<span class=\"string\">\"cont_\"</span> + ts);</div><div class=\"line\">  cont_h_param-&gt;add_top(<span class=\"string\">\"h_conted_\"</span> + tm1s);</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<ul>\n<li>对c不进行遗忘操作</li>\n</ul>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">//         c_t := cont_t * (f_t .* c_&#123;t-1&#125;) + (i_t .* g_t)</span></div><div class=\"line\"><span class=\"keyword\">const</span> Dtype f = (*flush == <span class=\"number\">0</span>) ? <span class=\"number\">0</span> :</div><div class=\"line\">    (*flush * sigmoid(X[<span class=\"number\">1</span> * hidden_dim_ + d]));</div></pre></td></tr></table></figure>\n<p>同时也可以看出来，当$h_0$和$c_0$的初始值设为多少不会有影响，因为</p>\n<ul>\n<li>在时刻0的时候cont为0，$h_0$会被归0</li>\n<li>且由于f_t=0，c_{t-1}对c_{t}没影响</li>\n</ul>\n<h2 id=\"收获\"><a href=\"#收获\" class=\"headerlink\" title=\"收获\"></a>收获</h2><ul>\n<li>看源码的时候先确定模型是<strong>标准模型</strong>还是<strong>变种</strong></li>\n<li>实现有违直观逻辑时，考虑<ul>\n<li><strong>效率</strong></li>\n<li><strong>实现便利度</strong></li>\n</ul>\n</li>\n</ul>\n","excerpt":"","more":"<h2 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h2><p>由于之前已经有一篇RNN的源码阅读文章，这里就不再从超类讲起了，而且整体思路上LSTM跟RNN比较相似，所以本文主要是将某些比较tricky的点提出来，而不再像往常的源码阅读一样对整份源码解析。</p>\n<h2 id=\"源码框架\"><a href=\"#源码框架\" class=\"headerlink\" title=\"源码框架\"></a>源码框架</h2><h3 id=\"目录结构\"><a href=\"#目录结构\" class=\"headerlink\" title=\"目录结构\"></a>目录结构</h3><ul>\n<li><strong>sequence_layers.hpp:</strong>  抽象类RecurrentLayer，子类RNN和LSTM的头文件</li>\n<li><strong>recurrent_layer.cpp:</strong> 抽象类RecurrentLayer的定义文件</li>\n<li><strong>lstm_layer.cpp:</strong> 子类LSTM的定义文件</li>\n<li><strong>lstm_unit_layer.cpp:</strong> 子类LSTM的辅助层定义文件</li>\n</ul>\n<h3 id=\"逻辑结构\"><a href=\"#逻辑结构\" class=\"headerlink\" title=\"逻辑结构\"></a>逻辑结构</h3><p>首先要说明的是这里的LSTM不是<a href=\"http://www.jianshu.com/p/9dc9f41f0b29/\">标准LSTM</a>，而是一种变种，具体参考论文<a href=\"https://github.com/vsubhashini/caffe/tree/recurrent/examples/s2vt\">Sequence to Sequence - Video to Text</a>，最关键的区别在于x和h的处理，不再是拼接，而是求和。</p>\n<p>每个for循环生成了一个像这样的net（省略cont）</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">     |---|         |---|</div><div class=\"line\"> c_0 |   |   c_0   |   |  c_1</div><div class=\"line\">-----|   |---------|   |-----</div><div class=\"line\"> h_0 |   | Wh+Wx+b |   |  h_1</div><div class=\"line\">-----|   |---------|   |-----</div><div class=\"line\">     |---|         |---|</div><div class=\"line\">   lstm_layer  lstm_unit_layer</div></pre></td></tr></table></figure>\n<h2 id=\"num-output-4\"><a href=\"#num-output-4\" class=\"headerlink\" title=\"num_output * 4\"></a>num_output * 4</h2><p>可以看到在lstm_layer.cpp中的内积层都是将num_output设置成num_output * 4</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">LayerParameter hidden_param;</div><div class=\"line\">hidden_param.set_type(<span class=\"string\">\"InnerProduct\"</span>);</div><div class=\"line\">hidden_param.mutable_inner_product_param()-&gt;set_num_output(num_output * <span class=\"number\">4</span>);</div><div class=\"line\">hidden_param.mutable_inner_product_param()-&gt;set_bias_term(<span class=\"literal\">false</span>);</div><div class=\"line\">hidden_param.mutable_inner_product_param()-&gt;set_axis(<span class=\"number\">2</span>);</div><div class=\"line\">hidden_param.mutable_inner_product_param()-&gt;</div><div class=\"line\">    mutable_weight_filler()-&gt;CopyFrom(weight_filler);</div></pre></td></tr></table></figure>\n<p>而这个内积层后面用作将h全连接成一个num_output * 4维的向量</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">LayerParameter* w_param = net_param-&gt;add_layer();</div><div class=\"line\">w_param-&gt;CopyFrom(hidden_param);</div><div class=\"line\">w_param-&gt;set_name(<span class=\"string\">\"transform_\"</span> + ts);</div><div class=\"line\">w_param-&gt;add_param()-&gt;set_name(<span class=\"string\">\"W_hc\"</span>);</div><div class=\"line\">w_param-&gt;add_bottom(<span class=\"string\">\"h_conted_\"</span> + tm1s);</div><div class=\"line\">w_param-&gt;add_top(<span class=\"string\">\"W_hc_h_\"</span> + tm1s);</div><div class=\"line\">w_param-&gt;mutable_inner_product_param()-&gt;set_axis(<span class=\"number\">2</span>);</div></pre></td></tr></table></figure>\n<p>最后又可以看到，在lstm_unit_layer.cpp中，当使用到这个num_output * 4维的向量时，是把它当作4个不同意义的向量来用的</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">const</span> Dtype i = sigmoid(X[d]);</div><div class=\"line\"><span class=\"keyword\">const</span> Dtype f = (*flush == <span class=\"number\">0</span>) ? <span class=\"number\">0</span> :</div><div class=\"line\">    (*flush * sigmoid(X[<span class=\"number\">1</span> * hidden_dim_ + d]));</div><div class=\"line\"><span class=\"keyword\">const</span> Dtype o = sigmoid(X[<span class=\"number\">2</span> * hidden_dim_ + d]);</div><div class=\"line\"><span class=\"keyword\">const</span> Dtype g = <span class=\"built_in\">tanh</span>(X[<span class=\"number\">3</span> * hidden_dim_ + d]);</div></pre></td></tr></table></figure>\n<p>那为什么要用一种这么不直观的方式来写呢？一般来说，有违直观理解的编码方式都是<strong>出于提高效率</strong>考虑的。下面讨论具体原因</p>\n<ul>\n<li>创建一个layer有<strong>开销</strong></li>\n<li>一个大矩阵的优化会比拆开的几个小矩阵的优化效果好，因为<ul>\n<li>拆开的几个小矩阵相当于用<strong>循环</strong></li>\n<li>在有<strong>优化矩阵计算</strong>的情况下，直接用矩阵计算会比用循环来计算快很多<a href=\"https://www.zhihu.com/question/19706331\">（为什么矩阵计算比循环快）</a></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"gate-input\"><a href=\"#gate-input\" class=\"headerlink\" title=\"gate_input\"></a>gate_input</h2><p>源码里面给到lstm_unit_layer.cpp的输入是通过h和x求完内积的gate_input，而不是比较直观地将h和x输入，然后在lstm_unit_layer.cpp里面求内积。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">// Add LSTMUnit layer to compute the cell &amp; hidden vectors c_t and h_t.</span></div><div class=\"line\"><span class=\"comment\">// Inputs: c_&#123;t-1&#125;, gate_input_t = (i_t, f_t, o_t, g_t), cont_t</span></div><div class=\"line\"><span class=\"comment\">// Outputs: c_t, h_t</span></div><div class=\"line\"><span class=\"comment\">//     [ i_t' ]</span></div><div class=\"line\"><span class=\"comment\">//     [ f_t' ] := gate_input_t</span></div><div class=\"line\"><span class=\"comment\">//     [ o_t' ]</span></div><div class=\"line\"><span class=\"comment\">//     [ g_t' ]</span></div><div class=\"line\"><span class=\"comment\">//         i_t := \\sigmoid[i_t']</span></div><div class=\"line\"><span class=\"comment\">//         f_t := \\sigmoid[f_t']</span></div><div class=\"line\"><span class=\"comment\">//         o_t := \\sigmoid[o_t']</span></div><div class=\"line\"><span class=\"comment\">//         g_t := \\tanh[g_t']</span></div><div class=\"line\"><span class=\"comment\">//         c_t := cont_t * (f_t .* c_&#123;t-1&#125;) + (i_t .* g_t)</span></div><div class=\"line\"><span class=\"comment\">//         h_t := o_t .* \\tanh[c_t]</span></div><div class=\"line\">&#123;</div><div class=\"line\">  LayerParameter* lstm_unit_param = net_param-&gt;add_layer();</div><div class=\"line\">  lstm_unit_param-&gt;set_type(<span class=\"string\">\"LSTMUnit\"</span>);</div><div class=\"line\">  lstm_unit_param-&gt;add_bottom(<span class=\"string\">\"c_\"</span> + tm1s);</div><div class=\"line\">  lstm_unit_param-&gt;add_bottom(<span class=\"string\">\"gate_input_\"</span> + ts);</div><div class=\"line\">  lstm_unit_param-&gt;add_bottom(<span class=\"string\">\"cont_\"</span> + ts);</div><div class=\"line\">  lstm_unit_param-&gt;add_top(<span class=\"string\">\"c_\"</span> + ts);</div><div class=\"line\">  lstm_unit_param-&gt;add_top(<span class=\"string\">\"h_\"</span> + ts);</div><div class=\"line\">  lstm_unit_param-&gt;set_name(<span class=\"string\">\"unit_\"</span> + ts);</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>X先在外面统一求，再通过切片的方式传给unit可以理解成为了提高效率。但是为什么要将h也在外面求完内积，和x求和后以一个统一的gate_input传给unit就是出于<strong>实现方便</strong>的角度考虑。</p>\n<ul>\n<li>试想将求内积的操作放在unit里面，那么在<strong>求回传梯度</strong>的时候，由于有一个内积层，就变得非常不好求</li>\n<li>而现在的实现方式，将所有内积操作放在unit外面，使得unit求梯度回传与内积层无关，变得简单</li>\n</ul>\n<h2 id=\"tanh与sigmoid\"><a href=\"#tanh与sigmoid\" class=\"headerlink\" title=\"tanh与sigmoid\"></a>tanh与sigmoid</h2><p>之前都没发现原来tanh和sigmoid之间的关系是这样的</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> Dtype&gt;</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">inline</span> Dtype <span class=\"title\">sigmoid</span><span class=\"params\">(Dtype x)</span> </span>&#123;</div><div class=\"line\">  <span class=\"keyword\">return</span> <span class=\"number\">1.</span> / (<span class=\"number\">1.</span> + <span class=\"built_in\">exp</span>(-x));</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> Dtype&gt;</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">inline</span> Dtype <span class=\"title\">tanh</span><span class=\"params\">(Dtype x)</span> </span>&#123;</div><div class=\"line\">  <span class=\"keyword\">return</span> <span class=\"number\">2.</span> * sigmoid(<span class=\"number\">2.</span> * x) - <span class=\"number\">1.</span>;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>进而他们的导数为</p>\n<p>$$<br>sigmoid’ = sigmoid * (1 - sigmoid)\\\\\\\\<br>tanh’ = 1 - tanh^{2}<br>$$</p>\n<h2 id=\"对cont的处理\"><a href=\"#对cont的处理\" class=\"headerlink\" title=\"对cont的处理\"></a>对cont的处理</h2><p>cont为0的时候需要截断操作，具体的表现为</p>\n<ul>\n<li>作为输入的h为0</li>\n</ul>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">// Add layers to flush the hidden state when beginning a new</span></div><div class=\"line\"><span class=\"comment\">// sequence, as indicated by cont_t.</span></div><div class=\"line\"><span class=\"comment\">//     h_conted_&#123;t-1&#125; := cont_t * h_&#123;t-1&#125;</span></div><div class=\"line\"><span class=\"comment\">//</span></div><div class=\"line\"><span class=\"comment\">// Normally, cont_t is binary (i.e., 0 or 1), so:</span></div><div class=\"line\"><span class=\"comment\">//     h_conted_&#123;t-1&#125; := h_&#123;t-1&#125; if cont_t == 1</span></div><div class=\"line\"><span class=\"comment\">//                       0   otherwise</span></div><div class=\"line\">&#123;</div><div class=\"line\">  LayerParameter* cont_h_param = net_param-&gt;add_layer();</div><div class=\"line\">  cont_h_param-&gt;CopyFrom(scalar_param);</div><div class=\"line\">  cont_h_param-&gt;set_name(<span class=\"string\">\"h_conted_\"</span> + tm1s);</div><div class=\"line\">  cont_h_param-&gt;add_bottom(<span class=\"string\">\"h_\"</span> + tm1s);</div><div class=\"line\">  cont_h_param-&gt;add_bottom(<span class=\"string\">\"cont_\"</span> + ts);</div><div class=\"line\">  cont_h_param-&gt;add_top(<span class=\"string\">\"h_conted_\"</span> + tm1s);</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<ul>\n<li>对c不进行遗忘操作</li>\n</ul>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">//         c_t := cont_t * (f_t .* c_&#123;t-1&#125;) + (i_t .* g_t)</span></div><div class=\"line\"><span class=\"keyword\">const</span> Dtype f = (*flush == <span class=\"number\">0</span>) ? <span class=\"number\">0</span> :</div><div class=\"line\">    (*flush * sigmoid(X[<span class=\"number\">1</span> * hidden_dim_ + d]));</div></pre></td></tr></table></figure>\n<p>同时也可以看出来，当$h_0$和$c_0$的初始值设为多少不会有影响，因为</p>\n<ul>\n<li>在时刻0的时候cont为0，$h_0$会被归0</li>\n<li>且由于f_t=0，c_{t-1}对c_{t}没影响</li>\n</ul>\n<h2 id=\"收获\"><a href=\"#收获\" class=\"headerlink\" title=\"收获\"></a>收获</h2><ul>\n<li>看源码的时候先确定模型是<strong>标准模型</strong>还是<strong>变种</strong></li>\n<li>实现有违直观逻辑时，考虑<ul>\n<li><strong>效率</strong></li>\n<li><strong>实现便利度</strong></li>\n</ul>\n</li>\n</ul>\n"},{"title":"Caffe学习：s2vt_captioner.py源码阅读","date":"2016-08-17T08:15:14.000Z","description":["s2vt_captioner.py源码阅读，是LSTM进行test的python脚本"],"_content":"\n## 简介\n\ns2vt_captioner.py是使用之前训练出来的s2vt model进行caption的脚本。整体逻辑跟训练的时候差不多，但还是有一些区别，比如\n\n- decode时候LSTM2的x不再是gt，而是上一个unit生成的单词\n- 使用了python的接口调用caffe\n\n下面按照脚本的核心函数调用链来展开。\n\n## 核心函数调用链\n\n- **main:** 划分为vid chunks\n\t* **run\\_pred\\_iters:** 划分为一个个vid\n\t\t- **encode\\_video\\_frames:** 使用vid的feats进行encode\n\t\t- **run\\_pred\\_iter:** decode一个vid，返回captions（有可能多个）\n\t\t\t* **predict\\_image\\_caption:** 根据caption策略选择对应的caption方式\n\t\t\t\t- **predict\\_image\\_caption\\_beam\\_search:** 使用beam search的方式进行caption\n\t\t\t\t\t* **predict\\_single\\_word:** 生成下一个单词\n\n## main\n\n将任务划分为一个个chunk，交给run\\_pred\\_iters完成任务\n\n```py\n    fsg = fc7FrameSequenceGenerator(filenames, BUFFER_SIZE,\n          vocab_file, max_words=MAX_WORDS, align=aligned, shuffle=False,\n          pad=aligned, truncate=aligned)\n    video_gt_pairs = all_video_gt_pairs(fsg)\n\n```\n\n- **video\\_gt\\_pairs:** dict{vid: list[gt\\_sents]}\n\t* 假若没有给gt的话，list[gt\\_sents]为空\n\n\n```py\n    outputs = run_pred_iters(lstm_net, chunk, video_gt_pairs,\n                  fsg, strategies=STRATEGIES, display_vocab=vocab_list)\n      \n```\n\n- **outputs:** dict{vid: output_batch}\n\t* 每个vid有可能有多于一个caption，所以是output_batch\n- **output_batch:** list[dict{caption, prob, gt, source}]\n\t* **caption:** 预测的句子，list[word1, word2, word3, ...]\n\t* **prob:** 句子各单词发生的概率，list[prob\\_word1, prob\\_word2, prob\\_word3, ...]\n\t* **source:** 搜索句子的策略 e.g. sample / beam\n\n```py\n    text_out_types = to_text_output(outputs, vocab_list)\n\n```\n\n- **text\\_output\\_types:** dict{source\\_type: list[output string]}\n\t* **source\\_type:** 搜索句子的策略 e.g. sample / beam\n\n## run\\_pred\\_iters\n\n将chunk进一步划分为一个个vid，交给run\\_pre\\_iter完成任务\n\n```py\n    # get fc7 feature for the video\n    video_features = video_to_descriptor(video_id, fsg)\n\n```\n\nvideo\\_features: list[1 \\* FEAT\\_DIM]\n\n```py\n    # run lstm on all the frames of video before predicting\n    encode_video_frames(pred_net, video_features)\n    outputs[video_id] = \\\n        run_pred_iter(pred_net, pad_img_feature, display_vocab, strategies=strategies)\n\n```\n\ncaption的流程：\n\n1. 将frame_feats encode到LSTM\n2. 从encode好的LSTM中decode出caption\n\n## encode\\_video\\_frames\n\n```py\n    net.forward(frames_fc7=image_features, cont_sentence=cont, input_sentence=data_en,\n       stage_indicator=stage_ind)\n\n```\n\n将数据格式匹配输入，将frame\\_feats依次传入LSTM，并设置input\\_sentence为0\n\n## run\\_pred\\_iter\n\n```py\n    captions, probs = predict_image_caption(net, pad_image_feature, vocab_list, strategy=strategy)\n```\n\n对每种strategy都调用predict\\_image\\_caption来进行caption\n\n## predict\\_image\\_caption\n\n根据strategy选择对应的image\\_caption函数进行caption\n\n## predict\\_image\\_caption\\_beam\\_search\n\n使用beam\\_search的方式生成句子。所谓的beam\\_search实际上为启发式的BFS，使用了贪心的思想：即每次搜索完下一层后，只在下一层中取beam\\_size个结点进一步展开，而其余的结点则不要\n\n```py\n  beam_size = 1\t#每层保留结点数\n  beams = [[]]\t#beams: list[sentence], sentence: list[word]\n  beams_complete = 0\t#当前层有多少beam时已经eos了\n  beam_probs = [[]]\t#粒度为单词，对应beams中每个单词出现的概率\n  beam_log_probs = [0.]\t#粒度为beam(i.e. 句子)，对应beams中每个beam出现的概率(log w1*w2*w3...)\n  current_input_word = 0  # first input is EOS\n  while beams_complete < len(beams):\n    # expansions: append a new word to current beams\n    expansions = []\t#记录了下一层单词的信息\n\n\t  #每一个单词的信息如下\n      # extension : the new word\n      exp = {'prefix_beam_index': beam_index, 'extension': [ind],\n             'prob_extension': [prob], 'log_prob': extended_beam_log_prob}\n      expansions.append(exp)\n\n      #prefix_beam_index: 这个单词是由哪条beam生成出来的\n      #extension: 这个单词在字典中的index\n      #prob_extension: 产生的是这个单词的概率\n      #log_prob: 加上这个单词后，beam的概率log w1*w2*w3...*w_extension\n\n```\n\n了解了数据结构后，先看内层循环\n\n```py\n    #       0       p_w1, p_w2...  w1, w2...\n    for beam_index, beam_log_prob, beam in \\\n        zip(range(len(beams)), beam_log_probs, beams):\n      if beam:\n        previous_word = beam[-1]\n        if len(beam) >= max_length or previous_word == 0:\n          exp = {'prefix_beam_index': beam_index, 'extension': [],\n                 'prob_extension': [], 'log_prob': beam_log_prob}\n          expansions.append(exp)\n          # Don't expand this beam; it was already ended with an EOS,\n          # or is the max length.\n          continue\n      else:\n        previous_word = 0  # EOS is first word\n      if beam_size == 1:\n        probs = predict_single_word(net, pad_img_feature, previous_word)\n      else:\n        probs = predict_single_word_from_all_previous(net, pad_img_feature, beam)\n      assert len(probs.shape) == 1\n      assert probs.shape[0] == len(vocab_list)\n      # index of top beam_size prob words\n      expansion_inds = probs.argsort()[-beam_size:]\n      for ind in expansion_inds:\n        prob = probs[ind]\n        extended_beam_log_prob = beam_log_prob + math.log(prob)\n        # extension : the new word\n        exp = {'prefix_beam_index': beam_index, 'extension': [ind],\n               'prob_extension': [prob], 'log_prob': extended_beam_log_prob}\n        expansions.append(exp)\n\n```\n\n将每条beam生成的单词中，概率最高的beam\\_size个单词保存到expansions中。内层循环结束后，expansions中含有len(beams) * beam\\_size个单词的信息。接下来看外层循环\n\n```py\n  while beams_complete < len(beams):\n    # expansions: append a new word to current beams\n    expansions = []\n\n  \t#内层循环\n\n    # Sort expansions in decreasing order of probabilitf.\n    expansions.sort(key=lambda expansion: -1 * expansion['log_prob'])\n    # only reserve beam_size number of node in each BFS layer\n    expansions = expansions[:beam_size]\n    new_beams = \\\n        [beams[e['prefix_beam_index']] + e['extension'] for e in expansions]\n    new_beam_probs = \\\n        [beam_probs[e['prefix_beam_index']] + e['prob_extension'] for e in expansions]\n    beam_log_probs = [e['log_prob'] for e in expansions]\n    beams_complete = 0\n    for beam in new_beams:\n      if beam[-1] == 0 or len(beam) >= max_length: beams_complete += 1\n    beams, beam_probs = new_beams, new_beam_probs\n\n```\n\n保留expansions中概率最高的beam\\_size个单词，并用这bean\\_size个单词扩展beams，得到size为beam\\_size的new_beams。一直循环，直到beams中所有beam都结束\n\n## predict\\_single\\_word\n\n同理encode\\_video\\_frame，不过这里以pad作为frames_fc7的输入\n\n## 关于caffemodel参数不匹配的问题\n\n可以看到\n\n- 在使用s2vt\\_captioner.py进行**test**的时候，网络的模型是**没有展开的**，然后通过将每次的output作为下次的input来传递c和h\n- 然而，在**train**的时候，可以看到网络的模型是将LSTM**展开的**\n- 显然，展开的LSTM的参数会比不展开的**参数要多得多**\n- 那为什么还能用**train出来的caffemodel给test用呢？**\n\n原因就在于，train的时候，展开的各部分实际上是share同一份参数的。而实现参数共享的trick就在我一开始想不明白有什么用的`add_param()->set_name()`\n\n```cpp\n  //lstm_layer.cpp\n\n  // Add layer to transform all timesteps of x to the hidden state dimension.\n  //     W_xc_x = W_xc * x + b_c\n  //{\n  //  LayerParameter* x_transform_param = net_param->add_layer();\n  //  x_transform_param->CopyFrom(biased_hidden_param);\n  //  x_transform_param->set_name(\"x_transform\");\n    x_transform_param->add_param()->set_name(\"W_xc\");\n    x_transform_param->add_param()->set_name(\"b_c\");\n  //  x_transform_param->add_bottom(\"x\");\n  //  x_transform_param->add_top(\"W_xc_x\");\n  //}\n\n  // Add layer to compute\n  //     W_hc_h_{t-1} := W_hc * h_conted_{t-1}\n  //{\n  //  LayerParameter* w_param = net_param->add_layer();\n  //  w_param->CopyFrom(hidden_param);\n  //  w_param->set_name(\"transform_\" + ts);\n    w_param->add_param()->set_name(\"W_hc\");\n  //  w_param->add_bottom(\"h_conted_\" + tm1s);\n  //  w_param->add_top(\"W_hc_h_\" + tm1s);\n  //  w_param->mutable_inner_product_param()->set_axis(2);\n  //}\n\n```\n\n再从caffe.proto中看这个param参数的含义\n\n```proto\n//caffe.proto\n\nmessage LayerParameter {\n  // Specifies training parameters (multipliers on global learning constants,\n  // and the name and other settings used for weight sharing).\n  repeated ParamSpec param = 6;\n}\n\n```\n\n所以说，所有参数都是共享同一份的\n\n## 收获\n\n- 在脚本迭代更新，备份上一份脚本时，**备份命名要有意义**，不要只加个.bak就算了，回去一个周末就忘记了.bak1, .bak2, .bak3是哪个跟哪个了\n- debug的时候还需要考虑**环境变量**，比如PYTHONPATH这种，特别是两份相同的代码在两台机子上跑出不一样的结果\n","source":"_posts/caffe_5_s2vt_captioner.md","raw":"---\ntitle: Caffe学习：s2vt_captioner.py源码阅读\ndate: 2016-08-17 16:15:14\ntags: \n  - s2vt_captioner\ndescription:\n  - s2vt_captioner.py源码阅读，是LSTM进行test的python脚本\ncategories:\n  - caffe\n---\n\n## 简介\n\ns2vt_captioner.py是使用之前训练出来的s2vt model进行caption的脚本。整体逻辑跟训练的时候差不多，但还是有一些区别，比如\n\n- decode时候LSTM2的x不再是gt，而是上一个unit生成的单词\n- 使用了python的接口调用caffe\n\n下面按照脚本的核心函数调用链来展开。\n\n## 核心函数调用链\n\n- **main:** 划分为vid chunks\n\t* **run\\_pred\\_iters:** 划分为一个个vid\n\t\t- **encode\\_video\\_frames:** 使用vid的feats进行encode\n\t\t- **run\\_pred\\_iter:** decode一个vid，返回captions（有可能多个）\n\t\t\t* **predict\\_image\\_caption:** 根据caption策略选择对应的caption方式\n\t\t\t\t- **predict\\_image\\_caption\\_beam\\_search:** 使用beam search的方式进行caption\n\t\t\t\t\t* **predict\\_single\\_word:** 生成下一个单词\n\n## main\n\n将任务划分为一个个chunk，交给run\\_pred\\_iters完成任务\n\n```py\n    fsg = fc7FrameSequenceGenerator(filenames, BUFFER_SIZE,\n          vocab_file, max_words=MAX_WORDS, align=aligned, shuffle=False,\n          pad=aligned, truncate=aligned)\n    video_gt_pairs = all_video_gt_pairs(fsg)\n\n```\n\n- **video\\_gt\\_pairs:** dict{vid: list[gt\\_sents]}\n\t* 假若没有给gt的话，list[gt\\_sents]为空\n\n\n```py\n    outputs = run_pred_iters(lstm_net, chunk, video_gt_pairs,\n                  fsg, strategies=STRATEGIES, display_vocab=vocab_list)\n      \n```\n\n- **outputs:** dict{vid: output_batch}\n\t* 每个vid有可能有多于一个caption，所以是output_batch\n- **output_batch:** list[dict{caption, prob, gt, source}]\n\t* **caption:** 预测的句子，list[word1, word2, word3, ...]\n\t* **prob:** 句子各单词发生的概率，list[prob\\_word1, prob\\_word2, prob\\_word3, ...]\n\t* **source:** 搜索句子的策略 e.g. sample / beam\n\n```py\n    text_out_types = to_text_output(outputs, vocab_list)\n\n```\n\n- **text\\_output\\_types:** dict{source\\_type: list[output string]}\n\t* **source\\_type:** 搜索句子的策略 e.g. sample / beam\n\n## run\\_pred\\_iters\n\n将chunk进一步划分为一个个vid，交给run\\_pre\\_iter完成任务\n\n```py\n    # get fc7 feature for the video\n    video_features = video_to_descriptor(video_id, fsg)\n\n```\n\nvideo\\_features: list[1 \\* FEAT\\_DIM]\n\n```py\n    # run lstm on all the frames of video before predicting\n    encode_video_frames(pred_net, video_features)\n    outputs[video_id] = \\\n        run_pred_iter(pred_net, pad_img_feature, display_vocab, strategies=strategies)\n\n```\n\ncaption的流程：\n\n1. 将frame_feats encode到LSTM\n2. 从encode好的LSTM中decode出caption\n\n## encode\\_video\\_frames\n\n```py\n    net.forward(frames_fc7=image_features, cont_sentence=cont, input_sentence=data_en,\n       stage_indicator=stage_ind)\n\n```\n\n将数据格式匹配输入，将frame\\_feats依次传入LSTM，并设置input\\_sentence为0\n\n## run\\_pred\\_iter\n\n```py\n    captions, probs = predict_image_caption(net, pad_image_feature, vocab_list, strategy=strategy)\n```\n\n对每种strategy都调用predict\\_image\\_caption来进行caption\n\n## predict\\_image\\_caption\n\n根据strategy选择对应的image\\_caption函数进行caption\n\n## predict\\_image\\_caption\\_beam\\_search\n\n使用beam\\_search的方式生成句子。所谓的beam\\_search实际上为启发式的BFS，使用了贪心的思想：即每次搜索完下一层后，只在下一层中取beam\\_size个结点进一步展开，而其余的结点则不要\n\n```py\n  beam_size = 1\t#每层保留结点数\n  beams = [[]]\t#beams: list[sentence], sentence: list[word]\n  beams_complete = 0\t#当前层有多少beam时已经eos了\n  beam_probs = [[]]\t#粒度为单词，对应beams中每个单词出现的概率\n  beam_log_probs = [0.]\t#粒度为beam(i.e. 句子)，对应beams中每个beam出现的概率(log w1*w2*w3...)\n  current_input_word = 0  # first input is EOS\n  while beams_complete < len(beams):\n    # expansions: append a new word to current beams\n    expansions = []\t#记录了下一层单词的信息\n\n\t  #每一个单词的信息如下\n      # extension : the new word\n      exp = {'prefix_beam_index': beam_index, 'extension': [ind],\n             'prob_extension': [prob], 'log_prob': extended_beam_log_prob}\n      expansions.append(exp)\n\n      #prefix_beam_index: 这个单词是由哪条beam生成出来的\n      #extension: 这个单词在字典中的index\n      #prob_extension: 产生的是这个单词的概率\n      #log_prob: 加上这个单词后，beam的概率log w1*w2*w3...*w_extension\n\n```\n\n了解了数据结构后，先看内层循环\n\n```py\n    #       0       p_w1, p_w2...  w1, w2...\n    for beam_index, beam_log_prob, beam in \\\n        zip(range(len(beams)), beam_log_probs, beams):\n      if beam:\n        previous_word = beam[-1]\n        if len(beam) >= max_length or previous_word == 0:\n          exp = {'prefix_beam_index': beam_index, 'extension': [],\n                 'prob_extension': [], 'log_prob': beam_log_prob}\n          expansions.append(exp)\n          # Don't expand this beam; it was already ended with an EOS,\n          # or is the max length.\n          continue\n      else:\n        previous_word = 0  # EOS is first word\n      if beam_size == 1:\n        probs = predict_single_word(net, pad_img_feature, previous_word)\n      else:\n        probs = predict_single_word_from_all_previous(net, pad_img_feature, beam)\n      assert len(probs.shape) == 1\n      assert probs.shape[0] == len(vocab_list)\n      # index of top beam_size prob words\n      expansion_inds = probs.argsort()[-beam_size:]\n      for ind in expansion_inds:\n        prob = probs[ind]\n        extended_beam_log_prob = beam_log_prob + math.log(prob)\n        # extension : the new word\n        exp = {'prefix_beam_index': beam_index, 'extension': [ind],\n               'prob_extension': [prob], 'log_prob': extended_beam_log_prob}\n        expansions.append(exp)\n\n```\n\n将每条beam生成的单词中，概率最高的beam\\_size个单词保存到expansions中。内层循环结束后，expansions中含有len(beams) * beam\\_size个单词的信息。接下来看外层循环\n\n```py\n  while beams_complete < len(beams):\n    # expansions: append a new word to current beams\n    expansions = []\n\n  \t#内层循环\n\n    # Sort expansions in decreasing order of probabilitf.\n    expansions.sort(key=lambda expansion: -1 * expansion['log_prob'])\n    # only reserve beam_size number of node in each BFS layer\n    expansions = expansions[:beam_size]\n    new_beams = \\\n        [beams[e['prefix_beam_index']] + e['extension'] for e in expansions]\n    new_beam_probs = \\\n        [beam_probs[e['prefix_beam_index']] + e['prob_extension'] for e in expansions]\n    beam_log_probs = [e['log_prob'] for e in expansions]\n    beams_complete = 0\n    for beam in new_beams:\n      if beam[-1] == 0 or len(beam) >= max_length: beams_complete += 1\n    beams, beam_probs = new_beams, new_beam_probs\n\n```\n\n保留expansions中概率最高的beam\\_size个单词，并用这bean\\_size个单词扩展beams，得到size为beam\\_size的new_beams。一直循环，直到beams中所有beam都结束\n\n## predict\\_single\\_word\n\n同理encode\\_video\\_frame，不过这里以pad作为frames_fc7的输入\n\n## 关于caffemodel参数不匹配的问题\n\n可以看到\n\n- 在使用s2vt\\_captioner.py进行**test**的时候，网络的模型是**没有展开的**，然后通过将每次的output作为下次的input来传递c和h\n- 然而，在**train**的时候，可以看到网络的模型是将LSTM**展开的**\n- 显然，展开的LSTM的参数会比不展开的**参数要多得多**\n- 那为什么还能用**train出来的caffemodel给test用呢？**\n\n原因就在于，train的时候，展开的各部分实际上是share同一份参数的。而实现参数共享的trick就在我一开始想不明白有什么用的`add_param()->set_name()`\n\n```cpp\n  //lstm_layer.cpp\n\n  // Add layer to transform all timesteps of x to the hidden state dimension.\n  //     W_xc_x = W_xc * x + b_c\n  //{\n  //  LayerParameter* x_transform_param = net_param->add_layer();\n  //  x_transform_param->CopyFrom(biased_hidden_param);\n  //  x_transform_param->set_name(\"x_transform\");\n    x_transform_param->add_param()->set_name(\"W_xc\");\n    x_transform_param->add_param()->set_name(\"b_c\");\n  //  x_transform_param->add_bottom(\"x\");\n  //  x_transform_param->add_top(\"W_xc_x\");\n  //}\n\n  // Add layer to compute\n  //     W_hc_h_{t-1} := W_hc * h_conted_{t-1}\n  //{\n  //  LayerParameter* w_param = net_param->add_layer();\n  //  w_param->CopyFrom(hidden_param);\n  //  w_param->set_name(\"transform_\" + ts);\n    w_param->add_param()->set_name(\"W_hc\");\n  //  w_param->add_bottom(\"h_conted_\" + tm1s);\n  //  w_param->add_top(\"W_hc_h_\" + tm1s);\n  //  w_param->mutable_inner_product_param()->set_axis(2);\n  //}\n\n```\n\n再从caffe.proto中看这个param参数的含义\n\n```proto\n//caffe.proto\n\nmessage LayerParameter {\n  // Specifies training parameters (multipliers on global learning constants,\n  // and the name and other settings used for weight sharing).\n  repeated ParamSpec param = 6;\n}\n\n```\n\n所以说，所有参数都是共享同一份的\n\n## 收获\n\n- 在脚本迭代更新，备份上一份脚本时，**备份命名要有意义**，不要只加个.bak就算了，回去一个周末就忘记了.bak1, .bak2, .bak3是哪个跟哪个了\n- debug的时候还需要考虑**环境变量**，比如PYTHONPATH这种，特别是两份相同的代码在两台机子上跑出不一样的结果\n","slug":"caffe_5_s2vt_captioner","published":1,"updated":"2024-08-13T16:03:47.848Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clzvf191c000beqwo8ml7xkus","content":"<h2 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h2><p>s2vt_captioner.py是使用之前训练出来的s2vt model进行caption的脚本。整体逻辑跟训练的时候差不多，但还是有一些区别，比如</p>\n<ul>\n<li>decode时候LSTM2的x不再是gt，而是上一个unit生成的单词</li>\n<li>使用了python的接口调用caffe</li>\n</ul>\n<p>下面按照脚本的核心函数调用链来展开。</p>\n<h2 id=\"核心函数调用链\"><a href=\"#核心函数调用链\" class=\"headerlink\" title=\"核心函数调用链\"></a>核心函数调用链</h2><ul>\n<li><strong>main:</strong> 划分为vid chunks<ul>\n<li><strong>run_pred_iters:</strong> 划分为一个个vid<ul>\n<li><strong>encode_video_frames:</strong> 使用vid的feats进行encode</li>\n<li><strong>run_pred_iter:</strong> decode一个vid，返回captions（有可能多个）<ul>\n<li><strong>predict_image_caption:</strong> 根据caption策略选择对应的caption方式<ul>\n<li><strong>predict_image_caption_beam_search:</strong> 使用beam search的方式进行caption<ul>\n<li><strong>predict_single_word:</strong> 生成下一个单词</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"main\"><a href=\"#main\" class=\"headerlink\" title=\"main\"></a>main</h2><p>将任务划分为一个个chunk，交给run_pred_iters完成任务</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">fsg = fc7FrameSequenceGenerator(filenames, BUFFER_SIZE,</div><div class=\"line\">      vocab_file, max_words=MAX_WORDS, align=aligned, shuffle=<span class=\"keyword\">False</span>,</div><div class=\"line\">      pad=aligned, truncate=aligned)</div><div class=\"line\">video_gt_pairs = all_video_gt_pairs(fsg)</div></pre></td></tr></table></figure>\n<ul>\n<li><strong>video_gt_pairs:</strong> dict{vid: list[gt_sents]}<ul>\n<li>假若没有给gt的话，list[gt_sents]为空</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">outputs = run_pred_iters(lstm_net, chunk, video_gt_pairs,</div><div class=\"line\">              fsg, strategies=STRATEGIES, display_vocab=vocab_list)</div></pre></td></tr></table></figure>\n<ul>\n<li><strong>outputs:</strong> dict{vid: output_batch}<ul>\n<li>每个vid有可能有多于一个caption，所以是output_batch</li>\n</ul>\n</li>\n<li><strong>output_batch:</strong> list[dict{caption, prob, gt, source}]<ul>\n<li><strong>caption:</strong> 预测的句子，list[word1, word2, word3, …]</li>\n<li><strong>prob:</strong> 句子各单词发生的概率，list[prob_word1, prob_word2, prob_word3, …]</li>\n<li><strong>source:</strong> 搜索句子的策略 e.g. sample / beam</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">text_out_types = to_text_output(outputs, vocab_list)</div></pre></td></tr></table></figure>\n<ul>\n<li><strong>text_output_types:</strong> dict{source_type: list[output string]}<ul>\n<li><strong>source_type:</strong> 搜索句子的策略 e.g. sample / beam</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"run-pred-iters\"><a href=\"#run-pred-iters\" class=\"headerlink\" title=\"run_pred_iters\"></a>run_pred_iters</h2><p>将chunk进一步划分为一个个vid，交给run_pre_iter完成任务</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># get fc7 feature for the video</span></div><div class=\"line\">video_features = video_to_descriptor(video_id, fsg)</div></pre></td></tr></table></figure>\n<p>video_features: list[1 * FEAT_DIM]</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># run lstm on all the frames of video before predicting</span></div><div class=\"line\">encode_video_frames(pred_net, video_features)</div><div class=\"line\">outputs[video_id] = \\</div><div class=\"line\">    run_pred_iter(pred_net, pad_img_feature, display_vocab, strategies=strategies)</div></pre></td></tr></table></figure>\n<p>caption的流程：</p>\n<ol>\n<li>将frame_feats encode到LSTM</li>\n<li>从encode好的LSTM中decode出caption</li>\n</ol>\n<h2 id=\"encode-video-frames\"><a href=\"#encode-video-frames\" class=\"headerlink\" title=\"encode_video_frames\"></a>encode_video_frames</h2><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">net.forward(frames_fc7=image_features, cont_sentence=cont, input_sentence=data_en,</div><div class=\"line\">   stage_indicator=stage_ind)</div></pre></td></tr></table></figure>\n<p>将数据格式匹配输入，将frame_feats依次传入LSTM，并设置input_sentence为0</p>\n<h2 id=\"run-pred-iter\"><a href=\"#run-pred-iter\" class=\"headerlink\" title=\"run_pred_iter\"></a>run_pred_iter</h2><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">captions, probs = predict_image_caption(net, pad_image_feature, vocab_list, strategy=strategy)</div></pre></td></tr></table></figure>\n<p>对每种strategy都调用predict_image_caption来进行caption</p>\n<h2 id=\"predict-image-caption\"><a href=\"#predict-image-caption\" class=\"headerlink\" title=\"predict_image_caption\"></a>predict_image_caption</h2><p>根据strategy选择对应的image_caption函数进行caption</p>\n<h2 id=\"predict-image-caption-beam-search\"><a href=\"#predict-image-caption-beam-search\" class=\"headerlink\" title=\"predict_image_caption_beam_search\"></a>predict_image_caption_beam_search</h2><p>使用beam_search的方式生成句子。所谓的beam_search实际上为启发式的BFS，使用了贪心的思想：即每次搜索完下一层后，只在下一层中取beam_size个结点进一步展开，而其余的结点则不要</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div></pre></td><td class=\"code\"><pre><div class=\"line\">beam_size = <span class=\"number\">1</span>\t<span class=\"comment\">#每层保留结点数</span></div><div class=\"line\">beams = [[]]\t<span class=\"comment\">#beams: list[sentence], sentence: list[word]</span></div><div class=\"line\">beams_complete = <span class=\"number\">0</span>\t<span class=\"comment\">#当前层有多少beam时已经eos了</span></div><div class=\"line\">beam_probs = [[]]\t<span class=\"comment\">#粒度为单词，对应beams中每个单词出现的概率</span></div><div class=\"line\">beam_log_probs = [<span class=\"number\">0.</span>]\t<span class=\"comment\">#粒度为beam(i.e. 句子)，对应beams中每个beam出现的概率(log w1*w2*w3...)</span></div><div class=\"line\">current_input_word = <span class=\"number\">0</span>  <span class=\"comment\"># first input is EOS</span></div><div class=\"line\"><span class=\"keyword\">while</span> beams_complete &lt; len(beams):</div><div class=\"line\">  <span class=\"comment\"># expansions: append a new word to current beams</span></div><div class=\"line\">  expansions = []\t<span class=\"comment\">#记录了下一层单词的信息</span></div><div class=\"line\"></div><div class=\"line\"> <span class=\"comment\">#每一个单词的信息如下</span></div><div class=\"line\">    <span class=\"comment\"># extension : the new word</span></div><div class=\"line\">    exp = &#123;<span class=\"string\">'prefix_beam_index'</span>: beam_index, <span class=\"string\">'extension'</span>: [ind],</div><div class=\"line\">           <span class=\"string\">'prob_extension'</span>: [prob], <span class=\"string\">'log_prob'</span>: extended_beam_log_prob&#125;</div><div class=\"line\">    expansions.append(exp)</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">#prefix_beam_index: 这个单词是由哪条beam生成出来的</span></div><div class=\"line\">    <span class=\"comment\">#extension: 这个单词在字典中的index</span></div><div class=\"line\">    <span class=\"comment\">#prob_extension: 产生的是这个单词的概率</span></div><div class=\"line\">    <span class=\"comment\">#log_prob: 加上这个单词后，beam的概率log w1*w2*w3...*w_extension</span></div></pre></td></tr></table></figure>\n<p>了解了数据结构后，先看内层循环</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#       0       p_w1, p_w2...  w1, w2...</span></div><div class=\"line\"><span class=\"keyword\">for</span> beam_index, beam_log_prob, beam <span class=\"keyword\">in</span> \\</div><div class=\"line\">    zip(range(len(beams)), beam_log_probs, beams):</div><div class=\"line\">  <span class=\"keyword\">if</span> beam:</div><div class=\"line\">    previous_word = beam[<span class=\"number\">-1</span>]</div><div class=\"line\">    <span class=\"keyword\">if</span> len(beam) &gt;= max_length <span class=\"keyword\">or</span> previous_word == <span class=\"number\">0</span>:</div><div class=\"line\">      exp = &#123;<span class=\"string\">'prefix_beam_index'</span>: beam_index, <span class=\"string\">'extension'</span>: [],</div><div class=\"line\">             <span class=\"string\">'prob_extension'</span>: [], <span class=\"string\">'log_prob'</span>: beam_log_prob&#125;</div><div class=\"line\">      expansions.append(exp)</div><div class=\"line\">      <span class=\"comment\"># Don't expand this beam; it was already ended with an EOS,</span></div><div class=\"line\">      <span class=\"comment\"># or is the max length.</span></div><div class=\"line\">      <span class=\"keyword\">continue</span></div><div class=\"line\">  <span class=\"keyword\">else</span>:</div><div class=\"line\">    previous_word = <span class=\"number\">0</span>  <span class=\"comment\"># EOS is first word</span></div><div class=\"line\">  <span class=\"keyword\">if</span> beam_size == <span class=\"number\">1</span>:</div><div class=\"line\">    probs = predict_single_word(net, pad_img_feature, previous_word)</div><div class=\"line\">  <span class=\"keyword\">else</span>:</div><div class=\"line\">    probs = predict_single_word_from_all_previous(net, pad_img_feature, beam)</div><div class=\"line\">  <span class=\"keyword\">assert</span> len(probs.shape) == <span class=\"number\">1</span></div><div class=\"line\">  <span class=\"keyword\">assert</span> probs.shape[<span class=\"number\">0</span>] == len(vocab_list)</div><div class=\"line\">  <span class=\"comment\"># index of top beam_size prob words</span></div><div class=\"line\">  expansion_inds = probs.argsort()[-beam_size:]</div><div class=\"line\">  <span class=\"keyword\">for</span> ind <span class=\"keyword\">in</span> expansion_inds:</div><div class=\"line\">    prob = probs[ind]</div><div class=\"line\">    extended_beam_log_prob = beam_log_prob + math.log(prob)</div><div class=\"line\">    <span class=\"comment\"># extension : the new word</span></div><div class=\"line\">    exp = &#123;<span class=\"string\">'prefix_beam_index'</span>: beam_index, <span class=\"string\">'extension'</span>: [ind],</div><div class=\"line\">           <span class=\"string\">'prob_extension'</span>: [prob], <span class=\"string\">'log_prob'</span>: extended_beam_log_prob&#125;</div><div class=\"line\">    expansions.append(exp)</div></pre></td></tr></table></figure>\n<p>将每条beam生成的单词中，概率最高的beam_size个单词保存到expansions中。内层循环结束后，expansions中含有len(beams) * beam_size个单词的信息。接下来看外层循环</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">while</span> beams_complete &lt; len(beams):</div><div class=\"line\">  <span class=\"comment\"># expansions: append a new word to current beams</span></div><div class=\"line\">  expansions = []</div><div class=\"line\"></div><div class=\"line\">\t<span class=\"comment\">#内层循环</span></div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\"># Sort expansions in decreasing order of probabilitf.</span></div><div class=\"line\">  expansions.sort(key=<span class=\"keyword\">lambda</span> expansion: <span class=\"number\">-1</span> * expansion[<span class=\"string\">'log_prob'</span>])</div><div class=\"line\">  <span class=\"comment\"># only reserve beam_size number of node in each BFS layer</span></div><div class=\"line\">  expansions = expansions[:beam_size]</div><div class=\"line\">  new_beams = \\</div><div class=\"line\">      [beams[e[<span class=\"string\">'prefix_beam_index'</span>]] + e[<span class=\"string\">'extension'</span>] <span class=\"keyword\">for</span> e <span class=\"keyword\">in</span> expansions]</div><div class=\"line\">  new_beam_probs = \\</div><div class=\"line\">      [beam_probs[e[<span class=\"string\">'prefix_beam_index'</span>]] + e[<span class=\"string\">'prob_extension'</span>] <span class=\"keyword\">for</span> e <span class=\"keyword\">in</span> expansions]</div><div class=\"line\">  beam_log_probs = [e[<span class=\"string\">'log_prob'</span>] <span class=\"keyword\">for</span> e <span class=\"keyword\">in</span> expansions]</div><div class=\"line\">  beams_complete = <span class=\"number\">0</span></div><div class=\"line\">  <span class=\"keyword\">for</span> beam <span class=\"keyword\">in</span> new_beams:</div><div class=\"line\">    <span class=\"keyword\">if</span> beam[<span class=\"number\">-1</span>] == <span class=\"number\">0</span> <span class=\"keyword\">or</span> len(beam) &gt;= max_length: beams_complete += <span class=\"number\">1</span></div><div class=\"line\">  beams, beam_probs = new_beams, new_beam_probs</div></pre></td></tr></table></figure>\n<p>保留expansions中概率最高的beam_size个单词，并用这bean_size个单词扩展beams，得到size为beam_size的new_beams。一直循环，直到beams中所有beam都结束</p>\n<h2 id=\"predict-single-word\"><a href=\"#predict-single-word\" class=\"headerlink\" title=\"predict_single_word\"></a>predict_single_word</h2><p>同理encode_video_frame，不过这里以pad作为frames_fc7的输入</p>\n<h2 id=\"关于caffemodel参数不匹配的问题\"><a href=\"#关于caffemodel参数不匹配的问题\" class=\"headerlink\" title=\"关于caffemodel参数不匹配的问题\"></a>关于caffemodel参数不匹配的问题</h2><p>可以看到</p>\n<ul>\n<li>在使用s2vt_captioner.py进行<strong>test</strong>的时候，网络的模型是<strong>没有展开的</strong>，然后通过将每次的output作为下次的input来传递c和h</li>\n<li>然而，在<strong>train</strong>的时候，可以看到网络的模型是将LSTM<strong>展开的</strong></li>\n<li>显然，展开的LSTM的参数会比不展开的<strong>参数要多得多</strong></li>\n<li>那为什么还能用<strong>train出来的caffemodel给test用呢？</strong></li>\n</ul>\n<p>原因就在于，train的时候，展开的各部分实际上是share同一份参数的。而实现参数共享的trick就在我一开始想不明白有什么用的<code>add_param()-&gt;set_name()</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">//lstm_layer.cpp</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">// Add layer to transform all timesteps of x to the hidden state dimension.</span></div><div class=\"line\"><span class=\"comment\">//     W_xc_x = W_xc * x + b_c</span></div><div class=\"line\"><span class=\"comment\">//&#123;</span></div><div class=\"line\"><span class=\"comment\">//  LayerParameter* x_transform_param = net_param-&gt;add_layer();</span></div><div class=\"line\"><span class=\"comment\">//  x_transform_param-&gt;CopyFrom(biased_hidden_param);</span></div><div class=\"line\"><span class=\"comment\">//  x_transform_param-&gt;set_name(\"x_transform\");</span></div><div class=\"line\">  x_transform_param-&gt;add_param()-&gt;set_name(<span class=\"string\">\"W_xc\"</span>);</div><div class=\"line\">  x_transform_param-&gt;add_param()-&gt;set_name(<span class=\"string\">\"b_c\"</span>);</div><div class=\"line\"><span class=\"comment\">//  x_transform_param-&gt;add_bottom(\"x\");</span></div><div class=\"line\"><span class=\"comment\">//  x_transform_param-&gt;add_top(\"W_xc_x\");</span></div><div class=\"line\"><span class=\"comment\">//&#125;</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">// Add layer to compute</span></div><div class=\"line\"><span class=\"comment\">//     W_hc_h_&#123;t-1&#125; := W_hc * h_conted_&#123;t-1&#125;</span></div><div class=\"line\"><span class=\"comment\">//&#123;</span></div><div class=\"line\"><span class=\"comment\">//  LayerParameter* w_param = net_param-&gt;add_layer();</span></div><div class=\"line\"><span class=\"comment\">//  w_param-&gt;CopyFrom(hidden_param);</span></div><div class=\"line\"><span class=\"comment\">//  w_param-&gt;set_name(\"transform_\" + ts);</span></div><div class=\"line\">  w_param-&gt;add_param()-&gt;set_name(<span class=\"string\">\"W_hc\"</span>);</div><div class=\"line\"><span class=\"comment\">//  w_param-&gt;add_bottom(\"h_conted_\" + tm1s);</span></div><div class=\"line\"><span class=\"comment\">//  w_param-&gt;add_top(\"W_hc_h_\" + tm1s);</span></div><div class=\"line\"><span class=\"comment\">//  w_param-&gt;mutable_inner_product_param()-&gt;set_axis(2);</span></div><div class=\"line\"><span class=\"comment\">//&#125;</span></div></pre></td></tr></table></figure>\n<p>再从caffe.proto中看这个param参数的含义</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">//caffe.proto</div><div class=\"line\"></div><div class=\"line\">message LayerParameter &#123;</div><div class=\"line\">  // Specifies training parameters (multipliers on global learning constants,</div><div class=\"line\">  // and the name and other settings used for weight sharing).</div><div class=\"line\">  repeated ParamSpec param = 6;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>所以说，所有参数都是共享同一份的</p>\n<h2 id=\"收获\"><a href=\"#收获\" class=\"headerlink\" title=\"收获\"></a>收获</h2><ul>\n<li>在脚本迭代更新，备份上一份脚本时，<strong>备份命名要有意义</strong>，不要只加个.bak就算了，回去一个周末就忘记了.bak1, .bak2, .bak3是哪个跟哪个了</li>\n<li>debug的时候还需要考虑<strong>环境变量</strong>，比如PYTHONPATH这种，特别是两份相同的代码在两台机子上跑出不一样的结果</li>\n</ul>\n","excerpt":"","more":"<h2 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h2><p>s2vt_captioner.py是使用之前训练出来的s2vt model进行caption的脚本。整体逻辑跟训练的时候差不多，但还是有一些区别，比如</p>\n<ul>\n<li>decode时候LSTM2的x不再是gt，而是上一个unit生成的单词</li>\n<li>使用了python的接口调用caffe</li>\n</ul>\n<p>下面按照脚本的核心函数调用链来展开。</p>\n<h2 id=\"核心函数调用链\"><a href=\"#核心函数调用链\" class=\"headerlink\" title=\"核心函数调用链\"></a>核心函数调用链</h2><ul>\n<li><strong>main:</strong> 划分为vid chunks<ul>\n<li><strong>run_pred_iters:</strong> 划分为一个个vid<ul>\n<li><strong>encode_video_frames:</strong> 使用vid的feats进行encode</li>\n<li><strong>run_pred_iter:</strong> decode一个vid，返回captions（有可能多个）<ul>\n<li><strong>predict_image_caption:</strong> 根据caption策略选择对应的caption方式<ul>\n<li><strong>predict_image_caption_beam_search:</strong> 使用beam search的方式进行caption<ul>\n<li><strong>predict_single_word:</strong> 生成下一个单词</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"main\"><a href=\"#main\" class=\"headerlink\" title=\"main\"></a>main</h2><p>将任务划分为一个个chunk，交给run_pred_iters完成任务</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">fsg = fc7FrameSequenceGenerator(filenames, BUFFER_SIZE,</div><div class=\"line\">      vocab_file, max_words=MAX_WORDS, align=aligned, shuffle=<span class=\"keyword\">False</span>,</div><div class=\"line\">      pad=aligned, truncate=aligned)</div><div class=\"line\">video_gt_pairs = all_video_gt_pairs(fsg)</div></pre></td></tr></table></figure>\n<ul>\n<li><strong>video_gt_pairs:</strong> dict{vid: list[gt_sents]}<ul>\n<li>假若没有给gt的话，list[gt_sents]为空</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">outputs = run_pred_iters(lstm_net, chunk, video_gt_pairs,</div><div class=\"line\">              fsg, strategies=STRATEGIES, display_vocab=vocab_list)</div></pre></td></tr></table></figure>\n<ul>\n<li><strong>outputs:</strong> dict{vid: output_batch}<ul>\n<li>每个vid有可能有多于一个caption，所以是output_batch</li>\n</ul>\n</li>\n<li><strong>output_batch:</strong> list[dict{caption, prob, gt, source}]<ul>\n<li><strong>caption:</strong> 预测的句子，list[word1, word2, word3, …]</li>\n<li><strong>prob:</strong> 句子各单词发生的概率，list[prob_word1, prob_word2, prob_word3, …]</li>\n<li><strong>source:</strong> 搜索句子的策略 e.g. sample / beam</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">text_out_types = to_text_output(outputs, vocab_list)</div></pre></td></tr></table></figure>\n<ul>\n<li><strong>text_output_types:</strong> dict{source_type: list[output string]}<ul>\n<li><strong>source_type:</strong> 搜索句子的策略 e.g. sample / beam</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"run-pred-iters\"><a href=\"#run-pred-iters\" class=\"headerlink\" title=\"run_pred_iters\"></a>run_pred_iters</h2><p>将chunk进一步划分为一个个vid，交给run_pre_iter完成任务</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># get fc7 feature for the video</span></div><div class=\"line\">video_features = video_to_descriptor(video_id, fsg)</div></pre></td></tr></table></figure>\n<p>video_features: list[1 * FEAT_DIM]</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># run lstm on all the frames of video before predicting</span></div><div class=\"line\">encode_video_frames(pred_net, video_features)</div><div class=\"line\">outputs[video_id] = \\</div><div class=\"line\">    run_pred_iter(pred_net, pad_img_feature, display_vocab, strategies=strategies)</div></pre></td></tr></table></figure>\n<p>caption的流程：</p>\n<ol>\n<li>将frame_feats encode到LSTM</li>\n<li>从encode好的LSTM中decode出caption</li>\n</ol>\n<h2 id=\"encode-video-frames\"><a href=\"#encode-video-frames\" class=\"headerlink\" title=\"encode_video_frames\"></a>encode_video_frames</h2><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">net.forward(frames_fc7=image_features, cont_sentence=cont, input_sentence=data_en,</div><div class=\"line\">   stage_indicator=stage_ind)</div></pre></td></tr></table></figure>\n<p>将数据格式匹配输入，将frame_feats依次传入LSTM，并设置input_sentence为0</p>\n<h2 id=\"run-pred-iter\"><a href=\"#run-pred-iter\" class=\"headerlink\" title=\"run_pred_iter\"></a>run_pred_iter</h2><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">captions, probs = predict_image_caption(net, pad_image_feature, vocab_list, strategy=strategy)</div></pre></td></tr></table></figure>\n<p>对每种strategy都调用predict_image_caption来进行caption</p>\n<h2 id=\"predict-image-caption\"><a href=\"#predict-image-caption\" class=\"headerlink\" title=\"predict_image_caption\"></a>predict_image_caption</h2><p>根据strategy选择对应的image_caption函数进行caption</p>\n<h2 id=\"predict-image-caption-beam-search\"><a href=\"#predict-image-caption-beam-search\" class=\"headerlink\" title=\"predict_image_caption_beam_search\"></a>predict_image_caption_beam_search</h2><p>使用beam_search的方式生成句子。所谓的beam_search实际上为启发式的BFS，使用了贪心的思想：即每次搜索完下一层后，只在下一层中取beam_size个结点进一步展开，而其余的结点则不要</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div></pre></td><td class=\"code\"><pre><div class=\"line\">beam_size = <span class=\"number\">1</span>\t<span class=\"comment\">#每层保留结点数</span></div><div class=\"line\">beams = [[]]\t<span class=\"comment\">#beams: list[sentence], sentence: list[word]</span></div><div class=\"line\">beams_complete = <span class=\"number\">0</span>\t<span class=\"comment\">#当前层有多少beam时已经eos了</span></div><div class=\"line\">beam_probs = [[]]\t<span class=\"comment\">#粒度为单词，对应beams中每个单词出现的概率</span></div><div class=\"line\">beam_log_probs = [<span class=\"number\">0.</span>]\t<span class=\"comment\">#粒度为beam(i.e. 句子)，对应beams中每个beam出现的概率(log w1*w2*w3...)</span></div><div class=\"line\">current_input_word = <span class=\"number\">0</span>  <span class=\"comment\"># first input is EOS</span></div><div class=\"line\"><span class=\"keyword\">while</span> beams_complete &lt; len(beams):</div><div class=\"line\">  <span class=\"comment\"># expansions: append a new word to current beams</span></div><div class=\"line\">  expansions = []\t<span class=\"comment\">#记录了下一层单词的信息</span></div><div class=\"line\"></div><div class=\"line\"> <span class=\"comment\">#每一个单词的信息如下</span></div><div class=\"line\">    <span class=\"comment\"># extension : the new word</span></div><div class=\"line\">    exp = &#123;<span class=\"string\">'prefix_beam_index'</span>: beam_index, <span class=\"string\">'extension'</span>: [ind],</div><div class=\"line\">           <span class=\"string\">'prob_extension'</span>: [prob], <span class=\"string\">'log_prob'</span>: extended_beam_log_prob&#125;</div><div class=\"line\">    expansions.append(exp)</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">#prefix_beam_index: 这个单词是由哪条beam生成出来的</span></div><div class=\"line\">    <span class=\"comment\">#extension: 这个单词在字典中的index</span></div><div class=\"line\">    <span class=\"comment\">#prob_extension: 产生的是这个单词的概率</span></div><div class=\"line\">    <span class=\"comment\">#log_prob: 加上这个单词后，beam的概率log w1*w2*w3...*w_extension</span></div></pre></td></tr></table></figure>\n<p>了解了数据结构后，先看内层循环</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#       0       p_w1, p_w2...  w1, w2...</span></div><div class=\"line\"><span class=\"keyword\">for</span> beam_index, beam_log_prob, beam <span class=\"keyword\">in</span> \\</div><div class=\"line\">    zip(range(len(beams)), beam_log_probs, beams):</div><div class=\"line\">  <span class=\"keyword\">if</span> beam:</div><div class=\"line\">    previous_word = beam[<span class=\"number\">-1</span>]</div><div class=\"line\">    <span class=\"keyword\">if</span> len(beam) &gt;= max_length <span class=\"keyword\">or</span> previous_word == <span class=\"number\">0</span>:</div><div class=\"line\">      exp = &#123;<span class=\"string\">'prefix_beam_index'</span>: beam_index, <span class=\"string\">'extension'</span>: [],</div><div class=\"line\">             <span class=\"string\">'prob_extension'</span>: [], <span class=\"string\">'log_prob'</span>: beam_log_prob&#125;</div><div class=\"line\">      expansions.append(exp)</div><div class=\"line\">      <span class=\"comment\"># Don't expand this beam; it was already ended with an EOS,</span></div><div class=\"line\">      <span class=\"comment\"># or is the max length.</span></div><div class=\"line\">      <span class=\"keyword\">continue</span></div><div class=\"line\">  <span class=\"keyword\">else</span>:</div><div class=\"line\">    previous_word = <span class=\"number\">0</span>  <span class=\"comment\"># EOS is first word</span></div><div class=\"line\">  <span class=\"keyword\">if</span> beam_size == <span class=\"number\">1</span>:</div><div class=\"line\">    probs = predict_single_word(net, pad_img_feature, previous_word)</div><div class=\"line\">  <span class=\"keyword\">else</span>:</div><div class=\"line\">    probs = predict_single_word_from_all_previous(net, pad_img_feature, beam)</div><div class=\"line\">  <span class=\"keyword\">assert</span> len(probs.shape) == <span class=\"number\">1</span></div><div class=\"line\">  <span class=\"keyword\">assert</span> probs.shape[<span class=\"number\">0</span>] == len(vocab_list)</div><div class=\"line\">  <span class=\"comment\"># index of top beam_size prob words</span></div><div class=\"line\">  expansion_inds = probs.argsort()[-beam_size:]</div><div class=\"line\">  <span class=\"keyword\">for</span> ind <span class=\"keyword\">in</span> expansion_inds:</div><div class=\"line\">    prob = probs[ind]</div><div class=\"line\">    extended_beam_log_prob = beam_log_prob + math.log(prob)</div><div class=\"line\">    <span class=\"comment\"># extension : the new word</span></div><div class=\"line\">    exp = &#123;<span class=\"string\">'prefix_beam_index'</span>: beam_index, <span class=\"string\">'extension'</span>: [ind],</div><div class=\"line\">           <span class=\"string\">'prob_extension'</span>: [prob], <span class=\"string\">'log_prob'</span>: extended_beam_log_prob&#125;</div><div class=\"line\">    expansions.append(exp)</div></pre></td></tr></table></figure>\n<p>将每条beam生成的单词中，概率最高的beam_size个单词保存到expansions中。内层循环结束后，expansions中含有len(beams) * beam_size个单词的信息。接下来看外层循环</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">while</span> beams_complete &lt; len(beams):</div><div class=\"line\">  <span class=\"comment\"># expansions: append a new word to current beams</span></div><div class=\"line\">  expansions = []</div><div class=\"line\"></div><div class=\"line\">\t<span class=\"comment\">#内层循环</span></div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\"># Sort expansions in decreasing order of probabilitf.</span></div><div class=\"line\">  expansions.sort(key=<span class=\"keyword\">lambda</span> expansion: <span class=\"number\">-1</span> * expansion[<span class=\"string\">'log_prob'</span>])</div><div class=\"line\">  <span class=\"comment\"># only reserve beam_size number of node in each BFS layer</span></div><div class=\"line\">  expansions = expansions[:beam_size]</div><div class=\"line\">  new_beams = \\</div><div class=\"line\">      [beams[e[<span class=\"string\">'prefix_beam_index'</span>]] + e[<span class=\"string\">'extension'</span>] <span class=\"keyword\">for</span> e <span class=\"keyword\">in</span> expansions]</div><div class=\"line\">  new_beam_probs = \\</div><div class=\"line\">      [beam_probs[e[<span class=\"string\">'prefix_beam_index'</span>]] + e[<span class=\"string\">'prob_extension'</span>] <span class=\"keyword\">for</span> e <span class=\"keyword\">in</span> expansions]</div><div class=\"line\">  beam_log_probs = [e[<span class=\"string\">'log_prob'</span>] <span class=\"keyword\">for</span> e <span class=\"keyword\">in</span> expansions]</div><div class=\"line\">  beams_complete = <span class=\"number\">0</span></div><div class=\"line\">  <span class=\"keyword\">for</span> beam <span class=\"keyword\">in</span> new_beams:</div><div class=\"line\">    <span class=\"keyword\">if</span> beam[<span class=\"number\">-1</span>] == <span class=\"number\">0</span> <span class=\"keyword\">or</span> len(beam) &gt;= max_length: beams_complete += <span class=\"number\">1</span></div><div class=\"line\">  beams, beam_probs = new_beams, new_beam_probs</div></pre></td></tr></table></figure>\n<p>保留expansions中概率最高的beam_size个单词，并用这bean_size个单词扩展beams，得到size为beam_size的new_beams。一直循环，直到beams中所有beam都结束</p>\n<h2 id=\"predict-single-word\"><a href=\"#predict-single-word\" class=\"headerlink\" title=\"predict_single_word\"></a>predict_single_word</h2><p>同理encode_video_frame，不过这里以pad作为frames_fc7的输入</p>\n<h2 id=\"关于caffemodel参数不匹配的问题\"><a href=\"#关于caffemodel参数不匹配的问题\" class=\"headerlink\" title=\"关于caffemodel参数不匹配的问题\"></a>关于caffemodel参数不匹配的问题</h2><p>可以看到</p>\n<ul>\n<li>在使用s2vt_captioner.py进行<strong>test</strong>的时候，网络的模型是<strong>没有展开的</strong>，然后通过将每次的output作为下次的input来传递c和h</li>\n<li>然而，在<strong>train</strong>的时候，可以看到网络的模型是将LSTM<strong>展开的</strong></li>\n<li>显然，展开的LSTM的参数会比不展开的<strong>参数要多得多</strong></li>\n<li>那为什么还能用<strong>train出来的caffemodel给test用呢？</strong></li>\n</ul>\n<p>原因就在于，train的时候，展开的各部分实际上是share同一份参数的。而实现参数共享的trick就在我一开始想不明白有什么用的<code>add_param()-&gt;set_name()</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">//lstm_layer.cpp</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">// Add layer to transform all timesteps of x to the hidden state dimension.</span></div><div class=\"line\"><span class=\"comment\">//     W_xc_x = W_xc * x + b_c</span></div><div class=\"line\"><span class=\"comment\">//&#123;</span></div><div class=\"line\"><span class=\"comment\">//  LayerParameter* x_transform_param = net_param-&gt;add_layer();</span></div><div class=\"line\"><span class=\"comment\">//  x_transform_param-&gt;CopyFrom(biased_hidden_param);</span></div><div class=\"line\"><span class=\"comment\">//  x_transform_param-&gt;set_name(\"x_transform\");</span></div><div class=\"line\">  x_transform_param-&gt;add_param()-&gt;set_name(<span class=\"string\">\"W_xc\"</span>);</div><div class=\"line\">  x_transform_param-&gt;add_param()-&gt;set_name(<span class=\"string\">\"b_c\"</span>);</div><div class=\"line\"><span class=\"comment\">//  x_transform_param-&gt;add_bottom(\"x\");</span></div><div class=\"line\"><span class=\"comment\">//  x_transform_param-&gt;add_top(\"W_xc_x\");</span></div><div class=\"line\"><span class=\"comment\">//&#125;</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">// Add layer to compute</span></div><div class=\"line\"><span class=\"comment\">//     W_hc_h_&#123;t-1&#125; := W_hc * h_conted_&#123;t-1&#125;</span></div><div class=\"line\"><span class=\"comment\">//&#123;</span></div><div class=\"line\"><span class=\"comment\">//  LayerParameter* w_param = net_param-&gt;add_layer();</span></div><div class=\"line\"><span class=\"comment\">//  w_param-&gt;CopyFrom(hidden_param);</span></div><div class=\"line\"><span class=\"comment\">//  w_param-&gt;set_name(\"transform_\" + ts);</span></div><div class=\"line\">  w_param-&gt;add_param()-&gt;set_name(<span class=\"string\">\"W_hc\"</span>);</div><div class=\"line\"><span class=\"comment\">//  w_param-&gt;add_bottom(\"h_conted_\" + tm1s);</span></div><div class=\"line\"><span class=\"comment\">//  w_param-&gt;add_top(\"W_hc_h_\" + tm1s);</span></div><div class=\"line\"><span class=\"comment\">//  w_param-&gt;mutable_inner_product_param()-&gt;set_axis(2);</span></div><div class=\"line\"><span class=\"comment\">//&#125;</span></div></pre></td></tr></table></figure>\n<p>再从caffe.proto中看这个param参数的含义</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">//caffe.proto</div><div class=\"line\"></div><div class=\"line\">message LayerParameter &#123;</div><div class=\"line\">  // Specifies training parameters (multipliers on global learning constants,</div><div class=\"line\">  // and the name and other settings used for weight sharing).</div><div class=\"line\">  repeated ParamSpec param = 6;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>所以说，所有参数都是共享同一份的</p>\n<h2 id=\"收获\"><a href=\"#收获\" class=\"headerlink\" title=\"收获\"></a>收获</h2><ul>\n<li>在脚本迭代更新，备份上一份脚本时，<strong>备份命名要有意义</strong>，不要只加个.bak就算了，回去一个周末就忘记了.bak1, .bak2, .bak3是哪个跟哪个了</li>\n<li>debug的时候还需要考虑<strong>环境变量</strong>，比如PYTHONPATH这种，特别是两份相同的代码在两台机子上跑出不一样的结果</li>\n</ul>\n"},{"title":"论文笔记《ImageNet Classification with Deep Convolutional Neural Networks》","date":"2016-07-01T11:10:02.000Z","description":["AlexNet介绍，包括其架构，如何加快收敛，怎样加强泛化能力以及如何评估模型"],"_content":"\n第一次阅读论文，没有什么阅读技巧，再加上对CNN[(CNN解析)](http://www.moonshile.com/post/juan-ji-shen-jing-wang-luo-quan-mian-jie-xi)没有什么概念，读了几次才大概明白讲的是什么。\n\n## The Architecture\n\n1. **ReLU Nonlinearity**\n\t- **目的：** 加快收敛速度\n\t- **手段：** 使用Rectified Linear Units(ReLUs)作为神经元。即采用$$f(x) = max(0, x)$$作为激活函数\n\t- **原理：** 一般使用的激活函数$$f(x) = tanh(x) \\\\\\\\ f(x) = \\frac{1}{1 + e^{-x} }$$具有饱和(saturating)的特性，即导数在越接近目标的时候越小[(原理参考)](http://zhangliliang.com/2014/07/01/paper-note-alexnet-nips2012/)。当使用梯度下降的方法时，步长由学习率以及导数决定，导数太小会导致步长太小，收敛会慢。ReLU对于大于0部分导数恒为1，所以能加快收敛。\n\n\n2. **Training on Multiple GPUs**\n\t- **目的：** 加快训练速度\n\n3. **Local Response Normalization**\n\t- **目的：** 加强泛化能力\n\t- **手段：** 神经元受附近神经元抑制，各神经元的输出为$$b_i = \\frac{a_i}{ {(k+\\alpha\\sum{a_j^2})}^\\beta}$$其中$b_i$为神经元i的输出，$a_i$为神经元i的输入\n\t- **原理：** 模拟神经元间的抑制作用\n\n4. **Overlapping Pooling**\n\t- **目的：** 加强泛化能力\n\t- **手段：** pooling的时候stride < filter size，重叠地pooling\n\t- **原理：** 实验性结果\n\n## Reduce Overfitting\n\n1. **Data Augmentation**\n\t- **目的：** 加强泛化能力\n\t- **手段1：** 随机裁剪，将原来256×256的图片随机裁剪为224×224,并且允许水平翻转，则增加了$(256-224)^2*2$倍的样本量。（裁剪的时候一定是要连片的，不能是随机取的）\n\t- **手段2：** PCA，这个部分不太懂原理。[(原理参考)](http://zhangliliang.com/2014/07/01/paper-note-alexnet-nips2012/)\n\t- **原理：** 增大样本数增强泛化能力。裁剪，旋转，滤镜并不影响图片内容，但是对于机器来说就是完全不同的样本\n\n2. **Dropout**\n\t- **目的：** 加强泛化能力\n\t- **手段：** 随机disable神经元\n\t- **原理：** 隐式多模型，迫使模型要学习更robust的feature，抓住核心特征\n\n## Qulitative Evaluations\n\n1. **准确性：** 对于每张图片，给出CNN分类结果前5的类别及概率\n2. **一致性：** 对于每张照片，给出CNN提取特征相似的照片 e.g. 图片$i_1$提取的特征为$f_1$，找特征跟$f_1$相似的$i_k$，看下是不是同一个物体\n","source":"_posts/imagenet.md","raw":"---\ntitle: 论文笔记《ImageNet Classification with Deep Convolutional Neural Networks》\ndate: 2016-07-01 19:10:02\ntags: \n  - AlexNet\ndescription:\n  - AlexNet介绍，包括其架构，如何加快收敛，怎样加强泛化能力以及如何评估模型\ncategories:\n  - 论文笔记\n---\n\n第一次阅读论文，没有什么阅读技巧，再加上对CNN[(CNN解析)](http://www.moonshile.com/post/juan-ji-shen-jing-wang-luo-quan-mian-jie-xi)没有什么概念，读了几次才大概明白讲的是什么。\n\n## The Architecture\n\n1. **ReLU Nonlinearity**\n\t- **目的：** 加快收敛速度\n\t- **手段：** 使用Rectified Linear Units(ReLUs)作为神经元。即采用$$f(x) = max(0, x)$$作为激活函数\n\t- **原理：** 一般使用的激活函数$$f(x) = tanh(x) \\\\\\\\ f(x) = \\frac{1}{1 + e^{-x} }$$具有饱和(saturating)的特性，即导数在越接近目标的时候越小[(原理参考)](http://zhangliliang.com/2014/07/01/paper-note-alexnet-nips2012/)。当使用梯度下降的方法时，步长由学习率以及导数决定，导数太小会导致步长太小，收敛会慢。ReLU对于大于0部分导数恒为1，所以能加快收敛。\n\n\n2. **Training on Multiple GPUs**\n\t- **目的：** 加快训练速度\n\n3. **Local Response Normalization**\n\t- **目的：** 加强泛化能力\n\t- **手段：** 神经元受附近神经元抑制，各神经元的输出为$$b_i = \\frac{a_i}{ {(k+\\alpha\\sum{a_j^2})}^\\beta}$$其中$b_i$为神经元i的输出，$a_i$为神经元i的输入\n\t- **原理：** 模拟神经元间的抑制作用\n\n4. **Overlapping Pooling**\n\t- **目的：** 加强泛化能力\n\t- **手段：** pooling的时候stride < filter size，重叠地pooling\n\t- **原理：** 实验性结果\n\n## Reduce Overfitting\n\n1. **Data Augmentation**\n\t- **目的：** 加强泛化能力\n\t- **手段1：** 随机裁剪，将原来256×256的图片随机裁剪为224×224,并且允许水平翻转，则增加了$(256-224)^2*2$倍的样本量。（裁剪的时候一定是要连片的，不能是随机取的）\n\t- **手段2：** PCA，这个部分不太懂原理。[(原理参考)](http://zhangliliang.com/2014/07/01/paper-note-alexnet-nips2012/)\n\t- **原理：** 增大样本数增强泛化能力。裁剪，旋转，滤镜并不影响图片内容，但是对于机器来说就是完全不同的样本\n\n2. **Dropout**\n\t- **目的：** 加强泛化能力\n\t- **手段：** 随机disable神经元\n\t- **原理：** 隐式多模型，迫使模型要学习更robust的feature，抓住核心特征\n\n## Qulitative Evaluations\n\n1. **准确性：** 对于每张图片，给出CNN分类结果前5的类别及概率\n2. **一致性：** 对于每张照片，给出CNN提取特征相似的照片 e.g. 图片$i_1$提取的特征为$f_1$，找特征跟$f_1$相似的$i_k$，看下是不是同一个物体\n","slug":"imagenet","published":1,"updated":"2024-08-13T16:03:47.848Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clzvf191g000deqwobf58k69b","content":"<p>第一次阅读论文，没有什么阅读技巧，再加上对CNN<a href=\"http://www.moonshile.com/post/juan-ji-shen-jing-wang-luo-quan-mian-jie-xi\" target=\"_blank\" rel=\"external\">(CNN解析)</a>没有什么概念，读了几次才大概明白讲的是什么。</p>\n<h2 id=\"The-Architecture\"><a href=\"#The-Architecture\" class=\"headerlink\" title=\"The Architecture\"></a>The Architecture</h2><ol>\n<li><strong>ReLU Nonlinearity</strong><ul>\n<li><strong>目的：</strong> 加快收敛速度</li>\n<li><strong>手段：</strong> 使用Rectified Linear Units(ReLUs)作为神经元。即采用$$f(x) = max(0, x)$$作为激活函数</li>\n<li><strong>原理：</strong> 一般使用的激活函数$$f(x) = tanh(x) \\\\\\ f(x) = \\frac{1}{1 + e^{-x} }$$具有饱和(saturating)的特性，即导数在越接近目标的时候越小<a href=\"http://zhangliliang.com/2014/07/01/paper-note-alexnet-nips2012/\" target=\"_blank\" rel=\"external\">(原理参考)</a>。当使用梯度下降的方法时，步长由学习率以及导数决定，导数太小会导致步长太小，收敛会慢。ReLU对于大于0部分导数恒为1，所以能加快收敛。</li>\n</ul>\n</li>\n</ol>\n<ol>\n<li><p><strong>Training on Multiple GPUs</strong></p>\n<ul>\n<li><strong>目的：</strong> 加快训练速度</li>\n</ul>\n</li>\n<li><p><strong>Local Response Normalization</strong></p>\n<ul>\n<li><strong>目的：</strong> 加强泛化能力</li>\n<li><strong>手段：</strong> 神经元受附近神经元抑制，各神经元的输出为$$b_i = \\frac{a_i}{ {(k+\\alpha\\sum{a_j^2})}^\\beta}$$其中$b_i$为神经元i的输出，$a_i$为神经元i的输入</li>\n<li><strong>原理：</strong> 模拟神经元间的抑制作用</li>\n</ul>\n</li>\n<li><p><strong>Overlapping Pooling</strong></p>\n<ul>\n<li><strong>目的：</strong> 加强泛化能力</li>\n<li><strong>手段：</strong> pooling的时候stride &lt; filter size，重叠地pooling</li>\n<li><strong>原理：</strong> 实验性结果</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"Reduce-Overfitting\"><a href=\"#Reduce-Overfitting\" class=\"headerlink\" title=\"Reduce Overfitting\"></a>Reduce Overfitting</h2><ol>\n<li><p><strong>Data Augmentation</strong></p>\n<ul>\n<li><strong>目的：</strong> 加强泛化能力</li>\n<li><strong>手段1：</strong> 随机裁剪，将原来256×256的图片随机裁剪为224×224,并且允许水平翻转，则增加了$(256-224)^2*2$倍的样本量。（裁剪的时候一定是要连片的，不能是随机取的）</li>\n<li><strong>手段2：</strong> PCA，这个部分不太懂原理。<a href=\"http://zhangliliang.com/2014/07/01/paper-note-alexnet-nips2012/\" target=\"_blank\" rel=\"external\">(原理参考)</a></li>\n<li><strong>原理：</strong> 增大样本数增强泛化能力。裁剪，旋转，滤镜并不影响图片内容，但是对于机器来说就是完全不同的样本</li>\n</ul>\n</li>\n<li><p><strong>Dropout</strong></p>\n<ul>\n<li><strong>目的：</strong> 加强泛化能力</li>\n<li><strong>手段：</strong> 随机disable神经元</li>\n<li><strong>原理：</strong> 隐式多模型，迫使模型要学习更robust的feature，抓住核心特征</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"Qulitative-Evaluations\"><a href=\"#Qulitative-Evaluations\" class=\"headerlink\" title=\"Qulitative Evaluations\"></a>Qulitative Evaluations</h2><ol>\n<li><strong>准确性：</strong> 对于每张图片，给出CNN分类结果前5的类别及概率</li>\n<li><strong>一致性：</strong> 对于每张照片，给出CNN提取特征相似的照片 e.g. 图片$i_1$提取的特征为$f_1$，找特征跟$f_1$相似的$i_k$，看下是不是同一个物体</li>\n</ol>\n","excerpt":"","more":"<p>第一次阅读论文，没有什么阅读技巧，再加上对CNN<a href=\"http://www.moonshile.com/post/juan-ji-shen-jing-wang-luo-quan-mian-jie-xi\">(CNN解析)</a>没有什么概念，读了几次才大概明白讲的是什么。</p>\n<h2 id=\"The-Architecture\"><a href=\"#The-Architecture\" class=\"headerlink\" title=\"The Architecture\"></a>The Architecture</h2><ol>\n<li><strong>ReLU Nonlinearity</strong><ul>\n<li><strong>目的：</strong> 加快收敛速度</li>\n<li><strong>手段：</strong> 使用Rectified Linear Units(ReLUs)作为神经元。即采用$$f(x) = max(0, x)$$作为激活函数</li>\n<li><strong>原理：</strong> 一般使用的激活函数$$f(x) = tanh(x) \\\\\\ f(x) = \\frac{1}{1 + e^{-x} }$$具有饱和(saturating)的特性，即导数在越接近目标的时候越小<a href=\"http://zhangliliang.com/2014/07/01/paper-note-alexnet-nips2012/\">(原理参考)</a>。当使用梯度下降的方法时，步长由学习率以及导数决定，导数太小会导致步长太小，收敛会慢。ReLU对于大于0部分导数恒为1，所以能加快收敛。</li>\n</ul>\n</li>\n</ol>\n<ol>\n<li><p><strong>Training on Multiple GPUs</strong></p>\n<ul>\n<li><strong>目的：</strong> 加快训练速度</li>\n</ul>\n</li>\n<li><p><strong>Local Response Normalization</strong></p>\n<ul>\n<li><strong>目的：</strong> 加强泛化能力</li>\n<li><strong>手段：</strong> 神经元受附近神经元抑制，各神经元的输出为$$b_i = \\frac{a_i}{ {(k+\\alpha\\sum{a_j^2})}^\\beta}$$其中$b_i$为神经元i的输出，$a_i$为神经元i的输入</li>\n<li><strong>原理：</strong> 模拟神经元间的抑制作用</li>\n</ul>\n</li>\n<li><p><strong>Overlapping Pooling</strong></p>\n<ul>\n<li><strong>目的：</strong> 加强泛化能力</li>\n<li><strong>手段：</strong> pooling的时候stride &lt; filter size，重叠地pooling</li>\n<li><strong>原理：</strong> 实验性结果</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"Reduce-Overfitting\"><a href=\"#Reduce-Overfitting\" class=\"headerlink\" title=\"Reduce Overfitting\"></a>Reduce Overfitting</h2><ol>\n<li><p><strong>Data Augmentation</strong></p>\n<ul>\n<li><strong>目的：</strong> 加强泛化能力</li>\n<li><strong>手段1：</strong> 随机裁剪，将原来256×256的图片随机裁剪为224×224,并且允许水平翻转，则增加了$(256-224)^2*2$倍的样本量。（裁剪的时候一定是要连片的，不能是随机取的）</li>\n<li><strong>手段2：</strong> PCA，这个部分不太懂原理。<a href=\"http://zhangliliang.com/2014/07/01/paper-note-alexnet-nips2012/\">(原理参考)</a></li>\n<li><strong>原理：</strong> 增大样本数增强泛化能力。裁剪，旋转，滤镜并不影响图片内容，但是对于机器来说就是完全不同的样本</li>\n</ul>\n</li>\n<li><p><strong>Dropout</strong></p>\n<ul>\n<li><strong>目的：</strong> 加强泛化能力</li>\n<li><strong>手段：</strong> 随机disable神经元</li>\n<li><strong>原理：</strong> 隐式多模型，迫使模型要学习更robust的feature，抓住核心特征</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"Qulitative-Evaluations\"><a href=\"#Qulitative-Evaluations\" class=\"headerlink\" title=\"Qulitative Evaluations\"></a>Qulitative Evaluations</h2><ol>\n<li><strong>准确性：</strong> 对于每张图片，给出CNN分类结果前5的类别及概率</li>\n<li><strong>一致性：</strong> 对于每张照片，给出CNN提取特征相似的照片 e.g. 图片$i_1$提取的特征为$f_1$，找特征跟$f_1$相似的$i_k$，看下是不是同一个物体</li>\n</ol>\n"},{"title":"思维导图《沟通的艺术》","date":"2016-08-29T14:19:14.000Z","description":["实用性很强的一本关于沟通的书目"],"_content":"\n作为[豆瓣](https://book.douban.com/subject/26275861/)8.6评分的一本书，《沟通的艺术》不仅阐述了沟通的各种概念，还给出了实实在在的方法去提升沟通的质量，包括\n\n- 校准认知和事实\n- 理解行为背后的原因\n- 监视自我情绪\n- 成为一个更好的聆听者\n- 营造良好的沟通氛围\n- 处理冲突\n\n\n![](http://o9xzp7efk.bkt.clouddn.com/%E6%B2%9F%E9%80%9A%E7%9A%84%E8%89%BA%E6%9C%AF.png)\n\n","source":"_posts/mindmap-goutongdeyishu.md","raw":"---\ntitle: 思维导图《沟通的艺术》\ndate: 2016-08-29 22:19:14\ntags:\n\t- 沟通的艺术\ndescription:\n\t- 实用性很强的一本关于沟通的书目\ncategories:\n\t- 思维导图\n---\n\n作为[豆瓣](https://book.douban.com/subject/26275861/)8.6评分的一本书，《沟通的艺术》不仅阐述了沟通的各种概念，还给出了实实在在的方法去提升沟通的质量，包括\n\n- 校准认知和事实\n- 理解行为背后的原因\n- 监视自我情绪\n- 成为一个更好的聆听者\n- 营造良好的沟通氛围\n- 处理冲突\n\n\n![](http://o9xzp7efk.bkt.clouddn.com/%E6%B2%9F%E9%80%9A%E7%9A%84%E8%89%BA%E6%9C%AF.png)\n\n","slug":"mindmap-goutongdeyishu","published":1,"updated":"2024-08-13T16:03:47.848Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clzvf191n000geqwo1a4ji40i","content":"<p>作为<a href=\"https://book.douban.com/subject/26275861/\" target=\"_blank\" rel=\"external\">豆瓣</a>8.6评分的一本书，《沟通的艺术》不仅阐述了沟通的各种概念，还给出了实实在在的方法去提升沟通的质量，包括</p>\n<ul>\n<li>校准认知和事实</li>\n<li>理解行为背后的原因</li>\n<li>监视自我情绪</li>\n<li>成为一个更好的聆听者</li>\n<li>营造良好的沟通氛围</li>\n<li>处理冲突</li>\n</ul>\n<p><img src=\"http://o9xzp7efk.bkt.clouddn.com/%E6%B2%9F%E9%80%9A%E7%9A%84%E8%89%BA%E6%9C%AF.png\" alt=\"\"></p>\n","excerpt":"","more":"<p>作为<a href=\"https://book.douban.com/subject/26275861/\">豆瓣</a>8.6评分的一本书，《沟通的艺术》不仅阐述了沟通的各种概念，还给出了实实在在的方法去提升沟通的质量，包括</p>\n<ul>\n<li>校准认知和事实</li>\n<li>理解行为背后的原因</li>\n<li>监视自我情绪</li>\n<li>成为一个更好的聆听者</li>\n<li>营造良好的沟通氛围</li>\n<li>处理冲突</li>\n</ul>\n<p><img src=\"http://o9xzp7efk.bkt.clouddn.com/%E6%B2%9F%E9%80%9A%E7%9A%84%E8%89%BA%E6%9C%AF.png\" alt=\"\"></p>\n"},{"title":"思维导图《精进》","date":"2016-07-07T11:36:25.000Z","description":["知乎大牛采铜的《精进》，干货满满"],"_content":"\n采铜阐述了自己在时间、选择、行动、学习、思维、努力和成功7个方面的思考与观点，内容不愧[豆瓣](https://book.douban.com/subject/26761696/)8.1的评分。\n\n![](http://o9xzp7efk.bkt.clouddn.com/%E7%B2%BE%E8%BF%9B.svg)\n","source":"_posts/mindmap-jingjin.md","raw":"---\ntitle: 思维导图《精进》\ndate: 2016-07-07 19:36:25\ntags:\n\t- 精进\ndescription:\n\t- 知乎大牛采铜的《精进》，干货满满\ncategories:\n\t- 思维导图\n---\n\n采铜阐述了自己在时间、选择、行动、学习、思维、努力和成功7个方面的思考与观点，内容不愧[豆瓣](https://book.douban.com/subject/26761696/)8.1的评分。\n\n![](http://o9xzp7efk.bkt.clouddn.com/%E7%B2%BE%E8%BF%9B.svg)\n","slug":"mindmap-jingjin","published":1,"updated":"2024-08-13T16:03:47.848Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clzvf191p000jeqwozxlcc8ad","content":"<p>采铜阐述了自己在时间、选择、行动、学习、思维、努力和成功7个方面的思考与观点，内容不愧<a href=\"https://book.douban.com/subject/26761696/\" target=\"_blank\" rel=\"external\">豆瓣</a>8.1的评分。</p>\n<p><img src=\"http://o9xzp7efk.bkt.clouddn.com/%E7%B2%BE%E8%BF%9B.svg\" alt=\"\"></p>\n","excerpt":"","more":"<p>采铜阐述了自己在时间、选择、行动、学习、思维、努力和成功7个方面的思考与观点，内容不愧<a href=\"https://book.douban.com/subject/26761696/\">豆瓣</a>8.1的评分。</p>\n<p><img src=\"http://o9xzp7efk.bkt.clouddn.com/%E7%B2%BE%E8%BF%9B.svg\" alt=\"\"></p>\n"},{"title":"思维导图《哲学家们都干了些什么》","date":"2016-09-02T12:34:46.000Z","description":["据说是最严谨又最不严肃的哲学史文普读物"],"_content":"\n[豆瓣](https://book.douban.com/subject/26390842/)8.7的评分，在评论区甚至有人称赞这是最好的哲学史入门读物。\n\n全书阅读起来比较轻松愉快，除了纯粹的历史以外，还穿插了不少作者的思考，包括该哲学思想对我们平时的日常生活能够有什么帮助。但是美中不足的是可能为了趣味性，在解释深度上面有些妥协，感觉有些观点没有解释清楚，不过对于一个哲学小白来说，收获还是很丰富的。\n\n![](http://o9xzp7efk.bkt.clouddn.com/%E5%93%B2%E5%AD%A6%E5%AE%B6%E4%BB%AC%E9%83%BD%E5%B9%B2%E4%BA%86%E4%BA%9B%E4%BB%80%E4%B9%88.png)\n","source":"_posts/mindmap-zhexuejiamendouganlexieshenme.md","raw":"---\ntitle: 思维导图《哲学家们都干了些什么》\ndate: 2016-09-02 20:34:46\ntags:\n\t- 哲学家们都干了些什么\ndescription:\n\t- 据说是最严谨又最不严肃的哲学史文普读物\ncategories:\n\t- 思维导图\n---\n\n[豆瓣](https://book.douban.com/subject/26390842/)8.7的评分，在评论区甚至有人称赞这是最好的哲学史入门读物。\n\n全书阅读起来比较轻松愉快，除了纯粹的历史以外，还穿插了不少作者的思考，包括该哲学思想对我们平时的日常生活能够有什么帮助。但是美中不足的是可能为了趣味性，在解释深度上面有些妥协，感觉有些观点没有解释清楚，不过对于一个哲学小白来说，收获还是很丰富的。\n\n![](http://o9xzp7efk.bkt.clouddn.com/%E5%93%B2%E5%AD%A6%E5%AE%B6%E4%BB%AC%E9%83%BD%E5%B9%B2%E4%BA%86%E4%BA%9B%E4%BB%80%E4%B9%88.png)\n","slug":"mindmap-zhexuejiamendouganlexieshenme","published":1,"updated":"2024-08-13T16:03:47.848Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clzvf191r000neqwodwng1z1c","content":"<p><a href=\"https://book.douban.com/subject/26390842/\" target=\"_blank\" rel=\"external\">豆瓣</a>8.7的评分，在评论区甚至有人称赞这是最好的哲学史入门读物。</p>\n<p>全书阅读起来比较轻松愉快，除了纯粹的历史以外，还穿插了不少作者的思考，包括该哲学思想对我们平时的日常生活能够有什么帮助。但是美中不足的是可能为了趣味性，在解释深度上面有些妥协，感觉有些观点没有解释清楚，不过对于一个哲学小白来说，收获还是很丰富的。</p>\n<p><img src=\"http://o9xzp7efk.bkt.clouddn.com/%E5%93%B2%E5%AD%A6%E5%AE%B6%E4%BB%AC%E9%83%BD%E5%B9%B2%E4%BA%86%E4%BA%9B%E4%BB%80%E4%B9%88.png\" alt=\"\"></p>\n","excerpt":"","more":"<p><a href=\"https://book.douban.com/subject/26390842/\">豆瓣</a>8.7的评分，在评论区甚至有人称赞这是最好的哲学史入门读物。</p>\n<p>全书阅读起来比较轻松愉快，除了纯粹的历史以外，还穿插了不少作者的思考，包括该哲学思想对我们平时的日常生活能够有什么帮助。但是美中不足的是可能为了趣味性，在解释深度上面有些妥协，感觉有些观点没有解释清楚，不过对于一个哲学小白来说，收获还是很丰富的。</p>\n<p><img src=\"http://o9xzp7efk.bkt.clouddn.com/%E5%93%B2%E5%AD%A6%E5%AE%B6%E4%BB%AC%E9%83%BD%E5%B9%B2%E4%BA%86%E4%BA%9B%E4%BB%80%E4%B9%88.png\" alt=\"\"></p>\n"},{"title":"学习笔记《A Tour of C++》上","date":"2024-08-11T13:18:04.000Z","description":["记录一下看C++之父写的《A Tour of C++》时，感到比较有意思的点"],"_content":"\n# 前言\n\n这书是C++之父Bjarne Stroustrup写的，比较高屋建瓴地介绍了现代C++的一些特性，没有涉及太多的细节，主要还是思想理念上的一些东西，对于快速了解现代C++有比较大的帮助。\n\n本文主要记录看此书1-7章时感到比较有意思的点，这7章的内容大致分为以下三个部分：\n- 面向过程：第1-3章是一些比较基础的的内容；\n- 面向对象：第4章介绍用户自定义的类型（类），第5章介绍一些核心算子（构造/析构/赋值）；\n- 泛型编程：第6章介绍模板，第7章介绍如何为模板实例化添加约束（Concept）。\n\n至于后面的第8-15章主要是以STL为例子去进一步介绍上述概念的，第16章则是介绍了这门语言的发展历史。\n\n下面开始正文部分。正文部分按照书的顺序展开，通过[✓]标记有较大实战价值的内容。\n\n---\n\n# 面向过程\n\n## 第一章：基础语法\n\n- [✓] 推荐使用*{} initialization*，因为自带类型检查，可以保证类型（比如`int x{1.2}`会直接报错）\n- 指定函数为*constexpr function*就可以用于初始化constexpr类型的变量\n    - constexpr编译期确定，const运行期确定\n- reference只能被初始化（init），不能被修改（assign），即不能修改指向谁，所以指针能做的还是比ref多\n- 引入`nullptr`的原因在于兼顾类型匹配和方便使用\n    - 用`int 0`指代空指针的问题：调用函数有可能出错，会混淆`func(class *ptr)`和`func(int x)`\n    - 用`(void *) 0`指代空指针的问题：没法`class *ptr = (void *) 0`，因为C++禁止这种转换，得很麻烦地写`A *p = static_cast<A*>((void *)0)`\n- [✓] `if`也能引入局部变量，比如`if (n = v.size(); n > 0)`\n- [✓] 推荐使用`auto`\n\n## 第二章：用户定义的类型\n\n- `struct`默认`public`，`class`默认`private`\n- `enum class`和`enum`的区别在于前者需要指定prefix，以及后者可以隐式地`enum`转`int`\n- `union`: 每次被使用时是多种类型中的一种（比如说一个表的Entry，可以是`int / string / double`，但每一条Entry只能是其中一种），`union`是个底层类型，一般使用`variant`这个封装\n\n## 第三章：模块化\n\n- C++20引入了`Module`来解决原有头文件系统的以下问题\n    - 重复编译\n    - 顺序相关（比如`#include h1 #include h2`有可能会与`#include h2 #include h1`的结果不同）\n- [✓] *structured binding*: `for (const auto [key,value] : map)`\n\n---\n\n# 面向对象\n\n## 第四章：类\n\n- [✓] *RAII (Resource Acquisition Is Initialization)*：利用离开scope会自动调destructor的特性来避免资源泄露\n- 类的类型\n    - *Concrete Type*（比如`Vector`）\n    - *Abstract Type*（比如`Container`）：一般包含`=0`\n- 一些符号\n    - `virtual`：虚函数\n    - `= 0`：纯虚函数\n    - 显式写`override`：避免typo\n- 继承的成本\n    - 时间上：多一次查虚表\n    - 空间上\n        - 每个对象多一个指向虚表的指针\n        - 每个类要有一个虚表\n- `dynamic_cast`用于将基类转向子类\n\n## 第五章：关键算子\n\n- 关键算子\n    - 增：构造(*constructor*)\n        - from different type: `default` / `ordinary`\n        - from same type:\n            - non-temporary: `copy`\n            - temporary: `move`\n    - 删：析构(*destructor*)\n    - 改：赋值(*assignment*)\n        - from same type:\n            - non-temporary: `copy`\n            - temporary: `move`\n- 一些符号\n    - `= default`可以兼顾显式实现和复用默认实现，即可以在省略`{}`内容的情况下复用默认实现\n    - `= delete`表明一定没有某个函数\n    - `explicit`相当于不能将int当class使了，必须手动class(int)\n- [✓] *default member initializer*: `int x = 0`\n- 不会连续调两次构造函数：`A a = A(1)`只会调一次带参构造函数，不会先调带参构造函数再调拷贝构造函数\n- `A a()`并没有调用A的默认构造函数，而是在声明一个不带参，返回值为A类型的函数，下面这三种才是调默认构造函数\n    - `B b`\n    - `B b{}`\n    - `B b{} = B()`\n- [✓] 关于`move`\n    - motivation是**根据copy时src的类型，采用不同的copy方法，以优化copy的性能**。\n    - 具体来说，**按照src后续是否还会被使用**，copy可以分成两种。针对不需要被使用的情况（比如说函数的值返回），有机会可以优化copy的性能（比如一种方法是偷，即不需要再申请内存，直接将dst的资源指针指向src的资源）。\n    - 为了标识后续不会再被使用的src，引入了右指引用`&&`这种类型，其实也可以把右值引用这个拗口的名字直接理解成**将死类型**（这个称呼不是我首创的，但是忘了在哪看到过这个说法，没有引用敬请原谅），当然这只是方便理解，取名叫右指引用还是有他的道理的，只是初看容易懵\n        - 右值：将死类型可以出现在等号右边，但等号右边的不一定是将死类型\n        - 引用：因为我们要偷他的东西，必然是引用\n    - 估计是因为针对该src类型（将死类型）的优化方法就是偷，而偷这个字眼不太正经，所以换了一个正经点的名字叫移动，也就是`move`\n    - 于是`move`也就成了跟`copy`并列的一个概念，本质上还是copy，只不过手段不一样\n    - 能够标记将死类型还不够，最后能起到优化效果还是依赖于针对将死类型如何操作，这也就是*move constructor*和*move assignment*要做的事了\n    - misc\n        - `std::move`干的事情只是一个简单的cast，把类型转成了将死类型\n        - 那啥类型会是将死类型呢\n            - `std::move`转换过的\n            - 各种无名变量，比如函数返回值\n            - 值得一提的是类型为右指引用的形参仍然是左指，要想以右指引用使用这个形参还得用`std::move`\n                - 估计是为了保留调用常规函数的可能性\n- [✓] *literal operator*：通过指定后缀将东西转成class\n    - `\"Surprise!\"s` is a `std::string`\n    - `\"Surprise!\"` is a `const char[10]`\n\n---\n\n# 泛型编程\n\n## 第六章：模板\n\n- [✓] 我自己关于模板的理解\n    - 正常编程语法：面向运行期(program generation)，模板编程语法：面向编译期(code generation)\n    - 运行期多态（继承）时为了不用写if xxx type call xxx function这种代码\n    - 编译期多态（模板）是为了不用写只替换类型或者某些const的代码\n- 类级别模板\n    - `typename/class`: for all T\n    - `Element`(e.g., `Sequence`)：for all T such that，跟第七章的*Concept*关系很大\n    - 类里面搞个`using value_type = T`，方便外界通过`Class::value_type`拿到T，\n    - *type deduction*可以直接`vector v{1,2,3}`，都不需要`<type>`了\n- [✓] 函数级别模板\n    - virtual function不可以是模板函数：估计主要考虑到虚表的复杂度\n        - 虚表的复杂度正比于`type * virtual func num * subclass depth`\n        - 类级别模板允许了`type`这个纬度的膨胀\n        - 假如再允许`virtual function num`这个纬度的膨胀，就会是平方级别的复杂度了\n    - 函数对象：带context的函数\n    - lambda：`[context](parameter){body}`\n        - context部分（也叫*capture list*）主要是描述lambda要用哪些local variable，`&`引用，`=`值\n        - 一个很nice的应用场景是使用lamda将原来先构造再赋值的初始化合并成拷贝构造\n- built-in级别模板\n    - variable: `template <class T> constexpr T viscosity = 0.4`\n    - alias: `template<typename C> using Value_type = typename C::value_type`\n    - compile time if: `if constexpr(xxx)`，一种用途是根据不同类型选择不同实现\n```c++\ntemplate<typename T>\nvoid update(T& target)\n{\n    // ...\n    if constexpr(is_pod<T>::value)\n        simple_and_fast(target); // for \"plain old data\"\n    else\n        slow_and_safe(target);\n    // ...\n}\n```\n\n## 第七章：约束模板实例化时，类型要满足的条件\n\n- *Concept*\n    - motivation是单凭`template<typename T>`的约束太少了，`T`可以是任意类型，我们想限定当前模板只适用于满足某些条件的类型`T`\n    - 关键词是`requires`，也支持重载，定义最基础的concept的关键词也是`requires`，比如以下，第一个`requires`是*requirements-clause*，表示需要满足什么条件；第二个`requires`是*requires−expression*。当然一般来说不太需要*requires−expression*，STL里面有现成的。\n```c++\ntemplate<Forward_iterator Iter, int n>\n    requires requires(Iter p, int i) { p[i]; p+i; } // Iter has subscripting and addition\nvoid advance(Iter p, int n) // move p n elements forward\n{\n    p+=n; // a random-access iterator has +=\n}\n```\n- 泛型编程的思路：先搞几个concrete，通过一直问哪些东西可以放宽限制的方法进行抽象，别一上来就想着复用，好的泛型编程会导致模板实例化出来的代码跟你要手写的代码是一样的\n- 变长参数模板：默认的方法是通过拆解为`<first, left>`递归去做的，C++17支持fold expression一把梭\n- 模板类里面支持再定义模板函数，配合`std::forward`（保留左指右指）很好用\n- 使用concept的好处在于\n    - 提早报错期（不需要等实例化后才知道错）\n    - 更好的报错（实例化之后的报错很奇怪）\n    - 避免*duck typing*（不基于operand，而是基于含义）\n- *module*之后，模板也可以像普通代码一样分离声名和定义了\n    - 模板的实现要放在.h主要因为缺乏沟通需要实例化哪些模板的渠道，导致需要将实例化放到普通的.cpp的编译过程中\n    - module估计增加了这个通信渠道，导致模板.cpp可以知道要实例化哪些模板","source":"_posts/note-a-tour-of-cpp-1.md","raw":"---\ntitle: 学习笔记《A Tour of C++》上\ndate: 2024-08-11 21:18:04\ntags:\n\t- A Tour of C++\ncategories:\n\t- 学习笔记\ndescription:\n\t- 记录一下看C++之父写的《A Tour of C++》时，感到比较有意思的点\n---\n\n# 前言\n\n这书是C++之父Bjarne Stroustrup写的，比较高屋建瓴地介绍了现代C++的一些特性，没有涉及太多的细节，主要还是思想理念上的一些东西，对于快速了解现代C++有比较大的帮助。\n\n本文主要记录看此书1-7章时感到比较有意思的点，这7章的内容大致分为以下三个部分：\n- 面向过程：第1-3章是一些比较基础的的内容；\n- 面向对象：第4章介绍用户自定义的类型（类），第5章介绍一些核心算子（构造/析构/赋值）；\n- 泛型编程：第6章介绍模板，第7章介绍如何为模板实例化添加约束（Concept）。\n\n至于后面的第8-15章主要是以STL为例子去进一步介绍上述概念的，第16章则是介绍了这门语言的发展历史。\n\n下面开始正文部分。正文部分按照书的顺序展开，通过[✓]标记有较大实战价值的内容。\n\n---\n\n# 面向过程\n\n## 第一章：基础语法\n\n- [✓] 推荐使用*{} initialization*，因为自带类型检查，可以保证类型（比如`int x{1.2}`会直接报错）\n- 指定函数为*constexpr function*就可以用于初始化constexpr类型的变量\n    - constexpr编译期确定，const运行期确定\n- reference只能被初始化（init），不能被修改（assign），即不能修改指向谁，所以指针能做的还是比ref多\n- 引入`nullptr`的原因在于兼顾类型匹配和方便使用\n    - 用`int 0`指代空指针的问题：调用函数有可能出错，会混淆`func(class *ptr)`和`func(int x)`\n    - 用`(void *) 0`指代空指针的问题：没法`class *ptr = (void *) 0`，因为C++禁止这种转换，得很麻烦地写`A *p = static_cast<A*>((void *)0)`\n- [✓] `if`也能引入局部变量，比如`if (n = v.size(); n > 0)`\n- [✓] 推荐使用`auto`\n\n## 第二章：用户定义的类型\n\n- `struct`默认`public`，`class`默认`private`\n- `enum class`和`enum`的区别在于前者需要指定prefix，以及后者可以隐式地`enum`转`int`\n- `union`: 每次被使用时是多种类型中的一种（比如说一个表的Entry，可以是`int / string / double`，但每一条Entry只能是其中一种），`union`是个底层类型，一般使用`variant`这个封装\n\n## 第三章：模块化\n\n- C++20引入了`Module`来解决原有头文件系统的以下问题\n    - 重复编译\n    - 顺序相关（比如`#include h1 #include h2`有可能会与`#include h2 #include h1`的结果不同）\n- [✓] *structured binding*: `for (const auto [key,value] : map)`\n\n---\n\n# 面向对象\n\n## 第四章：类\n\n- [✓] *RAII (Resource Acquisition Is Initialization)*：利用离开scope会自动调destructor的特性来避免资源泄露\n- 类的类型\n    - *Concrete Type*（比如`Vector`）\n    - *Abstract Type*（比如`Container`）：一般包含`=0`\n- 一些符号\n    - `virtual`：虚函数\n    - `= 0`：纯虚函数\n    - 显式写`override`：避免typo\n- 继承的成本\n    - 时间上：多一次查虚表\n    - 空间上\n        - 每个对象多一个指向虚表的指针\n        - 每个类要有一个虚表\n- `dynamic_cast`用于将基类转向子类\n\n## 第五章：关键算子\n\n- 关键算子\n    - 增：构造(*constructor*)\n        - from different type: `default` / `ordinary`\n        - from same type:\n            - non-temporary: `copy`\n            - temporary: `move`\n    - 删：析构(*destructor*)\n    - 改：赋值(*assignment*)\n        - from same type:\n            - non-temporary: `copy`\n            - temporary: `move`\n- 一些符号\n    - `= default`可以兼顾显式实现和复用默认实现，即可以在省略`{}`内容的情况下复用默认实现\n    - `= delete`表明一定没有某个函数\n    - `explicit`相当于不能将int当class使了，必须手动class(int)\n- [✓] *default member initializer*: `int x = 0`\n- 不会连续调两次构造函数：`A a = A(1)`只会调一次带参构造函数，不会先调带参构造函数再调拷贝构造函数\n- `A a()`并没有调用A的默认构造函数，而是在声明一个不带参，返回值为A类型的函数，下面这三种才是调默认构造函数\n    - `B b`\n    - `B b{}`\n    - `B b{} = B()`\n- [✓] 关于`move`\n    - motivation是**根据copy时src的类型，采用不同的copy方法，以优化copy的性能**。\n    - 具体来说，**按照src后续是否还会被使用**，copy可以分成两种。针对不需要被使用的情况（比如说函数的值返回），有机会可以优化copy的性能（比如一种方法是偷，即不需要再申请内存，直接将dst的资源指针指向src的资源）。\n    - 为了标识后续不会再被使用的src，引入了右指引用`&&`这种类型，其实也可以把右值引用这个拗口的名字直接理解成**将死类型**（这个称呼不是我首创的，但是忘了在哪看到过这个说法，没有引用敬请原谅），当然这只是方便理解，取名叫右指引用还是有他的道理的，只是初看容易懵\n        - 右值：将死类型可以出现在等号右边，但等号右边的不一定是将死类型\n        - 引用：因为我们要偷他的东西，必然是引用\n    - 估计是因为针对该src类型（将死类型）的优化方法就是偷，而偷这个字眼不太正经，所以换了一个正经点的名字叫移动，也就是`move`\n    - 于是`move`也就成了跟`copy`并列的一个概念，本质上还是copy，只不过手段不一样\n    - 能够标记将死类型还不够，最后能起到优化效果还是依赖于针对将死类型如何操作，这也就是*move constructor*和*move assignment*要做的事了\n    - misc\n        - `std::move`干的事情只是一个简单的cast，把类型转成了将死类型\n        - 那啥类型会是将死类型呢\n            - `std::move`转换过的\n            - 各种无名变量，比如函数返回值\n            - 值得一提的是类型为右指引用的形参仍然是左指，要想以右指引用使用这个形参还得用`std::move`\n                - 估计是为了保留调用常规函数的可能性\n- [✓] *literal operator*：通过指定后缀将东西转成class\n    - `\"Surprise!\"s` is a `std::string`\n    - `\"Surprise!\"` is a `const char[10]`\n\n---\n\n# 泛型编程\n\n## 第六章：模板\n\n- [✓] 我自己关于模板的理解\n    - 正常编程语法：面向运行期(program generation)，模板编程语法：面向编译期(code generation)\n    - 运行期多态（继承）时为了不用写if xxx type call xxx function这种代码\n    - 编译期多态（模板）是为了不用写只替换类型或者某些const的代码\n- 类级别模板\n    - `typename/class`: for all T\n    - `Element`(e.g., `Sequence`)：for all T such that，跟第七章的*Concept*关系很大\n    - 类里面搞个`using value_type = T`，方便外界通过`Class::value_type`拿到T，\n    - *type deduction*可以直接`vector v{1,2,3}`，都不需要`<type>`了\n- [✓] 函数级别模板\n    - virtual function不可以是模板函数：估计主要考虑到虚表的复杂度\n        - 虚表的复杂度正比于`type * virtual func num * subclass depth`\n        - 类级别模板允许了`type`这个纬度的膨胀\n        - 假如再允许`virtual function num`这个纬度的膨胀，就会是平方级别的复杂度了\n    - 函数对象：带context的函数\n    - lambda：`[context](parameter){body}`\n        - context部分（也叫*capture list*）主要是描述lambda要用哪些local variable，`&`引用，`=`值\n        - 一个很nice的应用场景是使用lamda将原来先构造再赋值的初始化合并成拷贝构造\n- built-in级别模板\n    - variable: `template <class T> constexpr T viscosity = 0.4`\n    - alias: `template<typename C> using Value_type = typename C::value_type`\n    - compile time if: `if constexpr(xxx)`，一种用途是根据不同类型选择不同实现\n```c++\ntemplate<typename T>\nvoid update(T& target)\n{\n    // ...\n    if constexpr(is_pod<T>::value)\n        simple_and_fast(target); // for \"plain old data\"\n    else\n        slow_and_safe(target);\n    // ...\n}\n```\n\n## 第七章：约束模板实例化时，类型要满足的条件\n\n- *Concept*\n    - motivation是单凭`template<typename T>`的约束太少了，`T`可以是任意类型，我们想限定当前模板只适用于满足某些条件的类型`T`\n    - 关键词是`requires`，也支持重载，定义最基础的concept的关键词也是`requires`，比如以下，第一个`requires`是*requirements-clause*，表示需要满足什么条件；第二个`requires`是*requires−expression*。当然一般来说不太需要*requires−expression*，STL里面有现成的。\n```c++\ntemplate<Forward_iterator Iter, int n>\n    requires requires(Iter p, int i) { p[i]; p+i; } // Iter has subscripting and addition\nvoid advance(Iter p, int n) // move p n elements forward\n{\n    p+=n; // a random-access iterator has +=\n}\n```\n- 泛型编程的思路：先搞几个concrete，通过一直问哪些东西可以放宽限制的方法进行抽象，别一上来就想着复用，好的泛型编程会导致模板实例化出来的代码跟你要手写的代码是一样的\n- 变长参数模板：默认的方法是通过拆解为`<first, left>`递归去做的，C++17支持fold expression一把梭\n- 模板类里面支持再定义模板函数，配合`std::forward`（保留左指右指）很好用\n- 使用concept的好处在于\n    - 提早报错期（不需要等实例化后才知道错）\n    - 更好的报错（实例化之后的报错很奇怪）\n    - 避免*duck typing*（不基于operand，而是基于含义）\n- *module*之后，模板也可以像普通代码一样分离声名和定义了\n    - 模板的实现要放在.h主要因为缺乏沟通需要实例化哪些模板的渠道，导致需要将实例化放到普通的.cpp的编译过程中\n    - module估计增加了这个通信渠道，导致模板.cpp可以知道要实例化哪些模板","slug":"note-a-tour-of-cpp-1","published":1,"updated":"2024-08-13T16:03:47.848Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clzvf191t000peqwoo01uu11x","content":"<h1 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h1><p>这书是C++之父Bjarne Stroustrup写的，比较高屋建瓴地介绍了现代C++的一些特性，没有涉及太多的细节，主要还是思想理念上的一些东西，对于快速了解现代C++有比较大的帮助。</p>\n<p>本文主要记录看此书1-7章时感到比较有意思的点，这7章的内容大致分为以下三个部分：</p>\n<ul>\n<li>面向过程：第1-3章是一些比较基础的的内容；</li>\n<li>面向对象：第4章介绍用户自定义的类型（类），第5章介绍一些核心算子（构造/析构/赋值）；</li>\n<li>泛型编程：第6章介绍模板，第7章介绍如何为模板实例化添加约束（Concept）。</li>\n</ul>\n<p>至于后面的第8-15章主要是以STL为例子去进一步介绍上述概念的，第16章则是介绍了这门语言的发展历史。</p>\n<p>下面开始正文部分。正文部分按照书的顺序展开，通过[✓]标记有较大实战价值的内容。</p>\n<hr>\n<h1 id=\"面向过程\"><a href=\"#面向过程\" class=\"headerlink\" title=\"面向过程\"></a>面向过程</h1><h2 id=\"第一章：基础语法\"><a href=\"#第一章：基础语法\" class=\"headerlink\" title=\"第一章：基础语法\"></a>第一章：基础语法</h2><ul>\n<li>[✓] 推荐使用<em>{} initialization</em>，因为自带类型检查，可以保证类型（比如<code>int x{1.2}</code>会直接报错）</li>\n<li>指定函数为<em>constexpr function</em>就可以用于初始化constexpr类型的变量<ul>\n<li>constexpr编译期确定，const运行期确定</li>\n</ul>\n</li>\n<li>reference只能被初始化（init），不能被修改（assign），即不能修改指向谁，所以指针能做的还是比ref多</li>\n<li>引入<code>nullptr</code>的原因在于兼顾类型匹配和方便使用<ul>\n<li>用<code>int 0</code>指代空指针的问题：调用函数有可能出错，会混淆<code>func(class *ptr)</code>和<code>func(int x)</code></li>\n<li>用<code>(void *) 0</code>指代空指针的问题：没法<code>class *ptr = (void *) 0</code>，因为C++禁止这种转换，得很麻烦地写<code>A *p = static_cast&lt;A*&gt;((void *)0)</code></li>\n</ul>\n</li>\n<li>[✓] <code>if</code>也能引入局部变量，比如<code>if (n = v.size(); n &gt; 0)</code></li>\n<li>[✓] 推荐使用<code>auto</code></li>\n</ul>\n<h2 id=\"第二章：用户定义的类型\"><a href=\"#第二章：用户定义的类型\" class=\"headerlink\" title=\"第二章：用户定义的类型\"></a>第二章：用户定义的类型</h2><ul>\n<li><code>struct</code>默认<code>public</code>，<code>class</code>默认<code>private</code></li>\n<li><code>enum class</code>和<code>enum</code>的区别在于前者需要指定prefix，以及后者可以隐式地<code>enum</code>转<code>int</code></li>\n<li><code>union</code>: 每次被使用时是多种类型中的一种（比如说一个表的Entry，可以是<code>int / string / double</code>，但每一条Entry只能是其中一种），<code>union</code>是个底层类型，一般使用<code>variant</code>这个封装</li>\n</ul>\n<h2 id=\"第三章：模块化\"><a href=\"#第三章：模块化\" class=\"headerlink\" title=\"第三章：模块化\"></a>第三章：模块化</h2><ul>\n<li>C++20引入了<code>Module</code>来解决原有头文件系统的以下问题<ul>\n<li>重复编译</li>\n<li>顺序相关（比如<code>#include h1 #include h2</code>有可能会与<code>#include h2 #include h1</code>的结果不同）</li>\n</ul>\n</li>\n<li>[✓] <em>structured binding</em>: <code>for (const auto [key,value] : map)</code></li>\n</ul>\n<hr>\n<h1 id=\"面向对象\"><a href=\"#面向对象\" class=\"headerlink\" title=\"面向对象\"></a>面向对象</h1><h2 id=\"第四章：类\"><a href=\"#第四章：类\" class=\"headerlink\" title=\"第四章：类\"></a>第四章：类</h2><ul>\n<li>[✓] <em>RAII (Resource Acquisition Is Initialization)</em>：利用离开scope会自动调destructor的特性来避免资源泄露</li>\n<li>类的类型<ul>\n<li><em>Concrete Type</em>（比如<code>Vector</code>）</li>\n<li><em>Abstract Type</em>（比如<code>Container</code>）：一般包含<code>=0</code></li>\n</ul>\n</li>\n<li>一些符号<ul>\n<li><code>virtual</code>：虚函数</li>\n<li><code>= 0</code>：纯虚函数</li>\n<li>显式写<code>override</code>：避免typo</li>\n</ul>\n</li>\n<li>继承的成本<ul>\n<li>时间上：多一次查虚表</li>\n<li>空间上<ul>\n<li>每个对象多一个指向虚表的指针</li>\n<li>每个类要有一个虚表</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><code>dynamic_cast</code>用于将基类转向子类</li>\n</ul>\n<h2 id=\"第五章：关键算子\"><a href=\"#第五章：关键算子\" class=\"headerlink\" title=\"第五章：关键算子\"></a>第五章：关键算子</h2><ul>\n<li>关键算子<ul>\n<li>增：构造(<em>constructor</em>)<ul>\n<li>from different type: <code>default</code> / <code>ordinary</code></li>\n<li>from same type:<ul>\n<li>non-temporary: <code>copy</code></li>\n<li>temporary: <code>move</code></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>删：析构(<em>destructor</em>)</li>\n<li>改：赋值(<em>assignment</em>)<ul>\n<li>from same type:<ul>\n<li>non-temporary: <code>copy</code></li>\n<li>temporary: <code>move</code></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>一些符号<ul>\n<li><code>= default</code>可以兼顾显式实现和复用默认实现，即可以在省略<code>{}</code>内容的情况下复用默认实现</li>\n<li><code>= delete</code>表明一定没有某个函数</li>\n<li><code>explicit</code>相当于不能将int当class使了，必须手动class(int)</li>\n</ul>\n</li>\n<li>[✓] <em>default member initializer</em>: <code>int x = 0</code></li>\n<li>不会连续调两次构造函数：<code>A a = A(1)</code>只会调一次带参构造函数，不会先调带参构造函数再调拷贝构造函数</li>\n<li><code>A a()</code>并没有调用A的默认构造函数，而是在声明一个不带参，返回值为A类型的函数，下面这三种才是调默认构造函数<ul>\n<li><code>B b</code></li>\n<li><code>B b{}</code></li>\n<li><code>B b{} = B()</code></li>\n</ul>\n</li>\n<li>[✓] 关于<code>move</code><ul>\n<li>motivation是<strong>根据copy时src的类型，采用不同的copy方法，以优化copy的性能</strong>。</li>\n<li>具体来说，<strong>按照src后续是否还会被使用</strong>，copy可以分成两种。针对不需要被使用的情况（比如说函数的值返回），有机会可以优化copy的性能（比如一种方法是偷，即不需要再申请内存，直接将dst的资源指针指向src的资源）。</li>\n<li>为了标识后续不会再被使用的src，引入了右指引用<code>&amp;&amp;</code>这种类型，其实也可以把右值引用这个拗口的名字直接理解成<strong>将死类型</strong>（这个称呼不是我首创的，但是忘了在哪看到过这个说法，没有引用敬请原谅），当然这只是方便理解，取名叫右指引用还是有他的道理的，只是初看容易懵<ul>\n<li>右值：将死类型可以出现在等号右边，但等号右边的不一定是将死类型</li>\n<li>引用：因为我们要偷他的东西，必然是引用</li>\n</ul>\n</li>\n<li>估计是因为针对该src类型（将死类型）的优化方法就是偷，而偷这个字眼不太正经，所以换了一个正经点的名字叫移动，也就是<code>move</code></li>\n<li>于是<code>move</code>也就成了跟<code>copy</code>并列的一个概念，本质上还是copy，只不过手段不一样</li>\n<li>能够标记将死类型还不够，最后能起到优化效果还是依赖于针对将死类型如何操作，这也就是<em>move constructor</em>和<em>move assignment</em>要做的事了</li>\n<li>misc<ul>\n<li><code>std::move</code>干的事情只是一个简单的cast，把类型转成了将死类型</li>\n<li>那啥类型会是将死类型呢<ul>\n<li><code>std::move</code>转换过的</li>\n<li>各种无名变量，比如函数返回值</li>\n<li>值得一提的是类型为右指引用的形参仍然是左指，要想以右指引用使用这个形参还得用<code>std::move</code><ul>\n<li>估计是为了保留调用常规函数的可能性</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>[✓] <em>literal operator</em>：通过指定后缀将东西转成class<ul>\n<li><code>&quot;Surprise!&quot;s</code> is a <code>std::string</code></li>\n<li><code>&quot;Surprise!&quot;</code> is a <code>const char[10]</code></li>\n</ul>\n</li>\n</ul>\n<hr>\n<h1 id=\"泛型编程\"><a href=\"#泛型编程\" class=\"headerlink\" title=\"泛型编程\"></a>泛型编程</h1><h2 id=\"第六章：模板\"><a href=\"#第六章：模板\" class=\"headerlink\" title=\"第六章：模板\"></a>第六章：模板</h2><ul>\n<li>[✓] 我自己关于模板的理解<ul>\n<li>正常编程语法：面向运行期(program generation)，模板编程语法：面向编译期(code generation)</li>\n<li>运行期多态（继承）时为了不用写if xxx type call xxx function这种代码</li>\n<li>编译期多态（模板）是为了不用写只替换类型或者某些const的代码</li>\n</ul>\n</li>\n<li>类级别模板<ul>\n<li><code>typename/class</code>: for all T</li>\n<li><code>Element</code>(e.g., <code>Sequence</code>)：for all T such that，跟第七章的<em>Concept</em>关系很大</li>\n<li>类里面搞个<code>using value_type = T</code>，方便外界通过<code>Class::value_type</code>拿到T，</li>\n<li><em>type deduction</em>可以直接<code>vector v{1,2,3}</code>，都不需要<code>&lt;type&gt;</code>了</li>\n</ul>\n</li>\n<li>[✓] 函数级别模板<ul>\n<li>virtual function不可以是模板函数：估计主要考虑到虚表的复杂度<ul>\n<li>虚表的复杂度正比于<code>type * virtual func num * subclass depth</code></li>\n<li>类级别模板允许了<code>type</code>这个纬度的膨胀</li>\n<li>假如再允许<code>virtual function num</code>这个纬度的膨胀，就会是平方级别的复杂度了</li>\n</ul>\n</li>\n<li>函数对象：带context的函数</li>\n<li>lambda：<code>[context](parameter){body}</code><ul>\n<li>context部分（也叫<em>capture list</em>）主要是描述lambda要用哪些local variable，<code>&amp;</code>引用，<code>=</code>值</li>\n<li>一个很nice的应用场景是使用lamda将原来先构造再赋值的初始化合并成拷贝构造</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>built-in级别模板<ul>\n<li>variable: <code>template &lt;class T&gt; constexpr T viscosity = 0.4</code></li>\n<li>alias: <code>template&lt;typename C&gt; using Value_type = typename C::value_type</code></li>\n<li>compile time if: <code>if constexpr(xxx)</code>，一种用途是根据不同类型选择不同实现<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">update</span><span class=\"params\">(T&amp; target)</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">    <span class=\"comment\">// ...</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">if</span> <span class=\"title\">constexpr</span><span class=\"params\">(is_pod&lt;T&gt;::value)</span></span></div><div class=\"line\">        <span class=\"title\">simple_and_fast</span><span class=\"params\">(target)</span>; <span class=\"comment\">// for \"plain old data\"</span></div><div class=\"line\">    <span class=\"keyword\">else</span></div><div class=\"line\">        slow_and_safe(target);</div><div class=\"line\">    <span class=\"comment\">// ...</span></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"第七章：约束模板实例化时，类型要满足的条件\"><a href=\"#第七章：约束模板实例化时，类型要满足的条件\" class=\"headerlink\" title=\"第七章：约束模板实例化时，类型要满足的条件\"></a>第七章：约束模板实例化时，类型要满足的条件</h2><ul>\n<li><p><em>Concept</em></p>\n<ul>\n<li>motivation是单凭<code>template&lt;typename T&gt;</code>的约束太少了，<code>T</code>可以是任意类型，我们想限定当前模板只适用于满足某些条件的类型<code>T</code></li>\n<li>关键词是<code>requires</code>，也支持重载，定义最基础的concept的关键词也是<code>requires</code>，比如以下，第一个<code>requires</code>是<em>requirements-clause</em>，表示需要满足什么条件；第二个<code>requires</code>是<em>requires−expression</em>。当然一般来说不太需要<em>requires−expression</em>，STL里面有现成的。<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span>&lt;Forward_iterator Iter, <span class=\"keyword\">int</span> n&gt;</div><div class=\"line\">    <span class=\"function\">requires <span class=\"title\">requires</span><span class=\"params\">(Iter p, <span class=\"keyword\">int</span> i)</span> </span>&#123; p[i]; p+i; &#125; <span class=\"comment\">// Iter has subscripting and addition</span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">advance</span><span class=\"params\">(Iter p, <span class=\"keyword\">int</span> n)</span> <span class=\"comment\">// move p n elements forward</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">    p+=n; <span class=\"comment\">// a random-access iterator has +=</span></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n<li><p>泛型编程的思路：先搞几个concrete，通过一直问哪些东西可以放宽限制的方法进行抽象，别一上来就想着复用，好的泛型编程会导致模板实例化出来的代码跟你要手写的代码是一样的</p>\n</li>\n<li>变长参数模板：默认的方法是通过拆解为<code>&lt;first, left&gt;</code>递归去做的，C++17支持fold expression一把梭</li>\n<li>模板类里面支持再定义模板函数，配合<code>std::forward</code>（保留左指右指）很好用</li>\n<li>使用concept的好处在于<ul>\n<li>提早报错期（不需要等实例化后才知道错）</li>\n<li>更好的报错（实例化之后的报错很奇怪）</li>\n<li>避免<em>duck typing</em>（不基于operand，而是基于含义）</li>\n</ul>\n</li>\n<li><em>module</em>之后，模板也可以像普通代码一样分离声名和定义了<ul>\n<li>模板的实现要放在.h主要因为缺乏沟通需要实例化哪些模板的渠道，导致需要将实例化放到普通的.cpp的编译过程中</li>\n<li>module估计增加了这个通信渠道，导致模板.cpp可以知道要实例化哪些模板</li>\n</ul>\n</li>\n</ul>\n","excerpt":"","more":"<h1 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h1><p>这书是C++之父Bjarne Stroustrup写的，比较高屋建瓴地介绍了现代C++的一些特性，没有涉及太多的细节，主要还是思想理念上的一些东西，对于快速了解现代C++有比较大的帮助。</p>\n<p>本文主要记录看此书1-7章时感到比较有意思的点，这7章的内容大致分为以下三个部分：</p>\n<ul>\n<li>面向过程：第1-3章是一些比较基础的的内容；</li>\n<li>面向对象：第4章介绍用户自定义的类型（类），第5章介绍一些核心算子（构造/析构/赋值）；</li>\n<li>泛型编程：第6章介绍模板，第7章介绍如何为模板实例化添加约束（Concept）。</li>\n</ul>\n<p>至于后面的第8-15章主要是以STL为例子去进一步介绍上述概念的，第16章则是介绍了这门语言的发展历史。</p>\n<p>下面开始正文部分。正文部分按照书的顺序展开，通过[✓]标记有较大实战价值的内容。</p>\n<hr>\n<h1 id=\"面向过程\"><a href=\"#面向过程\" class=\"headerlink\" title=\"面向过程\"></a>面向过程</h1><h2 id=\"第一章：基础语法\"><a href=\"#第一章：基础语法\" class=\"headerlink\" title=\"第一章：基础语法\"></a>第一章：基础语法</h2><ul>\n<li>[✓] 推荐使用<em>{} initialization</em>，因为自带类型检查，可以保证类型（比如<code>int x{1.2}</code>会直接报错）</li>\n<li>指定函数为<em>constexpr function</em>就可以用于初始化constexpr类型的变量<ul>\n<li>constexpr编译期确定，const运行期确定</li>\n</ul>\n</li>\n<li>reference只能被初始化（init），不能被修改（assign），即不能修改指向谁，所以指针能做的还是比ref多</li>\n<li>引入<code>nullptr</code>的原因在于兼顾类型匹配和方便使用<ul>\n<li>用<code>int 0</code>指代空指针的问题：调用函数有可能出错，会混淆<code>func(class *ptr)</code>和<code>func(int x)</code></li>\n<li>用<code>(void *) 0</code>指代空指针的问题：没法<code>class *ptr = (void *) 0</code>，因为C++禁止这种转换，得很麻烦地写<code>A *p = static_cast&lt;A*&gt;((void *)0)</code></li>\n</ul>\n</li>\n<li>[✓] <code>if</code>也能引入局部变量，比如<code>if (n = v.size(); n &gt; 0)</code></li>\n<li>[✓] 推荐使用<code>auto</code></li>\n</ul>\n<h2 id=\"第二章：用户定义的类型\"><a href=\"#第二章：用户定义的类型\" class=\"headerlink\" title=\"第二章：用户定义的类型\"></a>第二章：用户定义的类型</h2><ul>\n<li><code>struct</code>默认<code>public</code>，<code>class</code>默认<code>private</code></li>\n<li><code>enum class</code>和<code>enum</code>的区别在于前者需要指定prefix，以及后者可以隐式地<code>enum</code>转<code>int</code></li>\n<li><code>union</code>: 每次被使用时是多种类型中的一种（比如说一个表的Entry，可以是<code>int / string / double</code>，但每一条Entry只能是其中一种），<code>union</code>是个底层类型，一般使用<code>variant</code>这个封装</li>\n</ul>\n<h2 id=\"第三章：模块化\"><a href=\"#第三章：模块化\" class=\"headerlink\" title=\"第三章：模块化\"></a>第三章：模块化</h2><ul>\n<li>C++20引入了<code>Module</code>来解决原有头文件系统的以下问题<ul>\n<li>重复编译</li>\n<li>顺序相关（比如<code>#include h1 #include h2</code>有可能会与<code>#include h2 #include h1</code>的结果不同）</li>\n</ul>\n</li>\n<li>[✓] <em>structured binding</em>: <code>for (const auto [key,value] : map)</code></li>\n</ul>\n<hr>\n<h1 id=\"面向对象\"><a href=\"#面向对象\" class=\"headerlink\" title=\"面向对象\"></a>面向对象</h1><h2 id=\"第四章：类\"><a href=\"#第四章：类\" class=\"headerlink\" title=\"第四章：类\"></a>第四章：类</h2><ul>\n<li>[✓] <em>RAII (Resource Acquisition Is Initialization)</em>：利用离开scope会自动调destructor的特性来避免资源泄露</li>\n<li>类的类型<ul>\n<li><em>Concrete Type</em>（比如<code>Vector</code>）</li>\n<li><em>Abstract Type</em>（比如<code>Container</code>）：一般包含<code>=0</code></li>\n</ul>\n</li>\n<li>一些符号<ul>\n<li><code>virtual</code>：虚函数</li>\n<li><code>= 0</code>：纯虚函数</li>\n<li>显式写<code>override</code>：避免typo</li>\n</ul>\n</li>\n<li>继承的成本<ul>\n<li>时间上：多一次查虚表</li>\n<li>空间上<ul>\n<li>每个对象多一个指向虚表的指针</li>\n<li>每个类要有一个虚表</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><code>dynamic_cast</code>用于将基类转向子类</li>\n</ul>\n<h2 id=\"第五章：关键算子\"><a href=\"#第五章：关键算子\" class=\"headerlink\" title=\"第五章：关键算子\"></a>第五章：关键算子</h2><ul>\n<li>关键算子<ul>\n<li>增：构造(<em>constructor</em>)<ul>\n<li>from different type: <code>default</code> / <code>ordinary</code></li>\n<li>from same type:<ul>\n<li>non-temporary: <code>copy</code></li>\n<li>temporary: <code>move</code></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>删：析构(<em>destructor</em>)</li>\n<li>改：赋值(<em>assignment</em>)<ul>\n<li>from same type:<ul>\n<li>non-temporary: <code>copy</code></li>\n<li>temporary: <code>move</code></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>一些符号<ul>\n<li><code>= default</code>可以兼顾显式实现和复用默认实现，即可以在省略<code>{}</code>内容的情况下复用默认实现</li>\n<li><code>= delete</code>表明一定没有某个函数</li>\n<li><code>explicit</code>相当于不能将int当class使了，必须手动class(int)</li>\n</ul>\n</li>\n<li>[✓] <em>default member initializer</em>: <code>int x = 0</code></li>\n<li>不会连续调两次构造函数：<code>A a = A(1)</code>只会调一次带参构造函数，不会先调带参构造函数再调拷贝构造函数</li>\n<li><code>A a()</code>并没有调用A的默认构造函数，而是在声明一个不带参，返回值为A类型的函数，下面这三种才是调默认构造函数<ul>\n<li><code>B b</code></li>\n<li><code>B b{}</code></li>\n<li><code>B b{} = B()</code></li>\n</ul>\n</li>\n<li>[✓] 关于<code>move</code><ul>\n<li>motivation是<strong>根据copy时src的类型，采用不同的copy方法，以优化copy的性能</strong>。</li>\n<li>具体来说，<strong>按照src后续是否还会被使用</strong>，copy可以分成两种。针对不需要被使用的情况（比如说函数的值返回），有机会可以优化copy的性能（比如一种方法是偷，即不需要再申请内存，直接将dst的资源指针指向src的资源）。</li>\n<li>为了标识后续不会再被使用的src，引入了右指引用<code>&amp;&amp;</code>这种类型，其实也可以把右值引用这个拗口的名字直接理解成<strong>将死类型</strong>（这个称呼不是我首创的，但是忘了在哪看到过这个说法，没有引用敬请原谅），当然这只是方便理解，取名叫右指引用还是有他的道理的，只是初看容易懵<ul>\n<li>右值：将死类型可以出现在等号右边，但等号右边的不一定是将死类型</li>\n<li>引用：因为我们要偷他的东西，必然是引用</li>\n</ul>\n</li>\n<li>估计是因为针对该src类型（将死类型）的优化方法就是偷，而偷这个字眼不太正经，所以换了一个正经点的名字叫移动，也就是<code>move</code></li>\n<li>于是<code>move</code>也就成了跟<code>copy</code>并列的一个概念，本质上还是copy，只不过手段不一样</li>\n<li>能够标记将死类型还不够，最后能起到优化效果还是依赖于针对将死类型如何操作，这也就是<em>move constructor</em>和<em>move assignment</em>要做的事了</li>\n<li>misc<ul>\n<li><code>std::move</code>干的事情只是一个简单的cast，把类型转成了将死类型</li>\n<li>那啥类型会是将死类型呢<ul>\n<li><code>std::move</code>转换过的</li>\n<li>各种无名变量，比如函数返回值</li>\n<li>值得一提的是类型为右指引用的形参仍然是左指，要想以右指引用使用这个形参还得用<code>std::move</code><ul>\n<li>估计是为了保留调用常规函数的可能性</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>[✓] <em>literal operator</em>：通过指定后缀将东西转成class<ul>\n<li><code>&quot;Surprise!&quot;s</code> is a <code>std::string</code></li>\n<li><code>&quot;Surprise!&quot;</code> is a <code>const char[10]</code></li>\n</ul>\n</li>\n</ul>\n<hr>\n<h1 id=\"泛型编程\"><a href=\"#泛型编程\" class=\"headerlink\" title=\"泛型编程\"></a>泛型编程</h1><h2 id=\"第六章：模板\"><a href=\"#第六章：模板\" class=\"headerlink\" title=\"第六章：模板\"></a>第六章：模板</h2><ul>\n<li>[✓] 我自己关于模板的理解<ul>\n<li>正常编程语法：面向运行期(program generation)，模板编程语法：面向编译期(code generation)</li>\n<li>运行期多态（继承）时为了不用写if xxx type call xxx function这种代码</li>\n<li>编译期多态（模板）是为了不用写只替换类型或者某些const的代码</li>\n</ul>\n</li>\n<li>类级别模板<ul>\n<li><code>typename/class</code>: for all T</li>\n<li><code>Element</code>(e.g., <code>Sequence</code>)：for all T such that，跟第七章的<em>Concept</em>关系很大</li>\n<li>类里面搞个<code>using value_type = T</code>，方便外界通过<code>Class::value_type</code>拿到T，</li>\n<li><em>type deduction</em>可以直接<code>vector v{1,2,3}</code>，都不需要<code>&lt;type&gt;</code>了</li>\n</ul>\n</li>\n<li>[✓] 函数级别模板<ul>\n<li>virtual function不可以是模板函数：估计主要考虑到虚表的复杂度<ul>\n<li>虚表的复杂度正比于<code>type * virtual func num * subclass depth</code></li>\n<li>类级别模板允许了<code>type</code>这个纬度的膨胀</li>\n<li>假如再允许<code>virtual function num</code>这个纬度的膨胀，就会是平方级别的复杂度了</li>\n</ul>\n</li>\n<li>函数对象：带context的函数</li>\n<li>lambda：<code>[context](parameter){body}</code><ul>\n<li>context部分（也叫<em>capture list</em>）主要是描述lambda要用哪些local variable，<code>&amp;</code>引用，<code>=</code>值</li>\n<li>一个很nice的应用场景是使用lamda将原来先构造再赋值的初始化合并成拷贝构造</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>built-in级别模板<ul>\n<li>variable: <code>template &lt;class T&gt; constexpr T viscosity = 0.4</code></li>\n<li>alias: <code>template&lt;typename C&gt; using Value_type = typename C::value_type</code></li>\n<li>compile time if: <code>if constexpr(xxx)</code>，一种用途是根据不同类型选择不同实现<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">update</span><span class=\"params\">(T&amp; target)</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">    <span class=\"comment\">// ...</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">if</span> <span class=\"title\">constexpr</span><span class=\"params\">(is_pod&lt;T&gt;::value)</span></div><div class=\"line\">        <span class=\"title\">simple_and_fast</span><span class=\"params\">(target)</span></span>; <span class=\"comment\">// for \"plain old data\"</span></div><div class=\"line\">    <span class=\"keyword\">else</span></div><div class=\"line\">        slow_and_safe(target);</div><div class=\"line\">    <span class=\"comment\">// ...</span></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"第七章：约束模板实例化时，类型要满足的条件\"><a href=\"#第七章：约束模板实例化时，类型要满足的条件\" class=\"headerlink\" title=\"第七章：约束模板实例化时，类型要满足的条件\"></a>第七章：约束模板实例化时，类型要满足的条件</h2><ul>\n<li><p><em>Concept</em></p>\n<ul>\n<li>motivation是单凭<code>template&lt;typename T&gt;</code>的约束太少了，<code>T</code>可以是任意类型，我们想限定当前模板只适用于满足某些条件的类型<code>T</code></li>\n<li>关键词是<code>requires</code>，也支持重载，定义最基础的concept的关键词也是<code>requires</code>，比如以下，第一个<code>requires</code>是<em>requirements-clause</em>，表示需要满足什么条件；第二个<code>requires</code>是<em>requires−expression</em>。当然一般来说不太需要<em>requires−expression</em>，STL里面有现成的。<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span>&lt;Forward_iterator Iter, <span class=\"keyword\">int</span> n&gt;</div><div class=\"line\">    <span class=\"function\">requires <span class=\"title\">requires</span><span class=\"params\">(Iter p, <span class=\"keyword\">int</span> i)</span> </span>&#123; p[i]; p+i; &#125; <span class=\"comment\">// Iter has subscripting and addition</span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">advance</span><span class=\"params\">(Iter p, <span class=\"keyword\">int</span> n)</span> <span class=\"comment\">// move p n elements forward</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">    p+=n; <span class=\"comment\">// a random-access iterator has +=</span></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n<li><p>泛型编程的思路：先搞几个concrete，通过一直问哪些东西可以放宽限制的方法进行抽象，别一上来就想着复用，好的泛型编程会导致模板实例化出来的代码跟你要手写的代码是一样的</p>\n</li>\n<li>变长参数模板：默认的方法是通过拆解为<code>&lt;first, left&gt;</code>递归去做的，C++17支持fold expression一把梭</li>\n<li>模板类里面支持再定义模板函数，配合<code>std::forward</code>（保留左指右指）很好用</li>\n<li>使用concept的好处在于<ul>\n<li>提早报错期（不需要等实例化后才知道错）</li>\n<li>更好的报错（实例化之后的报错很奇怪）</li>\n<li>避免<em>duck typing</em>（不基于operand，而是基于含义）</li>\n</ul>\n</li>\n<li><em>module</em>之后，模板也可以像普通代码一样分离声名和定义了<ul>\n<li>模板的实现要放在.h主要因为缺乏沟通需要实例化哪些模板的渠道，导致需要将实例化放到普通的.cpp的编译过程中</li>\n<li>module估计增加了这个通信渠道，导致模板.cpp可以知道要实例化哪些模板</li>\n</ul>\n</li>\n</ul>\n"},{"title":"课程笔记《线性代数的本质》","description":["形象、直观地理解线性代数"],"date":"2017-09-09T03:15:46.000Z","_content":"\n## 向量\n\n### 不同视角下的向量\n\n- physics：箭头\n- cs：数字列表（e.g. $ \\begin{bmatrix} 1 \\\\\\\\ 2\\end{bmatrix} $）\n- mathematician： $ \\vec{\\bf{v}} $\n\t* 抽象理解，任何相加和数乘有意义的东西\n\t* physics和cs都只是其中一种实例，还可以是其他任意满足性质的东西（e.g. 函数）\n\n### physics view与cs view的联系\n\n- 桥梁：坐标系\n- 对偶性（独立推导、一一对应）：表示、运算（加法、数乘）\n- 作用\n\t* physics→cs：已知想要的图形变换效果，使用$ \\begin{bmatrix} 1 \\\\\\\\ 2\\end{bmatrix} $与计算机进行交流 \n\t* cs→physics：已知$ \\begin{bmatrix} 1 \\\\\\\\ 2\\end{bmatrix} $相关的等式，使用图形直观理解物理意义\n\n## 线性组合、张成的空间与基\n\n为什么称$a \\vec{\\bf{v}} + b \\vec{\\bf{w}}$是$\\vec{\\bf{v}}$与$\\vec{\\bf{w}}$的**线性**组合：固定$\\vec{\\bf{v}}$的条件下，任意取$\\vec{\\bf{w}}$，得到的是一条线\n\n## 矩阵与线性变换\n\n### Linear Transformation\n\n- transformation\n\t* 相当于function（输入、输出）\n\t* 但之所以不用function，是因为transformation更有动感（由一个地方运动到另外一个地方）\n\t* 用网格线可视化（i.e. 画出网格线变换前后的位置）的时候，直观感受是空间发生变化\n- linear\n\t* 直线仍然是直线、原点位置不变（i.e. 保持网格线平行并等距分布）\n\n### 如何表示这个Linear Transformation\n\n- 一般来说，描述一个变换，我们需要记下所有的输入、输出pair\n- 但由于线性变换具有保持网格线平行且等距分布的性质\n- 发现假如原向量$\\vec{\\bf{v}}$是$\\hat{\\bf{i}}$和$\\hat{\\bf{j}}$的线性组合（伸缩），那么新向量$\\vec{\\bf{v}}\\_{new}$会是$\\hat{\\bf{i}}\\_{new}$和$\\hat{\\bf{j}}\\_{new}$相同的线性组合（伸缩）\n- 因此仅需记录$\\hat{\\bf{i}}\\_{new}$和$\\hat{\\bf{j}}\\_{new}$即有**足够信息**表示该线性变换（假设知道输入向量关于原向量$\\hat{\\bf{i}}$和$\\hat{\\bf{j}}$的线性组合，通过$\\hat{\\bf{i}}\\_{new}$和$\\hat{\\bf{j}}\\_{new}$即可以求得输出向量）\n- 【以上全部都只用到了图形化的解释，没有涉及坐标这个概念（i.e. 保存这个信息可以不用坐标，而是直接把新的箭头画出来，然后做箭头的加法和数乘）】\n- 【下面为了用数学来表示，开始引入坐标的概念】\n- 为了用坐标表示，需要选择一个基，于是选择原来的$\\hat{\\bf{i}}$和$\\hat{\\bf{j}}$作为基，之后的所有坐标都基于这个基\n- 引入坐标后，只需记录$\\hat{\\bf{i}}\\_{new}$和$\\hat{\\bf{j}}\\_{new}$的坐标，就有足够的信息表示该线性变换\n- 该坐标可以表示成矩阵的形式，因此**矩阵与线性变换具有对偶性**\n\n### 线性组合、线性变换、向量的表示\n\n- 注意，下面三者是独立的：\n\t* 向量的线性组合：$\\vec{\\bf{v}}$如何由$\\hat{\\bf{i}}$和$\\hat{\\bf{j}}$通过加法和数乘得到\n\t* 线性变换：具有保持网格线平行且等距分布性质的mapping\n\t* 向量的表示：引入一组基，使用一个数字列表表示沿各基的伸缩\n- e.g.\n\t+ 向量的线性组合：$\\bf{v} = 2\\bf{i} + 3\\bf{j}$\n<div style=\"width:400px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img combination.png 向量的线性组合 %}\n</div>\n\t+ 线性变换\n\t\t* 通过变换后有${\\bf{v}}\\_{new}$、${\\bf{i}}\\_{new}$和${\\bf{j}}\\_{new}$\n\t\t* ${\\bf{v}}\\_{new}$关于${\\bf{i}}\\_{new}$和${\\bf{j}}\\_{new}$的线性组合仍然为2和3\n<div style=\"width:400px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img transformation.png 线性变换 %}\n</div>\n\t+ 向量的表示：\n\t\t* $\\bf{i}$和$\\bf{j}$的坐标可以基于任意基S\n\t\t* ${\\bf{i}}\\_{new}$和${\\bf{j}}\\_{new}$的坐标可以基于任意基T\n\t\t* 最终${\\bf{v}}\\_{new}$的坐标基于基T\n<div style=\"width:400px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img representation.png 向量的表示 %}\n</div>\n- 一般情况下，对于向量的表示，都直接选取$\\bf{i}$和$\\bf{j}$作为基，这样做的好处是\n\t+ 可以直接从$\\bf{v}$的坐标知道线性组合\n\t+ 不用再为${\\bf{i}}\\_{new}$和${\\bf{j}}\\_{new}$选取新的基\n\t+ 最终的${\\bf{v}}\\_{new}$的坐标与$\\bf{v}$基于相同的基\n- 核心在于三点：\n\t+ 追踪用于表示$\\vec{v}$的向量\n\t+ 线性组合\n\t+ 向量的表示\n\n### $A\\vec{\\bf{x}}$的两种理解\n\n- 结果上来看，就是得到一个新的向量（箭头）\n- 由于该箭头使用坐标的形式表示的，那么肯定跟基相关\n- 过程可以有两个理解（主要是针对坐标x的理解不同）：\n\t* 把A看成是线性变换的表示【有发生线性变换，向量的表示没变】：那么$A\\vec{\\bf{x}}$就可以理解为将在基1下的坐标x经过线性变换得到的在基1下的新坐标\n\t* 把A看成是基2【没有发生线性变换，只是向量的表示发生了变化】：那么$A\\vec{\\bf{x}}$就可以理解为在基2下的坐标x在基1下的坐标\n\n## 矩阵乘法与线性变换复合\n\n- 两个矩阵相乘：一个结合两种变换的变换\n- 复合矩阵求解：追踪${\\bf{i}}\\_{new}$和${\\bf{j}}\\_{new}$\n- 直观理解解释：\n\t+ 交换律（$AB \\neq BA$）不成立\n\t+ 结合律（$(AB)C = A(BC)$）成立：复合变换AB等价于顺序进行变换B、A\n\n## 行列式\n\n- 动机：衡量线性变换使得空间伸缩了多少\n- 含义：\n\t+ 大小表示：单位正方形/立方体的面积/体积伸缩的比例\n\t+ 正负表示：定向（右手法则）\n<div style=\"width:400px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img det.png 行列式的含义 %}\n</div>\n- 等价：\n\t+ 行列式等于0\n\t+ 降维\n- 直观解释$det(AB) = det(A)det(B)$：\n\t+ $det(AB)$的含义是求解复合变换$AB$使得体积伸缩了几倍\n\t+ 复合变换$AB$首先进行变换$B$使得空间伸缩了$det(B)$，然后进行变换$A$使得空间伸缩了$det(A)$倍\n\t+ 所以体积总共伸缩了$det(A)det(B)$倍\n\n## 逆矩阵、列空间与零空间\n\n### 矩阵的用途：求解线性方程组\n\n- $A\\vec{\\bf{x}} = \\vec{\\bf{b}}$：找一个经过变换后等于$\\vec{\\bf{b}}$的向量\n- $det(A) \\neq 0$：有唯一解，一一对应\n\t+ 假如有一个变换，能使得$\\vec{\\bf{b}}$变到$\\vec{\\bf{x}}$\n\t+ 那么只要对$\\vec{\\bf{b}}$进行该变换即可得到要求的$\\vec{\\bf{x}}$\n\t+ 因为对于$\\vec{\\bf{x}}$来说，先进行变换$A$后再进行该变换等于没变\n\t+ 所以称该变换为$A$的逆\n\t+ 由此含义可知，以下等价\n\t\t* 逆存在\n\t\t* 没有降维\n\t\t* 行列式不等于0\n- $det(A) = 0$：不一定有解，除非$\\vec{\\bf{b}}$恰好在降维所在空间（列空间），此时有无限多个解（e.g. 两个共线向量表示该方向上的向量）\n\t+ 行列式等于0\n\t+ 降维（e.g. 空间由面变成线）\n\t+ 逆不存在\n\t\t* 假如逆存在\n\t\t* 存在一个变换（函数）由线map到面\n\t\t* 矛盾（违反函数的定义）\n\n### Rank\n\n- 动机：衡量降维的程度（降到点/线/面）\n- 含义：降维后的维度\n\n### 零空间\n\n- 动机：衡量有多少向量被映射到零向量（$A\\vec{\\bf{x}}=\\vec{\\bf{0}}$）\n- 假如没有降维，只有零向量会被映射到零向量\n- 假如降维，会有其他向量被映射到零向量\n- 被映射到零向量的向量组成零空间\n\t+ 零空间有非零向量\n\t+ 降维\n\t+ 行列式等于0\n\n## 非方阵\n\n- $\\begin{bmatrix} 1 & 2 \\\\\\\\ 2 & 2 \\\\\\\\ 3 & 3 \\end{bmatrix}$：\n\t+ $\\begin{bmatrix} １ \\\\\\\\ ０\\end{bmatrix}$ →　$\\begin{bmatrix} 1 \\\\\\\\ 2  \\\\\\\\ 3 \\end{bmatrix}$\n\t+ $\\begin{bmatrix} 0 \\\\\\\\ 1\\end{bmatrix}$ →　$\\begin{bmatrix} ２ \\\\\\\\ 2  \\\\\\\\ 3 \\end{bmatrix}$\n- $\\begin{bmatrix} 1 & 2 & 3\\\\\\\\ 2 & 2 & 3 \\end{bmatrix}$：\n\t+ $\\begin{bmatrix} １ \\\\\\\\ ０ \\\\\\\\ 0\\end{bmatrix}$ →　$\\begin{bmatrix} 1 \\\\\\\\ 2\\end{bmatrix}$\n\t+ $\\begin{bmatrix} 0 \\\\\\\\ 1 \\\\\\\\ 0\\end{bmatrix}$ →　$\\begin{bmatrix} 2 \\\\\\\\ 2\\end{bmatrix}$\n\t+ $\\begin{bmatrix} 0 \\\\\\\\ ０ \\\\\\\\ 1\\end{bmatrix}$ →　$\\begin{bmatrix} 3 \\\\\\\\ 3\\end{bmatrix}$\n\n## 点积与对偶性\n\n- 证明点积与顺序无关思路：\n\t+ 先证等长时顺序无关\n\t+ 再证不等长时顺序无关（标量相乘）\n<div style=\"width:400px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img dot_product_order.png 点积顺序无关 %}\n</div>\n- 对偶性：一一对应\n- 点积：\n\t+ 物理含义：投影长度再乘以被投影向量长度\n\t+ 数学含义\n- 证明对偶型思路：\n\t+ 验证单位向量点积：\n\t\t+ 定义投影到单位向量$\\vec{\\bf{\\hat{u}}}=\\begin{bmatrix} x \\\\\\\\ y \\end{bmatrix}$的投影长度这种线性变换\n\t\t+ 得到投影长度这种线性变换对应的矩阵为$\\begin{bmatrix} x & y\\end{bmatrix}$\n\t\t+ 运算结果恰好等于与一个单位向量点积的数学形式\n<div style=\"width:400px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img dot_product_projection.png 单位向量点积等价于投影长度这种线性变换 %}\n</div>\n\t+ 验证非单位向量点积：\n\t\t+ 对于一个任意长度的向量$\\vec{\\bf{u}}=k\\vec{\\bf{\\hat{u}}}$\n\t\t+ 定义投影到其单位向量$\\vec{\\bf{\\hat{u}}}=\\begin{bmatrix} x \\\\\\\\ y \\end{bmatrix}$的投影长度乘以其长度k这种线性变换\n\t\t+ 得到投影长度这种线性变换对应的矩阵为$k\\begin{bmatrix} x & y\\end{bmatrix}$\n\t\t+ 运算结果恰好等于与一个非单位向量$\\vec{\\bf{u}}$点积的数学形式\n- 将一个向量倒过来：投影到这个向量的投影长度乘以这个向量的长度这种线性变换对应的矩阵\n\n## 叉乘\n\n- 叉乘：\n\t+ 向量：大小为两向量平行四边形面积，方向为右手定则的向量\n\t+ 数学含义\n\t\t* 二维：$det(\\begin{bmatrix} \\vec{\\bf{u}} & \\vec{\\bf{v}} \\end{bmatrix})$\n\t\t* 三维：$det(\\begin{bmatrix} {\\begin{bmatrix} i \\\\\\\\ j \\\\\\\\ k \\end{bmatrix}} & \\vec{\\bf{u}} & \\vec{\\bf{v}} \\end{bmatrix})$\n- 证明思路\n\t+ 根据叉乘的定义，他是由$det(\\begin{bmatrix} {\\begin{bmatrix} i \\\\\\\\ j \\\\\\\\ k \\end{bmatrix}} & \\vec{\\bf{u}} & \\vec{\\bf{v}} \\end{bmatrix}) = Xi + Yj +Zk$得到的向量$\\begin{bmatrix} X \\\\\\\\ Y \\\\\\\\ Z \\end{bmatrix}$\n\t+ 要证明$\\begin{bmatrix} X \\\\\\\\ Y \\\\\\\\ Z \\end{bmatrix}$的大小为$\\vec{\\bf{u}}$和 $\\vec{\\bf{v}}$构成的平行四边型的面积，方向为右手定则\n\t\t* $Xi + Yj +Zk$的大小的物理意义有两个（i.e. 所找向量必须同时满足以下两个性质）\n\t\t\t+ $\\begin{bmatrix} X \\\\\\\\ Y \\\\\\\\ Z \\end{bmatrix}$与$\\begin{bmatrix} i \\\\\\\\ j \\\\\\\\ k \\end{bmatrix}$的点积\n\t\t\t+ $\\begin{bmatrix} i \\\\\\\\ j \\\\\\\\ k \\end{bmatrix}$、$\\vec{\\bf{u}}$和 $\\vec{\\bf{v}}$构成的平行六面体的体积\n\t\t* 当$Xi + Yj +Zk$大小为$\\vec{\\bf{u}}$和 $\\vec{\\bf{v}}$构成的平行四边型的面积，方向为右手定则时同时成立\n\n## 基变换\n\n### 向量表示（坐标）的变换\n\n- 从基于A系的坐标得到基于B系的坐标\n\t+ 对于一个坐标为$\\begin{bmatrix} 2 \\\\\\\\ 3\\end{bmatrix}$的向量\n\t+ 我们可以假设这个坐标是基于$\\vec{\\bf{u}}$和$\\vec{\\bf{v}}$的（i.e. 2和3是向量关于$\\vec{\\bf{u}}$和$\\vec{\\bf{v}}$的线性组合）\n\t+ 那么假如想要得到这个向量基于$\\vec{\\bf{i}}$和$\\vec{\\bf{j}}$的表示，只需得到$\\vec{\\bf{u}}$和$\\vec{\\bf{v}}$基于$\\vec{\\bf{i}}$和$\\vec{\\bf{j}}$的表示（i.e. 从基于A系的坐标得到基于B系的坐标）\n\t+ 从之前关于矩阵的两个理解可知该变换是个矩阵，记为M\n- 根据上述得到的矩阵M直接取得B系到A系的坐标变换\n\t+ 假设B系到A系的坐标变换矩阵为M'\n\t+ 那么对于A系下坐标为$\\begin{bmatrix} 2 \\\\\\\\ 3\\end{bmatrix}$的向量\n\t+ 先进行M变换将该坐标转换为B系下的坐标，再进行M'变换将B系下坐标转换为A系下坐标，得到的结果必然还是$\\begin{bmatrix} 2 \\\\\\\\ 3\\end{bmatrix}$\n\t+ 由此可得M'M是一个什么都不干的变换，所以M'是M的逆\n\n### 变换表示（矩阵）的变换\n\n- 对于同一个线性变换，基于不同的系有不同的表示\n- 假设线性变换在标准系下的表示为M，要求该线性变化在系A下的表示\n\t* 一般来说，在表示一个变换的时候，希望输入的表示和输出的表示是基于同一个系的\n\t* 输入的表示取决于基\n\t* 输出的表示取决于变换后基的表示\n\t* 所以为了输入输出基于相同系，变换后基的表示也取表示输入的基\n\t* 因此矩阵里面的列向量要与输入基于相同的基\n\t* 所以下面第一步是将基统一\n- A：将A系下的表示转换为标准系下的表示\n- MA：在标准系下进行转换\n- A'MA：通过A'将标准系下的向量转换为A系下的表示\n- 因此A'MA也称M的【相似矩阵】\n\n## 特征向量与特征值\n\n- eigen vector：变换后方向不变的向量\n- eigen value：变换后在对应eigen vector的伸缩量\n- eigen basis：\n\t* 有可能不够eigen vector来张成整个空间\n\t* 假如有的话，好处是：\n\t\t+ 在该变换下，基只发生了伸缩\n\t\t+ 用该基表示变换的话可以是对角矩阵，因为变换后基只与变换前基的一项相关，其余全是0\n\t\t+ 对角矩阵算幂很爽\n\t* 应用：算A的幂\n\t\t+ A是标准系下某个线性变换的表示\n\t\t+ 假如A有eigen basis（i.e.　足够多的方向不变向量）\n\t\t+ 求A对应的线性变换在eigen　basis下的表示（形式为B'AB），且该表示必然为对角矩阵【矩阵的对角化】\n\t\t+ 在eigen basis下进行幂运算\n\t\t+ 最后再把向量在eigen basis下的表示转回在标准系下的表示\n\n## 抽象向量空间\n\n- 基本就是1中所说的mathematician view（i.e.　满足一些性质（定义了加法、数乘，且运算封闭等等）的东西，physics view和cs　view等等都是向量的具体化）\n- 这里举了一个例子：\n\t+ 向量：多项式函数\n\t+ 线性变换：求导\n\n## 收获\n\n- 对线性代数有了更加直观、深刻的理解\n\t+ 理清了原先混淆的概念\n\t+　知道了为什么一些操作的物理含义是这样的\n- 对偶性的idea很美\n- 视频开始的句子很美\n\n## References\n\n- [线性代数的本质](http://space.bilibili.com/88461692#!/channel/detail?cid=9450)\n","source":"_posts/note-essence-of-linear-algrbra.md","raw":"---\ntitle: 课程笔记《线性代数的本质》\ntags:\n  - 线性代数的本质\ndescription:\n  - 形象、直观地理解线性代数\ncategories:\n  - 课程笔记\ndate: 2017-09-9 11:15:46\n---\n\n## 向量\n\n### 不同视角下的向量\n\n- physics：箭头\n- cs：数字列表（e.g. $ \\begin{bmatrix} 1 \\\\\\\\ 2\\end{bmatrix} $）\n- mathematician： $ \\vec{\\bf{v}} $\n\t* 抽象理解，任何相加和数乘有意义的东西\n\t* physics和cs都只是其中一种实例，还可以是其他任意满足性质的东西（e.g. 函数）\n\n### physics view与cs view的联系\n\n- 桥梁：坐标系\n- 对偶性（独立推导、一一对应）：表示、运算（加法、数乘）\n- 作用\n\t* physics→cs：已知想要的图形变换效果，使用$ \\begin{bmatrix} 1 \\\\\\\\ 2\\end{bmatrix} $与计算机进行交流 \n\t* cs→physics：已知$ \\begin{bmatrix} 1 \\\\\\\\ 2\\end{bmatrix} $相关的等式，使用图形直观理解物理意义\n\n## 线性组合、张成的空间与基\n\n为什么称$a \\vec{\\bf{v}} + b \\vec{\\bf{w}}$是$\\vec{\\bf{v}}$与$\\vec{\\bf{w}}$的**线性**组合：固定$\\vec{\\bf{v}}$的条件下，任意取$\\vec{\\bf{w}}$，得到的是一条线\n\n## 矩阵与线性变换\n\n### Linear Transformation\n\n- transformation\n\t* 相当于function（输入、输出）\n\t* 但之所以不用function，是因为transformation更有动感（由一个地方运动到另外一个地方）\n\t* 用网格线可视化（i.e. 画出网格线变换前后的位置）的时候，直观感受是空间发生变化\n- linear\n\t* 直线仍然是直线、原点位置不变（i.e. 保持网格线平行并等距分布）\n\n### 如何表示这个Linear Transformation\n\n- 一般来说，描述一个变换，我们需要记下所有的输入、输出pair\n- 但由于线性变换具有保持网格线平行且等距分布的性质\n- 发现假如原向量$\\vec{\\bf{v}}$是$\\hat{\\bf{i}}$和$\\hat{\\bf{j}}$的线性组合（伸缩），那么新向量$\\vec{\\bf{v}}\\_{new}$会是$\\hat{\\bf{i}}\\_{new}$和$\\hat{\\bf{j}}\\_{new}$相同的线性组合（伸缩）\n- 因此仅需记录$\\hat{\\bf{i}}\\_{new}$和$\\hat{\\bf{j}}\\_{new}$即有**足够信息**表示该线性变换（假设知道输入向量关于原向量$\\hat{\\bf{i}}$和$\\hat{\\bf{j}}$的线性组合，通过$\\hat{\\bf{i}}\\_{new}$和$\\hat{\\bf{j}}\\_{new}$即可以求得输出向量）\n- 【以上全部都只用到了图形化的解释，没有涉及坐标这个概念（i.e. 保存这个信息可以不用坐标，而是直接把新的箭头画出来，然后做箭头的加法和数乘）】\n- 【下面为了用数学来表示，开始引入坐标的概念】\n- 为了用坐标表示，需要选择一个基，于是选择原来的$\\hat{\\bf{i}}$和$\\hat{\\bf{j}}$作为基，之后的所有坐标都基于这个基\n- 引入坐标后，只需记录$\\hat{\\bf{i}}\\_{new}$和$\\hat{\\bf{j}}\\_{new}$的坐标，就有足够的信息表示该线性变换\n- 该坐标可以表示成矩阵的形式，因此**矩阵与线性变换具有对偶性**\n\n### 线性组合、线性变换、向量的表示\n\n- 注意，下面三者是独立的：\n\t* 向量的线性组合：$\\vec{\\bf{v}}$如何由$\\hat{\\bf{i}}$和$\\hat{\\bf{j}}$通过加法和数乘得到\n\t* 线性变换：具有保持网格线平行且等距分布性质的mapping\n\t* 向量的表示：引入一组基，使用一个数字列表表示沿各基的伸缩\n- e.g.\n\t+ 向量的线性组合：$\\bf{v} = 2\\bf{i} + 3\\bf{j}$\n<div style=\"width:400px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img combination.png 向量的线性组合 %}\n</div>\n\t+ 线性变换\n\t\t* 通过变换后有${\\bf{v}}\\_{new}$、${\\bf{i}}\\_{new}$和${\\bf{j}}\\_{new}$\n\t\t* ${\\bf{v}}\\_{new}$关于${\\bf{i}}\\_{new}$和${\\bf{j}}\\_{new}$的线性组合仍然为2和3\n<div style=\"width:400px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img transformation.png 线性变换 %}\n</div>\n\t+ 向量的表示：\n\t\t* $\\bf{i}$和$\\bf{j}$的坐标可以基于任意基S\n\t\t* ${\\bf{i}}\\_{new}$和${\\bf{j}}\\_{new}$的坐标可以基于任意基T\n\t\t* 最终${\\bf{v}}\\_{new}$的坐标基于基T\n<div style=\"width:400px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img representation.png 向量的表示 %}\n</div>\n- 一般情况下，对于向量的表示，都直接选取$\\bf{i}$和$\\bf{j}$作为基，这样做的好处是\n\t+ 可以直接从$\\bf{v}$的坐标知道线性组合\n\t+ 不用再为${\\bf{i}}\\_{new}$和${\\bf{j}}\\_{new}$选取新的基\n\t+ 最终的${\\bf{v}}\\_{new}$的坐标与$\\bf{v}$基于相同的基\n- 核心在于三点：\n\t+ 追踪用于表示$\\vec{v}$的向量\n\t+ 线性组合\n\t+ 向量的表示\n\n### $A\\vec{\\bf{x}}$的两种理解\n\n- 结果上来看，就是得到一个新的向量（箭头）\n- 由于该箭头使用坐标的形式表示的，那么肯定跟基相关\n- 过程可以有两个理解（主要是针对坐标x的理解不同）：\n\t* 把A看成是线性变换的表示【有发生线性变换，向量的表示没变】：那么$A\\vec{\\bf{x}}$就可以理解为将在基1下的坐标x经过线性变换得到的在基1下的新坐标\n\t* 把A看成是基2【没有发生线性变换，只是向量的表示发生了变化】：那么$A\\vec{\\bf{x}}$就可以理解为在基2下的坐标x在基1下的坐标\n\n## 矩阵乘法与线性变换复合\n\n- 两个矩阵相乘：一个结合两种变换的变换\n- 复合矩阵求解：追踪${\\bf{i}}\\_{new}$和${\\bf{j}}\\_{new}$\n- 直观理解解释：\n\t+ 交换律（$AB \\neq BA$）不成立\n\t+ 结合律（$(AB)C = A(BC)$）成立：复合变换AB等价于顺序进行变换B、A\n\n## 行列式\n\n- 动机：衡量线性变换使得空间伸缩了多少\n- 含义：\n\t+ 大小表示：单位正方形/立方体的面积/体积伸缩的比例\n\t+ 正负表示：定向（右手法则）\n<div style=\"width:400px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img det.png 行列式的含义 %}\n</div>\n- 等价：\n\t+ 行列式等于0\n\t+ 降维\n- 直观解释$det(AB) = det(A)det(B)$：\n\t+ $det(AB)$的含义是求解复合变换$AB$使得体积伸缩了几倍\n\t+ 复合变换$AB$首先进行变换$B$使得空间伸缩了$det(B)$，然后进行变换$A$使得空间伸缩了$det(A)$倍\n\t+ 所以体积总共伸缩了$det(A)det(B)$倍\n\n## 逆矩阵、列空间与零空间\n\n### 矩阵的用途：求解线性方程组\n\n- $A\\vec{\\bf{x}} = \\vec{\\bf{b}}$：找一个经过变换后等于$\\vec{\\bf{b}}$的向量\n- $det(A) \\neq 0$：有唯一解，一一对应\n\t+ 假如有一个变换，能使得$\\vec{\\bf{b}}$变到$\\vec{\\bf{x}}$\n\t+ 那么只要对$\\vec{\\bf{b}}$进行该变换即可得到要求的$\\vec{\\bf{x}}$\n\t+ 因为对于$\\vec{\\bf{x}}$来说，先进行变换$A$后再进行该变换等于没变\n\t+ 所以称该变换为$A$的逆\n\t+ 由此含义可知，以下等价\n\t\t* 逆存在\n\t\t* 没有降维\n\t\t* 行列式不等于0\n- $det(A) = 0$：不一定有解，除非$\\vec{\\bf{b}}$恰好在降维所在空间（列空间），此时有无限多个解（e.g. 两个共线向量表示该方向上的向量）\n\t+ 行列式等于0\n\t+ 降维（e.g. 空间由面变成线）\n\t+ 逆不存在\n\t\t* 假如逆存在\n\t\t* 存在一个变换（函数）由线map到面\n\t\t* 矛盾（违反函数的定义）\n\n### Rank\n\n- 动机：衡量降维的程度（降到点/线/面）\n- 含义：降维后的维度\n\n### 零空间\n\n- 动机：衡量有多少向量被映射到零向量（$A\\vec{\\bf{x}}=\\vec{\\bf{0}}$）\n- 假如没有降维，只有零向量会被映射到零向量\n- 假如降维，会有其他向量被映射到零向量\n- 被映射到零向量的向量组成零空间\n\t+ 零空间有非零向量\n\t+ 降维\n\t+ 行列式等于0\n\n## 非方阵\n\n- $\\begin{bmatrix} 1 & 2 \\\\\\\\ 2 & 2 \\\\\\\\ 3 & 3 \\end{bmatrix}$：\n\t+ $\\begin{bmatrix} １ \\\\\\\\ ０\\end{bmatrix}$ →　$\\begin{bmatrix} 1 \\\\\\\\ 2  \\\\\\\\ 3 \\end{bmatrix}$\n\t+ $\\begin{bmatrix} 0 \\\\\\\\ 1\\end{bmatrix}$ →　$\\begin{bmatrix} ２ \\\\\\\\ 2  \\\\\\\\ 3 \\end{bmatrix}$\n- $\\begin{bmatrix} 1 & 2 & 3\\\\\\\\ 2 & 2 & 3 \\end{bmatrix}$：\n\t+ $\\begin{bmatrix} １ \\\\\\\\ ０ \\\\\\\\ 0\\end{bmatrix}$ →　$\\begin{bmatrix} 1 \\\\\\\\ 2\\end{bmatrix}$\n\t+ $\\begin{bmatrix} 0 \\\\\\\\ 1 \\\\\\\\ 0\\end{bmatrix}$ →　$\\begin{bmatrix} 2 \\\\\\\\ 2\\end{bmatrix}$\n\t+ $\\begin{bmatrix} 0 \\\\\\\\ ０ \\\\\\\\ 1\\end{bmatrix}$ →　$\\begin{bmatrix} 3 \\\\\\\\ 3\\end{bmatrix}$\n\n## 点积与对偶性\n\n- 证明点积与顺序无关思路：\n\t+ 先证等长时顺序无关\n\t+ 再证不等长时顺序无关（标量相乘）\n<div style=\"width:400px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img dot_product_order.png 点积顺序无关 %}\n</div>\n- 对偶性：一一对应\n- 点积：\n\t+ 物理含义：投影长度再乘以被投影向量长度\n\t+ 数学含义\n- 证明对偶型思路：\n\t+ 验证单位向量点积：\n\t\t+ 定义投影到单位向量$\\vec{\\bf{\\hat{u}}}=\\begin{bmatrix} x \\\\\\\\ y \\end{bmatrix}$的投影长度这种线性变换\n\t\t+ 得到投影长度这种线性变换对应的矩阵为$\\begin{bmatrix} x & y\\end{bmatrix}$\n\t\t+ 运算结果恰好等于与一个单位向量点积的数学形式\n<div style=\"width:400px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img dot_product_projection.png 单位向量点积等价于投影长度这种线性变换 %}\n</div>\n\t+ 验证非单位向量点积：\n\t\t+ 对于一个任意长度的向量$\\vec{\\bf{u}}=k\\vec{\\bf{\\hat{u}}}$\n\t\t+ 定义投影到其单位向量$\\vec{\\bf{\\hat{u}}}=\\begin{bmatrix} x \\\\\\\\ y \\end{bmatrix}$的投影长度乘以其长度k这种线性变换\n\t\t+ 得到投影长度这种线性变换对应的矩阵为$k\\begin{bmatrix} x & y\\end{bmatrix}$\n\t\t+ 运算结果恰好等于与一个非单位向量$\\vec{\\bf{u}}$点积的数学形式\n- 将一个向量倒过来：投影到这个向量的投影长度乘以这个向量的长度这种线性变换对应的矩阵\n\n## 叉乘\n\n- 叉乘：\n\t+ 向量：大小为两向量平行四边形面积，方向为右手定则的向量\n\t+ 数学含义\n\t\t* 二维：$det(\\begin{bmatrix} \\vec{\\bf{u}} & \\vec{\\bf{v}} \\end{bmatrix})$\n\t\t* 三维：$det(\\begin{bmatrix} {\\begin{bmatrix} i \\\\\\\\ j \\\\\\\\ k \\end{bmatrix}} & \\vec{\\bf{u}} & \\vec{\\bf{v}} \\end{bmatrix})$\n- 证明思路\n\t+ 根据叉乘的定义，他是由$det(\\begin{bmatrix} {\\begin{bmatrix} i \\\\\\\\ j \\\\\\\\ k \\end{bmatrix}} & \\vec{\\bf{u}} & \\vec{\\bf{v}} \\end{bmatrix}) = Xi + Yj +Zk$得到的向量$\\begin{bmatrix} X \\\\\\\\ Y \\\\\\\\ Z \\end{bmatrix}$\n\t+ 要证明$\\begin{bmatrix} X \\\\\\\\ Y \\\\\\\\ Z \\end{bmatrix}$的大小为$\\vec{\\bf{u}}$和 $\\vec{\\bf{v}}$构成的平行四边型的面积，方向为右手定则\n\t\t* $Xi + Yj +Zk$的大小的物理意义有两个（i.e. 所找向量必须同时满足以下两个性质）\n\t\t\t+ $\\begin{bmatrix} X \\\\\\\\ Y \\\\\\\\ Z \\end{bmatrix}$与$\\begin{bmatrix} i \\\\\\\\ j \\\\\\\\ k \\end{bmatrix}$的点积\n\t\t\t+ $\\begin{bmatrix} i \\\\\\\\ j \\\\\\\\ k \\end{bmatrix}$、$\\vec{\\bf{u}}$和 $\\vec{\\bf{v}}$构成的平行六面体的体积\n\t\t* 当$Xi + Yj +Zk$大小为$\\vec{\\bf{u}}$和 $\\vec{\\bf{v}}$构成的平行四边型的面积，方向为右手定则时同时成立\n\n## 基变换\n\n### 向量表示（坐标）的变换\n\n- 从基于A系的坐标得到基于B系的坐标\n\t+ 对于一个坐标为$\\begin{bmatrix} 2 \\\\\\\\ 3\\end{bmatrix}$的向量\n\t+ 我们可以假设这个坐标是基于$\\vec{\\bf{u}}$和$\\vec{\\bf{v}}$的（i.e. 2和3是向量关于$\\vec{\\bf{u}}$和$\\vec{\\bf{v}}$的线性组合）\n\t+ 那么假如想要得到这个向量基于$\\vec{\\bf{i}}$和$\\vec{\\bf{j}}$的表示，只需得到$\\vec{\\bf{u}}$和$\\vec{\\bf{v}}$基于$\\vec{\\bf{i}}$和$\\vec{\\bf{j}}$的表示（i.e. 从基于A系的坐标得到基于B系的坐标）\n\t+ 从之前关于矩阵的两个理解可知该变换是个矩阵，记为M\n- 根据上述得到的矩阵M直接取得B系到A系的坐标变换\n\t+ 假设B系到A系的坐标变换矩阵为M'\n\t+ 那么对于A系下坐标为$\\begin{bmatrix} 2 \\\\\\\\ 3\\end{bmatrix}$的向量\n\t+ 先进行M变换将该坐标转换为B系下的坐标，再进行M'变换将B系下坐标转换为A系下坐标，得到的结果必然还是$\\begin{bmatrix} 2 \\\\\\\\ 3\\end{bmatrix}$\n\t+ 由此可得M'M是一个什么都不干的变换，所以M'是M的逆\n\n### 变换表示（矩阵）的变换\n\n- 对于同一个线性变换，基于不同的系有不同的表示\n- 假设线性变换在标准系下的表示为M，要求该线性变化在系A下的表示\n\t* 一般来说，在表示一个变换的时候，希望输入的表示和输出的表示是基于同一个系的\n\t* 输入的表示取决于基\n\t* 输出的表示取决于变换后基的表示\n\t* 所以为了输入输出基于相同系，变换后基的表示也取表示输入的基\n\t* 因此矩阵里面的列向量要与输入基于相同的基\n\t* 所以下面第一步是将基统一\n- A：将A系下的表示转换为标准系下的表示\n- MA：在标准系下进行转换\n- A'MA：通过A'将标准系下的向量转换为A系下的表示\n- 因此A'MA也称M的【相似矩阵】\n\n## 特征向量与特征值\n\n- eigen vector：变换后方向不变的向量\n- eigen value：变换后在对应eigen vector的伸缩量\n- eigen basis：\n\t* 有可能不够eigen vector来张成整个空间\n\t* 假如有的话，好处是：\n\t\t+ 在该变换下，基只发生了伸缩\n\t\t+ 用该基表示变换的话可以是对角矩阵，因为变换后基只与变换前基的一项相关，其余全是0\n\t\t+ 对角矩阵算幂很爽\n\t* 应用：算A的幂\n\t\t+ A是标准系下某个线性变换的表示\n\t\t+ 假如A有eigen basis（i.e.　足够多的方向不变向量）\n\t\t+ 求A对应的线性变换在eigen　basis下的表示（形式为B'AB），且该表示必然为对角矩阵【矩阵的对角化】\n\t\t+ 在eigen basis下进行幂运算\n\t\t+ 最后再把向量在eigen basis下的表示转回在标准系下的表示\n\n## 抽象向量空间\n\n- 基本就是1中所说的mathematician view（i.e.　满足一些性质（定义了加法、数乘，且运算封闭等等）的东西，physics view和cs　view等等都是向量的具体化）\n- 这里举了一个例子：\n\t+ 向量：多项式函数\n\t+ 线性变换：求导\n\n## 收获\n\n- 对线性代数有了更加直观、深刻的理解\n\t+ 理清了原先混淆的概念\n\t+　知道了为什么一些操作的物理含义是这样的\n- 对偶性的idea很美\n- 视频开始的句子很美\n\n## References\n\n- [线性代数的本质](http://space.bilibili.com/88461692#!/channel/detail?cid=9450)\n","slug":"note-essence-of-linear-algrbra","published":1,"updated":"2024-08-13T16:03:47.848Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clzvf191x000teqwor5v4pmk4","content":"<h2 id=\"向量\"><a href=\"#向量\" class=\"headerlink\" title=\"向量\"></a>向量</h2><h3 id=\"不同视角下的向量\"><a href=\"#不同视角下的向量\" class=\"headerlink\" title=\"不同视角下的向量\"></a>不同视角下的向量</h3><ul>\n<li>physics：箭头</li>\n<li>cs：数字列表（e.g. $ \\begin{bmatrix} 1 \\\\\\ 2\\end{bmatrix} $）</li>\n<li>mathematician： $ \\vec{\\bf{v}} $<ul>\n<li>抽象理解，任何相加和数乘有意义的东西</li>\n<li>physics和cs都只是其中一种实例，还可以是其他任意满足性质的东西（e.g. 函数）</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"physics-view与cs-view的联系\"><a href=\"#physics-view与cs-view的联系\" class=\"headerlink\" title=\"physics view与cs view的联系\"></a>physics view与cs view的联系</h3><ul>\n<li>桥梁：坐标系</li>\n<li>对偶性（独立推导、一一对应）：表示、运算（加法、数乘）</li>\n<li>作用<ul>\n<li>physics→cs：已知想要的图形变换效果，使用$ \\begin{bmatrix} 1 \\\\\\ 2\\end{bmatrix} $与计算机进行交流 </li>\n<li>cs→physics：已知$ \\begin{bmatrix} 1 \\\\\\ 2\\end{bmatrix} $相关的等式，使用图形直观理解物理意义</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"线性组合、张成的空间与基\"><a href=\"#线性组合、张成的空间与基\" class=\"headerlink\" title=\"线性组合、张成的空间与基\"></a>线性组合、张成的空间与基</h2><p>为什么称$a \\vec{\\bf{v}} + b \\vec{\\bf{w}}$是$\\vec{\\bf{v}}$与$\\vec{\\bf{w}}$的<strong>线性</strong>组合：固定$\\vec{\\bf{v}}$的条件下，任意取$\\vec{\\bf{w}}$，得到的是一条线</p>\n<h2 id=\"矩阵与线性变换\"><a href=\"#矩阵与线性变换\" class=\"headerlink\" title=\"矩阵与线性变换\"></a>矩阵与线性变换</h2><h3 id=\"Linear-Transformation\"><a href=\"#Linear-Transformation\" class=\"headerlink\" title=\"Linear Transformation\"></a>Linear Transformation</h3><ul>\n<li>transformation<ul>\n<li>相当于function（输入、输出）</li>\n<li>但之所以不用function，是因为transformation更有动感（由一个地方运动到另外一个地方）</li>\n<li>用网格线可视化（i.e. 画出网格线变换前后的位置）的时候，直观感受是空间发生变化</li>\n</ul>\n</li>\n<li>linear<ul>\n<li>直线仍然是直线、原点位置不变（i.e. 保持网格线平行并等距分布）</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"如何表示这个Linear-Transformation\"><a href=\"#如何表示这个Linear-Transformation\" class=\"headerlink\" title=\"如何表示这个Linear Transformation\"></a>如何表示这个Linear Transformation</h3><ul>\n<li>一般来说，描述一个变换，我们需要记下所有的输入、输出pair</li>\n<li>但由于线性变换具有保持网格线平行且等距分布的性质</li>\n<li>发现假如原向量$\\vec{\\bf{v}}$是$\\hat{\\bf{i}}$和$\\hat{\\bf{j}}$的线性组合（伸缩），那么新向量$\\vec{\\bf{v}}_{new}$会是$\\hat{\\bf{i}}_{new}$和$\\hat{\\bf{j}}_{new}$相同的线性组合（伸缩）</li>\n<li>因此仅需记录$\\hat{\\bf{i}}_{new}$和$\\hat{\\bf{j}}_{new}$即有<strong>足够信息</strong>表示该线性变换（假设知道输入向量关于原向量$\\hat{\\bf{i}}$和$\\hat{\\bf{j}}$的线性组合，通过$\\hat{\\bf{i}}_{new}$和$\\hat{\\bf{j}}_{new}$即可以求得输出向量）</li>\n<li>【以上全部都只用到了图形化的解释，没有涉及坐标这个概念（i.e. 保存这个信息可以不用坐标，而是直接把新的箭头画出来，然后做箭头的加法和数乘）】</li>\n<li>【下面为了用数学来表示，开始引入坐标的概念】</li>\n<li>为了用坐标表示，需要选择一个基，于是选择原来的$\\hat{\\bf{i}}$和$\\hat{\\bf{j}}$作为基，之后的所有坐标都基于这个基</li>\n<li>引入坐标后，只需记录$\\hat{\\bf{i}}_{new}$和$\\hat{\\bf{j}}_{new}$的坐标，就有足够的信息表示该线性变换</li>\n<li>该坐标可以表示成矩阵的形式，因此<strong>矩阵与线性变换具有对偶性</strong></li>\n</ul>\n<h3 id=\"线性组合、线性变换、向量的表示\"><a href=\"#线性组合、线性变换、向量的表示\" class=\"headerlink\" title=\"线性组合、线性变换、向量的表示\"></a>线性组合、线性变换、向量的表示</h3><ul>\n<li>注意，下面三者是独立的：<ul>\n<li>向量的线性组合：$\\vec{\\bf{v}}$如何由$\\hat{\\bf{i}}$和$\\hat{\\bf{j}}$通过加法和数乘得到</li>\n<li>线性变换：具有保持网格线平行且等距分布性质的mapping</li>\n<li>向量的表示：引入一组基，使用一个数字列表表示沿各基的伸缩</li>\n</ul>\n</li>\n<li>e.g.<ul>\n<li>向量的线性组合：$\\bf{v} = 2\\bf{i} + 3\\bf{j}$<div style=\"width:400px; margin-left:auto; margin-right:auto;\"><br><img src=\"/2017/09/09/note-essence-of-linear-algrbra/combination.png\" alt=\"向量的线性组合\" title=\"向量的线性组合\"><br></div></li>\n<li>线性变换<ul>\n<li>通过变换后有${\\bf{v}}_{new}$、${\\bf{i}}_{new}$和${\\bf{j}}_{new}$</li>\n<li>${\\bf{v}}_{new}$关于${\\bf{i}}_{new}$和${\\bf{j}}_{new}$的线性组合仍然为2和3<div style=\"width:400px; margin-left:auto; margin-right:auto;\"><br><img src=\"/2017/09/09/note-essence-of-linear-algrbra/transformation.png\" alt=\"线性变换\" title=\"线性变换\"><br></div></li>\n</ul>\n</li>\n<li>向量的表示：<ul>\n<li>$\\bf{i}$和$\\bf{j}$的坐标可以基于任意基S</li>\n<li>${\\bf{i}}_{new}$和${\\bf{j}}_{new}$的坐标可以基于任意基T</li>\n<li>最终${\\bf{v}}_{new}$的坐标基于基T<div style=\"width:400px; margin-left:auto; margin-right:auto;\"><br><img src=\"/2017/09/09/note-essence-of-linear-algrbra/representation.png\" alt=\"向量的表示\" title=\"向量的表示\"><br></div></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>一般情况下，对于向量的表示，都直接选取$\\bf{i}$和$\\bf{j}$作为基，这样做的好处是<ul>\n<li>可以直接从$\\bf{v}$的坐标知道线性组合</li>\n<li>不用再为${\\bf{i}}_{new}$和${\\bf{j}}_{new}$选取新的基</li>\n<li>最终的${\\bf{v}}_{new}$的坐标与$\\bf{v}$基于相同的基</li>\n</ul>\n</li>\n<li>核心在于三点：<ul>\n<li>追踪用于表示$\\vec{v}$的向量</li>\n<li>线性组合</li>\n<li>向量的表示</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"A-vec-bf-x-的两种理解\"><a href=\"#A-vec-bf-x-的两种理解\" class=\"headerlink\" title=\"$A\\vec{\\bf{x}}$的两种理解\"></a>$A\\vec{\\bf{x}}$的两种理解</h3><ul>\n<li>结果上来看，就是得到一个新的向量（箭头）</li>\n<li>由于该箭头使用坐标的形式表示的，那么肯定跟基相关</li>\n<li>过程可以有两个理解（主要是针对坐标x的理解不同）：<ul>\n<li>把A看成是线性变换的表示【有发生线性变换，向量的表示没变】：那么$A\\vec{\\bf{x}}$就可以理解为将在基1下的坐标x经过线性变换得到的在基1下的新坐标</li>\n<li>把A看成是基2【没有发生线性变换，只是向量的表示发生了变化】：那么$A\\vec{\\bf{x}}$就可以理解为在基2下的坐标x在基1下的坐标</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"矩阵乘法与线性变换复合\"><a href=\"#矩阵乘法与线性变换复合\" class=\"headerlink\" title=\"矩阵乘法与线性变换复合\"></a>矩阵乘法与线性变换复合</h2><ul>\n<li>两个矩阵相乘：一个结合两种变换的变换</li>\n<li>复合矩阵求解：追踪${\\bf{i}}_{new}$和${\\bf{j}}_{new}$</li>\n<li>直观理解解释：<ul>\n<li>交换律（$AB \\neq BA$）不成立</li>\n<li>结合律（$(AB)C = A(BC)$）成立：复合变换AB等价于顺序进行变换B、A</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"行列式\"><a href=\"#行列式\" class=\"headerlink\" title=\"行列式\"></a>行列式</h2><ul>\n<li>动机：衡量线性变换使得空间伸缩了多少</li>\n<li>含义：<ul>\n<li>大小表示：单位正方形/立方体的面积/体积伸缩的比例</li>\n<li>正负表示：定向（右手法则）<div style=\"width:400px; margin-left:auto; margin-right:auto;\"><br><img src=\"/2017/09/09/note-essence-of-linear-algrbra/det.png\" alt=\"行列式的含义\" title=\"行列式的含义\"><br></div></li>\n</ul>\n</li>\n<li>等价：<ul>\n<li>行列式等于0</li>\n<li>降维</li>\n</ul>\n</li>\n<li>直观解释$det(AB) = det(A)det(B)$：<ul>\n<li>$det(AB)$的含义是求解复合变换$AB$使得体积伸缩了几倍</li>\n<li>复合变换$AB$首先进行变换$B$使得空间伸缩了$det(B)$，然后进行变换$A$使得空间伸缩了$det(A)$倍</li>\n<li>所以体积总共伸缩了$det(A)det(B)$倍</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"逆矩阵、列空间与零空间\"><a href=\"#逆矩阵、列空间与零空间\" class=\"headerlink\" title=\"逆矩阵、列空间与零空间\"></a>逆矩阵、列空间与零空间</h2><h3 id=\"矩阵的用途：求解线性方程组\"><a href=\"#矩阵的用途：求解线性方程组\" class=\"headerlink\" title=\"矩阵的用途：求解线性方程组\"></a>矩阵的用途：求解线性方程组</h3><ul>\n<li>$A\\vec{\\bf{x}} = \\vec{\\bf{b}}$：找一个经过变换后等于$\\vec{\\bf{b}}$的向量</li>\n<li>$det(A) \\neq 0$：有唯一解，一一对应<ul>\n<li>假如有一个变换，能使得$\\vec{\\bf{b}}$变到$\\vec{\\bf{x}}$</li>\n<li>那么只要对$\\vec{\\bf{b}}$进行该变换即可得到要求的$\\vec{\\bf{x}}$</li>\n<li>因为对于$\\vec{\\bf{x}}$来说，先进行变换$A$后再进行该变换等于没变</li>\n<li>所以称该变换为$A$的逆</li>\n<li>由此含义可知，以下等价<ul>\n<li>逆存在</li>\n<li>没有降维</li>\n<li>行列式不等于0</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>$det(A) = 0$：不一定有解，除非$\\vec{\\bf{b}}$恰好在降维所在空间（列空间），此时有无限多个解（e.g. 两个共线向量表示该方向上的向量）<ul>\n<li>行列式等于0</li>\n<li>降维（e.g. 空间由面变成线）</li>\n<li>逆不存在<ul>\n<li>假如逆存在</li>\n<li>存在一个变换（函数）由线map到面</li>\n<li>矛盾（违反函数的定义）</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Rank\"><a href=\"#Rank\" class=\"headerlink\" title=\"Rank\"></a>Rank</h3><ul>\n<li>动机：衡量降维的程度（降到点/线/面）</li>\n<li>含义：降维后的维度</li>\n</ul>\n<h3 id=\"零空间\"><a href=\"#零空间\" class=\"headerlink\" title=\"零空间\"></a>零空间</h3><ul>\n<li>动机：衡量有多少向量被映射到零向量（$A\\vec{\\bf{x}}=\\vec{\\bf{0}}$）</li>\n<li>假如没有降维，只有零向量会被映射到零向量</li>\n<li>假如降维，会有其他向量被映射到零向量</li>\n<li>被映射到零向量的向量组成零空间<ul>\n<li>零空间有非零向量</li>\n<li>降维</li>\n<li>行列式等于0</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"非方阵\"><a href=\"#非方阵\" class=\"headerlink\" title=\"非方阵\"></a>非方阵</h2><ul>\n<li>$\\begin{bmatrix} 1 &amp; 2 \\\\\\ 2 &amp; 2 \\\\\\ 3 &amp; 3 \\end{bmatrix}$：<ul>\n<li>$\\begin{bmatrix} １ \\\\\\ ０\\end{bmatrix}$ →　$\\begin{bmatrix} 1 \\\\\\ 2  \\\\\\ 3 \\end{bmatrix}$</li>\n<li>$\\begin{bmatrix} 0 \\\\\\ 1\\end{bmatrix}$ →　$\\begin{bmatrix} ２ \\\\\\ 2  \\\\\\ 3 \\end{bmatrix}$</li>\n</ul>\n</li>\n<li>$\\begin{bmatrix} 1 &amp; 2 &amp; 3\\\\\\ 2 &amp; 2 &amp; 3 \\end{bmatrix}$：<ul>\n<li>$\\begin{bmatrix} １ \\\\\\ ０ \\\\\\ 0\\end{bmatrix}$ →　$\\begin{bmatrix} 1 \\\\\\ 2\\end{bmatrix}$</li>\n<li>$\\begin{bmatrix} 0 \\\\\\ 1 \\\\\\ 0\\end{bmatrix}$ →　$\\begin{bmatrix} 2 \\\\\\ 2\\end{bmatrix}$</li>\n<li>$\\begin{bmatrix} 0 \\\\\\ ０ \\\\\\ 1\\end{bmatrix}$ →　$\\begin{bmatrix} 3 \\\\\\ 3\\end{bmatrix}$</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"点积与对偶性\"><a href=\"#点积与对偶性\" class=\"headerlink\" title=\"点积与对偶性\"></a>点积与对偶性</h2><ul>\n<li>证明点积与顺序无关思路：<ul>\n<li>先证等长时顺序无关</li>\n<li>再证不等长时顺序无关（标量相乘）<div style=\"width:400px; margin-left:auto; margin-right:auto;\"><br><img src=\"/2017/09/09/note-essence-of-linear-algrbra/dot_product_order.png\" alt=\"点积顺序无关\" title=\"点积顺序无关\"><br></div></li>\n</ul>\n</li>\n<li>对偶性：一一对应</li>\n<li>点积：<ul>\n<li>物理含义：投影长度再乘以被投影向量长度</li>\n<li>数学含义</li>\n</ul>\n</li>\n<li>证明对偶型思路：<ul>\n<li>验证单位向量点积：<ul>\n<li>定义投影到单位向量$\\vec{\\bf{\\hat{u}}}=\\begin{bmatrix} x \\\\\\ y \\end{bmatrix}$的投影长度这种线性变换</li>\n<li>得到投影长度这种线性变换对应的矩阵为$\\begin{bmatrix} x &amp; y\\end{bmatrix}$</li>\n<li>运算结果恰好等于与一个单位向量点积的数学形式<div style=\"width:400px; margin-left:auto; margin-right:auto;\"><br><img src=\"/2017/09/09/note-essence-of-linear-algrbra/dot_product_projection.png\" alt=\"单位向量点积等价于投影长度这种线性变换\" title=\"单位向量点积等价于投影长度这种线性变换\"><br></div></li>\n</ul>\n</li>\n<li>验证非单位向量点积：<ul>\n<li>对于一个任意长度的向量$\\vec{\\bf{u}}=k\\vec{\\bf{\\hat{u}}}$</li>\n<li>定义投影到其单位向量$\\vec{\\bf{\\hat{u}}}=\\begin{bmatrix} x \\\\\\ y \\end{bmatrix}$的投影长度乘以其长度k这种线性变换</li>\n<li>得到投影长度这种线性变换对应的矩阵为$k\\begin{bmatrix} x &amp; y\\end{bmatrix}$</li>\n<li>运算结果恰好等于与一个非单位向量$\\vec{\\bf{u}}$点积的数学形式</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>将一个向量倒过来：投影到这个向量的投影长度乘以这个向量的长度这种线性变换对应的矩阵</li>\n</ul>\n<h2 id=\"叉乘\"><a href=\"#叉乘\" class=\"headerlink\" title=\"叉乘\"></a>叉乘</h2><ul>\n<li>叉乘：<ul>\n<li>向量：大小为两向量平行四边形面积，方向为右手定则的向量</li>\n<li>数学含义<ul>\n<li>二维：$det(\\begin{bmatrix} \\vec{\\bf{u}} &amp; \\vec{\\bf{v}} \\end{bmatrix})$</li>\n<li>三维：$det(\\begin{bmatrix} {\\begin{bmatrix} i \\\\\\ j \\\\\\ k \\end{bmatrix}} &amp; \\vec{\\bf{u}} &amp; \\vec{\\bf{v}} \\end{bmatrix})$</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>证明思路<ul>\n<li>根据叉乘的定义，他是由$det(\\begin{bmatrix} {\\begin{bmatrix} i \\\\\\ j \\\\\\ k \\end{bmatrix}} &amp; \\vec{\\bf{u}} &amp; \\vec{\\bf{v}} \\end{bmatrix}) = Xi + Yj +Zk$得到的向量$\\begin{bmatrix} X \\\\\\ Y \\\\\\ Z \\end{bmatrix}$</li>\n<li>要证明$\\begin{bmatrix} X \\\\\\ Y \\\\\\ Z \\end{bmatrix}$的大小为$\\vec{\\bf{u}}$和 $\\vec{\\bf{v}}$构成的平行四边型的面积，方向为右手定则<ul>\n<li>$Xi + Yj +Zk$的大小的物理意义有两个（i.e. 所找向量必须同时满足以下两个性质）<ul>\n<li>$\\begin{bmatrix} X \\\\\\ Y \\\\\\ Z \\end{bmatrix}$与$\\begin{bmatrix} i \\\\\\ j \\\\\\ k \\end{bmatrix}$的点积</li>\n<li>$\\begin{bmatrix} i \\\\\\ j \\\\\\ k \\end{bmatrix}$、$\\vec{\\bf{u}}$和 $\\vec{\\bf{v}}$构成的平行六面体的体积</li>\n</ul>\n</li>\n<li>当$Xi + Yj +Zk$大小为$\\vec{\\bf{u}}$和 $\\vec{\\bf{v}}$构成的平行四边型的面积，方向为右手定则时同时成立</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"基变换\"><a href=\"#基变换\" class=\"headerlink\" title=\"基变换\"></a>基变换</h2><h3 id=\"向量表示（坐标）的变换\"><a href=\"#向量表示（坐标）的变换\" class=\"headerlink\" title=\"向量表示（坐标）的变换\"></a>向量表示（坐标）的变换</h3><ul>\n<li>从基于A系的坐标得到基于B系的坐标<ul>\n<li>对于一个坐标为$\\begin{bmatrix} 2 \\\\\\ 3\\end{bmatrix}$的向量</li>\n<li>我们可以假设这个坐标是基于$\\vec{\\bf{u}}$和$\\vec{\\bf{v}}$的（i.e. 2和3是向量关于$\\vec{\\bf{u}}$和$\\vec{\\bf{v}}$的线性组合）</li>\n<li>那么假如想要得到这个向量基于$\\vec{\\bf{i}}$和$\\vec{\\bf{j}}$的表示，只需得到$\\vec{\\bf{u}}$和$\\vec{\\bf{v}}$基于$\\vec{\\bf{i}}$和$\\vec{\\bf{j}}$的表示（i.e. 从基于A系的坐标得到基于B系的坐标）</li>\n<li>从之前关于矩阵的两个理解可知该变换是个矩阵，记为M</li>\n</ul>\n</li>\n<li>根据上述得到的矩阵M直接取得B系到A系的坐标变换<ul>\n<li>假设B系到A系的坐标变换矩阵为M’</li>\n<li>那么对于A系下坐标为$\\begin{bmatrix} 2 \\\\\\ 3\\end{bmatrix}$的向量</li>\n<li>先进行M变换将该坐标转换为B系下的坐标，再进行M’变换将B系下坐标转换为A系下坐标，得到的结果必然还是$\\begin{bmatrix} 2 \\\\\\ 3\\end{bmatrix}$</li>\n<li>由此可得M’M是一个什么都不干的变换，所以M’是M的逆</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"变换表示（矩阵）的变换\"><a href=\"#变换表示（矩阵）的变换\" class=\"headerlink\" title=\"变换表示（矩阵）的变换\"></a>变换表示（矩阵）的变换</h3><ul>\n<li>对于同一个线性变换，基于不同的系有不同的表示</li>\n<li>假设线性变换在标准系下的表示为M，要求该线性变化在系A下的表示<ul>\n<li>一般来说，在表示一个变换的时候，希望输入的表示和输出的表示是基于同一个系的</li>\n<li>输入的表示取决于基</li>\n<li>输出的表示取决于变换后基的表示</li>\n<li>所以为了输入输出基于相同系，变换后基的表示也取表示输入的基</li>\n<li>因此矩阵里面的列向量要与输入基于相同的基</li>\n<li>所以下面第一步是将基统一</li>\n</ul>\n</li>\n<li>A：将A系下的表示转换为标准系下的表示</li>\n<li>MA：在标准系下进行转换</li>\n<li>A’MA：通过A’将标准系下的向量转换为A系下的表示</li>\n<li>因此A’MA也称M的【相似矩阵】</li>\n</ul>\n<h2 id=\"特征向量与特征值\"><a href=\"#特征向量与特征值\" class=\"headerlink\" title=\"特征向量与特征值\"></a>特征向量与特征值</h2><ul>\n<li>eigen vector：变换后方向不变的向量</li>\n<li>eigen value：变换后在对应eigen vector的伸缩量</li>\n<li>eigen basis：<ul>\n<li>有可能不够eigen vector来张成整个空间</li>\n<li>假如有的话，好处是：<ul>\n<li>在该变换下，基只发生了伸缩</li>\n<li>用该基表示变换的话可以是对角矩阵，因为变换后基只与变换前基的一项相关，其余全是0</li>\n<li>对角矩阵算幂很爽</li>\n</ul>\n</li>\n<li>应用：算A的幂<ul>\n<li>A是标准系下某个线性变换的表示</li>\n<li>假如A有eigen basis（i.e.　足够多的方向不变向量）</li>\n<li>求A对应的线性变换在eigen　basis下的表示（形式为B’AB），且该表示必然为对角矩阵【矩阵的对角化】</li>\n<li>在eigen basis下进行幂运算</li>\n<li>最后再把向量在eigen basis下的表示转回在标准系下的表示</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"抽象向量空间\"><a href=\"#抽象向量空间\" class=\"headerlink\" title=\"抽象向量空间\"></a>抽象向量空间</h2><ul>\n<li>基本就是1中所说的mathematician view（i.e.　满足一些性质（定义了加法、数乘，且运算封闭等等）的东西，physics view和cs　view等等都是向量的具体化）</li>\n<li>这里举了一个例子：<ul>\n<li>向量：多项式函数</li>\n<li>线性变换：求导</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"收获\"><a href=\"#收获\" class=\"headerlink\" title=\"收获\"></a>收获</h2><ul>\n<li>对线性代数有了更加直观、深刻的理解<ul>\n<li>理清了原先混淆的概念<br>+　知道了为什么一些操作的物理含义是这样的</li>\n</ul>\n</li>\n<li>对偶性的idea很美</li>\n<li>视频开始的句子很美</li>\n</ul>\n<h2 id=\"References\"><a href=\"#References\" class=\"headerlink\" title=\"References\"></a>References</h2><ul>\n<li><a href=\"http://space.bilibili.com/88461692#!/channel/detail?cid=9450\" target=\"_blank\" rel=\"external\">线性代数的本质</a></li>\n</ul>\n","excerpt":"","more":"<h2 id=\"向量\"><a href=\"#向量\" class=\"headerlink\" title=\"向量\"></a>向量</h2><h3 id=\"不同视角下的向量\"><a href=\"#不同视角下的向量\" class=\"headerlink\" title=\"不同视角下的向量\"></a>不同视角下的向量</h3><ul>\n<li>physics：箭头</li>\n<li>cs：数字列表（e.g. $ \\begin{bmatrix} 1 \\\\\\ 2\\end{bmatrix} $）</li>\n<li>mathematician： $ \\vec{\\bf{v}} $<ul>\n<li>抽象理解，任何相加和数乘有意义的东西</li>\n<li>physics和cs都只是其中一种实例，还可以是其他任意满足性质的东西（e.g. 函数）</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"physics-view与cs-view的联系\"><a href=\"#physics-view与cs-view的联系\" class=\"headerlink\" title=\"physics view与cs view的联系\"></a>physics view与cs view的联系</h3><ul>\n<li>桥梁：坐标系</li>\n<li>对偶性（独立推导、一一对应）：表示、运算（加法、数乘）</li>\n<li>作用<ul>\n<li>physics→cs：已知想要的图形变换效果，使用$ \\begin{bmatrix} 1 \\\\\\ 2\\end{bmatrix} $与计算机进行交流 </li>\n<li>cs→physics：已知$ \\begin{bmatrix} 1 \\\\\\ 2\\end{bmatrix} $相关的等式，使用图形直观理解物理意义</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"线性组合、张成的空间与基\"><a href=\"#线性组合、张成的空间与基\" class=\"headerlink\" title=\"线性组合、张成的空间与基\"></a>线性组合、张成的空间与基</h2><p>为什么称$a \\vec{\\bf{v}} + b \\vec{\\bf{w}}$是$\\vec{\\bf{v}}$与$\\vec{\\bf{w}}$的<strong>线性</strong>组合：固定$\\vec{\\bf{v}}$的条件下，任意取$\\vec{\\bf{w}}$，得到的是一条线</p>\n<h2 id=\"矩阵与线性变换\"><a href=\"#矩阵与线性变换\" class=\"headerlink\" title=\"矩阵与线性变换\"></a>矩阵与线性变换</h2><h3 id=\"Linear-Transformation\"><a href=\"#Linear-Transformation\" class=\"headerlink\" title=\"Linear Transformation\"></a>Linear Transformation</h3><ul>\n<li>transformation<ul>\n<li>相当于function（输入、输出）</li>\n<li>但之所以不用function，是因为transformation更有动感（由一个地方运动到另外一个地方）</li>\n<li>用网格线可视化（i.e. 画出网格线变换前后的位置）的时候，直观感受是空间发生变化</li>\n</ul>\n</li>\n<li>linear<ul>\n<li>直线仍然是直线、原点位置不变（i.e. 保持网格线平行并等距分布）</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"如何表示这个Linear-Transformation\"><a href=\"#如何表示这个Linear-Transformation\" class=\"headerlink\" title=\"如何表示这个Linear Transformation\"></a>如何表示这个Linear Transformation</h3><ul>\n<li>一般来说，描述一个变换，我们需要记下所有的输入、输出pair</li>\n<li>但由于线性变换具有保持网格线平行且等距分布的性质</li>\n<li>发现假如原向量$\\vec{\\bf{v}}$是$\\hat{\\bf{i}}$和$\\hat{\\bf{j}}$的线性组合（伸缩），那么新向量$\\vec{\\bf{v}}_{new}$会是$\\hat{\\bf{i}}_{new}$和$\\hat{\\bf{j}}_{new}$相同的线性组合（伸缩）</li>\n<li>因此仅需记录$\\hat{\\bf{i}}_{new}$和$\\hat{\\bf{j}}_{new}$即有<strong>足够信息</strong>表示该线性变换（假设知道输入向量关于原向量$\\hat{\\bf{i}}$和$\\hat{\\bf{j}}$的线性组合，通过$\\hat{\\bf{i}}_{new}$和$\\hat{\\bf{j}}_{new}$即可以求得输出向量）</li>\n<li>【以上全部都只用到了图形化的解释，没有涉及坐标这个概念（i.e. 保存这个信息可以不用坐标，而是直接把新的箭头画出来，然后做箭头的加法和数乘）】</li>\n<li>【下面为了用数学来表示，开始引入坐标的概念】</li>\n<li>为了用坐标表示，需要选择一个基，于是选择原来的$\\hat{\\bf{i}}$和$\\hat{\\bf{j}}$作为基，之后的所有坐标都基于这个基</li>\n<li>引入坐标后，只需记录$\\hat{\\bf{i}}_{new}$和$\\hat{\\bf{j}}_{new}$的坐标，就有足够的信息表示该线性变换</li>\n<li>该坐标可以表示成矩阵的形式，因此<strong>矩阵与线性变换具有对偶性</strong></li>\n</ul>\n<h3 id=\"线性组合、线性变换、向量的表示\"><a href=\"#线性组合、线性变换、向量的表示\" class=\"headerlink\" title=\"线性组合、线性变换、向量的表示\"></a>线性组合、线性变换、向量的表示</h3><ul>\n<li>注意，下面三者是独立的：<ul>\n<li>向量的线性组合：$\\vec{\\bf{v}}$如何由$\\hat{\\bf{i}}$和$\\hat{\\bf{j}}$通过加法和数乘得到</li>\n<li>线性变换：具有保持网格线平行且等距分布性质的mapping</li>\n<li>向量的表示：引入一组基，使用一个数字列表表示沿各基的伸缩</li>\n</ul>\n</li>\n<li>e.g.<ul>\n<li>向量的线性组合：$\\bf{v} = 2\\bf{i} + 3\\bf{j}$<div style=\"width:400px; margin-left:auto; margin-right:auto;\" ><br><img src=\"/2017/09/09/note-essence-of-linear-algrbra/combination.png\" alt=\"向量的线性组合\" title=\"向量的线性组合\"><br></div></li>\n<li>线性变换<ul>\n<li>通过变换后有${\\bf{v}}_{new}$、${\\bf{i}}_{new}$和${\\bf{j}}_{new}$</li>\n<li>${\\bf{v}}_{new}$关于${\\bf{i}}_{new}$和${\\bf{j}}_{new}$的线性组合仍然为2和3<div style=\"width:400px; margin-left:auto; margin-right:auto;\" ><br><img src=\"/2017/09/09/note-essence-of-linear-algrbra/transformation.png\" alt=\"线性变换\" title=\"线性变换\"><br></div></li>\n</ul>\n</li>\n<li>向量的表示：<ul>\n<li>$\\bf{i}$和$\\bf{j}$的坐标可以基于任意基S</li>\n<li>${\\bf{i}}_{new}$和${\\bf{j}}_{new}$的坐标可以基于任意基T</li>\n<li>最终${\\bf{v}}_{new}$的坐标基于基T<div style=\"width:400px; margin-left:auto; margin-right:auto;\" ><br><img src=\"/2017/09/09/note-essence-of-linear-algrbra/representation.png\" alt=\"向量的表示\" title=\"向量的表示\"><br></div></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>一般情况下，对于向量的表示，都直接选取$\\bf{i}$和$\\bf{j}$作为基，这样做的好处是<ul>\n<li>可以直接从$\\bf{v}$的坐标知道线性组合</li>\n<li>不用再为${\\bf{i}}_{new}$和${\\bf{j}}_{new}$选取新的基</li>\n<li>最终的${\\bf{v}}_{new}$的坐标与$\\bf{v}$基于相同的基</li>\n</ul>\n</li>\n<li>核心在于三点：<ul>\n<li>追踪用于表示$\\vec{v}$的向量</li>\n<li>线性组合</li>\n<li>向量的表示</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"A-vec-bf-x-的两种理解\"><a href=\"#A-vec-bf-x-的两种理解\" class=\"headerlink\" title=\"$A\\vec{\\bf{x}}$的两种理解\"></a>$A\\vec{\\bf{x}}$的两种理解</h3><ul>\n<li>结果上来看，就是得到一个新的向量（箭头）</li>\n<li>由于该箭头使用坐标的形式表示的，那么肯定跟基相关</li>\n<li>过程可以有两个理解（主要是针对坐标x的理解不同）：<ul>\n<li>把A看成是线性变换的表示【有发生线性变换，向量的表示没变】：那么$A\\vec{\\bf{x}}$就可以理解为将在基1下的坐标x经过线性变换得到的在基1下的新坐标</li>\n<li>把A看成是基2【没有发生线性变换，只是向量的表示发生了变化】：那么$A\\vec{\\bf{x}}$就可以理解为在基2下的坐标x在基1下的坐标</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"矩阵乘法与线性变换复合\"><a href=\"#矩阵乘法与线性变换复合\" class=\"headerlink\" title=\"矩阵乘法与线性变换复合\"></a>矩阵乘法与线性变换复合</h2><ul>\n<li>两个矩阵相乘：一个结合两种变换的变换</li>\n<li>复合矩阵求解：追踪${\\bf{i}}_{new}$和${\\bf{j}}_{new}$</li>\n<li>直观理解解释：<ul>\n<li>交换律（$AB \\neq BA$）不成立</li>\n<li>结合律（$(AB)C = A(BC)$）成立：复合变换AB等价于顺序进行变换B、A</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"行列式\"><a href=\"#行列式\" class=\"headerlink\" title=\"行列式\"></a>行列式</h2><ul>\n<li>动机：衡量线性变换使得空间伸缩了多少</li>\n<li>含义：<ul>\n<li>大小表示：单位正方形/立方体的面积/体积伸缩的比例</li>\n<li>正负表示：定向（右手法则）<div style=\"width:400px; margin-left:auto; margin-right:auto;\" ><br><img src=\"/2017/09/09/note-essence-of-linear-algrbra/det.png\" alt=\"行列式的含义\" title=\"行列式的含义\"><br></div></li>\n</ul>\n</li>\n<li>等价：<ul>\n<li>行列式等于0</li>\n<li>降维</li>\n</ul>\n</li>\n<li>直观解释$det(AB) = det(A)det(B)$：<ul>\n<li>$det(AB)$的含义是求解复合变换$AB$使得体积伸缩了几倍</li>\n<li>复合变换$AB$首先进行变换$B$使得空间伸缩了$det(B)$，然后进行变换$A$使得空间伸缩了$det(A)$倍</li>\n<li>所以体积总共伸缩了$det(A)det(B)$倍</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"逆矩阵、列空间与零空间\"><a href=\"#逆矩阵、列空间与零空间\" class=\"headerlink\" title=\"逆矩阵、列空间与零空间\"></a>逆矩阵、列空间与零空间</h2><h3 id=\"矩阵的用途：求解线性方程组\"><a href=\"#矩阵的用途：求解线性方程组\" class=\"headerlink\" title=\"矩阵的用途：求解线性方程组\"></a>矩阵的用途：求解线性方程组</h3><ul>\n<li>$A\\vec{\\bf{x}} = \\vec{\\bf{b}}$：找一个经过变换后等于$\\vec{\\bf{b}}$的向量</li>\n<li>$det(A) \\neq 0$：有唯一解，一一对应<ul>\n<li>假如有一个变换，能使得$\\vec{\\bf{b}}$变到$\\vec{\\bf{x}}$</li>\n<li>那么只要对$\\vec{\\bf{b}}$进行该变换即可得到要求的$\\vec{\\bf{x}}$</li>\n<li>因为对于$\\vec{\\bf{x}}$来说，先进行变换$A$后再进行该变换等于没变</li>\n<li>所以称该变换为$A$的逆</li>\n<li>由此含义可知，以下等价<ul>\n<li>逆存在</li>\n<li>没有降维</li>\n<li>行列式不等于0</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>$det(A) = 0$：不一定有解，除非$\\vec{\\bf{b}}$恰好在降维所在空间（列空间），此时有无限多个解（e.g. 两个共线向量表示该方向上的向量）<ul>\n<li>行列式等于0</li>\n<li>降维（e.g. 空间由面变成线）</li>\n<li>逆不存在<ul>\n<li>假如逆存在</li>\n<li>存在一个变换（函数）由线map到面</li>\n<li>矛盾（违反函数的定义）</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Rank\"><a href=\"#Rank\" class=\"headerlink\" title=\"Rank\"></a>Rank</h3><ul>\n<li>动机：衡量降维的程度（降到点/线/面）</li>\n<li>含义：降维后的维度</li>\n</ul>\n<h3 id=\"零空间\"><a href=\"#零空间\" class=\"headerlink\" title=\"零空间\"></a>零空间</h3><ul>\n<li>动机：衡量有多少向量被映射到零向量（$A\\vec{\\bf{x}}=\\vec{\\bf{0}}$）</li>\n<li>假如没有降维，只有零向量会被映射到零向量</li>\n<li>假如降维，会有其他向量被映射到零向量</li>\n<li>被映射到零向量的向量组成零空间<ul>\n<li>零空间有非零向量</li>\n<li>降维</li>\n<li>行列式等于0</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"非方阵\"><a href=\"#非方阵\" class=\"headerlink\" title=\"非方阵\"></a>非方阵</h2><ul>\n<li>$\\begin{bmatrix} 1 &amp; 2 \\\\\\ 2 &amp; 2 \\\\\\ 3 &amp; 3 \\end{bmatrix}$：<ul>\n<li>$\\begin{bmatrix} １ \\\\\\ ０\\end{bmatrix}$ →　$\\begin{bmatrix} 1 \\\\\\ 2  \\\\\\ 3 \\end{bmatrix}$</li>\n<li>$\\begin{bmatrix} 0 \\\\\\ 1\\end{bmatrix}$ →　$\\begin{bmatrix} ２ \\\\\\ 2  \\\\\\ 3 \\end{bmatrix}$</li>\n</ul>\n</li>\n<li>$\\begin{bmatrix} 1 &amp; 2 &amp; 3\\\\\\ 2 &amp; 2 &amp; 3 \\end{bmatrix}$：<ul>\n<li>$\\begin{bmatrix} １ \\\\\\ ０ \\\\\\ 0\\end{bmatrix}$ →　$\\begin{bmatrix} 1 \\\\\\ 2\\end{bmatrix}$</li>\n<li>$\\begin{bmatrix} 0 \\\\\\ 1 \\\\\\ 0\\end{bmatrix}$ →　$\\begin{bmatrix} 2 \\\\\\ 2\\end{bmatrix}$</li>\n<li>$\\begin{bmatrix} 0 \\\\\\ ０ \\\\\\ 1\\end{bmatrix}$ →　$\\begin{bmatrix} 3 \\\\\\ 3\\end{bmatrix}$</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"点积与对偶性\"><a href=\"#点积与对偶性\" class=\"headerlink\" title=\"点积与对偶性\"></a>点积与对偶性</h2><ul>\n<li>证明点积与顺序无关思路：<ul>\n<li>先证等长时顺序无关</li>\n<li>再证不等长时顺序无关（标量相乘）<div style=\"width:400px; margin-left:auto; margin-right:auto;\" ><br><img src=\"/2017/09/09/note-essence-of-linear-algrbra/dot_product_order.png\" alt=\"点积顺序无关\" title=\"点积顺序无关\"><br></div></li>\n</ul>\n</li>\n<li>对偶性：一一对应</li>\n<li>点积：<ul>\n<li>物理含义：投影长度再乘以被投影向量长度</li>\n<li>数学含义</li>\n</ul>\n</li>\n<li>证明对偶型思路：<ul>\n<li>验证单位向量点积：<ul>\n<li>定义投影到单位向量$\\vec{\\bf{\\hat{u}}}=\\begin{bmatrix} x \\\\\\ y \\end{bmatrix}$的投影长度这种线性变换</li>\n<li>得到投影长度这种线性变换对应的矩阵为$\\begin{bmatrix} x &amp; y\\end{bmatrix}$</li>\n<li>运算结果恰好等于与一个单位向量点积的数学形式<div style=\"width:400px; margin-left:auto; margin-right:auto;\" ><br><img src=\"/2017/09/09/note-essence-of-linear-algrbra/dot_product_projection.png\" alt=\"单位向量点积等价于投影长度这种线性变换\" title=\"单位向量点积等价于投影长度这种线性变换\"><br></div></li>\n</ul>\n</li>\n<li>验证非单位向量点积：<ul>\n<li>对于一个任意长度的向量$\\vec{\\bf{u}}=k\\vec{\\bf{\\hat{u}}}$</li>\n<li>定义投影到其单位向量$\\vec{\\bf{\\hat{u}}}=\\begin{bmatrix} x \\\\\\ y \\end{bmatrix}$的投影长度乘以其长度k这种线性变换</li>\n<li>得到投影长度这种线性变换对应的矩阵为$k\\begin{bmatrix} x &amp; y\\end{bmatrix}$</li>\n<li>运算结果恰好等于与一个非单位向量$\\vec{\\bf{u}}$点积的数学形式</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>将一个向量倒过来：投影到这个向量的投影长度乘以这个向量的长度这种线性变换对应的矩阵</li>\n</ul>\n<h2 id=\"叉乘\"><a href=\"#叉乘\" class=\"headerlink\" title=\"叉乘\"></a>叉乘</h2><ul>\n<li>叉乘：<ul>\n<li>向量：大小为两向量平行四边形面积，方向为右手定则的向量</li>\n<li>数学含义<ul>\n<li>二维：$det(\\begin{bmatrix} \\vec{\\bf{u}} &amp; \\vec{\\bf{v}} \\end{bmatrix})$</li>\n<li>三维：$det(\\begin{bmatrix} {\\begin{bmatrix} i \\\\\\ j \\\\\\ k \\end{bmatrix}} &amp; \\vec{\\bf{u}} &amp; \\vec{\\bf{v}} \\end{bmatrix})$</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>证明思路<ul>\n<li>根据叉乘的定义，他是由$det(\\begin{bmatrix} {\\begin{bmatrix} i \\\\\\ j \\\\\\ k \\end{bmatrix}} &amp; \\vec{\\bf{u}} &amp; \\vec{\\bf{v}} \\end{bmatrix}) = Xi + Yj +Zk$得到的向量$\\begin{bmatrix} X \\\\\\ Y \\\\\\ Z \\end{bmatrix}$</li>\n<li>要证明$\\begin{bmatrix} X \\\\\\ Y \\\\\\ Z \\end{bmatrix}$的大小为$\\vec{\\bf{u}}$和 $\\vec{\\bf{v}}$构成的平行四边型的面积，方向为右手定则<ul>\n<li>$Xi + Yj +Zk$的大小的物理意义有两个（i.e. 所找向量必须同时满足以下两个性质）<ul>\n<li>$\\begin{bmatrix} X \\\\\\ Y \\\\\\ Z \\end{bmatrix}$与$\\begin{bmatrix} i \\\\\\ j \\\\\\ k \\end{bmatrix}$的点积</li>\n<li>$\\begin{bmatrix} i \\\\\\ j \\\\\\ k \\end{bmatrix}$、$\\vec{\\bf{u}}$和 $\\vec{\\bf{v}}$构成的平行六面体的体积</li>\n</ul>\n</li>\n<li>当$Xi + Yj +Zk$大小为$\\vec{\\bf{u}}$和 $\\vec{\\bf{v}}$构成的平行四边型的面积，方向为右手定则时同时成立</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"基变换\"><a href=\"#基变换\" class=\"headerlink\" title=\"基变换\"></a>基变换</h2><h3 id=\"向量表示（坐标）的变换\"><a href=\"#向量表示（坐标）的变换\" class=\"headerlink\" title=\"向量表示（坐标）的变换\"></a>向量表示（坐标）的变换</h3><ul>\n<li>从基于A系的坐标得到基于B系的坐标<ul>\n<li>对于一个坐标为$\\begin{bmatrix} 2 \\\\\\ 3\\end{bmatrix}$的向量</li>\n<li>我们可以假设这个坐标是基于$\\vec{\\bf{u}}$和$\\vec{\\bf{v}}$的（i.e. 2和3是向量关于$\\vec{\\bf{u}}$和$\\vec{\\bf{v}}$的线性组合）</li>\n<li>那么假如想要得到这个向量基于$\\vec{\\bf{i}}$和$\\vec{\\bf{j}}$的表示，只需得到$\\vec{\\bf{u}}$和$\\vec{\\bf{v}}$基于$\\vec{\\bf{i}}$和$\\vec{\\bf{j}}$的表示（i.e. 从基于A系的坐标得到基于B系的坐标）</li>\n<li>从之前关于矩阵的两个理解可知该变换是个矩阵，记为M</li>\n</ul>\n</li>\n<li>根据上述得到的矩阵M直接取得B系到A系的坐标变换<ul>\n<li>假设B系到A系的坐标变换矩阵为M’</li>\n<li>那么对于A系下坐标为$\\begin{bmatrix} 2 \\\\\\ 3\\end{bmatrix}$的向量</li>\n<li>先进行M变换将该坐标转换为B系下的坐标，再进行M’变换将B系下坐标转换为A系下坐标，得到的结果必然还是$\\begin{bmatrix} 2 \\\\\\ 3\\end{bmatrix}$</li>\n<li>由此可得M’M是一个什么都不干的变换，所以M’是M的逆</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"变换表示（矩阵）的变换\"><a href=\"#变换表示（矩阵）的变换\" class=\"headerlink\" title=\"变换表示（矩阵）的变换\"></a>变换表示（矩阵）的变换</h3><ul>\n<li>对于同一个线性变换，基于不同的系有不同的表示</li>\n<li>假设线性变换在标准系下的表示为M，要求该线性变化在系A下的表示<ul>\n<li>一般来说，在表示一个变换的时候，希望输入的表示和输出的表示是基于同一个系的</li>\n<li>输入的表示取决于基</li>\n<li>输出的表示取决于变换后基的表示</li>\n<li>所以为了输入输出基于相同系，变换后基的表示也取表示输入的基</li>\n<li>因此矩阵里面的列向量要与输入基于相同的基</li>\n<li>所以下面第一步是将基统一</li>\n</ul>\n</li>\n<li>A：将A系下的表示转换为标准系下的表示</li>\n<li>MA：在标准系下进行转换</li>\n<li>A’MA：通过A’将标准系下的向量转换为A系下的表示</li>\n<li>因此A’MA也称M的【相似矩阵】</li>\n</ul>\n<h2 id=\"特征向量与特征值\"><a href=\"#特征向量与特征值\" class=\"headerlink\" title=\"特征向量与特征值\"></a>特征向量与特征值</h2><ul>\n<li>eigen vector：变换后方向不变的向量</li>\n<li>eigen value：变换后在对应eigen vector的伸缩量</li>\n<li>eigen basis：<ul>\n<li>有可能不够eigen vector来张成整个空间</li>\n<li>假如有的话，好处是：<ul>\n<li>在该变换下，基只发生了伸缩</li>\n<li>用该基表示变换的话可以是对角矩阵，因为变换后基只与变换前基的一项相关，其余全是0</li>\n<li>对角矩阵算幂很爽</li>\n</ul>\n</li>\n<li>应用：算A的幂<ul>\n<li>A是标准系下某个线性变换的表示</li>\n<li>假如A有eigen basis（i.e.　足够多的方向不变向量）</li>\n<li>求A对应的线性变换在eigen　basis下的表示（形式为B’AB），且该表示必然为对角矩阵【矩阵的对角化】</li>\n<li>在eigen basis下进行幂运算</li>\n<li>最后再把向量在eigen basis下的表示转回在标准系下的表示</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"抽象向量空间\"><a href=\"#抽象向量空间\" class=\"headerlink\" title=\"抽象向量空间\"></a>抽象向量空间</h2><ul>\n<li>基本就是1中所说的mathematician view（i.e.　满足一些性质（定义了加法、数乘，且运算封闭等等）的东西，physics view和cs　view等等都是向量的具体化）</li>\n<li>这里举了一个例子：<ul>\n<li>向量：多项式函数</li>\n<li>线性变换：求导</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"收获\"><a href=\"#收获\" class=\"headerlink\" title=\"收获\"></a>收获</h2><ul>\n<li>对线性代数有了更加直观、深刻的理解<ul>\n<li>理清了原先混淆的概念<br>+　知道了为什么一些操作的物理含义是这样的</li>\n</ul>\n</li>\n<li>对偶性的idea很美</li>\n<li>视频开始的句子很美</li>\n</ul>\n<h2 id=\"References\"><a href=\"#References\" class=\"headerlink\" title=\"References\"></a>References</h2><ul>\n<li><a href=\"http://space.bilibili.com/88461692#!/channel/detail?cid=9450\">线性代数的本质</a></li>\n</ul>\n"},{"title":"课程笔记《Learning How to Learn》","description":["关于学习方法的一门课程"],"date":"2017-09-09T07:16:28.000Z","_content":"\n## 思维导图\n\n<div style=\"width:800px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img learning_how_to_learn.png Learning How to Learn思维导图 %}\n</div>\n\n## References\n\n- [Learning How to Learn](https://www.coursera.org/learn/learning-how-to-learn)","source":"_posts/note-learning-how-to-learn.md","raw":"---\ntitle: 课程笔记《Learning How to Learn》\ntags:\n  - 学习方法\ndescription:\n  - 关于学习方法的一门课程\ncategories:\n  - 课程笔记\ndate: 2017-09-09 15:16:28\n---\n\n## 思维导图\n\n<div style=\"width:800px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img learning_how_to_learn.png Learning How to Learn思维导图 %}\n</div>\n\n## References\n\n- [Learning How to Learn](https://www.coursera.org/learn/learning-how-to-learn)","slug":"note-learning-how-to-learn","published":1,"updated":"2024-08-13T16:03:47.852Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clzvf191z000veqwodbuu30tr","content":"<h2 id=\"思维导图\"><a href=\"#思维导图\" class=\"headerlink\" title=\"思维导图\"></a>思维导图</h2><div style=\"width:800px; margin-left:auto; margin-right:auto;\"><br>  <img src=\"/2017/09/09/note-learning-how-to-learn/learning_how_to_learn.png\" alt=\"Learning How to Learn思维导图\" title=\"Learning How to Learn思维导图\"><br></div>\n\n<h2 id=\"References\"><a href=\"#References\" class=\"headerlink\" title=\"References\"></a>References</h2><ul>\n<li><a href=\"https://www.coursera.org/learn/learning-how-to-learn\" target=\"_blank\" rel=\"external\">Learning How to Learn</a></li>\n</ul>\n","excerpt":"","more":"<h2 id=\"思维导图\"><a href=\"#思维导图\" class=\"headerlink\" title=\"思维导图\"></a>思维导图</h2><div style=\"width:800px; margin-left:auto; margin-right:auto;\" ><br>  <img src=\"/2017/09/09/note-learning-how-to-learn/learning_how_to_learn.png\" alt=\"Learning How to Learn思维导图\" title=\"Learning How to Learn思维导图\"><br></div>\n\n<h2 id=\"References\"><a href=\"#References\" class=\"headerlink\" title=\"References\"></a>References</h2><ul>\n<li><a href=\"https://www.coursera.org/learn/learning-how-to-learn\">Learning How to Learn</a></li>\n</ul>\n"},{"title":"课程笔记《MIT18.06线性代数》","description":["MIT Gilbert Strang深入浅出的线性代数课程"],"date":"2017-09-09T07:09:17.000Z","_content":"\n## 思维导图\n\n<div style=\"width:800px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img linear_algebra.png MIT18.06线性代数思维导图 %}\n</div>\n\n## References\n\n- [MIT18.06线性代数](http://open.163.com/special/opencourse/daishu.html)","source":"_posts/note-linear-algebra.md","raw":"---\ntitle: 课程笔记《MIT18.06线性代数》\ntags:\n  - 线性代数\ndescription:\n  - MIT Gilbert Strang深入浅出的线性代数课程\ncategories:\n  - 课程笔记\ndate: 2017-09-09 15:09:17\n---\n\n## 思维导图\n\n<div style=\"width:800px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img linear_algebra.png MIT18.06线性代数思维导图 %}\n</div>\n\n## References\n\n- [MIT18.06线性代数](http://open.163.com/special/opencourse/daishu.html)","slug":"note-linear-algebra","published":1,"updated":"2024-08-13T16:03:47.852Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clzvf1921000yeqwod4s8qyy0","content":"<h2 id=\"思维导图\"><a href=\"#思维导图\" class=\"headerlink\" title=\"思维导图\"></a>思维导图</h2><div style=\"width:800px; margin-left:auto; margin-right:auto;\"><br>  <img src=\"/2017/09/09/note-linear-algebra/linear_algebra.png\" alt=\"MIT18.06线性代数思维导图\" title=\"MIT18.06线性代数思维导图\"><br></div>\n\n<h2 id=\"References\"><a href=\"#References\" class=\"headerlink\" title=\"References\"></a>References</h2><ul>\n<li><a href=\"http://open.163.com/special/opencourse/daishu.html\" target=\"_blank\" rel=\"external\">MIT18.06线性代数</a></li>\n</ul>\n","excerpt":"","more":"<h2 id=\"思维导图\"><a href=\"#思维导图\" class=\"headerlink\" title=\"思维导图\"></a>思维导图</h2><div style=\"width:800px; margin-left:auto; margin-right:auto;\" ><br>  <img src=\"/2017/09/09/note-linear-algebra/linear_algebra.png\" alt=\"MIT18.06线性代数思维导图\" title=\"MIT18.06线性代数思维导图\"><br></div>\n\n<h2 id=\"References\"><a href=\"#References\" class=\"headerlink\" title=\"References\"></a>References</h2><ul>\n<li><a href=\"http://open.163.com/special/opencourse/daishu.html\">MIT18.06线性代数</a></li>\n</ul>\n"},{"title":"课程笔记《UCL强化学习》","description":["UCL David Silver的强化学习课程"],"date":"2017-09-09T07:21:42.000Z","_content":"\n## 思维导图\n\n### Intro to RL\n\n<div style=\"width:800px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img lec1_Intro_to_RL.png Intro to RL %}\n</div>\n\n### MDP\n\n<div style=\"width:800px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img lec2_MDP.png MDP %}\n</div>\n\n### Planning by DP\n\n<div style=\"width:800px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img lec3_Planning_by_DP.png Planning by DP %}\n</div>\n\n### Model-Free Prediction\n\n<div style=\"width:800px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img lec4_Model_Free_Prediction.png Model-Free Prediction %}\n</div>\n\n### Model-Free Control\n\n<div style=\"width:800px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img lec5_Model_Free_Control.png Model-Free Control %}\n</div>\n\n### Value Function Approximation\n\n<div style=\"width:800px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img lec6_Value_Function_Approximation.png Value Function Approximation %}\n</div>\n\n### Policy Gradient\n\n<div style=\"width:800px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img lec7_Policy_Gradient.png Policy Gradient %}\n</div>\n\n### Integrating Learning and Planning\n\n<div style=\"width:800px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img lec8_Integrating_Learning_and_Planning.png Integrating Learning and Planning %}\n</div>\n\n### Exploration and Exploitation\n\n<div style=\"width:800px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img lec9_Exploration_and_Exploitation.png Exploration and Exploitation %}\n</div>\n\n## References\n\n- [强化学习课程](http://www0.cs.ucl.ac.uk/staff/D.Silver/web/Teaching.html)\n- [强化学习教材](http://people.inf.elte.hu/lorincz/Files/RL_2006/SuttonBook.pdf)","source":"_posts/note-reinforcement-learning.md","raw":"---\ntitle: 课程笔记《UCL强化学习》\ntags:\n  - 强化学习\ndescription:\n  - UCL David Silver的强化学习课程\ncategories:\n  - 课程笔记\ndate: 2017-09-09 15:21:42\n---\n\n## 思维导图\n\n### Intro to RL\n\n<div style=\"width:800px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img lec1_Intro_to_RL.png Intro to RL %}\n</div>\n\n### MDP\n\n<div style=\"width:800px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img lec2_MDP.png MDP %}\n</div>\n\n### Planning by DP\n\n<div style=\"width:800px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img lec3_Planning_by_DP.png Planning by DP %}\n</div>\n\n### Model-Free Prediction\n\n<div style=\"width:800px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img lec4_Model_Free_Prediction.png Model-Free Prediction %}\n</div>\n\n### Model-Free Control\n\n<div style=\"width:800px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img lec5_Model_Free_Control.png Model-Free Control %}\n</div>\n\n### Value Function Approximation\n\n<div style=\"width:800px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img lec6_Value_Function_Approximation.png Value Function Approximation %}\n</div>\n\n### Policy Gradient\n\n<div style=\"width:800px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img lec7_Policy_Gradient.png Policy Gradient %}\n</div>\n\n### Integrating Learning and Planning\n\n<div style=\"width:800px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img lec8_Integrating_Learning_and_Planning.png Integrating Learning and Planning %}\n</div>\n\n### Exploration and Exploitation\n\n<div style=\"width:800px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img lec9_Exploration_and_Exploitation.png Exploration and Exploitation %}\n</div>\n\n## References\n\n- [强化学习课程](http://www0.cs.ucl.ac.uk/staff/D.Silver/web/Teaching.html)\n- [强化学习教材](http://people.inf.elte.hu/lorincz/Files/RL_2006/SuttonBook.pdf)","slug":"note-reinforcement-learning","published":1,"updated":"2024-08-13T16:03:47.856Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clzvf19230011eqwod5y0jaoq","content":"<h2 id=\"思维导图\"><a href=\"#思维导图\" class=\"headerlink\" title=\"思维导图\"></a>思维导图</h2><h3 id=\"Intro-to-RL\"><a href=\"#Intro-to-RL\" class=\"headerlink\" title=\"Intro to RL\"></a>Intro to RL</h3><div style=\"width:800px; margin-left:auto; margin-right:auto;\"><br>  <img src=\"/2017/09/09/note-reinforcement-learning/lec1_Intro_to_RL.png\" alt=\"Intro to RL\" title=\"Intro to RL\"><br></div>\n\n<h3 id=\"MDP\"><a href=\"#MDP\" class=\"headerlink\" title=\"MDP\"></a>MDP</h3><div style=\"width:800px; margin-left:auto; margin-right:auto;\"><br>  <img src=\"/2017/09/09/note-reinforcement-learning/lec2_MDP.png\" alt=\"MDP\" title=\"MDP\"><br></div>\n\n<h3 id=\"Planning-by-DP\"><a href=\"#Planning-by-DP\" class=\"headerlink\" title=\"Planning by DP\"></a>Planning by DP</h3><div style=\"width:800px; margin-left:auto; margin-right:auto;\"><br>  <img src=\"/2017/09/09/note-reinforcement-learning/lec3_Planning_by_DP.png\" alt=\"Planning by DP\" title=\"Planning by DP\"><br></div>\n\n<h3 id=\"Model-Free-Prediction\"><a href=\"#Model-Free-Prediction\" class=\"headerlink\" title=\"Model-Free Prediction\"></a>Model-Free Prediction</h3><div style=\"width:800px; margin-left:auto; margin-right:auto;\"><br>  <img src=\"/2017/09/09/note-reinforcement-learning/lec4_Model_Free_Prediction.png\" alt=\"Model-Free Prediction\" title=\"Model-Free Prediction\"><br></div>\n\n<h3 id=\"Model-Free-Control\"><a href=\"#Model-Free-Control\" class=\"headerlink\" title=\"Model-Free Control\"></a>Model-Free Control</h3><div style=\"width:800px; margin-left:auto; margin-right:auto;\"><br>  <img src=\"/2017/09/09/note-reinforcement-learning/lec5_Model_Free_Control.png\" alt=\"Model-Free Control\" title=\"Model-Free Control\"><br></div>\n\n<h3 id=\"Value-Function-Approximation\"><a href=\"#Value-Function-Approximation\" class=\"headerlink\" title=\"Value Function Approximation\"></a>Value Function Approximation</h3><div style=\"width:800px; margin-left:auto; margin-right:auto;\"><br>  <img src=\"/2017/09/09/note-reinforcement-learning/lec6_Value_Function_Approximation.png\" alt=\"Value Function Approximation\" title=\"Value Function Approximation\"><br></div>\n\n<h3 id=\"Policy-Gradient\"><a href=\"#Policy-Gradient\" class=\"headerlink\" title=\"Policy Gradient\"></a>Policy Gradient</h3><div style=\"width:800px; margin-left:auto; margin-right:auto;\"><br>  <img src=\"/2017/09/09/note-reinforcement-learning/lec7_Policy_Gradient.png\" alt=\"Policy Gradient\" title=\"Policy Gradient\"><br></div>\n\n<h3 id=\"Integrating-Learning-and-Planning\"><a href=\"#Integrating-Learning-and-Planning\" class=\"headerlink\" title=\"Integrating Learning and Planning\"></a>Integrating Learning and Planning</h3><div style=\"width:800px; margin-left:auto; margin-right:auto;\"><br>  <img src=\"/2017/09/09/note-reinforcement-learning/lec8_Integrating_Learning_and_Planning.png\" alt=\"Integrating Learning and Planning\" title=\"Integrating Learning and Planning\"><br></div>\n\n<h3 id=\"Exploration-and-Exploitation\"><a href=\"#Exploration-and-Exploitation\" class=\"headerlink\" title=\"Exploration and Exploitation\"></a>Exploration and Exploitation</h3><div style=\"width:800px; margin-left:auto; margin-right:auto;\"><br>  <img src=\"/2017/09/09/note-reinforcement-learning/lec9_Exploration_and_Exploitation.png\" alt=\"Exploration and Exploitation\" title=\"Exploration and Exploitation\"><br></div>\n\n<h2 id=\"References\"><a href=\"#References\" class=\"headerlink\" title=\"References\"></a>References</h2><ul>\n<li><a href=\"http://www0.cs.ucl.ac.uk/staff/D.Silver/web/Teaching.html\" target=\"_blank\" rel=\"external\">强化学习课程</a></li>\n<li><a href=\"http://people.inf.elte.hu/lorincz/Files/RL_2006/SuttonBook.pdf\" target=\"_blank\" rel=\"external\">强化学习教材</a></li>\n</ul>\n","excerpt":"","more":"<h2 id=\"思维导图\"><a href=\"#思维导图\" class=\"headerlink\" title=\"思维导图\"></a>思维导图</h2><h3 id=\"Intro-to-RL\"><a href=\"#Intro-to-RL\" class=\"headerlink\" title=\"Intro to RL\"></a>Intro to RL</h3><div style=\"width:800px; margin-left:auto; margin-right:auto;\" ><br>  <img src=\"/2017/09/09/note-reinforcement-learning/lec1_Intro_to_RL.png\" alt=\"Intro to RL\" title=\"Intro to RL\"><br></div>\n\n<h3 id=\"MDP\"><a href=\"#MDP\" class=\"headerlink\" title=\"MDP\"></a>MDP</h3><div style=\"width:800px; margin-left:auto; margin-right:auto;\" ><br>  <img src=\"/2017/09/09/note-reinforcement-learning/lec2_MDP.png\" alt=\"MDP\" title=\"MDP\"><br></div>\n\n<h3 id=\"Planning-by-DP\"><a href=\"#Planning-by-DP\" class=\"headerlink\" title=\"Planning by DP\"></a>Planning by DP</h3><div style=\"width:800px; margin-left:auto; margin-right:auto;\" ><br>  <img src=\"/2017/09/09/note-reinforcement-learning/lec3_Planning_by_DP.png\" alt=\"Planning by DP\" title=\"Planning by DP\"><br></div>\n\n<h3 id=\"Model-Free-Prediction\"><a href=\"#Model-Free-Prediction\" class=\"headerlink\" title=\"Model-Free Prediction\"></a>Model-Free Prediction</h3><div style=\"width:800px; margin-left:auto; margin-right:auto;\" ><br>  <img src=\"/2017/09/09/note-reinforcement-learning/lec4_Model_Free_Prediction.png\" alt=\"Model-Free Prediction\" title=\"Model-Free Prediction\"><br></div>\n\n<h3 id=\"Model-Free-Control\"><a href=\"#Model-Free-Control\" class=\"headerlink\" title=\"Model-Free Control\"></a>Model-Free Control</h3><div style=\"width:800px; margin-left:auto; margin-right:auto;\" ><br>  <img src=\"/2017/09/09/note-reinforcement-learning/lec5_Model_Free_Control.png\" alt=\"Model-Free Control\" title=\"Model-Free Control\"><br></div>\n\n<h3 id=\"Value-Function-Approximation\"><a href=\"#Value-Function-Approximation\" class=\"headerlink\" title=\"Value Function Approximation\"></a>Value Function Approximation</h3><div style=\"width:800px; margin-left:auto; margin-right:auto;\" ><br>  <img src=\"/2017/09/09/note-reinforcement-learning/lec6_Value_Function_Approximation.png\" alt=\"Value Function Approximation\" title=\"Value Function Approximation\"><br></div>\n\n<h3 id=\"Policy-Gradient\"><a href=\"#Policy-Gradient\" class=\"headerlink\" title=\"Policy Gradient\"></a>Policy Gradient</h3><div style=\"width:800px; margin-left:auto; margin-right:auto;\" ><br>  <img src=\"/2017/09/09/note-reinforcement-learning/lec7_Policy_Gradient.png\" alt=\"Policy Gradient\" title=\"Policy Gradient\"><br></div>\n\n<h3 id=\"Integrating-Learning-and-Planning\"><a href=\"#Integrating-Learning-and-Planning\" class=\"headerlink\" title=\"Integrating Learning and Planning\"></a>Integrating Learning and Planning</h3><div style=\"width:800px; margin-left:auto; margin-right:auto;\" ><br>  <img src=\"/2017/09/09/note-reinforcement-learning/lec8_Integrating_Learning_and_Planning.png\" alt=\"Integrating Learning and Planning\" title=\"Integrating Learning and Planning\"><br></div>\n\n<h3 id=\"Exploration-and-Exploitation\"><a href=\"#Exploration-and-Exploitation\" class=\"headerlink\" title=\"Exploration and Exploitation\"></a>Exploration and Exploitation</h3><div style=\"width:800px; margin-left:auto; margin-right:auto;\" ><br>  <img src=\"/2017/09/09/note-reinforcement-learning/lec9_Exploration_and_Exploitation.png\" alt=\"Exploration and Exploitation\" title=\"Exploration and Exploitation\"><br></div>\n\n<h2 id=\"References\"><a href=\"#References\" class=\"headerlink\" title=\"References\"></a>References</h2><ul>\n<li><a href=\"http://www0.cs.ucl.ac.uk/staff/D.Silver/web/Teaching.html\">强化学习课程</a></li>\n<li><a href=\"http://people.inf.elte.hu/lorincz/Files/RL_2006/SuttonBook.pdf\">强化学习教材</a></li>\n</ul>\n"},{"title":"论文笔记《Scalable trust-region method for deep reinforcement learning using  Kronecker-factored approximation》","date":"2018-02-26T06:30:42.000Z","description":["将K-FAC用到Actor-Critic框架中的算法"],"_content":"\n本文分为两部分，首先介绍优化方法Kronecker-factored Approximate Curvature（K-FAC），然后再介绍强化学习算法Actor Critic using Kronecker-factored Trust Region（ACKTR）。\n\n## K-FAC\n\n- motivation\n\t+ Natural Gradient（NG）\n\t\t+ 假设我们想**求样本$x_1, \\dots, x_n$所服从的概率分布**，我们的解决思路如下：\n\t\t\t1. 假设概率分布服从某一种参数化的概率分布（e.g., 假设$x \\sim q(x ; \\theta)$，其中，$q$为由$\\theta$决定的某种分布（e.g., 均值为$\\theta$，方差为1的高斯分布））；\n\t\t\t2. 建立对数似然函数$L(\\theta) = \\log \\prod _i q(x_i ; \\theta)$；\n\t\t\t3. 通过优化方法（e.g., SGD）找到$\\theta = \\mathop{\\text{argmax}}_{\\theta} \\log \\prod _i q(x_i ; \\theta)$。\n\t\t+ 一般来说，在使用诸如SGD这种优化方法时，我们都会**避免较大的步长**，以保证收敛。因为梯度仅仅是一个局部信息而不是全局信息，也就是说仅当在当前点附近时，才能保证梯度方向是函数值增大的方向。\n\t\t+ 对于我们的最大化对数似然函数优化问题，我们**真正想要优化的“参数”**应该是分布$q$，而不是$\\theta$，也就是说真正的优化问题应该是\n\t\t$$\n\t\tq = \\mathop{\\text{argmax}}_{q} \\log \\prod _i q(x_i).\n\t\t$$因此类比上面关于步长的讨论，我们希望迭代时相邻的两个分布$q_{\\text{new}}$与$q_{\\text{old}}$之间的“距离比较近”。\n\t\t+ 而$\\theta$空间的距离跟$q$空间的**距离有可能是不一致**的，也就是说有可能尽管$\\theta _{\\text{new}}$与$\\theta _{\\text{old}}$很接近，但$q_ {\\text{new}}$与$q _{\\text{old}}$的“距离”却很远。在这种情况下，尽管$\\theta$的step size很小，但由于$q$的step size很大，**收敛效果**并不理想。\n\t\t+ Natural Gradient就是解决上述问题的一种方案，它找到了一个方向$d$，使得当$\\theta$沿着$d$方向更新时（i.e., $\\theta _{\\text{new}} = \\theta _{\\text{old}} + \\alpha d$），$q(x ; \\theta)$的变化不大，从而**控制了$q$空间的step size**。\n\t+ Levenberg–Marquardt（LM）\n\t\t+ NG能够保证$q(x ; \\theta + d)$与$q(x ; \\theta)$相近，但作为代价，**牺牲了部分的单调性**，也就是说不能保证对数似然函数$L(\\theta + d) > L(\\theta)$（记得当step size较小时，SGD能够保证单调性）。\n\t\t+ Levenberg-Marquardt则是解决上述问题的一种方案，它通过一个参数来**调整算法是更像NGD（$q$空间step size较小，收敛性质较好）还是SGD（目标函数单调递增/减）**。\n\t+ Kronecker-factored Approximate Curvature（K-FAC）\n\t\t+ 无论是NGD还是LM，都需要存储一个$DIM(\\theta) \\times DIM(\\theta)$大小的矩阵$G(\\theta)$，然后还要求解一个线性方程组$G(\\theta)x=g$。在参数维度较高的问题中，这两种算法的**空间复杂度和时间复杂度都会非常的高**（e.g., 对于利用深度神经网络对$q$进行建模的算法，$O(\\Vert \\theta \\Vert ^2)$的空间复杂度是不能接受的）。\n\t\t+ K-FAC针对神经网络这种结构，通过一系列的近似**降低了存储矩阵$G(\\theta)$的空间复杂度以及求解线性方程组$G(\\theta) x=g$的时间复杂度**，使得NGD和LM能够在神经网络上应用。\n- idea\n\t+ NG\n\t\t- 求解一个方向$d$，使得当$\\theta$沿着$d$方向更新时（i.e., $\\theta _{\\text{new}} = \\theta _{\\text{old}} + \\alpha d$），$q(x ; \\theta)$的变化不大，并且$L(\\theta + d) > L(\\theta)$，形式化来说就是求解以下优化问题：\n\t\t$$\n\t\t\\begin{aligned}\n\t\t\\mathop{\\text{maximize }}_d & d^T \\nabla _ \\theta L(\\theta) \\\\\n\t\t\\text{subject to } & \\Vert d \\Vert _{G(\\theta)} ^2 < \\epsilon\n\t\t\\end{aligned},\n\t\t$$其中，$\\Vert d \\Vert _{G(\\theta)} ^2 = d^T G(\\theta) d$，$G(\\theta)$为Fisher Information Matrix。\n\t\t\t+ **约束条件**通过以symmetric KL divergence作为$q$空间“距离”的度量推导而来，体现了$\\theta$沿$d$方向更新，$q(x;\\theta)$的变化不大。具体来说，就是用$KL(q(x ; \\theta) \\Vert q(x; \\theta + d))$来表示当$\\theta$沿$d$方向更新时，$q$变化的大小；\n\t\t\t+ **目标函数**表示希望$d$与梯度方向一致，体现了$L(\\theta + d) > L(\\theta)$。\n\t\t\t+ 这里有个问题，既然把$d$理解成方向，为什么不加一个约束条件限制$d$为单位向量呢？\n\t\t- NG得到的$d \\propto G(\\theta)^{-1} \\nabla L(\\theta)$，$\\theta$的迭代公式为$\\theta _{k+1} = \\theta _{k} + \\alpha _k G(\\theta)^{-1} \\nabla L(\\theta)$。\n\t+ LM\n\t\t- 将$d$改写为$d = (G(\\theta) + \\tau I)^{-1} \\nabla L(\\theta)$，通过调整$\\tau$的大小来**调整算法趋向于NGD还是SGD**，具体来说，$\\tau$小的时候趋向于NGD，$\\tau$大的时候趋向于SGD。\n\t\t- 这里有个问题，调控$\\tau$大小的算法中，$p$的含义是什么？\n\t+ K-FAC\n\t\t- 对**Kronecker product做近似**以降低$G(\\theta)$的储存成本，再**强行对角化**（非对角block置为0）以降低求解方程组$G(\\theta)x = g$的计算复杂度。\n- more\n\t+ exponential average的迭代形式：\n\t$$G_{n+1} = (1-\\epsilon) \\hat{G}_n + \\epsilon G_n \\Leftrightarrow G_{n+1} = (1-\\epsilon)( \\hat{G}_n + \\epsilon \\hat{G}_{n-1} + \\epsilon ^2 \\hat{G}_{n-2} + \\dots).\n\t$$\n\t+ K-FAC中优化参数变为$q(y \\mid x ; \\theta) \\hat{q}(x)$；\n\t+ 针对LM的K-FAC（i.e., 近似$(G(\\theta) + \\tau I)^{-1}$的思路）。\n- references\n\t+ [K-FAC tutorial](https://www.youtube.com/watch?v=FLV-MLPt3sU)\n\t+ [Kronecker product tutorial](https://hec.unil.ch/docs/files/23/100/handout1.pdf)\n\n## ACKTR\n\n- motivation\n\t+ 将K-FAC用到actor-critic框架中，提高sample efficiency，加快收敛速度。\n- idea\n\t+ actor：对于stochastic policy，actor的输出就是分布，可以直接用K-FAC；\n\t+ critic：将回归问题\n\t$$\n\t\\mathop{\\text{minimize}}_{\\theta} \\sum_i \\Vert f(s_i ; \\theta) - v_i \\Vert^2\n\t$$建模为最大似然问题\n\t$$\n\t\\mathop{\\text{maximize}}_{\\theta} \\log \\prod _i p(v_i \\mid s_i ; \\theta).\n\t$$\n\t+ 针对sharing parameter framework：\n\t\t1. 理解为对pair(a, v)作最大似然估计；\n\t\t2. 假设actor与critic相互独立，得联合概率$p(a,v \\mid s ; \\theta) = \\pi(a \\mid s ; \\theta)p(v \\mid s ; \\theta)$；\n\t\t3. 对$p(a, v ; \\theta)$作最大似然估计。\n\t+ trust region：在K-FAC的基础上再对参数$\\theta$更新的步长再做一个限制。\n\t","source":"_posts/paper-acktr.md","raw":"---\ntitle: 论文笔记《Scalable trust-region method for deep reinforcement learning using  Kronecker-factored approximation》\ndate: 2018-02-26 14:30:42\ntags:\n\t- K-FAC\n\t- ACKTR\ncategories:\n\t- 论文笔记\ndescription:\n\t- 将K-FAC用到Actor-Critic框架中的算法\n\n---\n\n本文分为两部分，首先介绍优化方法Kronecker-factored Approximate Curvature（K-FAC），然后再介绍强化学习算法Actor Critic using Kronecker-factored Trust Region（ACKTR）。\n\n## K-FAC\n\n- motivation\n\t+ Natural Gradient（NG）\n\t\t+ 假设我们想**求样本$x_1, \\dots, x_n$所服从的概率分布**，我们的解决思路如下：\n\t\t\t1. 假设概率分布服从某一种参数化的概率分布（e.g., 假设$x \\sim q(x ; \\theta)$，其中，$q$为由$\\theta$决定的某种分布（e.g., 均值为$\\theta$，方差为1的高斯分布））；\n\t\t\t2. 建立对数似然函数$L(\\theta) = \\log \\prod _i q(x_i ; \\theta)$；\n\t\t\t3. 通过优化方法（e.g., SGD）找到$\\theta = \\mathop{\\text{argmax}}_{\\theta} \\log \\prod _i q(x_i ; \\theta)$。\n\t\t+ 一般来说，在使用诸如SGD这种优化方法时，我们都会**避免较大的步长**，以保证收敛。因为梯度仅仅是一个局部信息而不是全局信息，也就是说仅当在当前点附近时，才能保证梯度方向是函数值增大的方向。\n\t\t+ 对于我们的最大化对数似然函数优化问题，我们**真正想要优化的“参数”**应该是分布$q$，而不是$\\theta$，也就是说真正的优化问题应该是\n\t\t$$\n\t\tq = \\mathop{\\text{argmax}}_{q} \\log \\prod _i q(x_i).\n\t\t$$因此类比上面关于步长的讨论，我们希望迭代时相邻的两个分布$q_{\\text{new}}$与$q_{\\text{old}}$之间的“距离比较近”。\n\t\t+ 而$\\theta$空间的距离跟$q$空间的**距离有可能是不一致**的，也就是说有可能尽管$\\theta _{\\text{new}}$与$\\theta _{\\text{old}}$很接近，但$q_ {\\text{new}}$与$q _{\\text{old}}$的“距离”却很远。在这种情况下，尽管$\\theta$的step size很小，但由于$q$的step size很大，**收敛效果**并不理想。\n\t\t+ Natural Gradient就是解决上述问题的一种方案，它找到了一个方向$d$，使得当$\\theta$沿着$d$方向更新时（i.e., $\\theta _{\\text{new}} = \\theta _{\\text{old}} + \\alpha d$），$q(x ; \\theta)$的变化不大，从而**控制了$q$空间的step size**。\n\t+ Levenberg–Marquardt（LM）\n\t\t+ NG能够保证$q(x ; \\theta + d)$与$q(x ; \\theta)$相近，但作为代价，**牺牲了部分的单调性**，也就是说不能保证对数似然函数$L(\\theta + d) > L(\\theta)$（记得当step size较小时，SGD能够保证单调性）。\n\t\t+ Levenberg-Marquardt则是解决上述问题的一种方案，它通过一个参数来**调整算法是更像NGD（$q$空间step size较小，收敛性质较好）还是SGD（目标函数单调递增/减）**。\n\t+ Kronecker-factored Approximate Curvature（K-FAC）\n\t\t+ 无论是NGD还是LM，都需要存储一个$DIM(\\theta) \\times DIM(\\theta)$大小的矩阵$G(\\theta)$，然后还要求解一个线性方程组$G(\\theta)x=g$。在参数维度较高的问题中，这两种算法的**空间复杂度和时间复杂度都会非常的高**（e.g., 对于利用深度神经网络对$q$进行建模的算法，$O(\\Vert \\theta \\Vert ^2)$的空间复杂度是不能接受的）。\n\t\t+ K-FAC针对神经网络这种结构，通过一系列的近似**降低了存储矩阵$G(\\theta)$的空间复杂度以及求解线性方程组$G(\\theta) x=g$的时间复杂度**，使得NGD和LM能够在神经网络上应用。\n- idea\n\t+ NG\n\t\t- 求解一个方向$d$，使得当$\\theta$沿着$d$方向更新时（i.e., $\\theta _{\\text{new}} = \\theta _{\\text{old}} + \\alpha d$），$q(x ; \\theta)$的变化不大，并且$L(\\theta + d) > L(\\theta)$，形式化来说就是求解以下优化问题：\n\t\t$$\n\t\t\\begin{aligned}\n\t\t\\mathop{\\text{maximize }}_d & d^T \\nabla _ \\theta L(\\theta) \\\\\n\t\t\\text{subject to } & \\Vert d \\Vert _{G(\\theta)} ^2 < \\epsilon\n\t\t\\end{aligned},\n\t\t$$其中，$\\Vert d \\Vert _{G(\\theta)} ^2 = d^T G(\\theta) d$，$G(\\theta)$为Fisher Information Matrix。\n\t\t\t+ **约束条件**通过以symmetric KL divergence作为$q$空间“距离”的度量推导而来，体现了$\\theta$沿$d$方向更新，$q(x;\\theta)$的变化不大。具体来说，就是用$KL(q(x ; \\theta) \\Vert q(x; \\theta + d))$来表示当$\\theta$沿$d$方向更新时，$q$变化的大小；\n\t\t\t+ **目标函数**表示希望$d$与梯度方向一致，体现了$L(\\theta + d) > L(\\theta)$。\n\t\t\t+ 这里有个问题，既然把$d$理解成方向，为什么不加一个约束条件限制$d$为单位向量呢？\n\t\t- NG得到的$d \\propto G(\\theta)^{-1} \\nabla L(\\theta)$，$\\theta$的迭代公式为$\\theta _{k+1} = \\theta _{k} + \\alpha _k G(\\theta)^{-1} \\nabla L(\\theta)$。\n\t+ LM\n\t\t- 将$d$改写为$d = (G(\\theta) + \\tau I)^{-1} \\nabla L(\\theta)$，通过调整$\\tau$的大小来**调整算法趋向于NGD还是SGD**，具体来说，$\\tau$小的时候趋向于NGD，$\\tau$大的时候趋向于SGD。\n\t\t- 这里有个问题，调控$\\tau$大小的算法中，$p$的含义是什么？\n\t+ K-FAC\n\t\t- 对**Kronecker product做近似**以降低$G(\\theta)$的储存成本，再**强行对角化**（非对角block置为0）以降低求解方程组$G(\\theta)x = g$的计算复杂度。\n- more\n\t+ exponential average的迭代形式：\n\t$$G_{n+1} = (1-\\epsilon) \\hat{G}_n + \\epsilon G_n \\Leftrightarrow G_{n+1} = (1-\\epsilon)( \\hat{G}_n + \\epsilon \\hat{G}_{n-1} + \\epsilon ^2 \\hat{G}_{n-2} + \\dots).\n\t$$\n\t+ K-FAC中优化参数变为$q(y \\mid x ; \\theta) \\hat{q}(x)$；\n\t+ 针对LM的K-FAC（i.e., 近似$(G(\\theta) + \\tau I)^{-1}$的思路）。\n- references\n\t+ [K-FAC tutorial](https://www.youtube.com/watch?v=FLV-MLPt3sU)\n\t+ [Kronecker product tutorial](https://hec.unil.ch/docs/files/23/100/handout1.pdf)\n\n## ACKTR\n\n- motivation\n\t+ 将K-FAC用到actor-critic框架中，提高sample efficiency，加快收敛速度。\n- idea\n\t+ actor：对于stochastic policy，actor的输出就是分布，可以直接用K-FAC；\n\t+ critic：将回归问题\n\t$$\n\t\\mathop{\\text{minimize}}_{\\theta} \\sum_i \\Vert f(s_i ; \\theta) - v_i \\Vert^2\n\t$$建模为最大似然问题\n\t$$\n\t\\mathop{\\text{maximize}}_{\\theta} \\log \\prod _i p(v_i \\mid s_i ; \\theta).\n\t$$\n\t+ 针对sharing parameter framework：\n\t\t1. 理解为对pair(a, v)作最大似然估计；\n\t\t2. 假设actor与critic相互独立，得联合概率$p(a,v \\mid s ; \\theta) = \\pi(a \\mid s ; \\theta)p(v \\mid s ; \\theta)$；\n\t\t3. 对$p(a, v ; \\theta)$作最大似然估计。\n\t+ trust region：在K-FAC的基础上再对参数$\\theta$更新的步长再做一个限制。\n\t","slug":"paper-acktr","published":1,"updated":"2024-08-13T16:03:47.864Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clzvf19250014eqwofyyfgerk","content":"<p>本文分为两部分，首先介绍优化方法Kronecker-factored Approximate Curvature（K-FAC），然后再介绍强化学习算法Actor Critic using Kronecker-factored Trust Region（ACKTR）。</p>\n<h2 id=\"K-FAC\"><a href=\"#K-FAC\" class=\"headerlink\" title=\"K-FAC\"></a>K-FAC</h2><ul>\n<li>motivation<ul>\n<li>Natural Gradient（NG）<ul>\n<li>假设我们想<strong>求样本$x_1, \\dots, x_n$所服从的概率分布</strong>，我们的解决思路如下：<ol>\n<li>假设概率分布服从某一种参数化的概率分布（e.g., 假设$x \\sim q(x ; \\theta)$，其中，$q$为由$\\theta$决定的某种分布（e.g., 均值为$\\theta$，方差为1的高斯分布））；</li>\n<li>建立对数似然函数$L(\\theta) = \\log \\prod _i q(x_i ; \\theta)$；</li>\n<li>通过优化方法（e.g., SGD）找到$\\theta = \\mathop{\\text{argmax}}_{\\theta} \\log \\prod _i q(x_i ; \\theta)$。</li>\n</ol>\n</li>\n<li>一般来说，在使用诸如SGD这种优化方法时，我们都会<strong>避免较大的步长</strong>，以保证收敛。因为梯度仅仅是一个局部信息而不是全局信息，也就是说仅当在当前点附近时，才能保证梯度方向是函数值增大的方向。</li>\n<li>对于我们的最大化对数似然函数优化问题，我们<strong>真正想要优化的“参数”</strong>应该是分布$q$，而不是$\\theta$，也就是说真正的优化问题应该是<br>$$<br>q = \\mathop{\\text{argmax}}_{q} \\log \\prod _i q(x_i).<br>$$因此类比上面关于步长的讨论，我们希望迭代时相邻的两个分布$q_{\\text{new}}$与$q_{\\text{old}}$之间的“距离比较近”。</li>\n<li>而$\\theta$空间的距离跟$q$空间的<strong>距离有可能是不一致</strong>的，也就是说有可能尽管$\\theta _{\\text{new}}$与$\\theta _{\\text{old}}$很接近，但$q_ {\\text{new}}$与$q _{\\text{old}}$的“距离”却很远。在这种情况下，尽管$\\theta$的step size很小，但由于$q$的step size很大，<strong>收敛效果</strong>并不理想。</li>\n<li>Natural Gradient就是解决上述问题的一种方案，它找到了一个方向$d$，使得当$\\theta$沿着$d$方向更新时（i.e., $\\theta _{\\text{new}} = \\theta _{\\text{old}} + \\alpha d$），$q(x ; \\theta)$的变化不大，从而<strong>控制了$q$空间的step size</strong>。</li>\n</ul>\n</li>\n<li>Levenberg–Marquardt（LM）<ul>\n<li>NG能够保证$q(x ; \\theta + d)$与$q(x ; \\theta)$相近，但作为代价，<strong>牺牲了部分的单调性</strong>，也就是说不能保证对数似然函数$L(\\theta + d) &gt; L(\\theta)$（记得当step size较小时，SGD能够保证单调性）。</li>\n<li>Levenberg-Marquardt则是解决上述问题的一种方案，它通过一个参数来<strong>调整算法是更像NGD（$q$空间step size较小，收敛性质较好）还是SGD（目标函数单调递增/减）</strong>。</li>\n</ul>\n</li>\n<li>Kronecker-factored Approximate Curvature（K-FAC）<ul>\n<li>无论是NGD还是LM，都需要存储一个$DIM(\\theta) \\times DIM(\\theta)$大小的矩阵$G(\\theta)$，然后还要求解一个线性方程组$G(\\theta)x=g$。在参数维度较高的问题中，这两种算法的<strong>空间复杂度和时间复杂度都会非常的高</strong>（e.g., 对于利用深度神经网络对$q$进行建模的算法，$O(\\Vert \\theta \\Vert ^2)$的空间复杂度是不能接受的）。</li>\n<li>K-FAC针对神经网络这种结构，通过一系列的近似<strong>降低了存储矩阵$G(\\theta)$的空间复杂度以及求解线性方程组$G(\\theta) x=g$的时间复杂度</strong>，使得NGD和LM能够在神经网络上应用。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>idea<ul>\n<li>NG<ul>\n<li>求解一个方向$d$，使得当$\\theta$沿着$d$方向更新时（i.e., $\\theta _{\\text{new}} = \\theta _{\\text{old}} + \\alpha d$），$q(x ; \\theta)$的变化不大，并且$L(\\theta + d) &gt; L(\\theta)$，形式化来说就是求解以下优化问题：<br>$$<br>\\begin{aligned}<br>\\mathop{\\text{maximize }}_d &amp; d^T \\nabla _ \\theta L(\\theta) \\\\<br>\\text{subject to } &amp; \\Vert d \\Vert _{G(\\theta)} ^2 &lt; \\epsilon<br>\\end{aligned},<br>$$其中，$\\Vert d \\Vert _{G(\\theta)} ^2 = d^T G(\\theta) d$，$G(\\theta)$为Fisher Information Matrix。<ul>\n<li><strong>约束条件</strong>通过以symmetric KL divergence作为$q$空间“距离”的度量推导而来，体现了$\\theta$沿$d$方向更新，$q(x;\\theta)$的变化不大。具体来说，就是用$KL(q(x ; \\theta) \\Vert q(x; \\theta + d))$来表示当$\\theta$沿$d$方向更新时，$q$变化的大小；</li>\n<li><strong>目标函数</strong>表示希望$d$与梯度方向一致，体现了$L(\\theta + d) &gt; L(\\theta)$。</li>\n<li>这里有个问题，既然把$d$理解成方向，为什么不加一个约束条件限制$d$为单位向量呢？</li>\n</ul>\n</li>\n<li>NG得到的$d \\propto G(\\theta)^{-1} \\nabla L(\\theta)$，$\\theta$的迭代公式为$\\theta _{k+1} = \\theta _{k} + \\alpha _k G(\\theta)^{-1} \\nabla L(\\theta)$。</li>\n</ul>\n</li>\n<li>LM<ul>\n<li>将$d$改写为$d = (G(\\theta) + \\tau I)^{-1} \\nabla L(\\theta)$，通过调整$\\tau$的大小来<strong>调整算法趋向于NGD还是SGD</strong>，具体来说，$\\tau$小的时候趋向于NGD，$\\tau$大的时候趋向于SGD。</li>\n<li>这里有个问题，调控$\\tau$大小的算法中，$p$的含义是什么？</li>\n</ul>\n</li>\n<li>K-FAC<ul>\n<li>对<strong>Kronecker product做近似</strong>以降低$G(\\theta)$的储存成本，再<strong>强行对角化</strong>（非对角block置为0）以降低求解方程组$G(\\theta)x = g$的计算复杂度。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>more<ul>\n<li>exponential average的迭代形式：<br>$$G_{n+1} = (1-\\epsilon) \\hat{G}_n + \\epsilon G_n \\Leftrightarrow G_{n+1} = (1-\\epsilon)( \\hat{G}_n + \\epsilon \\hat{G}_{n-1} + \\epsilon ^2 \\hat{G}_{n-2} + \\dots).<br>$$</li>\n<li>K-FAC中优化参数变为$q(y \\mid x ; \\theta) \\hat{q}(x)$；</li>\n<li>针对LM的K-FAC（i.e., 近似$(G(\\theta) + \\tau I)^{-1}$的思路）。</li>\n</ul>\n</li>\n<li>references<ul>\n<li><a href=\"https://www.youtube.com/watch?v=FLV-MLPt3sU\" target=\"_blank\" rel=\"external\">K-FAC tutorial</a></li>\n<li><a href=\"https://hec.unil.ch/docs/files/23/100/handout1.pdf\" target=\"_blank\" rel=\"external\">Kronecker product tutorial</a></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"ACKTR\"><a href=\"#ACKTR\" class=\"headerlink\" title=\"ACKTR\"></a>ACKTR</h2><ul>\n<li>motivation<ul>\n<li>将K-FAC用到actor-critic框架中，提高sample efficiency，加快收敛速度。</li>\n</ul>\n</li>\n<li>idea<ul>\n<li>actor：对于stochastic policy，actor的输出就是分布，可以直接用K-FAC；</li>\n<li>critic：将回归问题<br>$$<br>\\mathop{\\text{minimize}}_{\\theta} \\sum_i \\Vert f(s_i ; \\theta) - v_i \\Vert^2<br>$$建模为最大似然问题<br>$$<br>\\mathop{\\text{maximize}}_{\\theta} \\log \\prod _i p(v_i \\mid s_i ; \\theta).<br>$$</li>\n<li>针对sharing parameter framework：<ol>\n<li>理解为对pair(a, v)作最大似然估计；</li>\n<li>假设actor与critic相互独立，得联合概率$p(a,v \\mid s ; \\theta) = \\pi(a \\mid s ; \\theta)p(v \\mid s ; \\theta)$；</li>\n<li>对$p(a, v ; \\theta)$作最大似然估计。</li>\n</ol>\n</li>\n<li>trust region：在K-FAC的基础上再对参数$\\theta$更新的步长再做一个限制。</li>\n</ul>\n</li>\n</ul>\n","excerpt":"","more":"<p>本文分为两部分，首先介绍优化方法Kronecker-factored Approximate Curvature（K-FAC），然后再介绍强化学习算法Actor Critic using Kronecker-factored Trust Region（ACKTR）。</p>\n<h2 id=\"K-FAC\"><a href=\"#K-FAC\" class=\"headerlink\" title=\"K-FAC\"></a>K-FAC</h2><ul>\n<li>motivation<ul>\n<li>Natural Gradient（NG）<ul>\n<li>假设我们想<strong>求样本$x_1, \\dots, x_n$所服从的概率分布</strong>，我们的解决思路如下：<ol>\n<li>假设概率分布服从某一种参数化的概率分布（e.g., 假设$x \\sim q(x ; \\theta)$，其中，$q$为由$\\theta$决定的某种分布（e.g., 均值为$\\theta$，方差为1的高斯分布））；</li>\n<li>建立对数似然函数$L(\\theta) = \\log \\prod _i q(x_i ; \\theta)$；</li>\n<li>通过优化方法（e.g., SGD）找到$\\theta = \\mathop{\\text{argmax}}_{\\theta} \\log \\prod _i q(x_i ; \\theta)$。</li>\n</ol>\n</li>\n<li>一般来说，在使用诸如SGD这种优化方法时，我们都会<strong>避免较大的步长</strong>，以保证收敛。因为梯度仅仅是一个局部信息而不是全局信息，也就是说仅当在当前点附近时，才能保证梯度方向是函数值增大的方向。</li>\n<li>对于我们的最大化对数似然函数优化问题，我们<strong>真正想要优化的“参数”</strong>应该是分布$q$，而不是$\\theta$，也就是说真正的优化问题应该是<br>$$<br>q = \\mathop{\\text{argmax}}_{q} \\log \\prod _i q(x_i).<br>$$因此类比上面关于步长的讨论，我们希望迭代时相邻的两个分布$q_{\\text{new}}$与$q_{\\text{old}}$之间的“距离比较近”。</li>\n<li>而$\\theta$空间的距离跟$q$空间的<strong>距离有可能是不一致</strong>的，也就是说有可能尽管$\\theta _{\\text{new}}$与$\\theta _{\\text{old}}$很接近，但$q_ {\\text{new}}$与$q _{\\text{old}}$的“距离”却很远。在这种情况下，尽管$\\theta$的step size很小，但由于$q$的step size很大，<strong>收敛效果</strong>并不理想。</li>\n<li>Natural Gradient就是解决上述问题的一种方案，它找到了一个方向$d$，使得当$\\theta$沿着$d$方向更新时（i.e., $\\theta _{\\text{new}} = \\theta _{\\text{old}} + \\alpha d$），$q(x ; \\theta)$的变化不大，从而<strong>控制了$q$空间的step size</strong>。</li>\n</ul>\n</li>\n<li>Levenberg–Marquardt（LM）<ul>\n<li>NG能够保证$q(x ; \\theta + d)$与$q(x ; \\theta)$相近，但作为代价，<strong>牺牲了部分的单调性</strong>，也就是说不能保证对数似然函数$L(\\theta + d) &gt; L(\\theta)$（记得当step size较小时，SGD能够保证单调性）。</li>\n<li>Levenberg-Marquardt则是解决上述问题的一种方案，它通过一个参数来<strong>调整算法是更像NGD（$q$空间step size较小，收敛性质较好）还是SGD（目标函数单调递增/减）</strong>。</li>\n</ul>\n</li>\n<li>Kronecker-factored Approximate Curvature（K-FAC）<ul>\n<li>无论是NGD还是LM，都需要存储一个$DIM(\\theta) \\times DIM(\\theta)$大小的矩阵$G(\\theta)$，然后还要求解一个线性方程组$G(\\theta)x=g$。在参数维度较高的问题中，这两种算法的<strong>空间复杂度和时间复杂度都会非常的高</strong>（e.g., 对于利用深度神经网络对$q$进行建模的算法，$O(\\Vert \\theta \\Vert ^2)$的空间复杂度是不能接受的）。</li>\n<li>K-FAC针对神经网络这种结构，通过一系列的近似<strong>降低了存储矩阵$G(\\theta)$的空间复杂度以及求解线性方程组$G(\\theta) x=g$的时间复杂度</strong>，使得NGD和LM能够在神经网络上应用。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>idea<ul>\n<li>NG<ul>\n<li>求解一个方向$d$，使得当$\\theta$沿着$d$方向更新时（i.e., $\\theta _{\\text{new}} = \\theta _{\\text{old}} + \\alpha d$），$q(x ; \\theta)$的变化不大，并且$L(\\theta + d) &gt; L(\\theta)$，形式化来说就是求解以下优化问题：<br>$$<br>\\begin{aligned}<br>\\mathop{\\text{maximize }}_d &amp; d^T \\nabla _ \\theta L(\\theta) \\\\<br>\\text{subject to } &amp; \\Vert d \\Vert _{G(\\theta)} ^2 &lt; \\epsilon<br>\\end{aligned},<br>$$其中，$\\Vert d \\Vert _{G(\\theta)} ^2 = d^T G(\\theta) d$，$G(\\theta)$为Fisher Information Matrix。<ul>\n<li><strong>约束条件</strong>通过以symmetric KL divergence作为$q$空间“距离”的度量推导而来，体现了$\\theta$沿$d$方向更新，$q(x;\\theta)$的变化不大。具体来说，就是用$KL(q(x ; \\theta) \\Vert q(x; \\theta + d))$来表示当$\\theta$沿$d$方向更新时，$q$变化的大小；</li>\n<li><strong>目标函数</strong>表示希望$d$与梯度方向一致，体现了$L(\\theta + d) &gt; L(\\theta)$。</li>\n<li>这里有个问题，既然把$d$理解成方向，为什么不加一个约束条件限制$d$为单位向量呢？</li>\n</ul>\n</li>\n<li>NG得到的$d \\propto G(\\theta)^{-1} \\nabla L(\\theta)$，$\\theta$的迭代公式为$\\theta _{k+1} = \\theta _{k} + \\alpha _k G(\\theta)^{-1} \\nabla L(\\theta)$。</li>\n</ul>\n</li>\n<li>LM<ul>\n<li>将$d$改写为$d = (G(\\theta) + \\tau I)^{-1} \\nabla L(\\theta)$，通过调整$\\tau$的大小来<strong>调整算法趋向于NGD还是SGD</strong>，具体来说，$\\tau$小的时候趋向于NGD，$\\tau$大的时候趋向于SGD。</li>\n<li>这里有个问题，调控$\\tau$大小的算法中，$p$的含义是什么？</li>\n</ul>\n</li>\n<li>K-FAC<ul>\n<li>对<strong>Kronecker product做近似</strong>以降低$G(\\theta)$的储存成本，再<strong>强行对角化</strong>（非对角block置为0）以降低求解方程组$G(\\theta)x = g$的计算复杂度。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>more<ul>\n<li>exponential average的迭代形式：<br>$$G_{n+1} = (1-\\epsilon) \\hat{G}_n + \\epsilon G_n \\Leftrightarrow G_{n+1} = (1-\\epsilon)( \\hat{G}_n + \\epsilon \\hat{G}_{n-1} + \\epsilon ^2 \\hat{G}_{n-2} + \\dots).<br>$$</li>\n<li>K-FAC中优化参数变为$q(y \\mid x ; \\theta) \\hat{q}(x)$；</li>\n<li>针对LM的K-FAC（i.e., 近似$(G(\\theta) + \\tau I)^{-1}$的思路）。</li>\n</ul>\n</li>\n<li>references<ul>\n<li><a href=\"https://www.youtube.com/watch?v=FLV-MLPt3sU\">K-FAC tutorial</a></li>\n<li><a href=\"https://hec.unil.ch/docs/files/23/100/handout1.pdf\">Kronecker product tutorial</a></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"ACKTR\"><a href=\"#ACKTR\" class=\"headerlink\" title=\"ACKTR\"></a>ACKTR</h2><ul>\n<li>motivation<ul>\n<li>将K-FAC用到actor-critic框架中，提高sample efficiency，加快收敛速度。</li>\n</ul>\n</li>\n<li>idea<ul>\n<li>actor：对于stochastic policy，actor的输出就是分布，可以直接用K-FAC；</li>\n<li>critic：将回归问题<br>$$<br>\\mathop{\\text{minimize}}_{\\theta} \\sum_i \\Vert f(s_i ; \\theta) - v_i \\Vert^2<br>$$建模为最大似然问题<br>$$<br>\\mathop{\\text{maximize}}_{\\theta} \\log \\prod _i p(v_i \\mid s_i ; \\theta).<br>$$</li>\n<li>针对sharing parameter framework：<ol>\n<li>理解为对pair(a, v)作最大似然估计；</li>\n<li>假设actor与critic相互独立，得联合概率$p(a,v \\mid s ; \\theta) = \\pi(a \\mid s ; \\theta)p(v \\mid s ; \\theta)$；</li>\n<li>对$p(a, v ; \\theta)$作最大似然估计。</li>\n</ol>\n</li>\n<li>trust region：在K-FAC的基础上再对参数$\\theta$更新的步长再做一个限制。</li>\n</ul>\n</li>\n</ul>\n"},{"title":"论文笔记《Reciprocal n-body Collision Avoidance》","description":["应用广泛的经典底层避障算法"],"date":"2017-01-14T13:41:51.000Z","_content":"\n\n## 简介\n\nORCA是经典的分布式底层避障算法，其任务是（对于A）：\n\n- **输入**：A与B的形状（$r\\_A$、$r\\_B$）、位置（$p\\_A$、$p\\_B$）、速度（$v\\_A$、$v\\_B$），以及A的偏好量（$v\\_A^{pref}$）和限制量（$v\\_A^{max}$）。\n- **输出**：不会发生碰撞的$v\\_A^{\\prime}$。\n- **特点**：双方只要都采用ORCA，那么双方**无需通信**，**分布式**地求出来的$v\\_A^{\\prime}$与$v\\_B^{\\prime}$也不会发生碰撞。\n\n跟RVO一样，ORCA也是基于VO的，但更加实用，因为：\n\n- **效果上**：考虑了**速度的大小**，使得筛选粒度更细。不像VO和RVO只考虑速度方向。\n- **效率上**：求解过程基本只用到了**线性规划**，比较高效。不像VO和RVO有大量的非线性求解。\n\n## 引入时间窗口$\\tau$\n\n1. 如下图(a)，在**空间坐标**上，有\n    + 位于$\\bf{p\\_B}$，半径为$r\\_B$的$B$\n    + 位于$\\bf{p\\_A}$，半径为$r\\_A$的$A$\n2. 如下图(b)，引入时间$\\tau$，将**空间坐标**转换为**速度坐标**\n    1. **相对化空间坐标**：将图(a)化为以$A$为原点，并将$A$化为质点\n    2. **转为速度坐标**：假设$B$静止，那么当$v\\_A * \\tau$达到红色弧线时，$A$与$B$会发生碰撞，所以VO内，速度上限为$\\frac{p\\_{弧线上的点}}{\\tau}$，得到绿色弧线。\n    3. 至此得到$VO^{\\tau}\\_{A|B}$，即绿色弧线与两射线组成的类扇形\n3. 如下图(c)，**考虑$B$取的速度集合$V\\_B$**，对假设$B$静止得到的$VO^{\\tau}\\_{A|B}$求闵氏和，得$CA^{\\tau}\\_{A|B}(V\\_B)$\n\n<div style=\"width:800px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img time_interval.png 时间窗口 %}\n</div>\n\n下面给出各变量规范的数学定义：\n\n- $D({\\bf{p}},r)$：以$p$为圆心$r$为半径的圆\n $$D({\\bf{p}},r)=\\\\{ \\ {\\bf{q}} \\ | \\ \\\\| {\\bf{q}} - {\\bf{p}} \\\\| < r \\ \\\\}$$\n\n- $VO^{\\tau}\\_{A|B}$：绿色弧线和两条射线组成的类扇形\n $$VO^{\\tau}\\_{A|B} = \\\\{ \\ {\\bf{v}} \\ | \\ \\exists t \\in [0, \\tau], t {\\bf{v}} \\in D({\\bf{p\\_B}} -{\\bf{p\\_A}}, r\\_A+r\\_B) \\  \\\\}$$\n\n- $CA^{\\tau}\\_{A|B}(V\\_B)$：考虑$B$取速度集合$V\\_B$\n $$CA^{\\tau}\\_{A|B}(V\\_B)=\\\\{ \\ {\\bf{v}} \\ | \\ {\\bf{v}} \\notin VO^{\\tau}\\_{A|B} \\oplus V\\_B \\ \\\\}，　其中\\oplus为闵氏和$$\n\n至此，成功在VO的基础上引入了时间窗口，避障的时候不仅考虑**速度方向**，还考虑**速度大小**。\n\np.s. 关于VO，闵氏和等内容可以参考上一篇文章{% post_link paper-rvo 论文笔记《Reciprocal Velocity Obstacles for Real-Time Multi-Agent Navigation》 %}\n\n## ORCA定义\n\nORCA全称为Optimal Reciprocal Collision Avoidance，含义就是在上述的$CA^{\\tau}\\_{A|B}(V\\_B)$中选择最优的一个。\n\n论文对最优的定义大概可以理解为**在$v^{opt}$附近的合法值越多越好**，即为满足下列条件的$V\\_A$与$V\\_B$对：\n\n- **Reciprocally collision avoiding**：很好理解，在对方的$CA$内即可，即\n$$V\\_A \\subseteq CA^{\\tau}\\_{A|B}(V\\_B) \\land V\\_B \\subseteq CA^{\\tau}\\_{B|A}(V\\_A)$$\n- **Reciprocally maximal**：两个速度集是最大的不碰撞速度集，$V\\_A$或$V\\_B$都没有更多的避撞速度可选\n$$V\\_A = CA^{\\tau}\\_{A|B}(V\\_B) \\land V\\_B = CA^{\\tau}\\_{B|A}(V\\_A)$$\n- **包含最多$v^{opt}$附近的避撞速度**：$v^{opt}$是一个预设值，可以理解为偏好值，论文中的最优希望：\n\t+ $v^{opt}$附近的值越多越好\n- **双方在各自$v^{opt}$附近的避撞速度数量一样**：$A$和$B$各自有$v^{opt}\\_A$和$v^{opt}\\_B$，论文中的最优希望：\n\t+ $A$求出来在$v^{opt}\\_A$附近的避撞速度的数量$n\\_A$\n\t+ $B$求出来在$v^{opt}\\_B$附近的避撞速度的数量$n\\_B$\n\t+ $n\\_A = n\\_B$\n\n那么用数学语言来描述上面几条性质就是：\n$$| ORCA^{\\tau}\\_{A|B} \\cap D({\\bf{v^{opt}\\_A}}, r) | = | ORCA^{\\tau}\\_{B|A} \\cap D({\\bf{v^{opt}\\_B}}, r) | \\ge min(|V\\_A \\cap D({\\bf{v^{opt}\\_A}}, r)|, |V\\_B \\cap D({\\bf{v^{opt}\\_B}}, r)|)$$\n\n其中\n\n- $ORCA^{\\tau}\\_{A|B}$与$ORCA^{\\tau}\\_{B|A}$：表示要求的最优速度集对，且满足reciprocally maximal，即\n$$ORCA^{\\tau}\\_{A|B} = CA^{\\tau}\\_{A|B}(ORCA^{\\tau}\\_{B|A}) \\land ORCA^{\\tau}\\_{B|A} = CA^{\\tau}\\_{B|A}(ORCA^{\\tau}\\_{A|B})$$\n- $V\\_A$与$V\\_B$：表示任意reciprocally collision avoiding的速度集对，即\n$$V\\_A \\subseteq CA^{\\tau}\\_{A|B}(V\\_B) \\land V\\_B \\subseteq CA^{\\tau}\\_{B|A}(V\\_A)$$\n- $r$：表示了“附近”的大小\n- $D({\\bf{v^{opt}}},r)$：表示$v^{opt}$附近的速度\n\n## ORCA求解\n\n论文采用构造法求解出满足上述性质的ORCA，下面先说怎么做，再说为什么这样做就能满足性质。\n\n下面从$A$的角度介绍构造过程（图示如下），这里假设$A$知道$\\bf{v^{opt}\\_B}$\n\n1. 求解**相对速度**${\\bf{v^{opt}\\_A}}-{\\bf{v^{opt}\\_B}}$\n2. 求解$VO^{\\tau}\\_{A|B}$**边界上**离相对速度${\\bf{v^{opt}\\_A}}-{\\bf{v^{opt}\\_B}}$**最近的点**$\\bf{x}$\n3. 求解从相对速度${\\bf{v^{opt}\\_A}}-{\\bf{v^{opt}\\_B}}$指向$\\bf{x}$的向量$\\bf{u}$\n4. 求解与${\\bf{v^{opt}\\_A}} + \\frac{1}{2}{\\bf{u}}$垂直的直线，将空间分为两个平面\n5. 直线${\\bf{v^{opt}\\_A}} + \\frac{1}{2}{\\bf{u}}$指向的平面即为所求$ORCA^{\\tau}\\_{A|B}$\n\n<div style=\"width:600px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img orca_sol.png ORCA求解 %}\n</div>\n\n下面逐条解释为什么符合性质：\n\n- **Reciprocally collision avoiding**：\n\t+ 由构造过程可知${\\bf{v^{opt}\\_A}}-{\\bf{v^{opt}\\_B}}+{\\bf{u}}$不在$VO^{\\tau}\\_{A|B}$内\n\t+ $A$取新速度${\\bf{v^{opt}\\_A}} + \\frac{1}{2}{\\bf{u}}$\n\t+ $B$取新速度${\\bf{v^{opt}\\_B}} - \\frac{1}{2}{\\bf{u}}$\n\t+ 此时，相对速度为${\\bf{v^{opt}\\_A}} + \\frac{1}{2}{\\bf{u}} - ({\\bf{v^{opt}\\_B}} - \\frac{1}{2}{\\bf{u}}) = {\\bf{v^{opt}\\_A}}-{\\bf{v^{opt}\\_B}}+{\\bf{u}}$，所以不在$VO^{\\tau}\\_{A|B}$内\n- **Reciprocally maximal**：\n\t+ 要证$ORCA^{\\tau}\\_{A|B} = CA^{\\tau}\\_{A|B}(ORCA^{\\tau}\\_{B|A})$\n\t+ 先求$CA^{\\tau}\\_{A|B}(ORCA^{\\tau}\\_{B|A})$：\n\t\t* 回忆之前引入时间窗口$\\tau$部分，构造$CA^{\\tau}\\_{A|B}(ORCA^{\\tau}\\_{B|A})$分两步\n\t\t\t1. 先将类扇形往${\\bf{v^{opt}\\_B}}-\\frac{1}{2}{\\bf{u}}$移动\n\t\t\t2. 沿直线$ORCA^{\\tau}\\_{B|A}$方向扫\n\t\t* 先将类扇形往$\\bf{v^{opt}\\_B}$方向平移（此时，类扇形中的${\\bf{v^{opt}\\_A}}-{\\bf{v^{opt}\\_B}}$到了$\\bf{v^{opt}\\_A}$，且$\\bf{x}$与$\\bf{v^{opt}\\_A}$的中点在直线$ORCA^{\\tau}\\_{A|B}$上）\n\t\t* 别忘了还要将类扇形往$-{\\frac{1}{2}\\bf{u}}$方向移动（此时，$\\bf{x}$刚好位于直线$ORCA^{\\tau}\\_{A|B}$上）\n\t\t* 最后再沿直线$ORCA^{\\tau}\\_{B|A}$方向扫，得$CA^{\\tau}\\_{A|B}(ORCA^{\\tau}\\_{B|A})$\n\t+ 而显然$CA^{\\tau}\\_{A|B}(ORCA^{\\tau}\\_{B|A})$正是$ORCA^{\\tau}\\_{A|B}$\n- **包含最多$v^{opt}$附近的避撞速度**：\n\t+ 选择了最近的$\\bf{x}$进行“突围”，那“舍弃”的速度应该是最少的\n\t+ p.s. 这一点的证明不太严谨，有更好的证明欢迎留言探讨\n- **双方在各自$v^{opt}$附近的避撞速度数量一样**：\n\t+ $\\bf{v^{opt}\\_A}$到$ORCA^{\\tau}\\_{A|B}$的距离等于$\\bf{v^{opt}\\_B}$到$ORCA^{\\tau}\\_{B|A}$的距离\n\t+ 定义“附近”用的是圆\n\n最后给出ORCA的数学定义\n\n$$ORCA^{\\tau}\\_{A|B} = \\\\{ \\ {\\bf{v}} \\ | \\ ({\\bf{v}} - ({\\bf{v^{opt}\\_A}} + \\frac{1}{2}{\\bf{u}})) \\cdot {\\bf{n}} \\ge 0 \\  \\\\}$$\n\n其中\n\n- ${\\bf{u}}$是最小偏移\n$${\\bf{u}} = (\\mathop{argmin}\\_{ {\\bf{v}} \\in \\partial VO^{\\tau}\\_{A|B}}{\\\\| {\\bf{v}} - ( {\\bf{v^{opt}\\_A}} - {\\bf{v^{opt}\\_B}} )  \\\\|}) - ({\\bf{v^{opt}\\_A}} - {\\bf{v^{opt}\\_B}})$$\n- ${\\bf{n}}$是跟${\\bf{u}}$同向的法向量\n- 用${\\bf{v}} \\cdot {\\bf{n}} \\ge 0$来表示一个平面\n\n## ORCA基本用法\n\n1. 对其他所有agents的$ORCA$求交（线性规划），再与自己可选速度求交集，得候选速度集$ORCA^{\\tau}\\_{A}$\n$$ORCA^{\\tau}\\_{A}=D({\\bf{0}}, {\\bf{v^{max}\\_A}}) \\cap \\mathop{\\bigcap}\\_{B \\ne A}{ORCA^{\\tau}\\_{A|B}}$$\n2. 在候选集中求解跟自己偏好速度最近的一个速度${\\bf{v^{new}\\_A}}$\n$${\\bf{v^{new}\\_A}} = \\mathop{argmin}\\_{ {\\bf{v}} \\in ORCA^{\\tau}\\_A}{\\\\| {\\bf{v}} - {\\bf{v^{opt}\\_A}} \\\\|}$$\n\n<div style=\"width:600px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img orca_app.png ORCA基本用法 %}\n</div>\n\n可见ORCA的求解，就是在$ORCA^{\\tau}\\_{A}$内，优化目标函数$\\\\| {\\bf{v}} - {\\bf{v^{opt}\\_A}} \\\\|$，所以计算效率很高。\n\n## 关于${\\bf{v^{opt}}}$的选择\n\n为方便阐述，假设${\\bf{v\\_A}} = {\\bf{0}}$，这样$ORCA^{\\tau}\\_{A|B}$就只是从原点移$\\frac{1}{2}{\\bf{u}}$\n\n讨论${\\bf{v^{opt}}}$的选择跟$ORCA^{\\tau}\\_{A}$的关系\n\n- ${\\bf{0}}$\n\t+ 一定有解，如下图(c)。很好理解，这相当于假设了别人都静止，那只要自己也静止，必然有解。\n\t+ 密集情况下容易死锁，因为这样相当于只考虑位置信息，而不考虑速度信息\n- ${\\bf{v^{pref}}}$\n\t+ 密集情况下容易无解，如下图(b)。因为一般来说${\\bf{v^{pref}}}$都比较大\n\t+ 而且实际上也不可能观察得到别人的${\\bf{v^{pref}}}$\n- ${\\bf{v\\_{curr}}}$\n\t+ 两者的折中\n\n<div style=\"width:800px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img opt.png opt选择 %}\n</div>\n\n## 无解情况的处理\n\n基本思路跟线性代数里面的投影差不多：选择离合法速度最近的速度\n\n$$ {\\bf{v^{new}\\_{A}}} = \\mathop{argmin}\\_{ {\\bf{v}} \\in D({\\bf{0}}, {\\bf{v^{max}\\_A}})} {\\mathop{max}\\_{B \\ne A}{\\ d\\_{A|B}({\\bf{v}})}} $$\n\n下面慢慢拆分来看\n\n1. $d\\_{A|B}({\\bf{v}})$：表示${\\bf{v}}$的“违规”程度。定义为${\\bf{v}}$到ORCA分割线的有向距离，${\\bf{v}}$在ORCA外则取正\n2. ${\\mathop{max}\\_{B \\ne A}{\\ d\\_{A|B}({\\bf{v}})}}$：对每个速度${\\bf{v}}$，取“违规”最多的值作为它的“违规程度”\n3. $\\mathop{argmin}\\_{ {\\bf{v}} \\in D({\\bf{0}}, {\\bf{v^{max}\\_A}})} {\\mathop{max}\\_{B \\ne A}{\\ d\\_{A|B}({\\bf{v}})}}$：在可行速度内，求”违规程度”最小的速度\n\n## 收获\n- 改进可以从以下角度考虑：\n\t+ **效果**：只考虑了方向，没有考虑速度\n\t+ **效率**：计算复杂度\n\n## References\n\n- [Reciprocal n-body Collision Avoidance](http://gamma.cs.unc.edu/ORCA/publications/ORCA.pdf)\n","source":"_posts/paper-orca.md","raw":"---\ntitle: 论文笔记《Reciprocal n-body Collision Avoidance》\ntags:\n  - ORCA\ndescription:\n  - 应用广泛的经典底层避障算法\ncategories:\n  - 论文笔记\ndate: 2017-01-14 21:41:51\n---\n\n\n## 简介\n\nORCA是经典的分布式底层避障算法，其任务是（对于A）：\n\n- **输入**：A与B的形状（$r\\_A$、$r\\_B$）、位置（$p\\_A$、$p\\_B$）、速度（$v\\_A$、$v\\_B$），以及A的偏好量（$v\\_A^{pref}$）和限制量（$v\\_A^{max}$）。\n- **输出**：不会发生碰撞的$v\\_A^{\\prime}$。\n- **特点**：双方只要都采用ORCA，那么双方**无需通信**，**分布式**地求出来的$v\\_A^{\\prime}$与$v\\_B^{\\prime}$也不会发生碰撞。\n\n跟RVO一样，ORCA也是基于VO的，但更加实用，因为：\n\n- **效果上**：考虑了**速度的大小**，使得筛选粒度更细。不像VO和RVO只考虑速度方向。\n- **效率上**：求解过程基本只用到了**线性规划**，比较高效。不像VO和RVO有大量的非线性求解。\n\n## 引入时间窗口$\\tau$\n\n1. 如下图(a)，在**空间坐标**上，有\n    + 位于$\\bf{p\\_B}$，半径为$r\\_B$的$B$\n    + 位于$\\bf{p\\_A}$，半径为$r\\_A$的$A$\n2. 如下图(b)，引入时间$\\tau$，将**空间坐标**转换为**速度坐标**\n    1. **相对化空间坐标**：将图(a)化为以$A$为原点，并将$A$化为质点\n    2. **转为速度坐标**：假设$B$静止，那么当$v\\_A * \\tau$达到红色弧线时，$A$与$B$会发生碰撞，所以VO内，速度上限为$\\frac{p\\_{弧线上的点}}{\\tau}$，得到绿色弧线。\n    3. 至此得到$VO^{\\tau}\\_{A|B}$，即绿色弧线与两射线组成的类扇形\n3. 如下图(c)，**考虑$B$取的速度集合$V\\_B$**，对假设$B$静止得到的$VO^{\\tau}\\_{A|B}$求闵氏和，得$CA^{\\tau}\\_{A|B}(V\\_B)$\n\n<div style=\"width:800px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img time_interval.png 时间窗口 %}\n</div>\n\n下面给出各变量规范的数学定义：\n\n- $D({\\bf{p}},r)$：以$p$为圆心$r$为半径的圆\n $$D({\\bf{p}},r)=\\\\{ \\ {\\bf{q}} \\ | \\ \\\\| {\\bf{q}} - {\\bf{p}} \\\\| < r \\ \\\\}$$\n\n- $VO^{\\tau}\\_{A|B}$：绿色弧线和两条射线组成的类扇形\n $$VO^{\\tau}\\_{A|B} = \\\\{ \\ {\\bf{v}} \\ | \\ \\exists t \\in [0, \\tau], t {\\bf{v}} \\in D({\\bf{p\\_B}} -{\\bf{p\\_A}}, r\\_A+r\\_B) \\  \\\\}$$\n\n- $CA^{\\tau}\\_{A|B}(V\\_B)$：考虑$B$取速度集合$V\\_B$\n $$CA^{\\tau}\\_{A|B}(V\\_B)=\\\\{ \\ {\\bf{v}} \\ | \\ {\\bf{v}} \\notin VO^{\\tau}\\_{A|B} \\oplus V\\_B \\ \\\\}，　其中\\oplus为闵氏和$$\n\n至此，成功在VO的基础上引入了时间窗口，避障的时候不仅考虑**速度方向**，还考虑**速度大小**。\n\np.s. 关于VO，闵氏和等内容可以参考上一篇文章{% post_link paper-rvo 论文笔记《Reciprocal Velocity Obstacles for Real-Time Multi-Agent Navigation》 %}\n\n## ORCA定义\n\nORCA全称为Optimal Reciprocal Collision Avoidance，含义就是在上述的$CA^{\\tau}\\_{A|B}(V\\_B)$中选择最优的一个。\n\n论文对最优的定义大概可以理解为**在$v^{opt}$附近的合法值越多越好**，即为满足下列条件的$V\\_A$与$V\\_B$对：\n\n- **Reciprocally collision avoiding**：很好理解，在对方的$CA$内即可，即\n$$V\\_A \\subseteq CA^{\\tau}\\_{A|B}(V\\_B) \\land V\\_B \\subseteq CA^{\\tau}\\_{B|A}(V\\_A)$$\n- **Reciprocally maximal**：两个速度集是最大的不碰撞速度集，$V\\_A$或$V\\_B$都没有更多的避撞速度可选\n$$V\\_A = CA^{\\tau}\\_{A|B}(V\\_B) \\land V\\_B = CA^{\\tau}\\_{B|A}(V\\_A)$$\n- **包含最多$v^{opt}$附近的避撞速度**：$v^{opt}$是一个预设值，可以理解为偏好值，论文中的最优希望：\n\t+ $v^{opt}$附近的值越多越好\n- **双方在各自$v^{opt}$附近的避撞速度数量一样**：$A$和$B$各自有$v^{opt}\\_A$和$v^{opt}\\_B$，论文中的最优希望：\n\t+ $A$求出来在$v^{opt}\\_A$附近的避撞速度的数量$n\\_A$\n\t+ $B$求出来在$v^{opt}\\_B$附近的避撞速度的数量$n\\_B$\n\t+ $n\\_A = n\\_B$\n\n那么用数学语言来描述上面几条性质就是：\n$$| ORCA^{\\tau}\\_{A|B} \\cap D({\\bf{v^{opt}\\_A}}, r) | = | ORCA^{\\tau}\\_{B|A} \\cap D({\\bf{v^{opt}\\_B}}, r) | \\ge min(|V\\_A \\cap D({\\bf{v^{opt}\\_A}}, r)|, |V\\_B \\cap D({\\bf{v^{opt}\\_B}}, r)|)$$\n\n其中\n\n- $ORCA^{\\tau}\\_{A|B}$与$ORCA^{\\tau}\\_{B|A}$：表示要求的最优速度集对，且满足reciprocally maximal，即\n$$ORCA^{\\tau}\\_{A|B} = CA^{\\tau}\\_{A|B}(ORCA^{\\tau}\\_{B|A}) \\land ORCA^{\\tau}\\_{B|A} = CA^{\\tau}\\_{B|A}(ORCA^{\\tau}\\_{A|B})$$\n- $V\\_A$与$V\\_B$：表示任意reciprocally collision avoiding的速度集对，即\n$$V\\_A \\subseteq CA^{\\tau}\\_{A|B}(V\\_B) \\land V\\_B \\subseteq CA^{\\tau}\\_{B|A}(V\\_A)$$\n- $r$：表示了“附近”的大小\n- $D({\\bf{v^{opt}}},r)$：表示$v^{opt}$附近的速度\n\n## ORCA求解\n\n论文采用构造法求解出满足上述性质的ORCA，下面先说怎么做，再说为什么这样做就能满足性质。\n\n下面从$A$的角度介绍构造过程（图示如下），这里假设$A$知道$\\bf{v^{opt}\\_B}$\n\n1. 求解**相对速度**${\\bf{v^{opt}\\_A}}-{\\bf{v^{opt}\\_B}}$\n2. 求解$VO^{\\tau}\\_{A|B}$**边界上**离相对速度${\\bf{v^{opt}\\_A}}-{\\bf{v^{opt}\\_B}}$**最近的点**$\\bf{x}$\n3. 求解从相对速度${\\bf{v^{opt}\\_A}}-{\\bf{v^{opt}\\_B}}$指向$\\bf{x}$的向量$\\bf{u}$\n4. 求解与${\\bf{v^{opt}\\_A}} + \\frac{1}{2}{\\bf{u}}$垂直的直线，将空间分为两个平面\n5. 直线${\\bf{v^{opt}\\_A}} + \\frac{1}{2}{\\bf{u}}$指向的平面即为所求$ORCA^{\\tau}\\_{A|B}$\n\n<div style=\"width:600px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img orca_sol.png ORCA求解 %}\n</div>\n\n下面逐条解释为什么符合性质：\n\n- **Reciprocally collision avoiding**：\n\t+ 由构造过程可知${\\bf{v^{opt}\\_A}}-{\\bf{v^{opt}\\_B}}+{\\bf{u}}$不在$VO^{\\tau}\\_{A|B}$内\n\t+ $A$取新速度${\\bf{v^{opt}\\_A}} + \\frac{1}{2}{\\bf{u}}$\n\t+ $B$取新速度${\\bf{v^{opt}\\_B}} - \\frac{1}{2}{\\bf{u}}$\n\t+ 此时，相对速度为${\\bf{v^{opt}\\_A}} + \\frac{1}{2}{\\bf{u}} - ({\\bf{v^{opt}\\_B}} - \\frac{1}{2}{\\bf{u}}) = {\\bf{v^{opt}\\_A}}-{\\bf{v^{opt}\\_B}}+{\\bf{u}}$，所以不在$VO^{\\tau}\\_{A|B}$内\n- **Reciprocally maximal**：\n\t+ 要证$ORCA^{\\tau}\\_{A|B} = CA^{\\tau}\\_{A|B}(ORCA^{\\tau}\\_{B|A})$\n\t+ 先求$CA^{\\tau}\\_{A|B}(ORCA^{\\tau}\\_{B|A})$：\n\t\t* 回忆之前引入时间窗口$\\tau$部分，构造$CA^{\\tau}\\_{A|B}(ORCA^{\\tau}\\_{B|A})$分两步\n\t\t\t1. 先将类扇形往${\\bf{v^{opt}\\_B}}-\\frac{1}{2}{\\bf{u}}$移动\n\t\t\t2. 沿直线$ORCA^{\\tau}\\_{B|A}$方向扫\n\t\t* 先将类扇形往$\\bf{v^{opt}\\_B}$方向平移（此时，类扇形中的${\\bf{v^{opt}\\_A}}-{\\bf{v^{opt}\\_B}}$到了$\\bf{v^{opt}\\_A}$，且$\\bf{x}$与$\\bf{v^{opt}\\_A}$的中点在直线$ORCA^{\\tau}\\_{A|B}$上）\n\t\t* 别忘了还要将类扇形往$-{\\frac{1}{2}\\bf{u}}$方向移动（此时，$\\bf{x}$刚好位于直线$ORCA^{\\tau}\\_{A|B}$上）\n\t\t* 最后再沿直线$ORCA^{\\tau}\\_{B|A}$方向扫，得$CA^{\\tau}\\_{A|B}(ORCA^{\\tau}\\_{B|A})$\n\t+ 而显然$CA^{\\tau}\\_{A|B}(ORCA^{\\tau}\\_{B|A})$正是$ORCA^{\\tau}\\_{A|B}$\n- **包含最多$v^{opt}$附近的避撞速度**：\n\t+ 选择了最近的$\\bf{x}$进行“突围”，那“舍弃”的速度应该是最少的\n\t+ p.s. 这一点的证明不太严谨，有更好的证明欢迎留言探讨\n- **双方在各自$v^{opt}$附近的避撞速度数量一样**：\n\t+ $\\bf{v^{opt}\\_A}$到$ORCA^{\\tau}\\_{A|B}$的距离等于$\\bf{v^{opt}\\_B}$到$ORCA^{\\tau}\\_{B|A}$的距离\n\t+ 定义“附近”用的是圆\n\n最后给出ORCA的数学定义\n\n$$ORCA^{\\tau}\\_{A|B} = \\\\{ \\ {\\bf{v}} \\ | \\ ({\\bf{v}} - ({\\bf{v^{opt}\\_A}} + \\frac{1}{2}{\\bf{u}})) \\cdot {\\bf{n}} \\ge 0 \\  \\\\}$$\n\n其中\n\n- ${\\bf{u}}$是最小偏移\n$${\\bf{u}} = (\\mathop{argmin}\\_{ {\\bf{v}} \\in \\partial VO^{\\tau}\\_{A|B}}{\\\\| {\\bf{v}} - ( {\\bf{v^{opt}\\_A}} - {\\bf{v^{opt}\\_B}} )  \\\\|}) - ({\\bf{v^{opt}\\_A}} - {\\bf{v^{opt}\\_B}})$$\n- ${\\bf{n}}$是跟${\\bf{u}}$同向的法向量\n- 用${\\bf{v}} \\cdot {\\bf{n}} \\ge 0$来表示一个平面\n\n## ORCA基本用法\n\n1. 对其他所有agents的$ORCA$求交（线性规划），再与自己可选速度求交集，得候选速度集$ORCA^{\\tau}\\_{A}$\n$$ORCA^{\\tau}\\_{A}=D({\\bf{0}}, {\\bf{v^{max}\\_A}}) \\cap \\mathop{\\bigcap}\\_{B \\ne A}{ORCA^{\\tau}\\_{A|B}}$$\n2. 在候选集中求解跟自己偏好速度最近的一个速度${\\bf{v^{new}\\_A}}$\n$${\\bf{v^{new}\\_A}} = \\mathop{argmin}\\_{ {\\bf{v}} \\in ORCA^{\\tau}\\_A}{\\\\| {\\bf{v}} - {\\bf{v^{opt}\\_A}} \\\\|}$$\n\n<div style=\"width:600px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img orca_app.png ORCA基本用法 %}\n</div>\n\n可见ORCA的求解，就是在$ORCA^{\\tau}\\_{A}$内，优化目标函数$\\\\| {\\bf{v}} - {\\bf{v^{opt}\\_A}} \\\\|$，所以计算效率很高。\n\n## 关于${\\bf{v^{opt}}}$的选择\n\n为方便阐述，假设${\\bf{v\\_A}} = {\\bf{0}}$，这样$ORCA^{\\tau}\\_{A|B}$就只是从原点移$\\frac{1}{2}{\\bf{u}}$\n\n讨论${\\bf{v^{opt}}}$的选择跟$ORCA^{\\tau}\\_{A}$的关系\n\n- ${\\bf{0}}$\n\t+ 一定有解，如下图(c)。很好理解，这相当于假设了别人都静止，那只要自己也静止，必然有解。\n\t+ 密集情况下容易死锁，因为这样相当于只考虑位置信息，而不考虑速度信息\n- ${\\bf{v^{pref}}}$\n\t+ 密集情况下容易无解，如下图(b)。因为一般来说${\\bf{v^{pref}}}$都比较大\n\t+ 而且实际上也不可能观察得到别人的${\\bf{v^{pref}}}$\n- ${\\bf{v\\_{curr}}}$\n\t+ 两者的折中\n\n<div style=\"width:800px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img opt.png opt选择 %}\n</div>\n\n## 无解情况的处理\n\n基本思路跟线性代数里面的投影差不多：选择离合法速度最近的速度\n\n$$ {\\bf{v^{new}\\_{A}}} = \\mathop{argmin}\\_{ {\\bf{v}} \\in D({\\bf{0}}, {\\bf{v^{max}\\_A}})} {\\mathop{max}\\_{B \\ne A}{\\ d\\_{A|B}({\\bf{v}})}} $$\n\n下面慢慢拆分来看\n\n1. $d\\_{A|B}({\\bf{v}})$：表示${\\bf{v}}$的“违规”程度。定义为${\\bf{v}}$到ORCA分割线的有向距离，${\\bf{v}}$在ORCA外则取正\n2. ${\\mathop{max}\\_{B \\ne A}{\\ d\\_{A|B}({\\bf{v}})}}$：对每个速度${\\bf{v}}$，取“违规”最多的值作为它的“违规程度”\n3. $\\mathop{argmin}\\_{ {\\bf{v}} \\in D({\\bf{0}}, {\\bf{v^{max}\\_A}})} {\\mathop{max}\\_{B \\ne A}{\\ d\\_{A|B}({\\bf{v}})}}$：在可行速度内，求”违规程度”最小的速度\n\n## 收获\n- 改进可以从以下角度考虑：\n\t+ **效果**：只考虑了方向，没有考虑速度\n\t+ **效率**：计算复杂度\n\n## References\n\n- [Reciprocal n-body Collision Avoidance](http://gamma.cs.unc.edu/ORCA/publications/ORCA.pdf)\n","slug":"paper-orca","published":1,"updated":"2024-08-13T16:03:47.864Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clzvf19270016eqwolnapvyjd","content":"<h2 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h2><p>ORCA是经典的分布式底层避障算法，其任务是（对于A）：</p>\n<ul>\n<li><strong>输入</strong>：A与B的形状（$r_A$、$r_B$）、位置（$p_A$、$p_B$）、速度（$v_A$、$v_B$），以及A的偏好量（$v_A^{pref}$）和限制量（$v_A^{max}$）。</li>\n<li><strong>输出</strong>：不会发生碰撞的$v_A^{\\prime}$。</li>\n<li><strong>特点</strong>：双方只要都采用ORCA，那么双方<strong>无需通信</strong>，<strong>分布式</strong>地求出来的$v_A^{\\prime}$与$v_B^{\\prime}$也不会发生碰撞。</li>\n</ul>\n<p>跟RVO一样，ORCA也是基于VO的，但更加实用，因为：</p>\n<ul>\n<li><strong>效果上</strong>：考虑了<strong>速度的大小</strong>，使得筛选粒度更细。不像VO和RVO只考虑速度方向。</li>\n<li><strong>效率上</strong>：求解过程基本只用到了<strong>线性规划</strong>，比较高效。不像VO和RVO有大量的非线性求解。</li>\n</ul>\n<h2 id=\"引入时间窗口-tau\"><a href=\"#引入时间窗口-tau\" class=\"headerlink\" title=\"引入时间窗口$\\tau$\"></a>引入时间窗口$\\tau$</h2><ol>\n<li>如下图(a)，在<strong>空间坐标</strong>上，有<ul>\n<li>位于$\\bf{p_B}$，半径为$r_B$的$B$</li>\n<li>位于$\\bf{p_A}$，半径为$r_A$的$A$</li>\n</ul>\n</li>\n<li>如下图(b)，引入时间$\\tau$，将<strong>空间坐标</strong>转换为<strong>速度坐标</strong><ol>\n<li><strong>相对化空间坐标</strong>：将图(a)化为以$A$为原点，并将$A$化为质点</li>\n<li><strong>转为速度坐标</strong>：假设$B$静止，那么当$v_A * \\tau$达到红色弧线时，$A$与$B$会发生碰撞，所以VO内，速度上限为$\\frac{p_{弧线上的点}}{\\tau}$，得到绿色弧线。</li>\n<li>至此得到$VO^{\\tau}_{A|B}$，即绿色弧线与两射线组成的类扇形</li>\n</ol>\n</li>\n<li>如下图(c)，<strong>考虑$B$取的速度集合$V_B$</strong>，对假设$B$静止得到的$VO^{\\tau}_{A|B}$求闵氏和，得$CA^{\\tau}_{A|B}(V_B)$</li>\n</ol>\n<div style=\"width:800px; margin-left:auto; margin-right:auto;\"><br>  <img src=\"/2017/01/14/paper-orca/time_interval.png\" alt=\"时间窗口\" title=\"时间窗口\"><br></div>\n\n<p>下面给出各变量规范的数学定义：</p>\n<ul>\n<li><p>$D({\\bf{p}},r)$：以$p$为圆心$r$为半径的圆<br>$$D({\\bf{p}},r)=\\{  {\\bf{q}}  |  \\| {\\bf{q}} - {\\bf{p}} \\| &lt; r  \\}$$</p>\n</li>\n<li><p>$VO^{\\tau}_{A|B}$：绿色弧线和两条射线组成的类扇形<br>$$VO^{\\tau}_{A|B} = \\{  {\\bf{v}}  |  \\exists t \\in [0, \\tau], t {\\bf{v}} \\in D({\\bf{p_B}} -{\\bf{p_A}}, r_A+r_B)   \\}$$</p>\n</li>\n<li><p>$CA^{\\tau}_{A|B}(V_B)$：考虑$B$取速度集合$V_B$<br>$$CA^{\\tau}_{A|B}(V_B)=\\{  {\\bf{v}}  |  {\\bf{v}} \\notin VO^{\\tau}_{A|B} \\oplus V_B  \\}，　其中\\oplus为闵氏和$$</p>\n</li>\n</ul>\n<p>至此，成功在VO的基础上引入了时间窗口，避障的时候不仅考虑<strong>速度方向</strong>，还考虑<strong>速度大小</strong>。</p>\n<p>p.s. 关于VO，闵氏和等内容可以参考上一篇文章<a href=\"/2017/01/13/paper-rvo/\" title=\"论文笔记《Reciprocal Velocity Obstacles for Real-Time Multi-Agent Navigation》\">论文笔记《Reciprocal Velocity Obstacles for Real-Time Multi-Agent Navigation》</a></p>\n<h2 id=\"ORCA定义\"><a href=\"#ORCA定义\" class=\"headerlink\" title=\"ORCA定义\"></a>ORCA定义</h2><p>ORCA全称为Optimal Reciprocal Collision Avoidance，含义就是在上述的$CA^{\\tau}_{A|B}(V_B)$中选择最优的一个。</p>\n<p>论文对最优的定义大概可以理解为<strong>在$v^{opt}$附近的合法值越多越好</strong>，即为满足下列条件的$V_A$与$V_B$对：</p>\n<ul>\n<li><strong>Reciprocally collision avoiding</strong>：很好理解，在对方的$CA$内即可，即<br>$$V_A \\subseteq CA^{\\tau}_{A|B}(V_B) \\land V_B \\subseteq CA^{\\tau}_{B|A}(V_A)$$</li>\n<li><strong>Reciprocally maximal</strong>：两个速度集是最大的不碰撞速度集，$V_A$或$V_B$都没有更多的避撞速度可选<br>$$V_A = CA^{\\tau}_{A|B}(V_B) \\land V_B = CA^{\\tau}_{B|A}(V_A)$$</li>\n<li><strong>包含最多$v^{opt}$附近的避撞速度</strong>：$v^{opt}$是一个预设值，可以理解为偏好值，论文中的最优希望：<ul>\n<li>$v^{opt}$附近的值越多越好</li>\n</ul>\n</li>\n<li><strong>双方在各自$v^{opt}$附近的避撞速度数量一样</strong>：$A$和$B$各自有$v^{opt}_A$和$v^{opt}_B$，论文中的最优希望：<ul>\n<li>$A$求出来在$v^{opt}_A$附近的避撞速度的数量$n_A$</li>\n<li>$B$求出来在$v^{opt}_B$附近的避撞速度的数量$n_B$</li>\n<li>$n_A = n_B$</li>\n</ul>\n</li>\n</ul>\n<p>那么用数学语言来描述上面几条性质就是：<br>$$| ORCA^{\\tau}_{A|B} \\cap D({\\bf{v^{opt}_A}}, r) | = | ORCA^{\\tau}_{B|A} \\cap D({\\bf{v^{opt}_B}}, r) | \\ge min(|V_A \\cap D({\\bf{v^{opt}_A}}, r)|, |V_B \\cap D({\\bf{v^{opt}_B}}, r)|)$$</p>\n<p>其中</p>\n<ul>\n<li>$ORCA^{\\tau}_{A|B}$与$ORCA^{\\tau}_{B|A}$：表示要求的最优速度集对，且满足reciprocally maximal，即<br>$$ORCA^{\\tau}_{A|B} = CA^{\\tau}_{A|B}(ORCA^{\\tau}_{B|A}) \\land ORCA^{\\tau}_{B|A} = CA^{\\tau}_{B|A}(ORCA^{\\tau}_{A|B})$$</li>\n<li>$V_A$与$V_B$：表示任意reciprocally collision avoiding的速度集对，即<br>$$V_A \\subseteq CA^{\\tau}_{A|B}(V_B) \\land V_B \\subseteq CA^{\\tau}_{B|A}(V_A)$$</li>\n<li>$r$：表示了“附近”的大小</li>\n<li>$D({\\bf{v^{opt}}},r)$：表示$v^{opt}$附近的速度</li>\n</ul>\n<h2 id=\"ORCA求解\"><a href=\"#ORCA求解\" class=\"headerlink\" title=\"ORCA求解\"></a>ORCA求解</h2><p>论文采用构造法求解出满足上述性质的ORCA，下面先说怎么做，再说为什么这样做就能满足性质。</p>\n<p>下面从$A$的角度介绍构造过程（图示如下），这里假设$A$知道$\\bf{v^{opt}_B}$</p>\n<ol>\n<li>求解<strong>相对速度</strong>${\\bf{v^{opt}_A}}-{\\bf{v^{opt}_B}}$</li>\n<li>求解$VO^{\\tau}_{A|B}$<strong>边界上</strong>离相对速度${\\bf{v^{opt}_A}}-{\\bf{v^{opt}_B}}$<strong>最近的点</strong>$\\bf{x}$</li>\n<li>求解从相对速度${\\bf{v^{opt}_A}}-{\\bf{v^{opt}_B}}$指向$\\bf{x}$的向量$\\bf{u}$</li>\n<li>求解与${\\bf{v^{opt}_A}} + \\frac{1}{2}{\\bf{u}}$垂直的直线，将空间分为两个平面</li>\n<li>直线${\\bf{v^{opt}_A}} + \\frac{1}{2}{\\bf{u}}$指向的平面即为所求$ORCA^{\\tau}_{A|B}$</li>\n</ol>\n<div style=\"width:600px; margin-left:auto; margin-right:auto;\"><br>  <img src=\"/2017/01/14/paper-orca/orca_sol.png\" alt=\"ORCA求解\" title=\"ORCA求解\"><br></div>\n\n<p>下面逐条解释为什么符合性质：</p>\n<ul>\n<li><strong>Reciprocally collision avoiding</strong>：<ul>\n<li>由构造过程可知${\\bf{v^{opt}_A}}-{\\bf{v^{opt}_B}}+{\\bf{u}}$不在$VO^{\\tau}_{A|B}$内</li>\n<li>$A$取新速度${\\bf{v^{opt}_A}} + \\frac{1}{2}{\\bf{u}}$</li>\n<li>$B$取新速度${\\bf{v^{opt}_B}} - \\frac{1}{2}{\\bf{u}}$</li>\n<li>此时，相对速度为${\\bf{v^{opt}_A}} + \\frac{1}{2}{\\bf{u}} - ({\\bf{v^{opt}_B}} - \\frac{1}{2}{\\bf{u}}) = {\\bf{v^{opt}_A}}-{\\bf{v^{opt}_B}}+{\\bf{u}}$，所以不在$VO^{\\tau}_{A|B}$内</li>\n</ul>\n</li>\n<li><strong>Reciprocally maximal</strong>：<ul>\n<li>要证$ORCA^{\\tau}_{A|B} = CA^{\\tau}_{A|B}(ORCA^{\\tau}_{B|A})$</li>\n<li>先求$CA^{\\tau}_{A|B}(ORCA^{\\tau}_{B|A})$：<ul>\n<li>回忆之前引入时间窗口$\\tau$部分，构造$CA^{\\tau}_{A|B}(ORCA^{\\tau}_{B|A})$分两步<ol>\n<li>先将类扇形往${\\bf{v^{opt}_B}}-\\frac{1}{2}{\\bf{u}}$移动</li>\n<li>沿直线$ORCA^{\\tau}_{B|A}$方向扫</li>\n</ol>\n</li>\n<li>先将类扇形往$\\bf{v^{opt}_B}$方向平移（此时，类扇形中的${\\bf{v^{opt}_A}}-{\\bf{v^{opt}_B}}$到了$\\bf{v^{opt}_A}$，且$\\bf{x}$与$\\bf{v^{opt}_A}$的中点在直线$ORCA^{\\tau}_{A|B}$上）</li>\n<li>别忘了还要将类扇形往$-{\\frac{1}{2}\\bf{u}}$方向移动（此时，$\\bf{x}$刚好位于直线$ORCA^{\\tau}_{A|B}$上）</li>\n<li>最后再沿直线$ORCA^{\\tau}_{B|A}$方向扫，得$CA^{\\tau}_{A|B}(ORCA^{\\tau}_{B|A})$</li>\n</ul>\n</li>\n<li>而显然$CA^{\\tau}_{A|B}(ORCA^{\\tau}_{B|A})$正是$ORCA^{\\tau}_{A|B}$</li>\n</ul>\n</li>\n<li><strong>包含最多$v^{opt}$附近的避撞速度</strong>：<ul>\n<li>选择了最近的$\\bf{x}$进行“突围”，那“舍弃”的速度应该是最少的</li>\n<li>p.s. 这一点的证明不太严谨，有更好的证明欢迎留言探讨</li>\n</ul>\n</li>\n<li><strong>双方在各自$v^{opt}$附近的避撞速度数量一样</strong>：<ul>\n<li>$\\bf{v^{opt}_A}$到$ORCA^{\\tau}_{A|B}$的距离等于$\\bf{v^{opt}_B}$到$ORCA^{\\tau}_{B|A}$的距离</li>\n<li>定义“附近”用的是圆</li>\n</ul>\n</li>\n</ul>\n<p>最后给出ORCA的数学定义</p>\n<p>$$ORCA^{\\tau}_{A|B} = \\{  {\\bf{v}}  |  ({\\bf{v}} - ({\\bf{v^{opt}_A}} + \\frac{1}{2}{\\bf{u}})) \\cdot {\\bf{n}} \\ge 0   \\}$$</p>\n<p>其中</p>\n<ul>\n<li>${\\bf{u}}$是最小偏移<br>$${\\bf{u}} = (\\mathop{argmin}_{ {\\bf{v}} \\in \\partial VO^{\\tau}_{A|B}}{\\| {\\bf{v}} - ( {\\bf{v^{opt}_A}} - {\\bf{v^{opt}_B}} )  \\|}) - ({\\bf{v^{opt}_A}} - {\\bf{v^{opt}_B}})$$</li>\n<li>${\\bf{n}}$是跟${\\bf{u}}$同向的法向量</li>\n<li>用${\\bf{v}} \\cdot {\\bf{n}} \\ge 0$来表示一个平面</li>\n</ul>\n<h2 id=\"ORCA基本用法\"><a href=\"#ORCA基本用法\" class=\"headerlink\" title=\"ORCA基本用法\"></a>ORCA基本用法</h2><ol>\n<li>对其他所有agents的$ORCA$求交（线性规划），再与自己可选速度求交集，得候选速度集$ORCA^{\\tau}_{A}$<br>$$ORCA^{\\tau}_{A}=D({\\bf{0}}, {\\bf{v^{max}_A}}) \\cap \\mathop{\\bigcap}_{B \\ne A}{ORCA^{\\tau}_{A|B}}$$</li>\n<li>在候选集中求解跟自己偏好速度最近的一个速度${\\bf{v^{new}_A}}$<br>$${\\bf{v^{new}_A}} = \\mathop{argmin}_{ {\\bf{v}} \\in ORCA^{\\tau}_A}{\\| {\\bf{v}} - {\\bf{v^{opt}_A}} \\|}$$</li>\n</ol>\n<div style=\"width:600px; margin-left:auto; margin-right:auto;\"><br>  <img src=\"/2017/01/14/paper-orca/orca_app.png\" alt=\"ORCA基本用法\" title=\"ORCA基本用法\"><br></div>\n\n<p>可见ORCA的求解，就是在$ORCA^{\\tau}_{A}$内，优化目标函数$\\| {\\bf{v}} - {\\bf{v^{opt}_A}} \\|$，所以计算效率很高。</p>\n<h2 id=\"关于-bf-v-opt-的选择\"><a href=\"#关于-bf-v-opt-的选择\" class=\"headerlink\" title=\"关于${\\bf{v^{opt}}}$的选择\"></a>关于${\\bf{v^{opt}}}$的选择</h2><p>为方便阐述，假设${\\bf{v_A}} = {\\bf{0}}$，这样$ORCA^{\\tau}_{A|B}$就只是从原点移$\\frac{1}{2}{\\bf{u}}$</p>\n<p>讨论${\\bf{v^{opt}}}$的选择跟$ORCA^{\\tau}_{A}$的关系</p>\n<ul>\n<li>${\\bf{0}}$<ul>\n<li>一定有解，如下图(c)。很好理解，这相当于假设了别人都静止，那只要自己也静止，必然有解。</li>\n<li>密集情况下容易死锁，因为这样相当于只考虑位置信息，而不考虑速度信息</li>\n</ul>\n</li>\n<li>${\\bf{v^{pref}}}$<ul>\n<li>密集情况下容易无解，如下图(b)。因为一般来说${\\bf{v^{pref}}}$都比较大</li>\n<li>而且实际上也不可能观察得到别人的${\\bf{v^{pref}}}$</li>\n</ul>\n</li>\n<li>${\\bf{v_{curr}}}$<ul>\n<li>两者的折中</li>\n</ul>\n</li>\n</ul>\n<div style=\"width:800px; margin-left:auto; margin-right:auto;\"><br>  <img src=\"/2017/01/14/paper-orca/opt.png\" alt=\"opt选择\" title=\"opt选择\"><br></div>\n\n<h2 id=\"无解情况的处理\"><a href=\"#无解情况的处理\" class=\"headerlink\" title=\"无解情况的处理\"></a>无解情况的处理</h2><p>基本思路跟线性代数里面的投影差不多：选择离合法速度最近的速度</p>\n<p>$$ {\\bf{v^{new}_{A}}} = \\mathop{argmin}_{ {\\bf{v}} \\in D({\\bf{0}}, {\\bf{v^{max}_A}})} {\\mathop{max}_{B \\ne A}{ d_{A|B}({\\bf{v}})}} $$</p>\n<p>下面慢慢拆分来看</p>\n<ol>\n<li>$d_{A|B}({\\bf{v}})$：表示${\\bf{v}}$的“违规”程度。定义为${\\bf{v}}$到ORCA分割线的有向距离，${\\bf{v}}$在ORCA外则取正</li>\n<li>${\\mathop{max}_{B \\ne A}{ d_{A|B}({\\bf{v}})}}$：对每个速度${\\bf{v}}$，取“违规”最多的值作为它的“违规程度”</li>\n<li>$\\mathop{argmin}_{ {\\bf{v}} \\in D({\\bf{0}}, {\\bf{v^{max}_A}})} {\\mathop{max}_{B \\ne A}{ d_{A|B}({\\bf{v}})}}$：在可行速度内，求”违规程度”最小的速度</li>\n</ol>\n<h2 id=\"收获\"><a href=\"#收获\" class=\"headerlink\" title=\"收获\"></a>收获</h2><ul>\n<li>改进可以从以下角度考虑：<ul>\n<li><strong>效果</strong>：只考虑了方向，没有考虑速度</li>\n<li><strong>效率</strong>：计算复杂度</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"References\"><a href=\"#References\" class=\"headerlink\" title=\"References\"></a>References</h2><ul>\n<li><a href=\"http://gamma.cs.unc.edu/ORCA/publications/ORCA.pdf\" target=\"_blank\" rel=\"external\">Reciprocal n-body Collision Avoidance</a></li>\n</ul>\n","excerpt":"","more":"<h2 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h2><p>ORCA是经典的分布式底层避障算法，其任务是（对于A）：</p>\n<ul>\n<li><strong>输入</strong>：A与B的形状（$r_A$、$r_B$）、位置（$p_A$、$p_B$）、速度（$v_A$、$v_B$），以及A的偏好量（$v_A^{pref}$）和限制量（$v_A^{max}$）。</li>\n<li><strong>输出</strong>：不会发生碰撞的$v_A^{\\prime}$。</li>\n<li><strong>特点</strong>：双方只要都采用ORCA，那么双方<strong>无需通信</strong>，<strong>分布式</strong>地求出来的$v_A^{\\prime}$与$v_B^{\\prime}$也不会发生碰撞。</li>\n</ul>\n<p>跟RVO一样，ORCA也是基于VO的，但更加实用，因为：</p>\n<ul>\n<li><strong>效果上</strong>：考虑了<strong>速度的大小</strong>，使得筛选粒度更细。不像VO和RVO只考虑速度方向。</li>\n<li><strong>效率上</strong>：求解过程基本只用到了<strong>线性规划</strong>，比较高效。不像VO和RVO有大量的非线性求解。</li>\n</ul>\n<h2 id=\"引入时间窗口-tau\"><a href=\"#引入时间窗口-tau\" class=\"headerlink\" title=\"引入时间窗口$\\tau$\"></a>引入时间窗口$\\tau$</h2><ol>\n<li>如下图(a)，在<strong>空间坐标</strong>上，有<ul>\n<li>位于$\\bf{p_B}$，半径为$r_B$的$B$</li>\n<li>位于$\\bf{p_A}$，半径为$r_A$的$A$</li>\n</ul>\n</li>\n<li>如下图(b)，引入时间$\\tau$，将<strong>空间坐标</strong>转换为<strong>速度坐标</strong><ol>\n<li><strong>相对化空间坐标</strong>：将图(a)化为以$A$为原点，并将$A$化为质点</li>\n<li><strong>转为速度坐标</strong>：假设$B$静止，那么当$v_A * \\tau$达到红色弧线时，$A$与$B$会发生碰撞，所以VO内，速度上限为$\\frac{p_{弧线上的点}}{\\tau}$，得到绿色弧线。</li>\n<li>至此得到$VO^{\\tau}_{A|B}$，即绿色弧线与两射线组成的类扇形</li>\n</ol>\n</li>\n<li>如下图(c)，<strong>考虑$B$取的速度集合$V_B$</strong>，对假设$B$静止得到的$VO^{\\tau}_{A|B}$求闵氏和，得$CA^{\\tau}_{A|B}(V_B)$</li>\n</ol>\n<div style=\"width:800px; margin-left:auto; margin-right:auto;\" ><br>  <img src=\"/2017/01/14/paper-orca/time_interval.png\" alt=\"时间窗口\" title=\"时间窗口\"><br></div>\n\n<p>下面给出各变量规范的数学定义：</p>\n<ul>\n<li><p>$D({\\bf{p}},r)$：以$p$为圆心$r$为半径的圆<br>$$D({\\bf{p}},r)=\\{  {\\bf{q}}  |  \\| {\\bf{q}} - {\\bf{p}} \\| &lt; r  \\}$$</p>\n</li>\n<li><p>$VO^{\\tau}_{A|B}$：绿色弧线和两条射线组成的类扇形<br>$$VO^{\\tau}_{A|B} = \\{  {\\bf{v}}  |  \\exists t \\in [0, \\tau], t {\\bf{v}} \\in D({\\bf{p_B}} -{\\bf{p_A}}, r_A+r_B)   \\}$$</p>\n</li>\n<li><p>$CA^{\\tau}_{A|B}(V_B)$：考虑$B$取速度集合$V_B$<br>$$CA^{\\tau}_{A|B}(V_B)=\\{  {\\bf{v}}  |  {\\bf{v}} \\notin VO^{\\tau}_{A|B} \\oplus V_B  \\}，　其中\\oplus为闵氏和$$</p>\n</li>\n</ul>\n<p>至此，成功在VO的基础上引入了时间窗口，避障的时候不仅考虑<strong>速度方向</strong>，还考虑<strong>速度大小</strong>。</p>\n<p>p.s. 关于VO，闵氏和等内容可以参考上一篇文章<a href=\"/2017/01/13/paper-rvo/\" title=\"论文笔记《Reciprocal Velocity Obstacles for Real-Time Multi-Agent Navigation》\">论文笔记《Reciprocal Velocity Obstacles for Real-Time Multi-Agent Navigation》</a></p>\n<h2 id=\"ORCA定义\"><a href=\"#ORCA定义\" class=\"headerlink\" title=\"ORCA定义\"></a>ORCA定义</h2><p>ORCA全称为Optimal Reciprocal Collision Avoidance，含义就是在上述的$CA^{\\tau}_{A|B}(V_B)$中选择最优的一个。</p>\n<p>论文对最优的定义大概可以理解为<strong>在$v^{opt}$附近的合法值越多越好</strong>，即为满足下列条件的$V_A$与$V_B$对：</p>\n<ul>\n<li><strong>Reciprocally collision avoiding</strong>：很好理解，在对方的$CA$内即可，即<br>$$V_A \\subseteq CA^{\\tau}_{A|B}(V_B) \\land V_B \\subseteq CA^{\\tau}_{B|A}(V_A)$$</li>\n<li><strong>Reciprocally maximal</strong>：两个速度集是最大的不碰撞速度集，$V_A$或$V_B$都没有更多的避撞速度可选<br>$$V_A = CA^{\\tau}_{A|B}(V_B) \\land V_B = CA^{\\tau}_{B|A}(V_A)$$</li>\n<li><strong>包含最多$v^{opt}$附近的避撞速度</strong>：$v^{opt}$是一个预设值，可以理解为偏好值，论文中的最优希望：<ul>\n<li>$v^{opt}$附近的值越多越好</li>\n</ul>\n</li>\n<li><strong>双方在各自$v^{opt}$附近的避撞速度数量一样</strong>：$A$和$B$各自有$v^{opt}_A$和$v^{opt}_B$，论文中的最优希望：<ul>\n<li>$A$求出来在$v^{opt}_A$附近的避撞速度的数量$n_A$</li>\n<li>$B$求出来在$v^{opt}_B$附近的避撞速度的数量$n_B$</li>\n<li>$n_A = n_B$</li>\n</ul>\n</li>\n</ul>\n<p>那么用数学语言来描述上面几条性质就是：<br>$$| ORCA^{\\tau}_{A|B} \\cap D({\\bf{v^{opt}_A}}, r) | = | ORCA^{\\tau}_{B|A} \\cap D({\\bf{v^{opt}_B}}, r) | \\ge min(|V_A \\cap D({\\bf{v^{opt}_A}}, r)|, |V_B \\cap D({\\bf{v^{opt}_B}}, r)|)$$</p>\n<p>其中</p>\n<ul>\n<li>$ORCA^{\\tau}_{A|B}$与$ORCA^{\\tau}_{B|A}$：表示要求的最优速度集对，且满足reciprocally maximal，即<br>$$ORCA^{\\tau}_{A|B} = CA^{\\tau}_{A|B}(ORCA^{\\tau}_{B|A}) \\land ORCA^{\\tau}_{B|A} = CA^{\\tau}_{B|A}(ORCA^{\\tau}_{A|B})$$</li>\n<li>$V_A$与$V_B$：表示任意reciprocally collision avoiding的速度集对，即<br>$$V_A \\subseteq CA^{\\tau}_{A|B}(V_B) \\land V_B \\subseteq CA^{\\tau}_{B|A}(V_A)$$</li>\n<li>$r$：表示了“附近”的大小</li>\n<li>$D({\\bf{v^{opt}}},r)$：表示$v^{opt}$附近的速度</li>\n</ul>\n<h2 id=\"ORCA求解\"><a href=\"#ORCA求解\" class=\"headerlink\" title=\"ORCA求解\"></a>ORCA求解</h2><p>论文采用构造法求解出满足上述性质的ORCA，下面先说怎么做，再说为什么这样做就能满足性质。</p>\n<p>下面从$A$的角度介绍构造过程（图示如下），这里假设$A$知道$\\bf{v^{opt}_B}$</p>\n<ol>\n<li>求解<strong>相对速度</strong>${\\bf{v^{opt}_A}}-{\\bf{v^{opt}_B}}$</li>\n<li>求解$VO^{\\tau}_{A|B}$<strong>边界上</strong>离相对速度${\\bf{v^{opt}_A}}-{\\bf{v^{opt}_B}}$<strong>最近的点</strong>$\\bf{x}$</li>\n<li>求解从相对速度${\\bf{v^{opt}_A}}-{\\bf{v^{opt}_B}}$指向$\\bf{x}$的向量$\\bf{u}$</li>\n<li>求解与${\\bf{v^{opt}_A}} + \\frac{1}{2}{\\bf{u}}$垂直的直线，将空间分为两个平面</li>\n<li>直线${\\bf{v^{opt}_A}} + \\frac{1}{2}{\\bf{u}}$指向的平面即为所求$ORCA^{\\tau}_{A|B}$</li>\n</ol>\n<div style=\"width:600px; margin-left:auto; margin-right:auto;\" ><br>  <img src=\"/2017/01/14/paper-orca/orca_sol.png\" alt=\"ORCA求解\" title=\"ORCA求解\"><br></div>\n\n<p>下面逐条解释为什么符合性质：</p>\n<ul>\n<li><strong>Reciprocally collision avoiding</strong>：<ul>\n<li>由构造过程可知${\\bf{v^{opt}_A}}-{\\bf{v^{opt}_B}}+{\\bf{u}}$不在$VO^{\\tau}_{A|B}$内</li>\n<li>$A$取新速度${\\bf{v^{opt}_A}} + \\frac{1}{2}{\\bf{u}}$</li>\n<li>$B$取新速度${\\bf{v^{opt}_B}} - \\frac{1}{2}{\\bf{u}}$</li>\n<li>此时，相对速度为${\\bf{v^{opt}_A}} + \\frac{1}{2}{\\bf{u}} - ({\\bf{v^{opt}_B}} - \\frac{1}{2}{\\bf{u}}) = {\\bf{v^{opt}_A}}-{\\bf{v^{opt}_B}}+{\\bf{u}}$，所以不在$VO^{\\tau}_{A|B}$内</li>\n</ul>\n</li>\n<li><strong>Reciprocally maximal</strong>：<ul>\n<li>要证$ORCA^{\\tau}_{A|B} = CA^{\\tau}_{A|B}(ORCA^{\\tau}_{B|A})$</li>\n<li>先求$CA^{\\tau}_{A|B}(ORCA^{\\tau}_{B|A})$：<ul>\n<li>回忆之前引入时间窗口$\\tau$部分，构造$CA^{\\tau}_{A|B}(ORCA^{\\tau}_{B|A})$分两步<ol>\n<li>先将类扇形往${\\bf{v^{opt}_B}}-\\frac{1}{2}{\\bf{u}}$移动</li>\n<li>沿直线$ORCA^{\\tau}_{B|A}$方向扫</li>\n</ol>\n</li>\n<li>先将类扇形往$\\bf{v^{opt}_B}$方向平移（此时，类扇形中的${\\bf{v^{opt}_A}}-{\\bf{v^{opt}_B}}$到了$\\bf{v^{opt}_A}$，且$\\bf{x}$与$\\bf{v^{opt}_A}$的中点在直线$ORCA^{\\tau}_{A|B}$上）</li>\n<li>别忘了还要将类扇形往$-{\\frac{1}{2}\\bf{u}}$方向移动（此时，$\\bf{x}$刚好位于直线$ORCA^{\\tau}_{A|B}$上）</li>\n<li>最后再沿直线$ORCA^{\\tau}_{B|A}$方向扫，得$CA^{\\tau}_{A|B}(ORCA^{\\tau}_{B|A})$</li>\n</ul>\n</li>\n<li>而显然$CA^{\\tau}_{A|B}(ORCA^{\\tau}_{B|A})$正是$ORCA^{\\tau}_{A|B}$</li>\n</ul>\n</li>\n<li><strong>包含最多$v^{opt}$附近的避撞速度</strong>：<ul>\n<li>选择了最近的$\\bf{x}$进行“突围”，那“舍弃”的速度应该是最少的</li>\n<li>p.s. 这一点的证明不太严谨，有更好的证明欢迎留言探讨</li>\n</ul>\n</li>\n<li><strong>双方在各自$v^{opt}$附近的避撞速度数量一样</strong>：<ul>\n<li>$\\bf{v^{opt}_A}$到$ORCA^{\\tau}_{A|B}$的距离等于$\\bf{v^{opt}_B}$到$ORCA^{\\tau}_{B|A}$的距离</li>\n<li>定义“附近”用的是圆</li>\n</ul>\n</li>\n</ul>\n<p>最后给出ORCA的数学定义</p>\n<p>$$ORCA^{\\tau}_{A|B} = \\{  {\\bf{v}}  |  ({\\bf{v}} - ({\\bf{v^{opt}_A}} + \\frac{1}{2}{\\bf{u}})) \\cdot {\\bf{n}} \\ge 0   \\}$$</p>\n<p>其中</p>\n<ul>\n<li>${\\bf{u}}$是最小偏移<br>$${\\bf{u}} = (\\mathop{argmin}_{ {\\bf{v}} \\in \\partial VO^{\\tau}_{A|B}}{\\| {\\bf{v}} - ( {\\bf{v^{opt}_A}} - {\\bf{v^{opt}_B}} )  \\|}) - ({\\bf{v^{opt}_A}} - {\\bf{v^{opt}_B}})$$</li>\n<li>${\\bf{n}}$是跟${\\bf{u}}$同向的法向量</li>\n<li>用${\\bf{v}} \\cdot {\\bf{n}} \\ge 0$来表示一个平面</li>\n</ul>\n<h2 id=\"ORCA基本用法\"><a href=\"#ORCA基本用法\" class=\"headerlink\" title=\"ORCA基本用法\"></a>ORCA基本用法</h2><ol>\n<li>对其他所有agents的$ORCA$求交（线性规划），再与自己可选速度求交集，得候选速度集$ORCA^{\\tau}_{A}$<br>$$ORCA^{\\tau}_{A}=D({\\bf{0}}, {\\bf{v^{max}_A}}) \\cap \\mathop{\\bigcap}_{B \\ne A}{ORCA^{\\tau}_{A|B}}$$</li>\n<li>在候选集中求解跟自己偏好速度最近的一个速度${\\bf{v^{new}_A}}$<br>$${\\bf{v^{new}_A}} = \\mathop{argmin}_{ {\\bf{v}} \\in ORCA^{\\tau}_A}{\\| {\\bf{v}} - {\\bf{v^{opt}_A}} \\|}$$</li>\n</ol>\n<div style=\"width:600px; margin-left:auto; margin-right:auto;\" ><br>  <img src=\"/2017/01/14/paper-orca/orca_app.png\" alt=\"ORCA基本用法\" title=\"ORCA基本用法\"><br></div>\n\n<p>可见ORCA的求解，就是在$ORCA^{\\tau}_{A}$内，优化目标函数$\\| {\\bf{v}} - {\\bf{v^{opt}_A}} \\|$，所以计算效率很高。</p>\n<h2 id=\"关于-bf-v-opt-的选择\"><a href=\"#关于-bf-v-opt-的选择\" class=\"headerlink\" title=\"关于${\\bf{v^{opt}}}$的选择\"></a>关于${\\bf{v^{opt}}}$的选择</h2><p>为方便阐述，假设${\\bf{v_A}} = {\\bf{0}}$，这样$ORCA^{\\tau}_{A|B}$就只是从原点移$\\frac{1}{2}{\\bf{u}}$</p>\n<p>讨论${\\bf{v^{opt}}}$的选择跟$ORCA^{\\tau}_{A}$的关系</p>\n<ul>\n<li>${\\bf{0}}$<ul>\n<li>一定有解，如下图(c)。很好理解，这相当于假设了别人都静止，那只要自己也静止，必然有解。</li>\n<li>密集情况下容易死锁，因为这样相当于只考虑位置信息，而不考虑速度信息</li>\n</ul>\n</li>\n<li>${\\bf{v^{pref}}}$<ul>\n<li>密集情况下容易无解，如下图(b)。因为一般来说${\\bf{v^{pref}}}$都比较大</li>\n<li>而且实际上也不可能观察得到别人的${\\bf{v^{pref}}}$</li>\n</ul>\n</li>\n<li>${\\bf{v_{curr}}}$<ul>\n<li>两者的折中</li>\n</ul>\n</li>\n</ul>\n<div style=\"width:800px; margin-left:auto; margin-right:auto;\" ><br>  <img src=\"/2017/01/14/paper-orca/opt.png\" alt=\"opt选择\" title=\"opt选择\"><br></div>\n\n<h2 id=\"无解情况的处理\"><a href=\"#无解情况的处理\" class=\"headerlink\" title=\"无解情况的处理\"></a>无解情况的处理</h2><p>基本思路跟线性代数里面的投影差不多：选择离合法速度最近的速度</p>\n<p>$$ {\\bf{v^{new}_{A}}} = \\mathop{argmin}_{ {\\bf{v}} \\in D({\\bf{0}}, {\\bf{v^{max}_A}})} {\\mathop{max}_{B \\ne A}{ d_{A|B}({\\bf{v}})}} $$</p>\n<p>下面慢慢拆分来看</p>\n<ol>\n<li>$d_{A|B}({\\bf{v}})$：表示${\\bf{v}}$的“违规”程度。定义为${\\bf{v}}$到ORCA分割线的有向距离，${\\bf{v}}$在ORCA外则取正</li>\n<li>${\\mathop{max}_{B \\ne A}{ d_{A|B}({\\bf{v}})}}$：对每个速度${\\bf{v}}$，取“违规”最多的值作为它的“违规程度”</li>\n<li>$\\mathop{argmin}_{ {\\bf{v}} \\in D({\\bf{0}}, {\\bf{v^{max}_A}})} {\\mathop{max}_{B \\ne A}{ d_{A|B}({\\bf{v}})}}$：在可行速度内，求”违规程度”最小的速度</li>\n</ol>\n<h2 id=\"收获\"><a href=\"#收获\" class=\"headerlink\" title=\"收获\"></a>收获</h2><ul>\n<li>改进可以从以下角度考虑：<ul>\n<li><strong>效果</strong>：只考虑了方向，没有考虑速度</li>\n<li><strong>效率</strong>：计算复杂度</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"References\"><a href=\"#References\" class=\"headerlink\" title=\"References\"></a>References</h2><ul>\n<li><a href=\"http://gamma.cs.unc.edu/ORCA/publications/ORCA.pdf\">Reciprocal n-body Collision Avoidance</a></li>\n</ul>\n"},{"title":"论文笔记《Prioritized Experience Replay》","date":"2018-03-18T03:46:52.000Z","description":["优化experience replay的一种方法"],"_content":"\n## motivation\n\nexperience replay是DQN的一个关键技术，它通过存取transition的操作**打破了数据之间的相关性**，使得数据**满足优化方法（e.g., SGD）的假设（i.e., i.i.d.）**，从而提高了学习的效果。\n\nnaive的experience replay在取transition时采用的策略是均匀采样，对所有transition一视同仁。但直觉上来说，**各个transition的重要性应该是不同的**，有的transition的“信息量”比较大，有的transition则没什么用。\n\n我们拿一个具体的例子来说明均匀采样有什么问题，假设我们有一个如下图所示的environment，它有$n$个状态，$2$个动作，初始状态为$1$，状态转移如箭头所示，当且仅当沿绿色箭头走的时候会有$1$的reward，其余情况的reward均为$0$。那么假如采用随机策略从初始状态开始走$n$步，我们能够获得有用的信息（reward非$0$）的可能性为$1/2^n$。也就是说，假如我们把各transition都存了起来，然后采用均匀采样来取transition，我们仅有$1/2^n$的概率取到有用的信息，这样的话学习效率就会很低。\n\n<div style=\"width:800px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img env.png environment %}\n</div>\n\n作者还做了个实验，来说明transition的选取顺序对学习效率有很大的影响。下图横轴代表experience replay的大小，纵轴表示学习所需的更新次数。黑色的线表示采用均匀采样得到的结果，绿色的线表示每次都选取”最好“的transition的结果。可以看到，这个效率提升是很明显的。\n\n<div style=\"width:800px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img fig.png transition选取顺序对学习效率的影响 %}\n</div>\n\n于是很自然的就会有一个想法，能不能通过**优先学习那些“信息量”比较大的transition**来提高学习效率呢？\n\n## idea\n\n- 首先需要给出一个**衡量“信息量”大小的指标**，文中用的是TD-error。\n- 有了一个评价指标之后，最直接的想法是贪心地选”信息量“最大的transition。但这种**贪心的方法有以下问题**：\n\t+ 贪心的依据不准确：由于考虑到算法效率，我们不会每次critic更新后都更新所有transition的TD-error，我们只会更新当次取到的transition的TD-error。因此**transition的TD-error对应的critic是以前的critic**（更准确地说，是上次取到该transition时的critic）而不是当前的critic。也就是说某一个transition的TD-error较低，只能够说明它对之前的critic“信息量”不大，而不能说明它对当前的critic“信息量”不大，因此根据TD-error进行贪心有可能会错过对当前critic“信息量”大的transition。\n\t+ **容易overfitting**：基于贪心的做法还容易**“旱的旱死，涝的涝死”**（这应该是一个empirical result，因为从原理上来说，被选中的transition的TD-error在critic更新后会下降，然后排到后面去，下一次就不会选中这些transition），来来去去都是那几个transition，导致overfitting。\n\t+ 为了处理上述问题，作者提出stochastic prioritization，随机化的采样过程，“信息量”越大，被抽中的概率越大，但即使是“信息量”最大的transition，也不一定会被抽中，仅仅只是被抽中的概率较大。\n- **改变采样顺序会改变样本分布**，假设原来的样本$x$服从分布$A$，在改变采样顺序后，$x$服从的分布为$B$，我们要求的是$\\mathbb{E}_{x \\sim A}[f(x)]$，而我们现在只有$\\mathbb{E}_{x \\sim B}[ \\bullet ]$。因此我们需要基于分布$B$的期望来计算在分布$A$下的期望，这就是importance sampling的作用。\n\n## detail\n\n- 两种stochastic prioritization方案\n\t+ 两种方案都基于以下概率模型（softmax）：\n\t$$\n\tP(i) = \\frac{p_i^\\alpha}{\\sum_k p_k^\\alpha},\n\t$$其中$p_i$为第$i$个transition的priority，$\\alpha$用于调节优先程度（$\\alpha = 0$的时候退化为均匀采样）。而两种方案的**区别在于对priority的定义不同**。\n\t- proportional prioritization\n\t\t+ $p_i = \\vert \\delta_i \\vert + \\epsilon$，其中$\\delta_i$为TD-erroe，$\\epsilon$用于防止概率为$0$。\n\t\t+ 可能会**对outlier更加敏感**。\n\t\t+ 实现的时候采用sum tree的数据结构。\n\t- rank-based prioritization\n\t\t+ $p_i = 1/\\text{rank}(i)$。\n\t\t+ 只是**定性**地考虑priority，没有定量地考虑priority。\n\t\t+ 实现类似分层抽样，事先将排名段分为几个等概率区间，再在各个等概率区间里面均匀采样。比如说，假设experience replay大小为100，batch size为3，那么就事先通过计算，将100分为3个等概率区间（e.g., A:1-20，B:21-50, C:51-100），之后就在A、B和C区间内分别做均匀采样，最后取得3个transition。\n- importance sampling\n\t+ 核心公式为：\n\t$$\\mathbb{E}_{x \\sim A}[f(x)] = \\sum_x P_A(x)f(x) = \\sum_x P_B(x) \\frac{P_A(x)}{P_B(x)}f(x) = \\mathbb{E}_{x \\sim B}[\\frac{P_A(x)}{P_B(x)}f(x)].$$\n\t+ 将具体的$P_A(x)=1/N$与$P_B(x)=P(i)$代入后，就得到所谓的importance-sampling weight\n\t$$\n\tw_i = (\\frac{1}{N} \\cdot \\frac{1}{P(i)})^\\beta,\n\t$$其中，$\\beta$用于调节bias程度（作者argue说学习的初始阶段有bias也没所谓，但在后期就要消除bias）。\n\t+ 作者还说这个importance sampling要除以$\\text{max}_i w_i$（这个$i$应该是指minibatch，如果是指experience replay的话，那在采取proportional prioritization的时候开销就太大了），以此保证update一定是scale downward的（感觉是为了控制step size）。\n\n## more\n\n- 针对具体问题，**某种stochastic prioritization方案会表现得比另外一种更好**。\n- 类似的priority思想可以**用到supervised learning中**。\n- 某个transition被访问的次数反映了这个transition的“重要性”，可以**作为一个feedback signal给到exploration**。\n- 可以通过这种方法**减小experience replay的大小**，从而减少训练所需的内存。\n","source":"_posts/paper-prioritized-experience-replay.md","raw":"---\ntitle: 论文笔记《Prioritized Experience Replay》\ndate: 2018-03-18 11:46:52\ntags:\n\t- Prioritized Experience Replay\ncategories:\n\t- 论文笔记\ndescription:\n\t- 优化experience replay的一种方法\n---\n\n## motivation\n\nexperience replay是DQN的一个关键技术，它通过存取transition的操作**打破了数据之间的相关性**，使得数据**满足优化方法（e.g., SGD）的假设（i.e., i.i.d.）**，从而提高了学习的效果。\n\nnaive的experience replay在取transition时采用的策略是均匀采样，对所有transition一视同仁。但直觉上来说，**各个transition的重要性应该是不同的**，有的transition的“信息量”比较大，有的transition则没什么用。\n\n我们拿一个具体的例子来说明均匀采样有什么问题，假设我们有一个如下图所示的environment，它有$n$个状态，$2$个动作，初始状态为$1$，状态转移如箭头所示，当且仅当沿绿色箭头走的时候会有$1$的reward，其余情况的reward均为$0$。那么假如采用随机策略从初始状态开始走$n$步，我们能够获得有用的信息（reward非$0$）的可能性为$1/2^n$。也就是说，假如我们把各transition都存了起来，然后采用均匀采样来取transition，我们仅有$1/2^n$的概率取到有用的信息，这样的话学习效率就会很低。\n\n<div style=\"width:800px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img env.png environment %}\n</div>\n\n作者还做了个实验，来说明transition的选取顺序对学习效率有很大的影响。下图横轴代表experience replay的大小，纵轴表示学习所需的更新次数。黑色的线表示采用均匀采样得到的结果，绿色的线表示每次都选取”最好“的transition的结果。可以看到，这个效率提升是很明显的。\n\n<div style=\"width:800px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img fig.png transition选取顺序对学习效率的影响 %}\n</div>\n\n于是很自然的就会有一个想法，能不能通过**优先学习那些“信息量”比较大的transition**来提高学习效率呢？\n\n## idea\n\n- 首先需要给出一个**衡量“信息量”大小的指标**，文中用的是TD-error。\n- 有了一个评价指标之后，最直接的想法是贪心地选”信息量“最大的transition。但这种**贪心的方法有以下问题**：\n\t+ 贪心的依据不准确：由于考虑到算法效率，我们不会每次critic更新后都更新所有transition的TD-error，我们只会更新当次取到的transition的TD-error。因此**transition的TD-error对应的critic是以前的critic**（更准确地说，是上次取到该transition时的critic）而不是当前的critic。也就是说某一个transition的TD-error较低，只能够说明它对之前的critic“信息量”不大，而不能说明它对当前的critic“信息量”不大，因此根据TD-error进行贪心有可能会错过对当前critic“信息量”大的transition。\n\t+ **容易overfitting**：基于贪心的做法还容易**“旱的旱死，涝的涝死”**（这应该是一个empirical result，因为从原理上来说，被选中的transition的TD-error在critic更新后会下降，然后排到后面去，下一次就不会选中这些transition），来来去去都是那几个transition，导致overfitting。\n\t+ 为了处理上述问题，作者提出stochastic prioritization，随机化的采样过程，“信息量”越大，被抽中的概率越大，但即使是“信息量”最大的transition，也不一定会被抽中，仅仅只是被抽中的概率较大。\n- **改变采样顺序会改变样本分布**，假设原来的样本$x$服从分布$A$，在改变采样顺序后，$x$服从的分布为$B$，我们要求的是$\\mathbb{E}_{x \\sim A}[f(x)]$，而我们现在只有$\\mathbb{E}_{x \\sim B}[ \\bullet ]$。因此我们需要基于分布$B$的期望来计算在分布$A$下的期望，这就是importance sampling的作用。\n\n## detail\n\n- 两种stochastic prioritization方案\n\t+ 两种方案都基于以下概率模型（softmax）：\n\t$$\n\tP(i) = \\frac{p_i^\\alpha}{\\sum_k p_k^\\alpha},\n\t$$其中$p_i$为第$i$个transition的priority，$\\alpha$用于调节优先程度（$\\alpha = 0$的时候退化为均匀采样）。而两种方案的**区别在于对priority的定义不同**。\n\t- proportional prioritization\n\t\t+ $p_i = \\vert \\delta_i \\vert + \\epsilon$，其中$\\delta_i$为TD-erroe，$\\epsilon$用于防止概率为$0$。\n\t\t+ 可能会**对outlier更加敏感**。\n\t\t+ 实现的时候采用sum tree的数据结构。\n\t- rank-based prioritization\n\t\t+ $p_i = 1/\\text{rank}(i)$。\n\t\t+ 只是**定性**地考虑priority，没有定量地考虑priority。\n\t\t+ 实现类似分层抽样，事先将排名段分为几个等概率区间，再在各个等概率区间里面均匀采样。比如说，假设experience replay大小为100，batch size为3，那么就事先通过计算，将100分为3个等概率区间（e.g., A:1-20，B:21-50, C:51-100），之后就在A、B和C区间内分别做均匀采样，最后取得3个transition。\n- importance sampling\n\t+ 核心公式为：\n\t$$\\mathbb{E}_{x \\sim A}[f(x)] = \\sum_x P_A(x)f(x) = \\sum_x P_B(x) \\frac{P_A(x)}{P_B(x)}f(x) = \\mathbb{E}_{x \\sim B}[\\frac{P_A(x)}{P_B(x)}f(x)].$$\n\t+ 将具体的$P_A(x)=1/N$与$P_B(x)=P(i)$代入后，就得到所谓的importance-sampling weight\n\t$$\n\tw_i = (\\frac{1}{N} \\cdot \\frac{1}{P(i)})^\\beta,\n\t$$其中，$\\beta$用于调节bias程度（作者argue说学习的初始阶段有bias也没所谓，但在后期就要消除bias）。\n\t+ 作者还说这个importance sampling要除以$\\text{max}_i w_i$（这个$i$应该是指minibatch，如果是指experience replay的话，那在采取proportional prioritization的时候开销就太大了），以此保证update一定是scale downward的（感觉是为了控制step size）。\n\n## more\n\n- 针对具体问题，**某种stochastic prioritization方案会表现得比另外一种更好**。\n- 类似的priority思想可以**用到supervised learning中**。\n- 某个transition被访问的次数反映了这个transition的“重要性”，可以**作为一个feedback signal给到exploration**。\n- 可以通过这种方法**减小experience replay的大小**，从而减少训练所需的内存。\n","slug":"paper-prioritized-experience-replay","published":1,"updated":"2024-08-13T16:03:47.864Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clzvf1929001aeqwoerh2iq55","content":"<h2 id=\"motivation\"><a href=\"#motivation\" class=\"headerlink\" title=\"motivation\"></a>motivation</h2><p>experience replay是DQN的一个关键技术，它通过存取transition的操作<strong>打破了数据之间的相关性</strong>，使得数据<strong>满足优化方法（e.g., SGD）的假设（i.e., i.i.d.）</strong>，从而提高了学习的效果。</p>\n<p>naive的experience replay在取transition时采用的策略是均匀采样，对所有transition一视同仁。但直觉上来说，<strong>各个transition的重要性应该是不同的</strong>，有的transition的“信息量”比较大，有的transition则没什么用。</p>\n<p>我们拿一个具体的例子来说明均匀采样有什么问题，假设我们有一个如下图所示的environment，它有$n$个状态，$2$个动作，初始状态为$1$，状态转移如箭头所示，当且仅当沿绿色箭头走的时候会有$1$的reward，其余情况的reward均为$0$。那么假如采用随机策略从初始状态开始走$n$步，我们能够获得有用的信息（reward非$0$）的可能性为$1/2^n$。也就是说，假如我们把各transition都存了起来，然后采用均匀采样来取transition，我们仅有$1/2^n$的概率取到有用的信息，这样的话学习效率就会很低。</p>\n<div style=\"width:800px; margin-left:auto; margin-right:auto;\"><br>  <img src=\"/2018/03/18/paper-prioritized-experience-replay/env.png\" alt=\"environment\" title=\"environment\"><br></div>\n\n<p>作者还做了个实验，来说明transition的选取顺序对学习效率有很大的影响。下图横轴代表experience replay的大小，纵轴表示学习所需的更新次数。黑色的线表示采用均匀采样得到的结果，绿色的线表示每次都选取”最好“的transition的结果。可以看到，这个效率提升是很明显的。</p>\n<div style=\"width:800px; margin-left:auto; margin-right:auto;\"><br>  <img src=\"/2018/03/18/paper-prioritized-experience-replay/fig.png\" alt=\"transition选取顺序对学习效率的影响\" title=\"transition选取顺序对学习效率的影响\"><br></div>\n\n<p>于是很自然的就会有一个想法，能不能通过<strong>优先学习那些“信息量”比较大的transition</strong>来提高学习效率呢？</p>\n<h2 id=\"idea\"><a href=\"#idea\" class=\"headerlink\" title=\"idea\"></a>idea</h2><ul>\n<li>首先需要给出一个<strong>衡量“信息量”大小的指标</strong>，文中用的是TD-error。</li>\n<li>有了一个评价指标之后，最直接的想法是贪心地选”信息量“最大的transition。但这种<strong>贪心的方法有以下问题</strong>：<ul>\n<li>贪心的依据不准确：由于考虑到算法效率，我们不会每次critic更新后都更新所有transition的TD-error，我们只会更新当次取到的transition的TD-error。因此<strong>transition的TD-error对应的critic是以前的critic</strong>（更准确地说，是上次取到该transition时的critic）而不是当前的critic。也就是说某一个transition的TD-error较低，只能够说明它对之前的critic“信息量”不大，而不能说明它对当前的critic“信息量”不大，因此根据TD-error进行贪心有可能会错过对当前critic“信息量”大的transition。</li>\n<li><strong>容易overfitting</strong>：基于贪心的做法还容易<strong>“旱的旱死，涝的涝死”</strong>（这应该是一个empirical result，因为从原理上来说，被选中的transition的TD-error在critic更新后会下降，然后排到后面去，下一次就不会选中这些transition），来来去去都是那几个transition，导致overfitting。</li>\n<li>为了处理上述问题，作者提出stochastic prioritization，随机化的采样过程，“信息量”越大，被抽中的概率越大，但即使是“信息量”最大的transition，也不一定会被抽中，仅仅只是被抽中的概率较大。</li>\n</ul>\n</li>\n<li><strong>改变采样顺序会改变样本分布</strong>，假设原来的样本$x$服从分布$A$，在改变采样顺序后，$x$服从的分布为$B$，我们要求的是$\\mathbb{E}_{x \\sim A}[f(x)]$，而我们现在只有$\\mathbb{E}_{x \\sim B}[ \\bullet ]$。因此我们需要基于分布$B$的期望来计算在分布$A$下的期望，这就是importance sampling的作用。</li>\n</ul>\n<h2 id=\"detail\"><a href=\"#detail\" class=\"headerlink\" title=\"detail\"></a>detail</h2><ul>\n<li>两种stochastic prioritization方案<ul>\n<li>两种方案都基于以下概率模型（softmax）：<br>$$<br>P(i) = \\frac{p_i^\\alpha}{\\sum_k p_k^\\alpha},<br>$$其中$p_i$为第$i$个transition的priority，$\\alpha$用于调节优先程度（$\\alpha = 0$的时候退化为均匀采样）。而两种方案的<strong>区别在于对priority的定义不同</strong>。</li>\n</ul>\n<ul>\n<li>proportional prioritization<ul>\n<li>$p_i = \\vert \\delta_i \\vert + \\epsilon$，其中$\\delta_i$为TD-erroe，$\\epsilon$用于防止概率为$0$。</li>\n<li>可能会<strong>对outlier更加敏感</strong>。</li>\n<li>实现的时候采用sum tree的数据结构。</li>\n</ul>\n</li>\n<li>rank-based prioritization<ul>\n<li>$p_i = 1/\\text{rank}(i)$。</li>\n<li>只是<strong>定性</strong>地考虑priority，没有定量地考虑priority。</li>\n<li>实现类似分层抽样，事先将排名段分为几个等概率区间，再在各个等概率区间里面均匀采样。比如说，假设experience replay大小为100，batch size为3，那么就事先通过计算，将100分为3个等概率区间（e.g., A:1-20，B:21-50, C:51-100），之后就在A、B和C区间内分别做均匀采样，最后取得3个transition。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>importance sampling<ul>\n<li>核心公式为：<br>$$\\mathbb{E}_{x \\sim A}[f(x)] = \\sum_x P_A(x)f(x) = \\sum_x P_B(x) \\frac{P_A(x)}{P_B(x)}f(x) = \\mathbb{E}_{x \\sim B}[\\frac{P_A(x)}{P_B(x)}f(x)].$$</li>\n<li>将具体的$P_A(x)=1/N$与$P_B(x)=P(i)$代入后，就得到所谓的importance-sampling weight<br>$$<br>w_i = (\\frac{1}{N} \\cdot \\frac{1}{P(i)})^\\beta,<br>$$其中，$\\beta$用于调节bias程度（作者argue说学习的初始阶段有bias也没所谓，但在后期就要消除bias）。</li>\n<li>作者还说这个importance sampling要除以$\\text{max}_i w_i$（这个$i$应该是指minibatch，如果是指experience replay的话，那在采取proportional prioritization的时候开销就太大了），以此保证update一定是scale downward的（感觉是为了控制step size）。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"more\"><a href=\"#more\" class=\"headerlink\" title=\"more\"></a>more</h2><ul>\n<li>针对具体问题，<strong>某种stochastic prioritization方案会表现得比另外一种更好</strong>。</li>\n<li>类似的priority思想可以<strong>用到supervised learning中</strong>。</li>\n<li>某个transition被访问的次数反映了这个transition的“重要性”，可以<strong>作为一个feedback signal给到exploration</strong>。</li>\n<li>可以通过这种方法<strong>减小experience replay的大小</strong>，从而减少训练所需的内存。</li>\n</ul>\n","excerpt":"","more":"<h2 id=\"motivation\"><a href=\"#motivation\" class=\"headerlink\" title=\"motivation\"></a>motivation</h2><p>experience replay是DQN的一个关键技术，它通过存取transition的操作<strong>打破了数据之间的相关性</strong>，使得数据<strong>满足优化方法（e.g., SGD）的假设（i.e., i.i.d.）</strong>，从而提高了学习的效果。</p>\n<p>naive的experience replay在取transition时采用的策略是均匀采样，对所有transition一视同仁。但直觉上来说，<strong>各个transition的重要性应该是不同的</strong>，有的transition的“信息量”比较大，有的transition则没什么用。</p>\n<p>我们拿一个具体的例子来说明均匀采样有什么问题，假设我们有一个如下图所示的environment，它有$n$个状态，$2$个动作，初始状态为$1$，状态转移如箭头所示，当且仅当沿绿色箭头走的时候会有$1$的reward，其余情况的reward均为$0$。那么假如采用随机策略从初始状态开始走$n$步，我们能够获得有用的信息（reward非$0$）的可能性为$1/2^n$。也就是说，假如我们把各transition都存了起来，然后采用均匀采样来取transition，我们仅有$1/2^n$的概率取到有用的信息，这样的话学习效率就会很低。</p>\n<div style=\"width:800px; margin-left:auto; margin-right:auto;\" ><br>  <img src=\"/2018/03/18/paper-prioritized-experience-replay/env.png\" alt=\"environment\" title=\"environment\"><br></div>\n\n<p>作者还做了个实验，来说明transition的选取顺序对学习效率有很大的影响。下图横轴代表experience replay的大小，纵轴表示学习所需的更新次数。黑色的线表示采用均匀采样得到的结果，绿色的线表示每次都选取”最好“的transition的结果。可以看到，这个效率提升是很明显的。</p>\n<div style=\"width:800px; margin-left:auto; margin-right:auto;\" ><br>  <img src=\"/2018/03/18/paper-prioritized-experience-replay/fig.png\" alt=\"transition选取顺序对学习效率的影响\" title=\"transition选取顺序对学习效率的影响\"><br></div>\n\n<p>于是很自然的就会有一个想法，能不能通过<strong>优先学习那些“信息量”比较大的transition</strong>来提高学习效率呢？</p>\n<h2 id=\"idea\"><a href=\"#idea\" class=\"headerlink\" title=\"idea\"></a>idea</h2><ul>\n<li>首先需要给出一个<strong>衡量“信息量”大小的指标</strong>，文中用的是TD-error。</li>\n<li>有了一个评价指标之后，最直接的想法是贪心地选”信息量“最大的transition。但这种<strong>贪心的方法有以下问题</strong>：<ul>\n<li>贪心的依据不准确：由于考虑到算法效率，我们不会每次critic更新后都更新所有transition的TD-error，我们只会更新当次取到的transition的TD-error。因此<strong>transition的TD-error对应的critic是以前的critic</strong>（更准确地说，是上次取到该transition时的critic）而不是当前的critic。也就是说某一个transition的TD-error较低，只能够说明它对之前的critic“信息量”不大，而不能说明它对当前的critic“信息量”不大，因此根据TD-error进行贪心有可能会错过对当前critic“信息量”大的transition。</li>\n<li><strong>容易overfitting</strong>：基于贪心的做法还容易<strong>“旱的旱死，涝的涝死”</strong>（这应该是一个empirical result，因为从原理上来说，被选中的transition的TD-error在critic更新后会下降，然后排到后面去，下一次就不会选中这些transition），来来去去都是那几个transition，导致overfitting。</li>\n<li>为了处理上述问题，作者提出stochastic prioritization，随机化的采样过程，“信息量”越大，被抽中的概率越大，但即使是“信息量”最大的transition，也不一定会被抽中，仅仅只是被抽中的概率较大。</li>\n</ul>\n</li>\n<li><strong>改变采样顺序会改变样本分布</strong>，假设原来的样本$x$服从分布$A$，在改变采样顺序后，$x$服从的分布为$B$，我们要求的是$\\mathbb{E}_{x \\sim A}[f(x)]$，而我们现在只有$\\mathbb{E}_{x \\sim B}[ \\bullet ]$。因此我们需要基于分布$B$的期望来计算在分布$A$下的期望，这就是importance sampling的作用。</li>\n</ul>\n<h2 id=\"detail\"><a href=\"#detail\" class=\"headerlink\" title=\"detail\"></a>detail</h2><ul>\n<li>两种stochastic prioritization方案<ul>\n<li>两种方案都基于以下概率模型（softmax）：<br>$$<br>P(i) = \\frac{p_i^\\alpha}{\\sum_k p_k^\\alpha},<br>$$其中$p_i$为第$i$个transition的priority，$\\alpha$用于调节优先程度（$\\alpha = 0$的时候退化为均匀采样）。而两种方案的<strong>区别在于对priority的定义不同</strong>。</li>\n</ul>\n<ul>\n<li>proportional prioritization<ul>\n<li>$p_i = \\vert \\delta_i \\vert + \\epsilon$，其中$\\delta_i$为TD-erroe，$\\epsilon$用于防止概率为$0$。</li>\n<li>可能会<strong>对outlier更加敏感</strong>。</li>\n<li>实现的时候采用sum tree的数据结构。</li>\n</ul>\n</li>\n<li>rank-based prioritization<ul>\n<li>$p_i = 1/\\text{rank}(i)$。</li>\n<li>只是<strong>定性</strong>地考虑priority，没有定量地考虑priority。</li>\n<li>实现类似分层抽样，事先将排名段分为几个等概率区间，再在各个等概率区间里面均匀采样。比如说，假设experience replay大小为100，batch size为3，那么就事先通过计算，将100分为3个等概率区间（e.g., A:1-20，B:21-50, C:51-100），之后就在A、B和C区间内分别做均匀采样，最后取得3个transition。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>importance sampling<ul>\n<li>核心公式为：<br>$$\\mathbb{E}_{x \\sim A}[f(x)] = \\sum_x P_A(x)f(x) = \\sum_x P_B(x) \\frac{P_A(x)}{P_B(x)}f(x) = \\mathbb{E}_{x \\sim B}[\\frac{P_A(x)}{P_B(x)}f(x)].$$</li>\n<li>将具体的$P_A(x)=1/N$与$P_B(x)=P(i)$代入后，就得到所谓的importance-sampling weight<br>$$<br>w_i = (\\frac{1}{N} \\cdot \\frac{1}{P(i)})^\\beta,<br>$$其中，$\\beta$用于调节bias程度（作者argue说学习的初始阶段有bias也没所谓，但在后期就要消除bias）。</li>\n<li>作者还说这个importance sampling要除以$\\text{max}_i w_i$（这个$i$应该是指minibatch，如果是指experience replay的话，那在采取proportional prioritization的时候开销就太大了），以此保证update一定是scale downward的（感觉是为了控制step size）。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"more\"><a href=\"#more\" class=\"headerlink\" title=\"more\"></a>more</h2><ul>\n<li>针对具体问题，<strong>某种stochastic prioritization方案会表现得比另外一种更好</strong>。</li>\n<li>类似的priority思想可以<strong>用到supervised learning中</strong>。</li>\n<li>某个transition被访问的次数反映了这个transition的“重要性”，可以<strong>作为一个feedback signal给到exploration</strong>。</li>\n<li>可以通过这种方法<strong>减小experience replay的大小</strong>，从而减少训练所需的内存。</li>\n</ul>\n"},{"title":"论文笔记《Reciprocal Velocity Obstacles for Real-Time Multi-Agent Navigation》","description":["经典的底层避障算法"],"date":"2017-01-13T13:08:51.000Z","_content":"\n\n\n## 简介\n\n在介绍VO，RVO之前，需要先介绍路径规划。\n\n对Agent进行路径规划，实际上要完成的**任务**就是让Agent从点A**无碰撞地**移动到点B。而路径规划的过程是层次化的，其基本框架大致如下：\n\n- **High level**: dijkstra等算法。\n- **Low level**: VO, RVO, ORCA等底层避障算法。\n\n很容易可以跟我们的日常生活进行类比，比如说我们要从学校的教学楼走到宿舍楼，那么以上框架对应的就是：\n\n- **High level**: 通过dijkstra算法，得到路径为: 教学楼→饭堂→体育馆→图书馆→宿舍楼。\n- **Low level**: 通过底层避障算法如VO，RVO，ORCA等底层避障算法，保证我们走的每一段路（e.g. 教学楼→饭堂），都不会跟别的同学发生碰撞。\n\nVO和RVO就是经典的底层避障算法。其中VO是最经典的，RVO则在VO的基础上进行了一些改进，解决了VO抖动的问题。\n\n## VO(Velocity Obstacle)\n\n**一句话总结**VO的思路：只要在未来有可能会发生碰撞的速度，都排除在外。\n\n为方便描述，以下都假设是在**平面**内，**圆形物体**之间的避障。\n\n## VO的直观理解\n\n<div style=\"width:400px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img prob_disc.png 问题描述 %}\n</div>\n\n> Q: 假设B静止，那么A取什么速度能够保证一定不会跟B发生碰撞呢？\n\n> A: 一种很粗暴的方法，就是**把A化作质点**，选择跟**$\\bar{B}$(扩展后的B)不相交**的速度方向。以后只要在每个周期里面，都选择不在VO的速度，就能够保证不会碰撞。\n\n<div style=\"width:400px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img prob_sol.png 解决办法 %}\n</div>\n\n以上就是VO的直观理解，需要注意的是：\n\n- VO是指速度方向与$\\bar{B}$相交的部分，即**会发生碰撞的部分（图中灰色斜线部分）**。\n- VO是抱着**宁杀错，不放过**的思想，把所有未来有可能会发生碰撞的速度都放弃了。\n- 实际上假如仅要求**一定时间内**不发生碰撞的话，有更多的速度可供选择，比如说上图中的($v\\_{A}^{\\prime}$)。\n\n## VO的图示理解\n\n有了直观理解之后就可以用更加严谨一点的数学语言图示VO了。\n\n首先将直观理解中口语化的表达转换成对应的数学语言表示。\n\n- **物体A(B)**：以$\\bf{p\\_{A}}$为圆心，$r\\_{A}$为半径的**点集$A$**\n- **假设B静止**：A相对于B的速度，即**相对速度$\\bf{v\\_{A}}-v\\_{B}$**\n- **把A化作质点**：求集合$B$与集合$-A$的Minkowski sum，即**闵氏和，$B\\oplus-A$**，其中\n\t+ $A \\oplus B = \\\\{    {\\bf{a}} + {\\bf{b}}\\ |\\ {\\bf{a}} \\in A, {\\bf{b}} \\in B \\\\} $\n\t+ $-A = \\\\{ -{\\bf{a}}\\ |\\ {\\bf{a}} \\in A \\\\}$\n\t+ [更多关于Minkowski sum](http://twistedoakstudios.com/blog/Post554\\_minkowski-sums-and-differences)\n\n于是就有了下图的左半部分（浅色三角形）：\n\n<div style=\"width:500px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img vo.png VO %}\n</div>\n\n而为了直接求$\\bf{v\\_{A}}$绝对速度的VO而不是$\\bf{v\\_{A}}-v\\_{B}$相对速度的VO，将相对速度下的VO延$\\bf{v\\_{B}}$方向平移，就有了图中右半部分（深色三角形）。\n\n## VO的数学定义\n\n理解了图示，数学定义就很好理解了。\n\n- 首先给出**射线的定义**，用$\\lambda({\\bf{p}},{\\bf{v}})$表示以点$\\bf{p}$为顶点，方向为$\\bf{v}$的射线。\n$$\\lambda({\\bf{p}}, {\\bf{v}}) = \\\\{ {\\bf{p}} +t{\\bf{v}} | t\\ge 0\\\\}$$\n- 接下来就是**VO的定义**了，用$VO^{A}\\_{B}({\\bf{v\\_{B}}})$表示速度为$\\bf{v\\_{B}}$的$B$对$A$的VO \n$$VO^{A}\\_{B}({\\bf{v\\_{B}}}) = \\\\{ {\\bf{v\\_A}} | \\lambda({\\bf{p\\_{A}}}, {\\bf{v\\_{A} - v\\_{B}}}) \\cap B \\oplus -A \\ne \\emptyset \\\\}$$\n\n## RVO(Reciprocal Velocity Obstacle)\n\nVO给出了很漂亮的避障条件，所以后面很多底层的避障算法都是基于VO的，而RVO就是其中之一。\n\nRVO主要解决了VO的抖动问题\n\n- **抖动现象**：如下左图所示，即$A$会在$\\bf{v\\_{A}}$与$\\bf{v\\_{A}^{\\prime}}$之间来回切换\n- **RVO的效果**：如下右图所示，保持$\\bf{v\\_{A}}$，不会抖动\n\n<div style=\"width:700px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img oscillation.png 抖动现象 %}\n</div>\n\n## 证明VO抖动现象存在\n\n首先论文给出了VO的三条性质\n\n- **Symmetry**：$\\bf{v\\_A}$的$A$会撞上$\\bf{v\\_B}$的$B$，则$\\bf{v\\_B}$的$B$也会撞上$\\bf{v\\_A}$的$A$\n$${\\bf{v\\_A}} \\in VO^{A}\\_{B}({\\bf{v\\_{B}}}) \\Leftrightarrow {\\bf{v\\_B}} \\in VO^{B}\\_{A}({\\bf{v\\_{A}}})$$\n- **Translation Invariance**：$\\bf{v\\_A}$的$A$会撞上$\\bf{v\\_B}$的$B$，则$\\bf{v\\_A+u}$的$A$会撞上$\\bf{v\\_B+u}$的$B$\n$${\\bf{v\\_A}} \\in VO^{A}\\_{B}({\\bf{v\\_{B}}}) \\Leftrightarrow {\\bf{v\\_A+u}} \\in VO^{A}\\_{B}({\\bf{v\\_{B}+u}})$$\n- **Convexity**：在$VO^{A}\\_{B}({\\bf{v\\_{B}}})$的左（右）侧的两个速度之间的任意速度，也在$VO^{A}\\_{B}({\\bf{v\\_{B}}})$的左（右）侧。VO左（右）侧如下图所示：\n$${\\bf{v\\_A}} \\overrightarrow{\\notin} VO^{A}\\_{B}({\\bf{v\\_{B}}}) \\land  {\\bf{v\\_A^{\\prime}}} \\overrightarrow{\\notin} VO^{A}\\_{B}({\\bf{v\\_{B}}}) \\Rightarrow (1-\\alpha){\\bf{v\\_A}} + \\alpha{\\bf{v\\_{A}^{\\prime}}} \\overrightarrow{\\notin} VO^{A}\\_{B}({\\bf{v\\_{B}}}),\\ for\\ 0\\le \\alpha \\le 1$$\n\n<div style=\"width:300px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img left_right.png VO左（右）侧示意 %}\n</div>\n\n接下来是抖动现象存在的证明\n\n1. 假设初始状态为会发生碰撞：${\\bf{v\\_A}} \\in VO^{A}\\_{B}({\\bf{v\\_{B}}}),\\ {\\bf{v\\_B}} \\in VO^{B}\\_{A}({\\bf{v\\_{A}}})$\n2. 由于在对方的VO内，所以各自选择新的速度以防止碰撞：${\\bf{v\\_A^{\\prime}}} \\notin VO^{A}\\_{B}({\\bf{v\\_{B}}}),\\ {\\bf{v\\_B^{\\prime}}} \\notin VO^{B}\\_{A}({\\bf{v\\_{A}}})$\n3. 由前面VO的Symmetry性质可知：此时，**原来的速度不在当前速度的VO内**：${\\bf{v\\_B}} \\notin VO^{B}\\_{A}({\\bf{v\\_{A}^{\\prime}}}),\\ {\\bf{v\\_A}} \\notin VO^{A}\\_{B}({\\bf{v\\_{B}^{\\prime}}})$\n4. 假设我们**更加prefer原来的速度**，则又会回到原来的$\\bf{v\\_A}$与$\\bf{v\\_B}$\n5. 于是在**1→4之间循环**，即发生抖动\n\n## RVO的Insight\n\n首先回想一下为什么会发生抖动：\n\n> 双方为了避障，都偏移了当前速度太多，导致更新速度后，原来速度不再会发生碰撞。\n\n那么我们有没有办法减少对当前速度的偏移，同时又能保证避障呢，RVO的回答是肯定的：\n\n- 缩小VO的大小，新的\"VO\"就叫做RVO\n\t+ p.s. 我个人对Reciprocal的理解是：相对于VO**完全把对方当做木头**，RVO假设对方在避障中也**会承担一定责任**，所以**不用完全靠自己**改变速度来走出VO，有种**互相合作**避障的感觉。\n- 或者换一个角度理解，不再直接选择VO外的速度$\\bf{v\\_A^{\\prime}}$作为新的速度，而是average当前速度$\\bf{v\\_A}$与VO外的速度$\\bf{v\\_A^{\\prime}}$\n\n## RVO的定义与图示\n\n- 速度为$\\bf{v\\_{B}}$的$B$对速度为$\\bf{v\\_A}$的$A$产生的RVO为：\n\n$$ RVO\\_{B}^{A}({\\bf{v\\_B}}, {\\bf{v\\_A}}) = \\\\{ {\\bf{v\\_{A}^{\\prime}}}\\ |\\ 2{\\bf{v\\_{A}^{\\prime}}} - {\\bf{v\\_A}} \\in VO^{A}\\_{B}({\\bf{v\\_{B}}})\\\\}$$\n\n- 图示理解如下：\n\n<div style=\"width:500px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img rvo.png RVO %}\n</div>\n\n- 释意：\n\t+ $2{\\bf{v\\_{A}^{\\prime}}} - {\\bf{v\\_A}}$：${\\bf{v\\_A}}$相对于$\\bf{v\\_A^{\\prime}}$的对称点。\n\t+ 所以**公式的含义**是：对称点在原VO中，则中点在RVO中。\n\t+ 所以**RVO的构成**是：$\\bf{v_A}$与原VO中的点的中点。\n\n## RVO不会发生碰撞且没有抖动现象的证明\n\n这一部分不赘述了，论文中写得很详尽，只说一下证明的思路：\n\n- 双方选择**同侧**避障时，不会发生碰撞。\n- 双方一定会选择同侧避障。\n- 不会有抖动现象：原来会撞的在选择新速度后**依然**会撞。\n\n## 收获\n\n- **用数学语言来描述问题**：化作质点的描述、抖动的描述。\n- **从实际应用中发现问题**：抖动问题的发现。\n- **特殊到一般的推广**：论文后面还将RVO推广到一般情况，很漂亮的推广。\n\n## References\n\n- [Reciprocal Velocity Obstacles for Real-Time Multi-Agent Navigation](http://gamma.cs.unc.edu/RVO/)\n- [Minkowski Sums](http://twistedoakstudios.com/blog/Post554\\_minkowski-sums-and-differences)\n","source":"_posts/paper-rvo.md","raw":"---\ntitle: 论文笔记《Reciprocal Velocity Obstacles for Real-Time Multi-Agent Navigation》\ntags:\n  - VO(Velocity Obstacle)\n  - RVO(Reciprocal Velocity Obstacle)\ndescription:\n  - 经典的底层避障算法\ncategories:\n  - 论文笔记\ndate: 2017-01-13 21:08:51\n---\n\n\n\n## 简介\n\n在介绍VO，RVO之前，需要先介绍路径规划。\n\n对Agent进行路径规划，实际上要完成的**任务**就是让Agent从点A**无碰撞地**移动到点B。而路径规划的过程是层次化的，其基本框架大致如下：\n\n- **High level**: dijkstra等算法。\n- **Low level**: VO, RVO, ORCA等底层避障算法。\n\n很容易可以跟我们的日常生活进行类比，比如说我们要从学校的教学楼走到宿舍楼，那么以上框架对应的就是：\n\n- **High level**: 通过dijkstra算法，得到路径为: 教学楼→饭堂→体育馆→图书馆→宿舍楼。\n- **Low level**: 通过底层避障算法如VO，RVO，ORCA等底层避障算法，保证我们走的每一段路（e.g. 教学楼→饭堂），都不会跟别的同学发生碰撞。\n\nVO和RVO就是经典的底层避障算法。其中VO是最经典的，RVO则在VO的基础上进行了一些改进，解决了VO抖动的问题。\n\n## VO(Velocity Obstacle)\n\n**一句话总结**VO的思路：只要在未来有可能会发生碰撞的速度，都排除在外。\n\n为方便描述，以下都假设是在**平面**内，**圆形物体**之间的避障。\n\n## VO的直观理解\n\n<div style=\"width:400px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img prob_disc.png 问题描述 %}\n</div>\n\n> Q: 假设B静止，那么A取什么速度能够保证一定不会跟B发生碰撞呢？\n\n> A: 一种很粗暴的方法，就是**把A化作质点**，选择跟**$\\bar{B}$(扩展后的B)不相交**的速度方向。以后只要在每个周期里面，都选择不在VO的速度，就能够保证不会碰撞。\n\n<div style=\"width:400px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img prob_sol.png 解决办法 %}\n</div>\n\n以上就是VO的直观理解，需要注意的是：\n\n- VO是指速度方向与$\\bar{B}$相交的部分，即**会发生碰撞的部分（图中灰色斜线部分）**。\n- VO是抱着**宁杀错，不放过**的思想，把所有未来有可能会发生碰撞的速度都放弃了。\n- 实际上假如仅要求**一定时间内**不发生碰撞的话，有更多的速度可供选择，比如说上图中的($v\\_{A}^{\\prime}$)。\n\n## VO的图示理解\n\n有了直观理解之后就可以用更加严谨一点的数学语言图示VO了。\n\n首先将直观理解中口语化的表达转换成对应的数学语言表示。\n\n- **物体A(B)**：以$\\bf{p\\_{A}}$为圆心，$r\\_{A}$为半径的**点集$A$**\n- **假设B静止**：A相对于B的速度，即**相对速度$\\bf{v\\_{A}}-v\\_{B}$**\n- **把A化作质点**：求集合$B$与集合$-A$的Minkowski sum，即**闵氏和，$B\\oplus-A$**，其中\n\t+ $A \\oplus B = \\\\{    {\\bf{a}} + {\\bf{b}}\\ |\\ {\\bf{a}} \\in A, {\\bf{b}} \\in B \\\\} $\n\t+ $-A = \\\\{ -{\\bf{a}}\\ |\\ {\\bf{a}} \\in A \\\\}$\n\t+ [更多关于Minkowski sum](http://twistedoakstudios.com/blog/Post554\\_minkowski-sums-and-differences)\n\n于是就有了下图的左半部分（浅色三角形）：\n\n<div style=\"width:500px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img vo.png VO %}\n</div>\n\n而为了直接求$\\bf{v\\_{A}}$绝对速度的VO而不是$\\bf{v\\_{A}}-v\\_{B}$相对速度的VO，将相对速度下的VO延$\\bf{v\\_{B}}$方向平移，就有了图中右半部分（深色三角形）。\n\n## VO的数学定义\n\n理解了图示，数学定义就很好理解了。\n\n- 首先给出**射线的定义**，用$\\lambda({\\bf{p}},{\\bf{v}})$表示以点$\\bf{p}$为顶点，方向为$\\bf{v}$的射线。\n$$\\lambda({\\bf{p}}, {\\bf{v}}) = \\\\{ {\\bf{p}} +t{\\bf{v}} | t\\ge 0\\\\}$$\n- 接下来就是**VO的定义**了，用$VO^{A}\\_{B}({\\bf{v\\_{B}}})$表示速度为$\\bf{v\\_{B}}$的$B$对$A$的VO \n$$VO^{A}\\_{B}({\\bf{v\\_{B}}}) = \\\\{ {\\bf{v\\_A}} | \\lambda({\\bf{p\\_{A}}}, {\\bf{v\\_{A} - v\\_{B}}}) \\cap B \\oplus -A \\ne \\emptyset \\\\}$$\n\n## RVO(Reciprocal Velocity Obstacle)\n\nVO给出了很漂亮的避障条件，所以后面很多底层的避障算法都是基于VO的，而RVO就是其中之一。\n\nRVO主要解决了VO的抖动问题\n\n- **抖动现象**：如下左图所示，即$A$会在$\\bf{v\\_{A}}$与$\\bf{v\\_{A}^{\\prime}}$之间来回切换\n- **RVO的效果**：如下右图所示，保持$\\bf{v\\_{A}}$，不会抖动\n\n<div style=\"width:700px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img oscillation.png 抖动现象 %}\n</div>\n\n## 证明VO抖动现象存在\n\n首先论文给出了VO的三条性质\n\n- **Symmetry**：$\\bf{v\\_A}$的$A$会撞上$\\bf{v\\_B}$的$B$，则$\\bf{v\\_B}$的$B$也会撞上$\\bf{v\\_A}$的$A$\n$${\\bf{v\\_A}} \\in VO^{A}\\_{B}({\\bf{v\\_{B}}}) \\Leftrightarrow {\\bf{v\\_B}} \\in VO^{B}\\_{A}({\\bf{v\\_{A}}})$$\n- **Translation Invariance**：$\\bf{v\\_A}$的$A$会撞上$\\bf{v\\_B}$的$B$，则$\\bf{v\\_A+u}$的$A$会撞上$\\bf{v\\_B+u}$的$B$\n$${\\bf{v\\_A}} \\in VO^{A}\\_{B}({\\bf{v\\_{B}}}) \\Leftrightarrow {\\bf{v\\_A+u}} \\in VO^{A}\\_{B}({\\bf{v\\_{B}+u}})$$\n- **Convexity**：在$VO^{A}\\_{B}({\\bf{v\\_{B}}})$的左（右）侧的两个速度之间的任意速度，也在$VO^{A}\\_{B}({\\bf{v\\_{B}}})$的左（右）侧。VO左（右）侧如下图所示：\n$${\\bf{v\\_A}} \\overrightarrow{\\notin} VO^{A}\\_{B}({\\bf{v\\_{B}}}) \\land  {\\bf{v\\_A^{\\prime}}} \\overrightarrow{\\notin} VO^{A}\\_{B}({\\bf{v\\_{B}}}) \\Rightarrow (1-\\alpha){\\bf{v\\_A}} + \\alpha{\\bf{v\\_{A}^{\\prime}}} \\overrightarrow{\\notin} VO^{A}\\_{B}({\\bf{v\\_{B}}}),\\ for\\ 0\\le \\alpha \\le 1$$\n\n<div style=\"width:300px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img left_right.png VO左（右）侧示意 %}\n</div>\n\n接下来是抖动现象存在的证明\n\n1. 假设初始状态为会发生碰撞：${\\bf{v\\_A}} \\in VO^{A}\\_{B}({\\bf{v\\_{B}}}),\\ {\\bf{v\\_B}} \\in VO^{B}\\_{A}({\\bf{v\\_{A}}})$\n2. 由于在对方的VO内，所以各自选择新的速度以防止碰撞：${\\bf{v\\_A^{\\prime}}} \\notin VO^{A}\\_{B}({\\bf{v\\_{B}}}),\\ {\\bf{v\\_B^{\\prime}}} \\notin VO^{B}\\_{A}({\\bf{v\\_{A}}})$\n3. 由前面VO的Symmetry性质可知：此时，**原来的速度不在当前速度的VO内**：${\\bf{v\\_B}} \\notin VO^{B}\\_{A}({\\bf{v\\_{A}^{\\prime}}}),\\ {\\bf{v\\_A}} \\notin VO^{A}\\_{B}({\\bf{v\\_{B}^{\\prime}}})$\n4. 假设我们**更加prefer原来的速度**，则又会回到原来的$\\bf{v\\_A}$与$\\bf{v\\_B}$\n5. 于是在**1→4之间循环**，即发生抖动\n\n## RVO的Insight\n\n首先回想一下为什么会发生抖动：\n\n> 双方为了避障，都偏移了当前速度太多，导致更新速度后，原来速度不再会发生碰撞。\n\n那么我们有没有办法减少对当前速度的偏移，同时又能保证避障呢，RVO的回答是肯定的：\n\n- 缩小VO的大小，新的\"VO\"就叫做RVO\n\t+ p.s. 我个人对Reciprocal的理解是：相对于VO**完全把对方当做木头**，RVO假设对方在避障中也**会承担一定责任**，所以**不用完全靠自己**改变速度来走出VO，有种**互相合作**避障的感觉。\n- 或者换一个角度理解，不再直接选择VO外的速度$\\bf{v\\_A^{\\prime}}$作为新的速度，而是average当前速度$\\bf{v\\_A}$与VO外的速度$\\bf{v\\_A^{\\prime}}$\n\n## RVO的定义与图示\n\n- 速度为$\\bf{v\\_{B}}$的$B$对速度为$\\bf{v\\_A}$的$A$产生的RVO为：\n\n$$ RVO\\_{B}^{A}({\\bf{v\\_B}}, {\\bf{v\\_A}}) = \\\\{ {\\bf{v\\_{A}^{\\prime}}}\\ |\\ 2{\\bf{v\\_{A}^{\\prime}}} - {\\bf{v\\_A}} \\in VO^{A}\\_{B}({\\bf{v\\_{B}}})\\\\}$$\n\n- 图示理解如下：\n\n<div style=\"width:500px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img rvo.png RVO %}\n</div>\n\n- 释意：\n\t+ $2{\\bf{v\\_{A}^{\\prime}}} - {\\bf{v\\_A}}$：${\\bf{v\\_A}}$相对于$\\bf{v\\_A^{\\prime}}$的对称点。\n\t+ 所以**公式的含义**是：对称点在原VO中，则中点在RVO中。\n\t+ 所以**RVO的构成**是：$\\bf{v_A}$与原VO中的点的中点。\n\n## RVO不会发生碰撞且没有抖动现象的证明\n\n这一部分不赘述了，论文中写得很详尽，只说一下证明的思路：\n\n- 双方选择**同侧**避障时，不会发生碰撞。\n- 双方一定会选择同侧避障。\n- 不会有抖动现象：原来会撞的在选择新速度后**依然**会撞。\n\n## 收获\n\n- **用数学语言来描述问题**：化作质点的描述、抖动的描述。\n- **从实际应用中发现问题**：抖动问题的发现。\n- **特殊到一般的推广**：论文后面还将RVO推广到一般情况，很漂亮的推广。\n\n## References\n\n- [Reciprocal Velocity Obstacles for Real-Time Multi-Agent Navigation](http://gamma.cs.unc.edu/RVO/)\n- [Minkowski Sums](http://twistedoakstudios.com/blog/Post554\\_minkowski-sums-and-differences)\n","slug":"paper-rvo","published":1,"updated":"2024-08-13T16:03:47.868Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clzvf192b001deqwo96q5li2c","content":"<h2 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h2><p>在介绍VO，RVO之前，需要先介绍路径规划。</p>\n<p>对Agent进行路径规划，实际上要完成的<strong>任务</strong>就是让Agent从点A<strong>无碰撞地</strong>移动到点B。而路径规划的过程是层次化的，其基本框架大致如下：</p>\n<ul>\n<li><strong>High level</strong>: dijkstra等算法。</li>\n<li><strong>Low level</strong>: VO, RVO, ORCA等底层避障算法。</li>\n</ul>\n<p>很容易可以跟我们的日常生活进行类比，比如说我们要从学校的教学楼走到宿舍楼，那么以上框架对应的就是：</p>\n<ul>\n<li><strong>High level</strong>: 通过dijkstra算法，得到路径为: 教学楼→饭堂→体育馆→图书馆→宿舍楼。</li>\n<li><strong>Low level</strong>: 通过底层避障算法如VO，RVO，ORCA等底层避障算法，保证我们走的每一段路（e.g. 教学楼→饭堂），都不会跟别的同学发生碰撞。</li>\n</ul>\n<p>VO和RVO就是经典的底层避障算法。其中VO是最经典的，RVO则在VO的基础上进行了一些改进，解决了VO抖动的问题。</p>\n<h2 id=\"VO-Velocity-Obstacle\"><a href=\"#VO-Velocity-Obstacle\" class=\"headerlink\" title=\"VO(Velocity Obstacle)\"></a>VO(Velocity Obstacle)</h2><p><strong>一句话总结</strong>VO的思路：只要在未来有可能会发生碰撞的速度，都排除在外。</p>\n<p>为方便描述，以下都假设是在<strong>平面</strong>内，<strong>圆形物体</strong>之间的避障。</p>\n<h2 id=\"VO的直观理解\"><a href=\"#VO的直观理解\" class=\"headerlink\" title=\"VO的直观理解\"></a>VO的直观理解</h2><div style=\"width:400px; margin-left:auto; margin-right:auto;\"><br>  <img src=\"/2017/01/13/paper-rvo/prob_disc.png\" alt=\"问题描述\" title=\"问题描述\"><br></div>\n\n<blockquote>\n<p>Q: 假设B静止，那么A取什么速度能够保证一定不会跟B发生碰撞呢？</p>\n<p>A: 一种很粗暴的方法，就是<strong>把A化作质点</strong>，选择跟<strong>$\\bar{B}$(扩展后的B)不相交</strong>的速度方向。以后只要在每个周期里面，都选择不在VO的速度，就能够保证不会碰撞。</p>\n</blockquote>\n<div style=\"width:400px; margin-left:auto; margin-right:auto;\"><br>  <img src=\"/2017/01/13/paper-rvo/prob_sol.png\" alt=\"解决办法\" title=\"解决办法\"><br></div>\n\n<p>以上就是VO的直观理解，需要注意的是：</p>\n<ul>\n<li>VO是指速度方向与$\\bar{B}$相交的部分，即<strong>会发生碰撞的部分（图中灰色斜线部分）</strong>。</li>\n<li>VO是抱着<strong>宁杀错，不放过</strong>的思想，把所有未来有可能会发生碰撞的速度都放弃了。</li>\n<li>实际上假如仅要求<strong>一定时间内</strong>不发生碰撞的话，有更多的速度可供选择，比如说上图中的($v_{A}^{\\prime}$)。</li>\n</ul>\n<h2 id=\"VO的图示理解\"><a href=\"#VO的图示理解\" class=\"headerlink\" title=\"VO的图示理解\"></a>VO的图示理解</h2><p>有了直观理解之后就可以用更加严谨一点的数学语言图示VO了。</p>\n<p>首先将直观理解中口语化的表达转换成对应的数学语言表示。</p>\n<ul>\n<li><strong>物体A(B)</strong>：以$\\bf{p_{A}}$为圆心，$r_{A}$为半径的<strong>点集$A$</strong></li>\n<li><strong>假设B静止</strong>：A相对于B的速度，即<strong>相对速度$\\bf{v_{A}}-v_{B}$</strong></li>\n<li><strong>把A化作质点</strong>：求集合$B$与集合$-A$的Minkowski sum，即<strong>闵氏和，$B\\oplus-A$</strong>，其中<ul>\n<li>$A \\oplus B = \\{    {\\bf{a}} + {\\bf{b}} | {\\bf{a}} \\in A, {\\bf{b}} \\in B \\} $</li>\n<li>$-A = \\{ -{\\bf{a}} | {\\bf{a}} \\in A \\}$</li>\n<li><a href=\"http://twistedoakstudios.com/blog/Post554\\_minkowski-sums-and-differences\" target=\"_blank\" rel=\"external\">更多关于Minkowski sum</a></li>\n</ul>\n</li>\n</ul>\n<p>于是就有了下图的左半部分（浅色三角形）：</p>\n<div style=\"width:500px; margin-left:auto; margin-right:auto;\"><br>  <img src=\"/2017/01/13/paper-rvo/vo.png\" alt=\"VO\" title=\"VO\"><br></div>\n\n<p>而为了直接求$\\bf{v_{A}}$绝对速度的VO而不是$\\bf{v_{A}}-v_{B}$相对速度的VO，将相对速度下的VO延$\\bf{v_{B}}$方向平移，就有了图中右半部分（深色三角形）。</p>\n<h2 id=\"VO的数学定义\"><a href=\"#VO的数学定义\" class=\"headerlink\" title=\"VO的数学定义\"></a>VO的数学定义</h2><p>理解了图示，数学定义就很好理解了。</p>\n<ul>\n<li>首先给出<strong>射线的定义</strong>，用$\\lambda({\\bf{p}},{\\bf{v}})$表示以点$\\bf{p}$为顶点，方向为$\\bf{v}$的射线。<br>$$\\lambda({\\bf{p}}, {\\bf{v}}) = \\{ {\\bf{p}} +t{\\bf{v}} | t\\ge 0\\}$$</li>\n<li>接下来就是<strong>VO的定义</strong>了，用$VO^{A}_{B}({\\bf{v_{B}}})$表示速度为$\\bf{v_{B}}$的$B$对$A$的VO<br>$$VO^{A}_{B}({\\bf{v_{B}}}) = \\{ {\\bf{v_A}} | \\lambda({\\bf{p_{A}}}, {\\bf{v_{A} - v_{B}}}) \\cap B \\oplus -A \\ne \\emptyset \\}$$</li>\n</ul>\n<h2 id=\"RVO-Reciprocal-Velocity-Obstacle\"><a href=\"#RVO-Reciprocal-Velocity-Obstacle\" class=\"headerlink\" title=\"RVO(Reciprocal Velocity Obstacle)\"></a>RVO(Reciprocal Velocity Obstacle)</h2><p>VO给出了很漂亮的避障条件，所以后面很多底层的避障算法都是基于VO的，而RVO就是其中之一。</p>\n<p>RVO主要解决了VO的抖动问题</p>\n<ul>\n<li><strong>抖动现象</strong>：如下左图所示，即$A$会在$\\bf{v_{A}}$与$\\bf{v_{A}^{\\prime}}$之间来回切换</li>\n<li><strong>RVO的效果</strong>：如下右图所示，保持$\\bf{v_{A}}$，不会抖动</li>\n</ul>\n<div style=\"width:700px; margin-left:auto; margin-right:auto;\"><br>  <img src=\"/2017/01/13/paper-rvo/oscillation.png\" alt=\"抖动现象\" title=\"抖动现象\"><br></div>\n\n<h2 id=\"证明VO抖动现象存在\"><a href=\"#证明VO抖动现象存在\" class=\"headerlink\" title=\"证明VO抖动现象存在\"></a>证明VO抖动现象存在</h2><p>首先论文给出了VO的三条性质</p>\n<ul>\n<li><strong>Symmetry</strong>：$\\bf{v_A}$的$A$会撞上$\\bf{v_B}$的$B$，则$\\bf{v_B}$的$B$也会撞上$\\bf{v_A}$的$A$<br>$${\\bf{v_A}} \\in VO^{A}_{B}({\\bf{v_{B}}}) \\Leftrightarrow {\\bf{v_B}} \\in VO^{B}_{A}({\\bf{v_{A}}})$$</li>\n<li><strong>Translation Invariance</strong>：$\\bf{v_A}$的$A$会撞上$\\bf{v_B}$的$B$，则$\\bf{v_A+u}$的$A$会撞上$\\bf{v_B+u}$的$B$<br>$${\\bf{v_A}} \\in VO^{A}_{B}({\\bf{v_{B}}}) \\Leftrightarrow {\\bf{v_A+u}} \\in VO^{A}_{B}({\\bf{v_{B}+u}})$$</li>\n<li><strong>Convexity</strong>：在$VO^{A}_{B}({\\bf{v_{B}}})$的左（右）侧的两个速度之间的任意速度，也在$VO^{A}_{B}({\\bf{v_{B}}})$的左（右）侧。VO左（右）侧如下图所示：<br>$${\\bf{v_A}} \\overrightarrow{\\notin} VO^{A}_{B}({\\bf{v_{B}}}) \\land  {\\bf{v_A^{\\prime}}} \\overrightarrow{\\notin} VO^{A}_{B}({\\bf{v_{B}}}) \\Rightarrow (1-\\alpha){\\bf{v_A}} + \\alpha{\\bf{v_{A}^{\\prime}}} \\overrightarrow{\\notin} VO^{A}_{B}({\\bf{v_{B}}}), for 0\\le \\alpha \\le 1$$</li>\n</ul>\n<div style=\"width:300px; margin-left:auto; margin-right:auto;\"><br>  <img src=\"/2017/01/13/paper-rvo/left_right.png\" alt=\"VO左（右）侧示意\" title=\"VO左（右）侧示意\"><br></div>\n\n<p>接下来是抖动现象存在的证明</p>\n<ol>\n<li>假设初始状态为会发生碰撞：${\\bf{v_A}} \\in VO^{A}_{B}({\\bf{v_{B}}}), {\\bf{v_B}} \\in VO^{B}_{A}({\\bf{v_{A}}})$</li>\n<li>由于在对方的VO内，所以各自选择新的速度以防止碰撞：${\\bf{v_A^{\\prime}}} \\notin VO^{A}_{B}({\\bf{v_{B}}}), {\\bf{v_B^{\\prime}}} \\notin VO^{B}_{A}({\\bf{v_{A}}})$</li>\n<li>由前面VO的Symmetry性质可知：此时，<strong>原来的速度不在当前速度的VO内</strong>：${\\bf{v_B}} \\notin VO^{B}_{A}({\\bf{v_{A}^{\\prime}}}), {\\bf{v_A}} \\notin VO^{A}_{B}({\\bf{v_{B}^{\\prime}}})$</li>\n<li>假设我们<strong>更加prefer原来的速度</strong>，则又会回到原来的$\\bf{v_A}$与$\\bf{v_B}$</li>\n<li>于是在<strong>1→4之间循环</strong>，即发生抖动</li>\n</ol>\n<h2 id=\"RVO的Insight\"><a href=\"#RVO的Insight\" class=\"headerlink\" title=\"RVO的Insight\"></a>RVO的Insight</h2><p>首先回想一下为什么会发生抖动：</p>\n<blockquote>\n<p>双方为了避障，都偏移了当前速度太多，导致更新速度后，原来速度不再会发生碰撞。</p>\n</blockquote>\n<p>那么我们有没有办法减少对当前速度的偏移，同时又能保证避障呢，RVO的回答是肯定的：</p>\n<ul>\n<li>缩小VO的大小，新的”VO”就叫做RVO<ul>\n<li>p.s. 我个人对Reciprocal的理解是：相对于VO<strong>完全把对方当做木头</strong>，RVO假设对方在避障中也<strong>会承担一定责任</strong>，所以<strong>不用完全靠自己</strong>改变速度来走出VO，有种<strong>互相合作</strong>避障的感觉。</li>\n</ul>\n</li>\n<li>或者换一个角度理解，不再直接选择VO外的速度$\\bf{v_A^{\\prime}}$作为新的速度，而是average当前速度$\\bf{v_A}$与VO外的速度$\\bf{v_A^{\\prime}}$</li>\n</ul>\n<h2 id=\"RVO的定义与图示\"><a href=\"#RVO的定义与图示\" class=\"headerlink\" title=\"RVO的定义与图示\"></a>RVO的定义与图示</h2><ul>\n<li>速度为$\\bf{v_{B}}$的$B$对速度为$\\bf{v_A}$的$A$产生的RVO为：</li>\n</ul>\n<p>$$ RVO_{B}^{A}({\\bf{v_B}}, {\\bf{v_A}}) = \\{ {\\bf{v_{A}^{\\prime}}} | 2{\\bf{v_{A}^{\\prime}}} - {\\bf{v_A}} \\in VO^{A}_{B}({\\bf{v_{B}}})\\}$$</p>\n<ul>\n<li>图示理解如下：</li>\n</ul>\n<div style=\"width:500px; margin-left:auto; margin-right:auto;\"><br>  <img src=\"/2017/01/13/paper-rvo/rvo.png\" alt=\"RVO\" title=\"RVO\"><br></div>\n\n<ul>\n<li>释意：<ul>\n<li>$2{\\bf{v_{A}^{\\prime}}} - {\\bf{v_A}}$：${\\bf{v_A}}$相对于$\\bf{v_A^{\\prime}}$的对称点。</li>\n<li>所以<strong>公式的含义</strong>是：对称点在原VO中，则中点在RVO中。</li>\n<li>所以<strong>RVO的构成</strong>是：$\\bf{v_A}$与原VO中的点的中点。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"RVO不会发生碰撞且没有抖动现象的证明\"><a href=\"#RVO不会发生碰撞且没有抖动现象的证明\" class=\"headerlink\" title=\"RVO不会发生碰撞且没有抖动现象的证明\"></a>RVO不会发生碰撞且没有抖动现象的证明</h2><p>这一部分不赘述了，论文中写得很详尽，只说一下证明的思路：</p>\n<ul>\n<li>双方选择<strong>同侧</strong>避障时，不会发生碰撞。</li>\n<li>双方一定会选择同侧避障。</li>\n<li>不会有抖动现象：原来会撞的在选择新速度后<strong>依然</strong>会撞。</li>\n</ul>\n<h2 id=\"收获\"><a href=\"#收获\" class=\"headerlink\" title=\"收获\"></a>收获</h2><ul>\n<li><strong>用数学语言来描述问题</strong>：化作质点的描述、抖动的描述。</li>\n<li><strong>从实际应用中发现问题</strong>：抖动问题的发现。</li>\n<li><strong>特殊到一般的推广</strong>：论文后面还将RVO推广到一般情况，很漂亮的推广。</li>\n</ul>\n<h2 id=\"References\"><a href=\"#References\" class=\"headerlink\" title=\"References\"></a>References</h2><ul>\n<li><a href=\"http://gamma.cs.unc.edu/RVO/\" target=\"_blank\" rel=\"external\">Reciprocal Velocity Obstacles for Real-Time Multi-Agent Navigation</a></li>\n<li><a href=\"http://twistedoakstudios.com/blog/Post554\\_minkowski-sums-and-differences\" target=\"_blank\" rel=\"external\">Minkowski Sums</a></li>\n</ul>\n","excerpt":"","more":"<h2 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h2><p>在介绍VO，RVO之前，需要先介绍路径规划。</p>\n<p>对Agent进行路径规划，实际上要完成的<strong>任务</strong>就是让Agent从点A<strong>无碰撞地</strong>移动到点B。而路径规划的过程是层次化的，其基本框架大致如下：</p>\n<ul>\n<li><strong>High level</strong>: dijkstra等算法。</li>\n<li><strong>Low level</strong>: VO, RVO, ORCA等底层避障算法。</li>\n</ul>\n<p>很容易可以跟我们的日常生活进行类比，比如说我们要从学校的教学楼走到宿舍楼，那么以上框架对应的就是：</p>\n<ul>\n<li><strong>High level</strong>: 通过dijkstra算法，得到路径为: 教学楼→饭堂→体育馆→图书馆→宿舍楼。</li>\n<li><strong>Low level</strong>: 通过底层避障算法如VO，RVO，ORCA等底层避障算法，保证我们走的每一段路（e.g. 教学楼→饭堂），都不会跟别的同学发生碰撞。</li>\n</ul>\n<p>VO和RVO就是经典的底层避障算法。其中VO是最经典的，RVO则在VO的基础上进行了一些改进，解决了VO抖动的问题。</p>\n<h2 id=\"VO-Velocity-Obstacle\"><a href=\"#VO-Velocity-Obstacle\" class=\"headerlink\" title=\"VO(Velocity Obstacle)\"></a>VO(Velocity Obstacle)</h2><p><strong>一句话总结</strong>VO的思路：只要在未来有可能会发生碰撞的速度，都排除在外。</p>\n<p>为方便描述，以下都假设是在<strong>平面</strong>内，<strong>圆形物体</strong>之间的避障。</p>\n<h2 id=\"VO的直观理解\"><a href=\"#VO的直观理解\" class=\"headerlink\" title=\"VO的直观理解\"></a>VO的直观理解</h2><div style=\"width:400px; margin-left:auto; margin-right:auto;\" ><br>  <img src=\"/2017/01/13/paper-rvo/prob_disc.png\" alt=\"问题描述\" title=\"问题描述\"><br></div>\n\n<blockquote>\n<p>Q: 假设B静止，那么A取什么速度能够保证一定不会跟B发生碰撞呢？</p>\n<p>A: 一种很粗暴的方法，就是<strong>把A化作质点</strong>，选择跟<strong>$\\bar{B}$(扩展后的B)不相交</strong>的速度方向。以后只要在每个周期里面，都选择不在VO的速度，就能够保证不会碰撞。</p>\n</blockquote>\n<div style=\"width:400px; margin-left:auto; margin-right:auto;\" ><br>  <img src=\"/2017/01/13/paper-rvo/prob_sol.png\" alt=\"解决办法\" title=\"解决办法\"><br></div>\n\n<p>以上就是VO的直观理解，需要注意的是：</p>\n<ul>\n<li>VO是指速度方向与$\\bar{B}$相交的部分，即<strong>会发生碰撞的部分（图中灰色斜线部分）</strong>。</li>\n<li>VO是抱着<strong>宁杀错，不放过</strong>的思想，把所有未来有可能会发生碰撞的速度都放弃了。</li>\n<li>实际上假如仅要求<strong>一定时间内</strong>不发生碰撞的话，有更多的速度可供选择，比如说上图中的($v_{A}^{\\prime}$)。</li>\n</ul>\n<h2 id=\"VO的图示理解\"><a href=\"#VO的图示理解\" class=\"headerlink\" title=\"VO的图示理解\"></a>VO的图示理解</h2><p>有了直观理解之后就可以用更加严谨一点的数学语言图示VO了。</p>\n<p>首先将直观理解中口语化的表达转换成对应的数学语言表示。</p>\n<ul>\n<li><strong>物体A(B)</strong>：以$\\bf{p_{A}}$为圆心，$r_{A}$为半径的<strong>点集$A$</strong></li>\n<li><strong>假设B静止</strong>：A相对于B的速度，即<strong>相对速度$\\bf{v_{A}}-v_{B}$</strong></li>\n<li><strong>把A化作质点</strong>：求集合$B$与集合$-A$的Minkowski sum，即<strong>闵氏和，$B\\oplus-A$</strong>，其中<ul>\n<li>$A \\oplus B = \\{    {\\bf{a}} + {\\bf{b}} | {\\bf{a}} \\in A, {\\bf{b}} \\in B \\} $</li>\n<li>$-A = \\{ -{\\bf{a}} | {\\bf{a}} \\in A \\}$</li>\n<li><a href=\"http://twistedoakstudios.com/blog/Post554\\_minkowski-sums-and-differences\">更多关于Minkowski sum</a></li>\n</ul>\n</li>\n</ul>\n<p>于是就有了下图的左半部分（浅色三角形）：</p>\n<div style=\"width:500px; margin-left:auto; margin-right:auto;\" ><br>  <img src=\"/2017/01/13/paper-rvo/vo.png\" alt=\"VO\" title=\"VO\"><br></div>\n\n<p>而为了直接求$\\bf{v_{A}}$绝对速度的VO而不是$\\bf{v_{A}}-v_{B}$相对速度的VO，将相对速度下的VO延$\\bf{v_{B}}$方向平移，就有了图中右半部分（深色三角形）。</p>\n<h2 id=\"VO的数学定义\"><a href=\"#VO的数学定义\" class=\"headerlink\" title=\"VO的数学定义\"></a>VO的数学定义</h2><p>理解了图示，数学定义就很好理解了。</p>\n<ul>\n<li>首先给出<strong>射线的定义</strong>，用$\\lambda({\\bf{p}},{\\bf{v}})$表示以点$\\bf{p}$为顶点，方向为$\\bf{v}$的射线。<br>$$\\lambda({\\bf{p}}, {\\bf{v}}) = \\{ {\\bf{p}} +t{\\bf{v}} | t\\ge 0\\}$$</li>\n<li>接下来就是<strong>VO的定义</strong>了，用$VO^{A}_{B}({\\bf{v_{B}}})$表示速度为$\\bf{v_{B}}$的$B$对$A$的VO<br>$$VO^{A}_{B}({\\bf{v_{B}}}) = \\{ {\\bf{v_A}} | \\lambda({\\bf{p_{A}}}, {\\bf{v_{A} - v_{B}}}) \\cap B \\oplus -A \\ne \\emptyset \\}$$</li>\n</ul>\n<h2 id=\"RVO-Reciprocal-Velocity-Obstacle\"><a href=\"#RVO-Reciprocal-Velocity-Obstacle\" class=\"headerlink\" title=\"RVO(Reciprocal Velocity Obstacle)\"></a>RVO(Reciprocal Velocity Obstacle)</h2><p>VO给出了很漂亮的避障条件，所以后面很多底层的避障算法都是基于VO的，而RVO就是其中之一。</p>\n<p>RVO主要解决了VO的抖动问题</p>\n<ul>\n<li><strong>抖动现象</strong>：如下左图所示，即$A$会在$\\bf{v_{A}}$与$\\bf{v_{A}^{\\prime}}$之间来回切换</li>\n<li><strong>RVO的效果</strong>：如下右图所示，保持$\\bf{v_{A}}$，不会抖动</li>\n</ul>\n<div style=\"width:700px; margin-left:auto; margin-right:auto;\" ><br>  <img src=\"/2017/01/13/paper-rvo/oscillation.png\" alt=\"抖动现象\" title=\"抖动现象\"><br></div>\n\n<h2 id=\"证明VO抖动现象存在\"><a href=\"#证明VO抖动现象存在\" class=\"headerlink\" title=\"证明VO抖动现象存在\"></a>证明VO抖动现象存在</h2><p>首先论文给出了VO的三条性质</p>\n<ul>\n<li><strong>Symmetry</strong>：$\\bf{v_A}$的$A$会撞上$\\bf{v_B}$的$B$，则$\\bf{v_B}$的$B$也会撞上$\\bf{v_A}$的$A$<br>$${\\bf{v_A}} \\in VO^{A}_{B}({\\bf{v_{B}}}) \\Leftrightarrow {\\bf{v_B}} \\in VO^{B}_{A}({\\bf{v_{A}}})$$</li>\n<li><strong>Translation Invariance</strong>：$\\bf{v_A}$的$A$会撞上$\\bf{v_B}$的$B$，则$\\bf{v_A+u}$的$A$会撞上$\\bf{v_B+u}$的$B$<br>$${\\bf{v_A}} \\in VO^{A}_{B}({\\bf{v_{B}}}) \\Leftrightarrow {\\bf{v_A+u}} \\in VO^{A}_{B}({\\bf{v_{B}+u}})$$</li>\n<li><strong>Convexity</strong>：在$VO^{A}_{B}({\\bf{v_{B}}})$的左（右）侧的两个速度之间的任意速度，也在$VO^{A}_{B}({\\bf{v_{B}}})$的左（右）侧。VO左（右）侧如下图所示：<br>$${\\bf{v_A}} \\overrightarrow{\\notin} VO^{A}_{B}({\\bf{v_{B}}}) \\land  {\\bf{v_A^{\\prime}}} \\overrightarrow{\\notin} VO^{A}_{B}({\\bf{v_{B}}}) \\Rightarrow (1-\\alpha){\\bf{v_A}} + \\alpha{\\bf{v_{A}^{\\prime}}} \\overrightarrow{\\notin} VO^{A}_{B}({\\bf{v_{B}}}), for 0\\le \\alpha \\le 1$$</li>\n</ul>\n<div style=\"width:300px; margin-left:auto; margin-right:auto;\" ><br>  <img src=\"/2017/01/13/paper-rvo/left_right.png\" alt=\"VO左（右）侧示意\" title=\"VO左（右）侧示意\"><br></div>\n\n<p>接下来是抖动现象存在的证明</p>\n<ol>\n<li>假设初始状态为会发生碰撞：${\\bf{v_A}} \\in VO^{A}_{B}({\\bf{v_{B}}}), {\\bf{v_B}} \\in VO^{B}_{A}({\\bf{v_{A}}})$</li>\n<li>由于在对方的VO内，所以各自选择新的速度以防止碰撞：${\\bf{v_A^{\\prime}}} \\notin VO^{A}_{B}({\\bf{v_{B}}}), {\\bf{v_B^{\\prime}}} \\notin VO^{B}_{A}({\\bf{v_{A}}})$</li>\n<li>由前面VO的Symmetry性质可知：此时，<strong>原来的速度不在当前速度的VO内</strong>：${\\bf{v_B}} \\notin VO^{B}_{A}({\\bf{v_{A}^{\\prime}}}), {\\bf{v_A}} \\notin VO^{A}_{B}({\\bf{v_{B}^{\\prime}}})$</li>\n<li>假设我们<strong>更加prefer原来的速度</strong>，则又会回到原来的$\\bf{v_A}$与$\\bf{v_B}$</li>\n<li>于是在<strong>1→4之间循环</strong>，即发生抖动</li>\n</ol>\n<h2 id=\"RVO的Insight\"><a href=\"#RVO的Insight\" class=\"headerlink\" title=\"RVO的Insight\"></a>RVO的Insight</h2><p>首先回想一下为什么会发生抖动：</p>\n<blockquote>\n<p>双方为了避障，都偏移了当前速度太多，导致更新速度后，原来速度不再会发生碰撞。</p>\n</blockquote>\n<p>那么我们有没有办法减少对当前速度的偏移，同时又能保证避障呢，RVO的回答是肯定的：</p>\n<ul>\n<li>缩小VO的大小，新的”VO”就叫做RVO<ul>\n<li>p.s. 我个人对Reciprocal的理解是：相对于VO<strong>完全把对方当做木头</strong>，RVO假设对方在避障中也<strong>会承担一定责任</strong>，所以<strong>不用完全靠自己</strong>改变速度来走出VO，有种<strong>互相合作</strong>避障的感觉。</li>\n</ul>\n</li>\n<li>或者换一个角度理解，不再直接选择VO外的速度$\\bf{v_A^{\\prime}}$作为新的速度，而是average当前速度$\\bf{v_A}$与VO外的速度$\\bf{v_A^{\\prime}}$</li>\n</ul>\n<h2 id=\"RVO的定义与图示\"><a href=\"#RVO的定义与图示\" class=\"headerlink\" title=\"RVO的定义与图示\"></a>RVO的定义与图示</h2><ul>\n<li>速度为$\\bf{v_{B}}$的$B$对速度为$\\bf{v_A}$的$A$产生的RVO为：</li>\n</ul>\n<p>$$ RVO_{B}^{A}({\\bf{v_B}}, {\\bf{v_A}}) = \\{ {\\bf{v_{A}^{\\prime}}} | 2{\\bf{v_{A}^{\\prime}}} - {\\bf{v_A}} \\in VO^{A}_{B}({\\bf{v_{B}}})\\}$$</p>\n<ul>\n<li>图示理解如下：</li>\n</ul>\n<div style=\"width:500px; margin-left:auto; margin-right:auto;\" ><br>  <img src=\"/2017/01/13/paper-rvo/rvo.png\" alt=\"RVO\" title=\"RVO\"><br></div>\n\n<ul>\n<li>释意：<ul>\n<li>$2{\\bf{v_{A}^{\\prime}}} - {\\bf{v_A}}$：${\\bf{v_A}}$相对于$\\bf{v_A^{\\prime}}$的对称点。</li>\n<li>所以<strong>公式的含义</strong>是：对称点在原VO中，则中点在RVO中。</li>\n<li>所以<strong>RVO的构成</strong>是：$\\bf{v_A}$与原VO中的点的中点。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"RVO不会发生碰撞且没有抖动现象的证明\"><a href=\"#RVO不会发生碰撞且没有抖动现象的证明\" class=\"headerlink\" title=\"RVO不会发生碰撞且没有抖动现象的证明\"></a>RVO不会发生碰撞且没有抖动现象的证明</h2><p>这一部分不赘述了，论文中写得很详尽，只说一下证明的思路：</p>\n<ul>\n<li>双方选择<strong>同侧</strong>避障时，不会发生碰撞。</li>\n<li>双方一定会选择同侧避障。</li>\n<li>不会有抖动现象：原来会撞的在选择新速度后<strong>依然</strong>会撞。</li>\n</ul>\n<h2 id=\"收获\"><a href=\"#收获\" class=\"headerlink\" title=\"收获\"></a>收获</h2><ul>\n<li><strong>用数学语言来描述问题</strong>：化作质点的描述、抖动的描述。</li>\n<li><strong>从实际应用中发现问题</strong>：抖动问题的发现。</li>\n<li><strong>特殊到一般的推广</strong>：论文后面还将RVO推广到一般情况，很漂亮的推广。</li>\n</ul>\n<h2 id=\"References\"><a href=\"#References\" class=\"headerlink\" title=\"References\"></a>References</h2><ul>\n<li><a href=\"http://gamma.cs.unc.edu/RVO/\">Reciprocal Velocity Obstacles for Real-Time Multi-Agent Navigation</a></li>\n<li><a href=\"http://twistedoakstudios.com/blog/Post554\\_minkowski-sums-and-differences\">Minkowski Sums</a></li>\n</ul>\n"},{"title":"论文笔记《Rich feature hierarchies for accurate object detection and semantic segmentation》","date":"2016-07-08T07:45:08.000Z","description":["用于完成object detection的RCNN"],"_content":"\n## 任务简介\n- **目标：**object detection\n- **输入：**图片\n- **输出：**框住前景物体**（有可能多种且每种有多个）**，并且给物体标上类别\n\n## 思路\n1. **分解成两个子任务**\n\t* localization \n\t* classification\n2. **localization：**枚举\n3. **classification：**CNN\n4. 最后再**筛掉**多余的\n\n## 实现流程\n1. **localization：**用selective search提取region proposals（即一个个候选框）\n2. **warped region：**为了适配CNN输入，将region proposals格式归一化\n3. **feature extraction：**CNN\n4. **classification：**对于每个类别训练一个二分类SVM\n5. **综合策略：**NMS(non-maximum suppression)，重叠的选最有信心的\n\n## 实现细节\n- **pre-training：**直接用ILSVRC 2012训练CNN\n- **fine-tuning：**将pre-training训练出来的CNN换上匹配当前任务的输入层（warped region）和分类层（1000-way to 21-way）来训练模型\n\t* **训练集：**warped region的label根据其与GT(Ground Truth)的IoU(Intersection-over-Union，交集/并集)的大小来定。这里将threshold设为0.5\n- **classifier：**将fine-tuning训练出来的模型换上SVM作为分类层\n\t* **训练集：**方法同fine-tuning的训练集，不过这里的threshold设为0.3\n\n## Visualization\n- **学习：**定义某个unit学习的内容为**让这个unit输出最高的input**，即给定一堆input，unit对某个input\\_0的输出最高，则认为这个unit识别的就是这个input\\_0。通过这个定义可以将各个unit学习什么输出出来\n\n## Ablation studies（切除）（用于验证有效性）\n- **ablation：**比较要不要某一个层，对于结果的影响\n- **结果：**\n\t* 在不进行fine-tuning的情况下，CNN中的全连接层并没有什么卵用\n\t* 在进行fine-tuning的情况下，提升很大\n\n## Detection error analysis\n- **量化误差：**给出了percentage of each type - total false positives图，说明了在各个FP时的误差类型分布。错误类型有以下\n\t* 框错位置\n\t* 分成相似的类\n\t* 分成不相似的类\n\t* 分成背景\n- **结果：**RCNN的错误基本都是框错了位置，作者认为这时因为**bottom-up region proposals**还有**positional invariance learned from pre-training CNN**导致的\n- **解决方案：**对于生成的框，要使用**BB(Bounding box regression)**进行进一步调整\n\n## 收获\n- object detection的任务\n- RCNN\n- 评价模型的指标\n\t* 定性：visualization\n\t* 定量：Ablation, detection error\n\t","source":"_posts/paper_rcnn.md","raw":"---\ntitle: 论文笔记《Rich feature hierarchies for accurate object detection and semantic segmentation》\ndate: 2016-07-08 15:45:08\ntags:\n\t- rcnn\ncategories:\n\t- 论文笔记\ndescription:\n\t- 用于完成object detection的RCNN\n---\n\n## 任务简介\n- **目标：**object detection\n- **输入：**图片\n- **输出：**框住前景物体**（有可能多种且每种有多个）**，并且给物体标上类别\n\n## 思路\n1. **分解成两个子任务**\n\t* localization \n\t* classification\n2. **localization：**枚举\n3. **classification：**CNN\n4. 最后再**筛掉**多余的\n\n## 实现流程\n1. **localization：**用selective search提取region proposals（即一个个候选框）\n2. **warped region：**为了适配CNN输入，将region proposals格式归一化\n3. **feature extraction：**CNN\n4. **classification：**对于每个类别训练一个二分类SVM\n5. **综合策略：**NMS(non-maximum suppression)，重叠的选最有信心的\n\n## 实现细节\n- **pre-training：**直接用ILSVRC 2012训练CNN\n- **fine-tuning：**将pre-training训练出来的CNN换上匹配当前任务的输入层（warped region）和分类层（1000-way to 21-way）来训练模型\n\t* **训练集：**warped region的label根据其与GT(Ground Truth)的IoU(Intersection-over-Union，交集/并集)的大小来定。这里将threshold设为0.5\n- **classifier：**将fine-tuning训练出来的模型换上SVM作为分类层\n\t* **训练集：**方法同fine-tuning的训练集，不过这里的threshold设为0.3\n\n## Visualization\n- **学习：**定义某个unit学习的内容为**让这个unit输出最高的input**，即给定一堆input，unit对某个input\\_0的输出最高，则认为这个unit识别的就是这个input\\_0。通过这个定义可以将各个unit学习什么输出出来\n\n## Ablation studies（切除）（用于验证有效性）\n- **ablation：**比较要不要某一个层，对于结果的影响\n- **结果：**\n\t* 在不进行fine-tuning的情况下，CNN中的全连接层并没有什么卵用\n\t* 在进行fine-tuning的情况下，提升很大\n\n## Detection error analysis\n- **量化误差：**给出了percentage of each type - total false positives图，说明了在各个FP时的误差类型分布。错误类型有以下\n\t* 框错位置\n\t* 分成相似的类\n\t* 分成不相似的类\n\t* 分成背景\n- **结果：**RCNN的错误基本都是框错了位置，作者认为这时因为**bottom-up region proposals**还有**positional invariance learned from pre-training CNN**导致的\n- **解决方案：**对于生成的框，要使用**BB(Bounding box regression)**进行进一步调整\n\n## 收获\n- object detection的任务\n- RCNN\n- 评价模型的指标\n\t* 定性：visualization\n\t* 定量：Ablation, detection error\n\t","slug":"paper_rcnn","published":1,"updated":"2024-08-13T16:03:47.872Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clzvf192d001heqwo26yc4qn3","content":"<h2 id=\"任务简介\"><a href=\"#任务简介\" class=\"headerlink\" title=\"任务简介\"></a>任务简介</h2><ul>\n<li><strong>目标：</strong>object detection</li>\n<li><strong>输入：</strong>图片</li>\n<li><strong>输出：</strong>框住前景物体<strong>（有可能多种且每种有多个）</strong>，并且给物体标上类别</li>\n</ul>\n<h2 id=\"思路\"><a href=\"#思路\" class=\"headerlink\" title=\"思路\"></a>思路</h2><ol>\n<li><strong>分解成两个子任务</strong><ul>\n<li>localization </li>\n<li>classification</li>\n</ul>\n</li>\n<li><strong>localization：</strong>枚举</li>\n<li><strong>classification：</strong>CNN</li>\n<li>最后再<strong>筛掉</strong>多余的</li>\n</ol>\n<h2 id=\"实现流程\"><a href=\"#实现流程\" class=\"headerlink\" title=\"实现流程\"></a>实现流程</h2><ol>\n<li><strong>localization：</strong>用selective search提取region proposals（即一个个候选框）</li>\n<li><strong>warped region：</strong>为了适配CNN输入，将region proposals格式归一化</li>\n<li><strong>feature extraction：</strong>CNN</li>\n<li><strong>classification：</strong>对于每个类别训练一个二分类SVM</li>\n<li><strong>综合策略：</strong>NMS(non-maximum suppression)，重叠的选最有信心的</li>\n</ol>\n<h2 id=\"实现细节\"><a href=\"#实现细节\" class=\"headerlink\" title=\"实现细节\"></a>实现细节</h2><ul>\n<li><strong>pre-training：</strong>直接用ILSVRC 2012训练CNN</li>\n<li><strong>fine-tuning：</strong>将pre-training训练出来的CNN换上匹配当前任务的输入层（warped region）和分类层（1000-way to 21-way）来训练模型<ul>\n<li><strong>训练集：</strong>warped region的label根据其与GT(Ground Truth)的IoU(Intersection-over-Union，交集/并集)的大小来定。这里将threshold设为0.5</li>\n</ul>\n</li>\n<li><strong>classifier：</strong>将fine-tuning训练出来的模型换上SVM作为分类层<ul>\n<li><strong>训练集：</strong>方法同fine-tuning的训练集，不过这里的threshold设为0.3</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Visualization\"><a href=\"#Visualization\" class=\"headerlink\" title=\"Visualization\"></a>Visualization</h2><ul>\n<li><strong>学习：</strong>定义某个unit学习的内容为<strong>让这个unit输出最高的input</strong>，即给定一堆input，unit对某个input_0的输出最高，则认为这个unit识别的就是这个input_0。通过这个定义可以将各个unit学习什么输出出来</li>\n</ul>\n<h2 id=\"Ablation-studies（切除）（用于验证有效性）\"><a href=\"#Ablation-studies（切除）（用于验证有效性）\" class=\"headerlink\" title=\"Ablation studies（切除）（用于验证有效性）\"></a>Ablation studies（切除）（用于验证有效性）</h2><ul>\n<li><strong>ablation：</strong>比较要不要某一个层，对于结果的影响</li>\n<li><strong>结果：</strong><ul>\n<li>在不进行fine-tuning的情况下，CNN中的全连接层并没有什么卵用</li>\n<li>在进行fine-tuning的情况下，提升很大</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Detection-error-analysis\"><a href=\"#Detection-error-analysis\" class=\"headerlink\" title=\"Detection error analysis\"></a>Detection error analysis</h2><ul>\n<li><strong>量化误差：</strong>给出了percentage of each type - total false positives图，说明了在各个FP时的误差类型分布。错误类型有以下<ul>\n<li>框错位置</li>\n<li>分成相似的类</li>\n<li>分成不相似的类</li>\n<li>分成背景</li>\n</ul>\n</li>\n<li><strong>结果：</strong>RCNN的错误基本都是框错了位置，作者认为这时因为<strong>bottom-up region proposals</strong>还有<strong>positional invariance learned from pre-training CNN</strong>导致的</li>\n<li><strong>解决方案：</strong>对于生成的框，要使用<strong>BB(Bounding box regression)</strong>进行进一步调整</li>\n</ul>\n<h2 id=\"收获\"><a href=\"#收获\" class=\"headerlink\" title=\"收获\"></a>收获</h2><ul>\n<li>object detection的任务</li>\n<li>RCNN</li>\n<li>评价模型的指标<ul>\n<li>定性：visualization</li>\n<li>定量：Ablation, detection error</li>\n</ul>\n</li>\n</ul>\n","excerpt":"","more":"<h2 id=\"任务简介\"><a href=\"#任务简介\" class=\"headerlink\" title=\"任务简介\"></a>任务简介</h2><ul>\n<li><strong>目标：</strong>object detection</li>\n<li><strong>输入：</strong>图片</li>\n<li><strong>输出：</strong>框住前景物体<strong>（有可能多种且每种有多个）</strong>，并且给物体标上类别</li>\n</ul>\n<h2 id=\"思路\"><a href=\"#思路\" class=\"headerlink\" title=\"思路\"></a>思路</h2><ol>\n<li><strong>分解成两个子任务</strong><ul>\n<li>localization </li>\n<li>classification</li>\n</ul>\n</li>\n<li><strong>localization：</strong>枚举</li>\n<li><strong>classification：</strong>CNN</li>\n<li>最后再<strong>筛掉</strong>多余的</li>\n</ol>\n<h2 id=\"实现流程\"><a href=\"#实现流程\" class=\"headerlink\" title=\"实现流程\"></a>实现流程</h2><ol>\n<li><strong>localization：</strong>用selective search提取region proposals（即一个个候选框）</li>\n<li><strong>warped region：</strong>为了适配CNN输入，将region proposals格式归一化</li>\n<li><strong>feature extraction：</strong>CNN</li>\n<li><strong>classification：</strong>对于每个类别训练一个二分类SVM</li>\n<li><strong>综合策略：</strong>NMS(non-maximum suppression)，重叠的选最有信心的</li>\n</ol>\n<h2 id=\"实现细节\"><a href=\"#实现细节\" class=\"headerlink\" title=\"实现细节\"></a>实现细节</h2><ul>\n<li><strong>pre-training：</strong>直接用ILSVRC 2012训练CNN</li>\n<li><strong>fine-tuning：</strong>将pre-training训练出来的CNN换上匹配当前任务的输入层（warped region）和分类层（1000-way to 21-way）来训练模型<ul>\n<li><strong>训练集：</strong>warped region的label根据其与GT(Ground Truth)的IoU(Intersection-over-Union，交集/并集)的大小来定。这里将threshold设为0.5</li>\n</ul>\n</li>\n<li><strong>classifier：</strong>将fine-tuning训练出来的模型换上SVM作为分类层<ul>\n<li><strong>训练集：</strong>方法同fine-tuning的训练集，不过这里的threshold设为0.3</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Visualization\"><a href=\"#Visualization\" class=\"headerlink\" title=\"Visualization\"></a>Visualization</h2><ul>\n<li><strong>学习：</strong>定义某个unit学习的内容为<strong>让这个unit输出最高的input</strong>，即给定一堆input，unit对某个input_0的输出最高，则认为这个unit识别的就是这个input_0。通过这个定义可以将各个unit学习什么输出出来</li>\n</ul>\n<h2 id=\"Ablation-studies（切除）（用于验证有效性）\"><a href=\"#Ablation-studies（切除）（用于验证有效性）\" class=\"headerlink\" title=\"Ablation studies（切除）（用于验证有效性）\"></a>Ablation studies（切除）（用于验证有效性）</h2><ul>\n<li><strong>ablation：</strong>比较要不要某一个层，对于结果的影响</li>\n<li><strong>结果：</strong><ul>\n<li>在不进行fine-tuning的情况下，CNN中的全连接层并没有什么卵用</li>\n<li>在进行fine-tuning的情况下，提升很大</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Detection-error-analysis\"><a href=\"#Detection-error-analysis\" class=\"headerlink\" title=\"Detection error analysis\"></a>Detection error analysis</h2><ul>\n<li><strong>量化误差：</strong>给出了percentage of each type - total false positives图，说明了在各个FP时的误差类型分布。错误类型有以下<ul>\n<li>框错位置</li>\n<li>分成相似的类</li>\n<li>分成不相似的类</li>\n<li>分成背景</li>\n</ul>\n</li>\n<li><strong>结果：</strong>RCNN的错误基本都是框错了位置，作者认为这时因为<strong>bottom-up region proposals</strong>还有<strong>positional invariance learned from pre-training CNN</strong>导致的</li>\n<li><strong>解决方案：</strong>对于生成的框，要使用<strong>BB(Bounding box regression)</strong>进行进一步调整</li>\n</ul>\n<h2 id=\"收获\"><a href=\"#收获\" class=\"headerlink\" title=\"收获\"></a>收获</h2><ul>\n<li>object detection的任务</li>\n<li>RCNN</li>\n<li>评价模型的指标<ul>\n<li>定性：visualization</li>\n<li>定量：Ablation, detection error</li>\n</ul>\n</li>\n</ul>\n"},{"title":"源码阅读《CarlaUE5整体架构》","date":"2024-08-13T14:36:17.000Z","description":["总结CarlaUE5的整体架构"],"_content":"\n# 前言\n\n总结了一下CarlaUE5的整体代码架构，该总结基于以下代码：\n\n- repo: https://github.com/carla-simulator/carla.git\n- branch: `ue5-dev`\n- commit: `141a8a2`\n\n# 整体架构\n\n<!-- <div style=\"width:400px; margin-left:auto; margin-right:auto;\" > -->\n<div style=\"max-width: 100%; margin: 0 auto;\">\n  {% asset_img carla.png 整体架构 %}\n</div>\n\n# Server架构\n\n<!-- <div style=\"width:auto; margin-left:auto; margin-right:auto;\" > -->\n<div style=\"max-width: 100%; margin: 0 auto;\">\n  {% asset_img server.png Server架构 %}\n</div>\n\n# Client架构\n\n<!-- <div style=\"width:400px; margin-left:auto; margin-right:auto;\" > -->\n<div style=\"max-width: 100%; margin: 0 auto;\">\n  {% asset_img client.png Client架构 %}\n</div>\n\n# PythonAPI\n\n<!-- <div style=\"width:400px; margin-left:auto; margin-right:auto;\" > -->\n<div style=\"max-width: 100%; margin: 0 auto;\">\n  {% asset_img pythonapi.png PythonAPI架构 %}\n</div>\n\n# 一些C++知识点\n\n## `weak_ptr`\n\n- motivation：只有`shared_ptr`的话会出现循环引用的问题\n- 具体来说，就是搞一个阉割版的，不会影响计数的“智能指针”，也就是`weak_ptr`了\n- `weak_ptr`不能直接用，只能先通过`.lock()`提级（构造）为`shared_ptr`之后再用\n- [这个blog](https://blog.csdn.net/qq_38410730/article/details/105903979)和[这个blog](https://blog.csdn.net/Xiejingfa/article/details/50772571)讲解得挺好的\n\n## `atomic`\n\n- motivation：针对变量的高效线程安全读写工具\n- 相比`lock`, `mutex`这些要跟跟内核打交道（有用户态和内核态的切换开销）的多线程工具，`atomic`属于硬件指令集的工具，效率更高\n- 对于`atomic<int> ai;`，需要调用`ai.load()`和`ai.store(1)`进行读写\n- 又由于编译器会对代码的实际执行顺序进行优化，`atomic`提供了一些指令去控制代码的执行顺序，具体可以参考[这个blog](https://www.cnblogs.com/kekec/p/14470150.html)\n\n## `enable_shared_from_this`\n\n- motivation：使得成员函数使用`shared_ptr<T>(this)`成为可能。假如没有额外支持的话，成员函数直接裸使用`shared_ptr<T>(this)`会导致`this`被析构两次\n- 核心要做的事情就是使得对象知道管理自己的`shared_ptr`是什么。具体来说：\n    - `esft`是个模板类，我们需要继承他。这个类里有一个`weak_ptr`成员，语意是指向管理本对象的`shared_ptr`；同时会提供一个`shared_from_this`方法，去调用`weak_ptr.lock()`\n    - 在调用`make_shared`的时候，会调用`dynamic_cast`来检查当前要构造的对象是否继承自`esft`，假如是，就会将其`weak_ptr`对象指向`shared_ptr`\n- 关于这部分，可以参考[这个blog](https://blog.csdn.net/caoshangpa/article/details/79392878)\n\n## `mutable`\n\n- motivation：允许`const`成员函数修改的成员变量\n\n## `pImpl`\n\n- motivation\n    - 完全隐藏实现细节\n    - 避免修改成员变量引起头文件变化\n- 具体来说，就是\n    - 在类的`private`里面前向声明一个`Impl`类\n    - 成员变量只保留一个指向`Impl`类的`unique_ptr`\n\n## `compare_exchange`\n\n- motivation：解决多线程编程时，读到的值在要用的时候可能已经被修改的问题，主要用于条件赋值，否则直接用`store`就好了\n- 思路就是在用的时候再验一下货。具体来说，就是搞了一个包含比较和赋值这两个指令的原子操作，只有当`self`跟`expected`相等的时候，`self`才会被赋值为`target`\n- 这个也被叫做CAS(Compare and Swap)，属于无锁编程的概念。\n- 可以参考[这个blog](https://mk.woa.com/q/295415/answer/123484?kmref=vkm_push)\n\n<!-- ```mermaid\n---\ntitle: Carla Architecture\n---\nflowchart LR\n    PY[Python API]\n    C_CPP[C++ Carla Client]\n    C_RPC[C++ RPC Client]\n    S_RPC[C++ RPC Server]\n    S_PLUGIN[C++ Carla UE5 Plugin]\n    UE[UE]\n    PY --- |boost python| C_CPP\n    subgraph \"Client (LibCarla)\"\n    C_CPP --- C_RPC\n    end\n\n    C_RPC <--RPC--> S_RPC\n\n    subgraph Server\n    S_RPC --- S_PLUGIN\n    S_PLUGIN --- UE\n    end\n```\n\n```mermaid\n---\ntitle: Server Architecture\n---\nsequenceDiagram\n    autonumber\n    participant UE as UE\n    participant GM as CarlaGameModeBase.cpp\n    participant GI as CarlaGameInstance.cpp\n    participant NGN as CarlaEngine.cpp <br> (Define tick logic)\n    participant OBS as WorldObserver.cpp <br> (Hold actor states)\n    participant EPI as CarlaEpisode.cpp <br> (Hold UE APIs)\n    participant SVR as CarlaServer.cpp <br> (RPC Server)\n    participant CLIENT as RPC Client\n\n    UE ->> GM : DefaultEngine.ini\n    UE ->> GI : DefaultEngine.ini\n    UE ->> GM : InitGame\n    GM ->> GI : NotifyInitGame\n    GI ->> NGN : NotifyInitGame\n    NGN ->> UE : Register OnPreTick and OnPostTick\n    NGN ->> SVR : Start RPC Server\n    Note over SVR: Initialize RPC Server <br> FCarlaServer::FPimpl::BindActions()\n    SVR -->> NGN : return BroadcastStream\n    NGN ->> OBS : Bind stream <br> WorldObserver.SetStream(BroadcastStream);\n\n    UE ->> GM : BeginPlay\n    GM ->> EPI : Episode->InitializeAtBeginPlay()\n    GM ->> GI : NotifyBeginEpisode(UCarlaEpisode &)\n    GI ->> NGN : NotifyBeginEpisode\n    NGN ->> SVR : NotifyBeginEpisode\n    SVR ->> EPI : Bind <br> Pimpl->Episode = &Episode\n\n    loop UE Tick\n        rect rgb(191, 223, 255)\n            note over UE, GM : Client to Server communication\n            UE ->> NGN : Call registered OnPreTick\n            NGN ->> SVR : Server.RunSome(1u)\n            CLIENT ->> SVR : RPC requests\n            SVR ->> EPI : Call Episode's methods\n        end\n\n        rect rgb(191, 223, 255)\n            note over UE, GM : Server to Client communication\n            UE ->> NGN : Call registered OnPostTick\n            NGN ->> OBS : WorldObserver.BroadcastTick\n            OBS ->> SVR : SerializeAndSend\n            SVR ->> CLIENT : Broadcast\n        end\n    end\n```\n\n```mermaid\n---\ntitle: Client Architecture\n---\nsequenceDiagram\n    autonumber\n    participant CLIENT as Client.h <br> (High-level Carla Client)\n    participant WORLD as World.cpp <br> (Core API for user)\n    participant SIM as detail/Simulator.cpp\n    participant EPI as detail/Episode.cpp\n    participant EPI_PXY as detail/EpisodeProxy.cpp <br> (Util Class to wrap detail/Simulator.cpp, help handling different pointer types)\n    participant RPC_CLIENT as detail/Client.cpp <br> (RPC Client)\n    participant SVR as RPC Server in UE\n\n    CLIENT ->> SIM : Client():_simulator(new detail::Simulator(host, port, worker_threads)\n    SIM ->> RPC_CLIENT : Simulator():_client(host, port, worker_threads)\n\n    rect rgb(191, 223, 255)\n        note right of CLIENT: Client::GetWorld() {return World(_simulator->GetCurrentEpisode())}\n\n        CLIENT ->> SIM : _simulator->GetCurrentEpisode()\n        rect rgb(200, 150, 255)\n            note right of CLIENT: Simulator::GetCurrentEpisode()\n            SIM ->> EPI : _episode = std::make_shared<Episode>(_client, std::weak_ptr<Simulator>(shared_from_this()));\n            SIM ->> EPI : _episode->Listen();\n            EPI ->> RPC_CLIENT : Register callback to update EpisodeState(snapshot): _client.SubscribeToStream\n            note over RPC_CLIENT :     _pimpl->streaming_client.Subscribe\n            SIM ->> EPI_PXY : epi_pxy = EpisodeProxy{shared_from_this()}\n            note over EPI_PXY: EpisodeProxy():_simulator(std::move(simulator))\n            SIM -->> CLIENT : return epi_pxy\n        end\n\n        CLIENT ->> WORLD : World(_simulator->GetCurrentEpisode())\n        note over WORLD: World():_episode(std::move(episode))\n    end\n\n    rect rgb(191, 223, 255)   \n        note over WORLD: Client to Server communication \n        note right of WORLD: e.g., World::SpawnActor() {_episode.Lock()->SpawnActor}\n        WORLD ->> EPI_PXY : _episode.Lock()\n        EPI_PXY -->> WORLD : return Load(_simulator) <br> Load(ptr) {return ptr.load() / ptr.lock()}\n        WORLD ->> SIM : _episode.Lock().SpawnActor\n        SIM ->> RPC_CLIENT : _client.SpawnActor\n        RPC_CLIENT ->> SVR: _pimpl->CallAndWait<rpc::Actor>(\"spawn_actor\", description, transform);\n    end\n\n    rect rgb(191, 223, 255)\n    note over EPI: Server to Client communication\n    loop\n    SVR ->> RPC_CLIENT : Stream broadcast\n    RPC_CLIENT ->> EPI : Call registered callback\n    end\n    end\n```\n\n```mermaid\n---\ntitle: Python API\n---\nflowchart LR\n    LIBCARLA[LibCarla]\n    H[PythonAPI.h]\n    CPP[PythonAPI.cpp]\n    CLIENT[PythonAPI\\carla\\src\\Client.cpp]\n    WORLD[PythonAPI\\carla\\src\\World.cpp]\n\n    LIBCARLA ---|include| H\n\n    subgraph \"Main of boost python\"\n    H --- CPP \n    end\n\n    subgraph Exporter\n    CPP --- CLIENT \n    CPP --- WORLD\n    CPP --- ...\n    end\n``` -->","source":"_posts/source-carlaue5-architecture.md","raw":"---\ntitle: 源码阅读《CarlaUE5整体架构》\ndate: 2024-08-13 22:36:17\ntags: \n  - CarlaUE5\ndescription:\n  - 总结CarlaUE5的整体架构\ncategories:\n  - 源码阅读\n---\n\n# 前言\n\n总结了一下CarlaUE5的整体代码架构，该总结基于以下代码：\n\n- repo: https://github.com/carla-simulator/carla.git\n- branch: `ue5-dev`\n- commit: `141a8a2`\n\n# 整体架构\n\n<!-- <div style=\"width:400px; margin-left:auto; margin-right:auto;\" > -->\n<div style=\"max-width: 100%; margin: 0 auto;\">\n  {% asset_img carla.png 整体架构 %}\n</div>\n\n# Server架构\n\n<!-- <div style=\"width:auto; margin-left:auto; margin-right:auto;\" > -->\n<div style=\"max-width: 100%; margin: 0 auto;\">\n  {% asset_img server.png Server架构 %}\n</div>\n\n# Client架构\n\n<!-- <div style=\"width:400px; margin-left:auto; margin-right:auto;\" > -->\n<div style=\"max-width: 100%; margin: 0 auto;\">\n  {% asset_img client.png Client架构 %}\n</div>\n\n# PythonAPI\n\n<!-- <div style=\"width:400px; margin-left:auto; margin-right:auto;\" > -->\n<div style=\"max-width: 100%; margin: 0 auto;\">\n  {% asset_img pythonapi.png PythonAPI架构 %}\n</div>\n\n# 一些C++知识点\n\n## `weak_ptr`\n\n- motivation：只有`shared_ptr`的话会出现循环引用的问题\n- 具体来说，就是搞一个阉割版的，不会影响计数的“智能指针”，也就是`weak_ptr`了\n- `weak_ptr`不能直接用，只能先通过`.lock()`提级（构造）为`shared_ptr`之后再用\n- [这个blog](https://blog.csdn.net/qq_38410730/article/details/105903979)和[这个blog](https://blog.csdn.net/Xiejingfa/article/details/50772571)讲解得挺好的\n\n## `atomic`\n\n- motivation：针对变量的高效线程安全读写工具\n- 相比`lock`, `mutex`这些要跟跟内核打交道（有用户态和内核态的切换开销）的多线程工具，`atomic`属于硬件指令集的工具，效率更高\n- 对于`atomic<int> ai;`，需要调用`ai.load()`和`ai.store(1)`进行读写\n- 又由于编译器会对代码的实际执行顺序进行优化，`atomic`提供了一些指令去控制代码的执行顺序，具体可以参考[这个blog](https://www.cnblogs.com/kekec/p/14470150.html)\n\n## `enable_shared_from_this`\n\n- motivation：使得成员函数使用`shared_ptr<T>(this)`成为可能。假如没有额外支持的话，成员函数直接裸使用`shared_ptr<T>(this)`会导致`this`被析构两次\n- 核心要做的事情就是使得对象知道管理自己的`shared_ptr`是什么。具体来说：\n    - `esft`是个模板类，我们需要继承他。这个类里有一个`weak_ptr`成员，语意是指向管理本对象的`shared_ptr`；同时会提供一个`shared_from_this`方法，去调用`weak_ptr.lock()`\n    - 在调用`make_shared`的时候，会调用`dynamic_cast`来检查当前要构造的对象是否继承自`esft`，假如是，就会将其`weak_ptr`对象指向`shared_ptr`\n- 关于这部分，可以参考[这个blog](https://blog.csdn.net/caoshangpa/article/details/79392878)\n\n## `mutable`\n\n- motivation：允许`const`成员函数修改的成员变量\n\n## `pImpl`\n\n- motivation\n    - 完全隐藏实现细节\n    - 避免修改成员变量引起头文件变化\n- 具体来说，就是\n    - 在类的`private`里面前向声明一个`Impl`类\n    - 成员变量只保留一个指向`Impl`类的`unique_ptr`\n\n## `compare_exchange`\n\n- motivation：解决多线程编程时，读到的值在要用的时候可能已经被修改的问题，主要用于条件赋值，否则直接用`store`就好了\n- 思路就是在用的时候再验一下货。具体来说，就是搞了一个包含比较和赋值这两个指令的原子操作，只有当`self`跟`expected`相等的时候，`self`才会被赋值为`target`\n- 这个也被叫做CAS(Compare and Swap)，属于无锁编程的概念。\n- 可以参考[这个blog](https://mk.woa.com/q/295415/answer/123484?kmref=vkm_push)\n\n<!-- ```mermaid\n---\ntitle: Carla Architecture\n---\nflowchart LR\n    PY[Python API]\n    C_CPP[C++ Carla Client]\n    C_RPC[C++ RPC Client]\n    S_RPC[C++ RPC Server]\n    S_PLUGIN[C++ Carla UE5 Plugin]\n    UE[UE]\n    PY --- |boost python| C_CPP\n    subgraph \"Client (LibCarla)\"\n    C_CPP --- C_RPC\n    end\n\n    C_RPC <--RPC--> S_RPC\n\n    subgraph Server\n    S_RPC --- S_PLUGIN\n    S_PLUGIN --- UE\n    end\n```\n\n```mermaid\n---\ntitle: Server Architecture\n---\nsequenceDiagram\n    autonumber\n    participant UE as UE\n    participant GM as CarlaGameModeBase.cpp\n    participant GI as CarlaGameInstance.cpp\n    participant NGN as CarlaEngine.cpp <br> (Define tick logic)\n    participant OBS as WorldObserver.cpp <br> (Hold actor states)\n    participant EPI as CarlaEpisode.cpp <br> (Hold UE APIs)\n    participant SVR as CarlaServer.cpp <br> (RPC Server)\n    participant CLIENT as RPC Client\n\n    UE ->> GM : DefaultEngine.ini\n    UE ->> GI : DefaultEngine.ini\n    UE ->> GM : InitGame\n    GM ->> GI : NotifyInitGame\n    GI ->> NGN : NotifyInitGame\n    NGN ->> UE : Register OnPreTick and OnPostTick\n    NGN ->> SVR : Start RPC Server\n    Note over SVR: Initialize RPC Server <br> FCarlaServer::FPimpl::BindActions()\n    SVR -->> NGN : return BroadcastStream\n    NGN ->> OBS : Bind stream <br> WorldObserver.SetStream(BroadcastStream);\n\n    UE ->> GM : BeginPlay\n    GM ->> EPI : Episode->InitializeAtBeginPlay()\n    GM ->> GI : NotifyBeginEpisode(UCarlaEpisode &)\n    GI ->> NGN : NotifyBeginEpisode\n    NGN ->> SVR : NotifyBeginEpisode\n    SVR ->> EPI : Bind <br> Pimpl->Episode = &Episode\n\n    loop UE Tick\n        rect rgb(191, 223, 255)\n            note over UE, GM : Client to Server communication\n            UE ->> NGN : Call registered OnPreTick\n            NGN ->> SVR : Server.RunSome(1u)\n            CLIENT ->> SVR : RPC requests\n            SVR ->> EPI : Call Episode's methods\n        end\n\n        rect rgb(191, 223, 255)\n            note over UE, GM : Server to Client communication\n            UE ->> NGN : Call registered OnPostTick\n            NGN ->> OBS : WorldObserver.BroadcastTick\n            OBS ->> SVR : SerializeAndSend\n            SVR ->> CLIENT : Broadcast\n        end\n    end\n```\n\n```mermaid\n---\ntitle: Client Architecture\n---\nsequenceDiagram\n    autonumber\n    participant CLIENT as Client.h <br> (High-level Carla Client)\n    participant WORLD as World.cpp <br> (Core API for user)\n    participant SIM as detail/Simulator.cpp\n    participant EPI as detail/Episode.cpp\n    participant EPI_PXY as detail/EpisodeProxy.cpp <br> (Util Class to wrap detail/Simulator.cpp, help handling different pointer types)\n    participant RPC_CLIENT as detail/Client.cpp <br> (RPC Client)\n    participant SVR as RPC Server in UE\n\n    CLIENT ->> SIM : Client():_simulator(new detail::Simulator(host, port, worker_threads)\n    SIM ->> RPC_CLIENT : Simulator():_client(host, port, worker_threads)\n\n    rect rgb(191, 223, 255)\n        note right of CLIENT: Client::GetWorld() {return World(_simulator->GetCurrentEpisode())}\n\n        CLIENT ->> SIM : _simulator->GetCurrentEpisode()\n        rect rgb(200, 150, 255)\n            note right of CLIENT: Simulator::GetCurrentEpisode()\n            SIM ->> EPI : _episode = std::make_shared<Episode>(_client, std::weak_ptr<Simulator>(shared_from_this()));\n            SIM ->> EPI : _episode->Listen();\n            EPI ->> RPC_CLIENT : Register callback to update EpisodeState(snapshot): _client.SubscribeToStream\n            note over RPC_CLIENT :     _pimpl->streaming_client.Subscribe\n            SIM ->> EPI_PXY : epi_pxy = EpisodeProxy{shared_from_this()}\n            note over EPI_PXY: EpisodeProxy():_simulator(std::move(simulator))\n            SIM -->> CLIENT : return epi_pxy\n        end\n\n        CLIENT ->> WORLD : World(_simulator->GetCurrentEpisode())\n        note over WORLD: World():_episode(std::move(episode))\n    end\n\n    rect rgb(191, 223, 255)   \n        note over WORLD: Client to Server communication \n        note right of WORLD: e.g., World::SpawnActor() {_episode.Lock()->SpawnActor}\n        WORLD ->> EPI_PXY : _episode.Lock()\n        EPI_PXY -->> WORLD : return Load(_simulator) <br> Load(ptr) {return ptr.load() / ptr.lock()}\n        WORLD ->> SIM : _episode.Lock().SpawnActor\n        SIM ->> RPC_CLIENT : _client.SpawnActor\n        RPC_CLIENT ->> SVR: _pimpl->CallAndWait<rpc::Actor>(\"spawn_actor\", description, transform);\n    end\n\n    rect rgb(191, 223, 255)\n    note over EPI: Server to Client communication\n    loop\n    SVR ->> RPC_CLIENT : Stream broadcast\n    RPC_CLIENT ->> EPI : Call registered callback\n    end\n    end\n```\n\n```mermaid\n---\ntitle: Python API\n---\nflowchart LR\n    LIBCARLA[LibCarla]\n    H[PythonAPI.h]\n    CPP[PythonAPI.cpp]\n    CLIENT[PythonAPI\\carla\\src\\Client.cpp]\n    WORLD[PythonAPI\\carla\\src\\World.cpp]\n\n    LIBCARLA ---|include| H\n\n    subgraph \"Main of boost python\"\n    H --- CPP \n    end\n\n    subgraph Exporter\n    CPP --- CLIENT \n    CPP --- WORLD\n    CPP --- ...\n    end\n``` -->","slug":"source-carlaue5-architecture","published":1,"updated":"2024-08-14T13:37:58.881Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clzvf192e001keqwonw4xqcj0","content":"<h1 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h1><p>总结了一下CarlaUE5的整体代码架构，该总结基于以下代码：</p>\n<ul>\n<li>repo: <a href=\"https://github.com/carla-simulator/carla.git\" target=\"_blank\" rel=\"external\">https://github.com/carla-simulator/carla.git</a></li>\n<li>branch: <code>ue5-dev</code></li>\n<li>commit: <code>141a8a2</code></li>\n</ul>\n<h1 id=\"整体架构\"><a href=\"#整体架构\" class=\"headerlink\" title=\"整体架构\"></a>整体架构</h1><!-- <div style=\"width:400px; margin-left:auto; margin-right:auto;\" > -->\n<div style=\"max-width: 100%; margin: 0 auto;\"><br>  <img src=\"/2024/08/13/source-carlaue5-architecture/carla.png\" alt=\"整体架构\" title=\"整体架构\"><br></div>\n\n<h1 id=\"Server架构\"><a href=\"#Server架构\" class=\"headerlink\" title=\"Server架构\"></a>Server架构</h1><!-- <div style=\"width:auto; margin-left:auto; margin-right:auto;\" > -->\n<div style=\"max-width: 100%; margin: 0 auto;\"><br>  <img src=\"/2024/08/13/source-carlaue5-architecture/server.png\" alt=\"Server架构\" title=\"Server架构\"><br></div>\n\n<h1 id=\"Client架构\"><a href=\"#Client架构\" class=\"headerlink\" title=\"Client架构\"></a>Client架构</h1><!-- <div style=\"width:400px; margin-left:auto; margin-right:auto;\" > -->\n<div style=\"max-width: 100%; margin: 0 auto;\"><br>  <img src=\"/2024/08/13/source-carlaue5-architecture/client.png\" alt=\"Client架构\" title=\"Client架构\"><br></div>\n\n<h1 id=\"PythonAPI\"><a href=\"#PythonAPI\" class=\"headerlink\" title=\"PythonAPI\"></a>PythonAPI</h1><!-- <div style=\"width:400px; margin-left:auto; margin-right:auto;\" > -->\n<div style=\"max-width: 100%; margin: 0 auto;\"><br>  <img src=\"/2024/08/13/source-carlaue5-architecture/pythonapi.png\" alt=\"PythonAPI架构\" title=\"PythonAPI架构\"><br></div>\n\n<h1 id=\"一些C-知识点\"><a href=\"#一些C-知识点\" class=\"headerlink\" title=\"一些C++知识点\"></a>一些C++知识点</h1><h2 id=\"weak-ptr\"><a href=\"#weak-ptr\" class=\"headerlink\" title=\"weak_ptr\"></a><code>weak_ptr</code></h2><ul>\n<li>motivation：只有<code>shared_ptr</code>的话会出现循环引用的问题</li>\n<li>具体来说，就是搞一个阉割版的，不会影响计数的“智能指针”，也就是<code>weak_ptr</code>了</li>\n<li><code>weak_ptr</code>不能直接用，只能先通过<code>.lock()</code>提级（构造）为<code>shared_ptr</code>之后再用</li>\n<li><a href=\"https://blog.csdn.net/qq_38410730/article/details/105903979\" target=\"_blank\" rel=\"external\">这个blog</a>和<a href=\"https://blog.csdn.net/Xiejingfa/article/details/50772571\" target=\"_blank\" rel=\"external\">这个blog</a>讲解得挺好的</li>\n</ul>\n<h2 id=\"atomic\"><a href=\"#atomic\" class=\"headerlink\" title=\"atomic\"></a><code>atomic</code></h2><ul>\n<li>motivation：针对变量的高效线程安全读写工具</li>\n<li>相比<code>lock</code>, <code>mutex</code>这些要跟跟内核打交道（有用户态和内核态的切换开销）的多线程工具，<code>atomic</code>属于硬件指令集的工具，效率更高</li>\n<li>对于<code>atomic&lt;int&gt; ai;</code>，需要调用<code>ai.load()</code>和<code>ai.store(1)</code>进行读写</li>\n<li>又由于编译器会对代码的实际执行顺序进行优化，<code>atomic</code>提供了一些指令去控制代码的执行顺序，具体可以参考<a href=\"https://www.cnblogs.com/kekec/p/14470150.html\" target=\"_blank\" rel=\"external\">这个blog</a></li>\n</ul>\n<h2 id=\"enable-shared-from-this\"><a href=\"#enable-shared-from-this\" class=\"headerlink\" title=\"enable_shared_from_this\"></a><code>enable_shared_from_this</code></h2><ul>\n<li>motivation：使得成员函数使用<code>shared_ptr&lt;T&gt;(this)</code>成为可能。假如没有额外支持的话，成员函数直接裸使用<code>shared_ptr&lt;T&gt;(this)</code>会导致<code>this</code>被析构两次</li>\n<li>核心要做的事情就是使得对象知道管理自己的<code>shared_ptr</code>是什么。具体来说：<ul>\n<li><code>esft</code>是个模板类，我们需要继承他。这个类里有一个<code>weak_ptr</code>成员，语意是指向管理本对象的<code>shared_ptr</code>；同时会提供一个<code>shared_from_this</code>方法，去调用<code>weak_ptr.lock()</code></li>\n<li>在调用<code>make_shared</code>的时候，会调用<code>dynamic_cast</code>来检查当前要构造的对象是否继承自<code>esft</code>，假如是，就会将其<code>weak_ptr</code>对象指向<code>shared_ptr</code></li>\n</ul>\n</li>\n<li>关于这部分，可以参考<a href=\"https://blog.csdn.net/caoshangpa/article/details/79392878\" target=\"_blank\" rel=\"external\">这个blog</a></li>\n</ul>\n<h2 id=\"mutable\"><a href=\"#mutable\" class=\"headerlink\" title=\"mutable\"></a><code>mutable</code></h2><ul>\n<li>motivation：允许<code>const</code>成员函数修改的成员变量</li>\n</ul>\n<h2 id=\"pImpl\"><a href=\"#pImpl\" class=\"headerlink\" title=\"pImpl\"></a><code>pImpl</code></h2><ul>\n<li>motivation<ul>\n<li>完全隐藏实现细节</li>\n<li>避免修改成员变量引起头文件变化</li>\n</ul>\n</li>\n<li>具体来说，就是<ul>\n<li>在类的<code>private</code>里面前向声明一个<code>Impl</code>类</li>\n<li>成员变量只保留一个指向<code>Impl</code>类的<code>unique_ptr</code></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"compare-exchange\"><a href=\"#compare-exchange\" class=\"headerlink\" title=\"compare_exchange\"></a><code>compare_exchange</code></h2><ul>\n<li>motivation：解决多线程编程时，读到的值在要用的时候可能已经被修改的问题，主要用于条件赋值，否则直接用<code>store</code>就好了</li>\n<li>思路就是在用的时候再验一下货。具体来说，就是搞了一个包含比较和赋值这两个指令的原子操作，只有当<code>self</code>跟<code>expected</code>相等的时候，<code>self</code>才会被赋值为<code>target</code></li>\n<li>这个也被叫做CAS(Compare and Swap)，属于无锁编程的概念。</li>\n<li>可以参考<a href=\"https://mk.woa.com/q/295415/answer/123484?kmref=vkm_push\" target=\"_blank\" rel=\"external\">这个blog</a></li>\n</ul>\n<!-- <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div></pre></td><td class=\"code\"><pre><div class=\"line\">---</div><div class=\"line\">title: Carla Architecture</div><div class=\"line\">---</div><div class=\"line\">flowchart LR</div><div class=\"line\">    PY[Python API]</div><div class=\"line\">    C_CPP[C++ Carla Client]</div><div class=\"line\">    C_RPC[C++ RPC Client]</div><div class=\"line\">    S_RPC[C++ RPC Server]</div><div class=\"line\">    S_PLUGIN[C++ Carla UE5 Plugin]</div><div class=\"line\">    UE[UE]</div><div class=\"line\">    PY --- |boost python| C_CPP</div><div class=\"line\">    subgraph &quot;Client (LibCarla)&quot;</div><div class=\"line\">    C_CPP --- C_RPC</div><div class=\"line\">    end</div><div class=\"line\"></div><div class=\"line\">    C_RPC &lt;--RPC--&gt; S_RPC</div><div class=\"line\"></div><div class=\"line\">    subgraph Server</div><div class=\"line\">    S_RPC --- S_PLUGIN</div><div class=\"line\">    S_PLUGIN --- UE</div><div class=\"line\">    end</div></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div></pre></td><td class=\"code\"><pre><div class=\"line\">---</div><div class=\"line\">title: Server Architecture</div><div class=\"line\">---</div><div class=\"line\">sequenceDiagram</div><div class=\"line\">    autonumber</div><div class=\"line\">    participant UE as UE</div><div class=\"line\">    participant GM as CarlaGameModeBase.cpp</div><div class=\"line\">    participant GI as CarlaGameInstance.cpp</div><div class=\"line\">    participant NGN as CarlaEngine.cpp &lt;br&gt; (Define tick logic)</div><div class=\"line\">    participant OBS as WorldObserver.cpp &lt;br&gt; (Hold actor states)</div><div class=\"line\">    participant EPI as CarlaEpisode.cpp &lt;br&gt; (Hold UE APIs)</div><div class=\"line\">    participant SVR as CarlaServer.cpp &lt;br&gt; (RPC Server)</div><div class=\"line\">    participant CLIENT as RPC Client</div><div class=\"line\"></div><div class=\"line\">    UE -&gt;&gt; GM : DefaultEngine.ini</div><div class=\"line\">    UE -&gt;&gt; GI : DefaultEngine.ini</div><div class=\"line\">    UE -&gt;&gt; GM : InitGame</div><div class=\"line\">    GM -&gt;&gt; GI : NotifyInitGame</div><div class=\"line\">    GI -&gt;&gt; NGN : NotifyInitGame</div><div class=\"line\">    NGN -&gt;&gt; UE : Register OnPreTick and OnPostTick</div><div class=\"line\">    NGN -&gt;&gt; SVR : Start RPC Server</div><div class=\"line\">    Note over SVR: Initialize RPC Server &lt;br&gt; FCarlaServer::FPimpl::BindActions()</div><div class=\"line\">    SVR --&gt;&gt; NGN : return BroadcastStream</div><div class=\"line\">    NGN -&gt;&gt; OBS : Bind stream &lt;br&gt; WorldObserver.SetStream(BroadcastStream);</div><div class=\"line\"></div><div class=\"line\">    UE -&gt;&gt; GM : BeginPlay</div><div class=\"line\">    GM -&gt;&gt; EPI : Episode-&gt;InitializeAtBeginPlay()</div><div class=\"line\">    GM -&gt;&gt; GI : NotifyBeginEpisode(UCarlaEpisode &amp;)</div><div class=\"line\">    GI -&gt;&gt; NGN : NotifyBeginEpisode</div><div class=\"line\">    NGN -&gt;&gt; SVR : NotifyBeginEpisode</div><div class=\"line\">    SVR -&gt;&gt; EPI : Bind &lt;br&gt; Pimpl-&gt;Episode = &amp;Episode</div><div class=\"line\"></div><div class=\"line\">    loop UE Tick</div><div class=\"line\">        rect rgb(191, 223, 255)</div><div class=\"line\">            note over UE, GM : Client to Server communication</div><div class=\"line\">            UE -&gt;&gt; NGN : Call registered OnPreTick</div><div class=\"line\">            NGN -&gt;&gt; SVR : Server.RunSome(1u)</div><div class=\"line\">            CLIENT -&gt;&gt; SVR : RPC requests</div><div class=\"line\">            SVR -&gt;&gt; EPI : Call Episode&apos;s methods</div><div class=\"line\">        end</div><div class=\"line\"></div><div class=\"line\">        rect rgb(191, 223, 255)</div><div class=\"line\">            note over UE, GM : Server to Client communication</div><div class=\"line\">            UE -&gt;&gt; NGN : Call registered OnPostTick</div><div class=\"line\">            NGN -&gt;&gt; OBS : WorldObserver.BroadcastTick</div><div class=\"line\">            OBS -&gt;&gt; SVR : SerializeAndSend</div><div class=\"line\">            SVR -&gt;&gt; CLIENT : Broadcast</div><div class=\"line\">        end</div><div class=\"line\">    end</div></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div></pre></td><td class=\"code\"><pre><div class=\"line\">---</div><div class=\"line\">title: Client Architecture</div><div class=\"line\">---</div><div class=\"line\">sequenceDiagram</div><div class=\"line\">    autonumber</div><div class=\"line\">    participant CLIENT as Client.h &lt;br&gt; (High-level Carla Client)</div><div class=\"line\">    participant WORLD as World.cpp &lt;br&gt; (Core API for user)</div><div class=\"line\">    participant SIM as detail/Simulator.cpp</div><div class=\"line\">    participant EPI as detail/Episode.cpp</div><div class=\"line\">    participant EPI_PXY as detail/EpisodeProxy.cpp &lt;br&gt; (Util Class to wrap detail/Simulator.cpp, help handling different pointer types)</div><div class=\"line\">    participant RPC_CLIENT as detail/Client.cpp &lt;br&gt; (RPC Client)</div><div class=\"line\">    participant SVR as RPC Server in UE</div><div class=\"line\"></div><div class=\"line\">    CLIENT -&gt;&gt; SIM : Client():_simulator(new detail::Simulator(host, port, worker_threads)</div><div class=\"line\">    SIM -&gt;&gt; RPC_CLIENT : Simulator():_client(host, port, worker_threads)</div><div class=\"line\"></div><div class=\"line\">    rect rgb(191, 223, 255)</div><div class=\"line\">        note right of CLIENT: Client::GetWorld() &#123;return World(_simulator-&gt;GetCurrentEpisode())&#125;</div><div class=\"line\"></div><div class=\"line\">        CLIENT -&gt;&gt; SIM : _simulator-&gt;GetCurrentEpisode()</div><div class=\"line\">        rect rgb(200, 150, 255)</div><div class=\"line\">            note right of CLIENT: Simulator::GetCurrentEpisode()</div><div class=\"line\">            SIM -&gt;&gt; EPI : _episode = std::make_shared&lt;Episode&gt;(_client, std::weak_ptr&lt;Simulator&gt;(shared_from_this()));</div><div class=\"line\">            SIM -&gt;&gt; EPI : _episode-&gt;Listen();</div><div class=\"line\">            EPI -&gt;&gt; RPC_CLIENT : Register callback to update EpisodeState(snapshot): _client.SubscribeToStream</div><div class=\"line\">            note over RPC_CLIENT :     _pimpl-&gt;streaming_client.Subscribe</div><div class=\"line\">            SIM -&gt;&gt; EPI_PXY : epi_pxy = EpisodeProxy&#123;shared_from_this()&#125;</div><div class=\"line\">            note over EPI_PXY: EpisodeProxy():_simulator(std::move(simulator))</div><div class=\"line\">            SIM --&gt;&gt; CLIENT : return epi_pxy</div><div class=\"line\">        end</div><div class=\"line\"></div><div class=\"line\">        CLIENT -&gt;&gt; WORLD : World(_simulator-&gt;GetCurrentEpisode())</div><div class=\"line\">        note over WORLD: World():_episode(std::move(episode))</div><div class=\"line\">    end</div><div class=\"line\"></div><div class=\"line\">    rect rgb(191, 223, 255)   </div><div class=\"line\">        note over WORLD: Client to Server communication </div><div class=\"line\">        note right of WORLD: e.g., World::SpawnActor() &#123;_episode.Lock()-&gt;SpawnActor&#125;</div><div class=\"line\">        WORLD -&gt;&gt; EPI_PXY : _episode.Lock()</div><div class=\"line\">        EPI_PXY --&gt;&gt; WORLD : return Load(_simulator) &lt;br&gt; Load(ptr) &#123;return ptr.load() / ptr.lock()&#125;</div><div class=\"line\">        WORLD -&gt;&gt; SIM : _episode.Lock().SpawnActor</div><div class=\"line\">        SIM -&gt;&gt; RPC_CLIENT : _client.SpawnActor</div><div class=\"line\">        RPC_CLIENT -&gt;&gt; SVR: _pimpl-&gt;CallAndWait&lt;rpc::Actor&gt;(&quot;spawn_actor&quot;, description, transform);</div><div class=\"line\">    end</div><div class=\"line\"></div><div class=\"line\">    rect rgb(191, 223, 255)</div><div class=\"line\">    note over EPI: Server to Client communication</div><div class=\"line\">    loop</div><div class=\"line\">    SVR -&gt;&gt; RPC_CLIENT : Stream broadcast</div><div class=\"line\">    RPC_CLIENT -&gt;&gt; EPI : Call registered callback</div><div class=\"line\">    end</div><div class=\"line\">    end</div></pre></td></tr></table></figure>\n<h2 id=\"mermaid\"><a href=\"#mermaid\" class=\"headerlink\" title=\"```mermaid\"></a>```mermaid</h2><h2 id=\"title-Python-API\"><a href=\"#title-Python-API\" class=\"headerlink\" title=\"title: Python API\"></a>title: Python API</h2><p>flowchart LR<br>    LIBCARLA[LibCarla]<br>    H[PythonAPI.h]<br>    CPP[PythonAPI.cpp]<br>    CLIENT[PythonAPI\\carla\\src\\Client.cpp]<br>    WORLD[PythonAPI\\carla\\src\\World.cpp]</p>\n<pre><code>LIBCARLA ---|include| H\n\nsubgraph &quot;Main of boost python&quot;\nH --- CPP \nend\n\nsubgraph Exporter\nCPP --- CLIENT \nCPP --- WORLD\nCPP --- ...\nend\n</code></pre><p>``` –&gt;</p>\n-->","excerpt":"","more":"<h1 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h1><p>总结了一下CarlaUE5的整体代码架构，该总结基于以下代码：</p>\n<ul>\n<li>repo: <a href=\"https://github.com/carla-simulator/carla.git\">https://github.com/carla-simulator/carla.git</a></li>\n<li>branch: <code>ue5-dev</code></li>\n<li>commit: <code>141a8a2</code></li>\n</ul>\n<h1 id=\"整体架构\"><a href=\"#整体架构\" class=\"headerlink\" title=\"整体架构\"></a>整体架构</h1><!-- <div style=\"width:400px; margin-left:auto; margin-right:auto;\" > -->\n<div style=\"max-width: 100%; margin: 0 auto;\"><br>  <img src=\"/2024/08/13/source-carlaue5-architecture/carla.png\" alt=\"整体架构\" title=\"整体架构\"><br></div>\n\n<h1 id=\"Server架构\"><a href=\"#Server架构\" class=\"headerlink\" title=\"Server架构\"></a>Server架构</h1><!-- <div style=\"width:auto; margin-left:auto; margin-right:auto;\" > -->\n<div style=\"max-width: 100%; margin: 0 auto;\"><br>  <img src=\"/2024/08/13/source-carlaue5-architecture/server.png\" alt=\"Server架构\" title=\"Server架构\"><br></div>\n\n<h1 id=\"Client架构\"><a href=\"#Client架构\" class=\"headerlink\" title=\"Client架构\"></a>Client架构</h1><!-- <div style=\"width:400px; margin-left:auto; margin-right:auto;\" > -->\n<div style=\"max-width: 100%; margin: 0 auto;\"><br>  <img src=\"/2024/08/13/source-carlaue5-architecture/client.png\" alt=\"Client架构\" title=\"Client架构\"><br></div>\n\n<h1 id=\"PythonAPI\"><a href=\"#PythonAPI\" class=\"headerlink\" title=\"PythonAPI\"></a>PythonAPI</h1><!-- <div style=\"width:400px; margin-left:auto; margin-right:auto;\" > -->\n<div style=\"max-width: 100%; margin: 0 auto;\"><br>  <img src=\"/2024/08/13/source-carlaue5-architecture/pythonapi.png\" alt=\"PythonAPI架构\" title=\"PythonAPI架构\"><br></div>\n\n<h1 id=\"一些C-知识点\"><a href=\"#一些C-知识点\" class=\"headerlink\" title=\"一些C++知识点\"></a>一些C++知识点</h1><h2 id=\"weak-ptr\"><a href=\"#weak-ptr\" class=\"headerlink\" title=\"weak_ptr\"></a><code>weak_ptr</code></h2><ul>\n<li>motivation：只有<code>shared_ptr</code>的话会出现循环引用的问题</li>\n<li>具体来说，就是搞一个阉割版的，不会影响计数的“智能指针”，也就是<code>weak_ptr</code>了</li>\n<li><code>weak_ptr</code>不能直接用，只能先通过<code>.lock()</code>提级（构造）为<code>shared_ptr</code>之后再用</li>\n<li><a href=\"https://blog.csdn.net/qq_38410730/article/details/105903979\">这个blog</a>和<a href=\"https://blog.csdn.net/Xiejingfa/article/details/50772571\">这个blog</a>讲解得挺好的</li>\n</ul>\n<h2 id=\"atomic\"><a href=\"#atomic\" class=\"headerlink\" title=\"atomic\"></a><code>atomic</code></h2><ul>\n<li>motivation：针对变量的高效线程安全读写工具</li>\n<li>相比<code>lock</code>, <code>mutex</code>这些要跟跟内核打交道（有用户态和内核态的切换开销）的多线程工具，<code>atomic</code>属于硬件指令集的工具，效率更高</li>\n<li>对于<code>atomic&lt;int&gt; ai;</code>，需要调用<code>ai.load()</code>和<code>ai.store(1)</code>进行读写</li>\n<li>又由于编译器会对代码的实际执行顺序进行优化，<code>atomic</code>提供了一些指令去控制代码的执行顺序，具体可以参考<a href=\"https://www.cnblogs.com/kekec/p/14470150.html\">这个blog</a></li>\n</ul>\n<h2 id=\"enable-shared-from-this\"><a href=\"#enable-shared-from-this\" class=\"headerlink\" title=\"enable_shared_from_this\"></a><code>enable_shared_from_this</code></h2><ul>\n<li>motivation：使得成员函数使用<code>shared_ptr&lt;T&gt;(this)</code>成为可能。假如没有额外支持的话，成员函数直接裸使用<code>shared_ptr&lt;T&gt;(this)</code>会导致<code>this</code>被析构两次</li>\n<li>核心要做的事情就是使得对象知道管理自己的<code>shared_ptr</code>是什么。具体来说：<ul>\n<li><code>esft</code>是个模板类，我们需要继承他。这个类里有一个<code>weak_ptr</code>成员，语意是指向管理本对象的<code>shared_ptr</code>；同时会提供一个<code>shared_from_this</code>方法，去调用<code>weak_ptr.lock()</code></li>\n<li>在调用<code>make_shared</code>的时候，会调用<code>dynamic_cast</code>来检查当前要构造的对象是否继承自<code>esft</code>，假如是，就会将其<code>weak_ptr</code>对象指向<code>shared_ptr</code></li>\n</ul>\n</li>\n<li>关于这部分，可以参考<a href=\"https://blog.csdn.net/caoshangpa/article/details/79392878\">这个blog</a></li>\n</ul>\n<h2 id=\"mutable\"><a href=\"#mutable\" class=\"headerlink\" title=\"mutable\"></a><code>mutable</code></h2><ul>\n<li>motivation：允许<code>const</code>成员函数修改的成员变量</li>\n</ul>\n<h2 id=\"pImpl\"><a href=\"#pImpl\" class=\"headerlink\" title=\"pImpl\"></a><code>pImpl</code></h2><ul>\n<li>motivation<ul>\n<li>完全隐藏实现细节</li>\n<li>避免修改成员变量引起头文件变化</li>\n</ul>\n</li>\n<li>具体来说，就是<ul>\n<li>在类的<code>private</code>里面前向声明一个<code>Impl</code>类</li>\n<li>成员变量只保留一个指向<code>Impl</code>类的<code>unique_ptr</code></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"compare-exchange\"><a href=\"#compare-exchange\" class=\"headerlink\" title=\"compare_exchange\"></a><code>compare_exchange</code></h2><ul>\n<li>motivation：解决多线程编程时，读到的值在要用的时候可能已经被修改的问题，主要用于条件赋值，否则直接用<code>store</code>就好了</li>\n<li>思路就是在用的时候再验一下货。具体来说，就是搞了一个包含比较和赋值这两个指令的原子操作，只有当<code>self</code>跟<code>expected</code>相等的时候，<code>self</code>才会被赋值为<code>target</code></li>\n<li>这个也被叫做CAS(Compare and Swap)，属于无锁编程的概念。</li>\n<li>可以参考<a href=\"https://mk.woa.com/q/295415/answer/123484?kmref=vkm_push\">这个blog</a></li>\n</ul>\n<!-- <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div></pre></td><td class=\"code\"><pre><div class=\"line\">---</div><div class=\"line\">title: Carla Architecture</div><div class=\"line\">---</div><div class=\"line\">flowchart LR</div><div class=\"line\">    PY[Python API]</div><div class=\"line\">    C_CPP[C++ Carla Client]</div><div class=\"line\">    C_RPC[C++ RPC Client]</div><div class=\"line\">    S_RPC[C++ RPC Server]</div><div class=\"line\">    S_PLUGIN[C++ Carla UE5 Plugin]</div><div class=\"line\">    UE[UE]</div><div class=\"line\">    PY --- |boost python| C_CPP</div><div class=\"line\">    subgraph &quot;Client (LibCarla)&quot;</div><div class=\"line\">    C_CPP --- C_RPC</div><div class=\"line\">    end</div><div class=\"line\"></div><div class=\"line\">    C_RPC &lt;--RPC--&gt; S_RPC</div><div class=\"line\"></div><div class=\"line\">    subgraph Server</div><div class=\"line\">    S_RPC --- S_PLUGIN</div><div class=\"line\">    S_PLUGIN --- UE</div><div class=\"line\">    end</div></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div></pre></td><td class=\"code\"><pre><div class=\"line\">---</div><div class=\"line\">title: Server Architecture</div><div class=\"line\">---</div><div class=\"line\">sequenceDiagram</div><div class=\"line\">    autonumber</div><div class=\"line\">    participant UE as UE</div><div class=\"line\">    participant GM as CarlaGameModeBase.cpp</div><div class=\"line\">    participant GI as CarlaGameInstance.cpp</div><div class=\"line\">    participant NGN as CarlaEngine.cpp &lt;br&gt; (Define tick logic)</div><div class=\"line\">    participant OBS as WorldObserver.cpp &lt;br&gt; (Hold actor states)</div><div class=\"line\">    participant EPI as CarlaEpisode.cpp &lt;br&gt; (Hold UE APIs)</div><div class=\"line\">    participant SVR as CarlaServer.cpp &lt;br&gt; (RPC Server)</div><div class=\"line\">    participant CLIENT as RPC Client</div><div class=\"line\"></div><div class=\"line\">    UE -&gt;&gt; GM : DefaultEngine.ini</div><div class=\"line\">    UE -&gt;&gt; GI : DefaultEngine.ini</div><div class=\"line\">    UE -&gt;&gt; GM : InitGame</div><div class=\"line\">    GM -&gt;&gt; GI : NotifyInitGame</div><div class=\"line\">    GI -&gt;&gt; NGN : NotifyInitGame</div><div class=\"line\">    NGN -&gt;&gt; UE : Register OnPreTick and OnPostTick</div><div class=\"line\">    NGN -&gt;&gt; SVR : Start RPC Server</div><div class=\"line\">    Note over SVR: Initialize RPC Server &lt;br&gt; FCarlaServer::FPimpl::BindActions()</div><div class=\"line\">    SVR --&gt;&gt; NGN : return BroadcastStream</div><div class=\"line\">    NGN -&gt;&gt; OBS : Bind stream &lt;br&gt; WorldObserver.SetStream(BroadcastStream);</div><div class=\"line\"></div><div class=\"line\">    UE -&gt;&gt; GM : BeginPlay</div><div class=\"line\">    GM -&gt;&gt; EPI : Episode-&gt;InitializeAtBeginPlay()</div><div class=\"line\">    GM -&gt;&gt; GI : NotifyBeginEpisode(UCarlaEpisode &amp;)</div><div class=\"line\">    GI -&gt;&gt; NGN : NotifyBeginEpisode</div><div class=\"line\">    NGN -&gt;&gt; SVR : NotifyBeginEpisode</div><div class=\"line\">    SVR -&gt;&gt; EPI : Bind &lt;br&gt; Pimpl-&gt;Episode = &amp;Episode</div><div class=\"line\"></div><div class=\"line\">    loop UE Tick</div><div class=\"line\">        rect rgb(191, 223, 255)</div><div class=\"line\">            note over UE, GM : Client to Server communication</div><div class=\"line\">            UE -&gt;&gt; NGN : Call registered OnPreTick</div><div class=\"line\">            NGN -&gt;&gt; SVR : Server.RunSome(1u)</div><div class=\"line\">            CLIENT -&gt;&gt; SVR : RPC requests</div><div class=\"line\">            SVR -&gt;&gt; EPI : Call Episode&apos;s methods</div><div class=\"line\">        end</div><div class=\"line\"></div><div class=\"line\">        rect rgb(191, 223, 255)</div><div class=\"line\">            note over UE, GM : Server to Client communication</div><div class=\"line\">            UE -&gt;&gt; NGN : Call registered OnPostTick</div><div class=\"line\">            NGN -&gt;&gt; OBS : WorldObserver.BroadcastTick</div><div class=\"line\">            OBS -&gt;&gt; SVR : SerializeAndSend</div><div class=\"line\">            SVR -&gt;&gt; CLIENT : Broadcast</div><div class=\"line\">        end</div><div class=\"line\">    end</div></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div></pre></td><td class=\"code\"><pre><div class=\"line\">---</div><div class=\"line\">title: Client Architecture</div><div class=\"line\">---</div><div class=\"line\">sequenceDiagram</div><div class=\"line\">    autonumber</div><div class=\"line\">    participant CLIENT as Client.h &lt;br&gt; (High-level Carla Client)</div><div class=\"line\">    participant WORLD as World.cpp &lt;br&gt; (Core API for user)</div><div class=\"line\">    participant SIM as detail/Simulator.cpp</div><div class=\"line\">    participant EPI as detail/Episode.cpp</div><div class=\"line\">    participant EPI_PXY as detail/EpisodeProxy.cpp &lt;br&gt; (Util Class to wrap detail/Simulator.cpp, help handling different pointer types)</div><div class=\"line\">    participant RPC_CLIENT as detail/Client.cpp &lt;br&gt; (RPC Client)</div><div class=\"line\">    participant SVR as RPC Server in UE</div><div class=\"line\"></div><div class=\"line\">    CLIENT -&gt;&gt; SIM : Client():_simulator(new detail::Simulator(host, port, worker_threads)</div><div class=\"line\">    SIM -&gt;&gt; RPC_CLIENT : Simulator():_client(host, port, worker_threads)</div><div class=\"line\"></div><div class=\"line\">    rect rgb(191, 223, 255)</div><div class=\"line\">        note right of CLIENT: Client::GetWorld() &#123;return World(_simulator-&gt;GetCurrentEpisode())&#125;</div><div class=\"line\"></div><div class=\"line\">        CLIENT -&gt;&gt; SIM : _simulator-&gt;GetCurrentEpisode()</div><div class=\"line\">        rect rgb(200, 150, 255)</div><div class=\"line\">            note right of CLIENT: Simulator::GetCurrentEpisode()</div><div class=\"line\">            SIM -&gt;&gt; EPI : _episode = std::make_shared&lt;Episode&gt;(_client, std::weak_ptr&lt;Simulator&gt;(shared_from_this()));</div><div class=\"line\">            SIM -&gt;&gt; EPI : _episode-&gt;Listen();</div><div class=\"line\">            EPI -&gt;&gt; RPC_CLIENT : Register callback to update EpisodeState(snapshot): _client.SubscribeToStream</div><div class=\"line\">            note over RPC_CLIENT :     _pimpl-&gt;streaming_client.Subscribe</div><div class=\"line\">            SIM -&gt;&gt; EPI_PXY : epi_pxy = EpisodeProxy&#123;shared_from_this()&#125;</div><div class=\"line\">            note over EPI_PXY: EpisodeProxy():_simulator(std::move(simulator))</div><div class=\"line\">            SIM --&gt;&gt; CLIENT : return epi_pxy</div><div class=\"line\">        end</div><div class=\"line\"></div><div class=\"line\">        CLIENT -&gt;&gt; WORLD : World(_simulator-&gt;GetCurrentEpisode())</div><div class=\"line\">        note over WORLD: World():_episode(std::move(episode))</div><div class=\"line\">    end</div><div class=\"line\"></div><div class=\"line\">    rect rgb(191, 223, 255)   </div><div class=\"line\">        note over WORLD: Client to Server communication </div><div class=\"line\">        note right of WORLD: e.g., World::SpawnActor() &#123;_episode.Lock()-&gt;SpawnActor&#125;</div><div class=\"line\">        WORLD -&gt;&gt; EPI_PXY : _episode.Lock()</div><div class=\"line\">        EPI_PXY --&gt;&gt; WORLD : return Load(_simulator) &lt;br&gt; Load(ptr) &#123;return ptr.load() / ptr.lock()&#125;</div><div class=\"line\">        WORLD -&gt;&gt; SIM : _episode.Lock().SpawnActor</div><div class=\"line\">        SIM -&gt;&gt; RPC_CLIENT : _client.SpawnActor</div><div class=\"line\">        RPC_CLIENT -&gt;&gt; SVR: _pimpl-&gt;CallAndWait&lt;rpc::Actor&gt;(&quot;spawn_actor&quot;, description, transform);</div><div class=\"line\">    end</div><div class=\"line\"></div><div class=\"line\">    rect rgb(191, 223, 255)</div><div class=\"line\">    note over EPI: Server to Client communication</div><div class=\"line\">    loop</div><div class=\"line\">    SVR -&gt;&gt; RPC_CLIENT : Stream broadcast</div><div class=\"line\">    RPC_CLIENT -&gt;&gt; EPI : Call registered callback</div><div class=\"line\">    end</div><div class=\"line\">    end</div></pre></td></tr></table></figure>\n<h2 id=\"mermaid\"><a href=\"#mermaid\" class=\"headerlink\" title=\"```mermaid\"></a>```mermaid</h2><h2 id=\"title-Python-API\"><a href=\"#title-Python-API\" class=\"headerlink\" title=\"title: Python API\"></a>title: Python API</h2><p>flowchart LR<br>    LIBCARLA[LibCarla]<br>    H[PythonAPI.h]<br>    CPP[PythonAPI.cpp]<br>    CLIENT[PythonAPI\\carla\\src\\Client.cpp]<br>    WORLD[PythonAPI\\carla\\src\\World.cpp]</p>\n<pre><code>LIBCARLA ---|include| H\n\nsubgraph &quot;Main of boost python&quot;\nH --- CPP \nend\n\nsubgraph Exporter\nCPP --- CLIENT \nCPP --- WORLD\nCPP --- ...\nend\n</code></pre><p>``` –&gt;</p>\n"},{"title":"源码阅读《PyTorch PPO》","date":"2018-10-09T03:56:11.000Z","description":["基于PyTorch的PPO的源码阅读"],"_content":"\n## Introduction\n\n本文介绍的Proximal Policy Optimization (PPO)实现是基于PyTorch的，其Github地址在[这里](https://github.com/ikostrikov/pytorch-a2c-ppo-acktr)。实际上它一共实现了三个算法，包括PPO、A2C以及ACKTR。这份代码的逻辑抽象做得不错，三个算法共用了很多代码，因此看懂了PPO对于理解另外两个算法的实现有很大帮助。\n\n这份PPO代码依赖于[OpenAI baselines](https://github.com/openai/baselines)，主要用到了其并行环境的wrapper。由于PPO和OpenAI baselines的代码一直在更新，所以最新的代码跟本文可能有所出入。**本文所述代码对应的commit id前缀**为：\n\n- PPO：3aea397\n- OpenAI baselines：f272969\n\n下面先介绍代码的**逻辑框架**，然后再看**具体代码**。具体代码部分以一个类似于**深度优先**的方式展开。\n\n## Logical framework\n\n这份代码按照RL的思想，将代码分成了environment和robot（之所以不用agent这个词，主要是为了跟下面的变量名做区分）两大模块。environment部分主要是`envs`这个变量，它通过OpenAI baselines的wrapper实现了多环境并行化。robot部分分为了三个子模块，第一个是parametric policy变量`actor_critic`；第二个是用来保存trajectory的`rollouts`变量；最后一个是用于参数更新的RL algorithm变量`agent`。总结一下，其**逻辑框架**如下:\n\n- environment\n\t- multiprocess wrapper: `envs`\n- robot\n\t- parametric policy: `actor_critic`\n    - trajectory: `rollouts`\n\t- RL algorithm: `agent`\n\n整个**交互流程**基本上是robot从`envs`中得到一个observation，然后根据`actor_critic`作出反应，并且将交互过程记录到`rollouts`中，接着使用`agent`根据`rollouts`中的信息来更新`actor_critic`。\n\n## Source code\n\n### main\n\n```py\n# PPO_ROOT/main.py\n\ndef main():\n    ...\n    \n    # 创建并行交互环境envs\n    envs = [make_env(args.env_name, args.seed, i, args.log_dir, args.add_timestep)\n                for i in range(args.num_processes)]\n    \n    if args.num_processes > 1:\n        envs = SubprocVecEnv(envs)\n    else:\n        ...\n    \n    if len(envs.observation_space.shape) == 1:\n        envs = VecNormalize(envs, gamma=args.gamma)\n    \n    ...\n    \n    for j in range(num_updates):\n        for step in range(args.num_steps):\n            # 通过rollouts获得t时刻的的信息（e.g., o_t），使用actor_critic(i.e., policy)来计算a_t\n            with torch.no_grad():\n                value, action, action_log_prob, states = actor_critic.act(\n                        rollouts.observations[step],\n                        rollouts.states[step],\n                        rollouts.masks[step])\n    \n            ...\n    \n            # 使用a_t跟envs(i.e., environment)进行交互\n            obs, reward, done, info = envs.step(cpu_actions)\n            \n            ...\n    \n            # 将交互信息存入rollouts中\n            rollouts.insert(current_obs, states, action, action_log_prob, value, reward, masks)\n    \n        ...\n        \n        # 根据rollouts提供的信息，使用RL algorithm（i.e., PPO）对actor_critic(i.e., policy)进行参数更新\n        value_loss, action_loss, dist_entropy = agent.update(rollouts)\n    \n        ...\n```\n\n以上代码将`main`函数的核心部分提了出来。可见，`main`函数主要有以下**核心步骤**：\n\n1. 创建并行交互环境`envs`；\n2. 通过`actor_critic`与环境进行交互；\n3. 将交互信息存入`rollouts`；\n4. 使用`agent`进行参数更新。\n\n接下来分别展开介绍这四个变量。\n\n---\n\n### envs\n\n由`main`函数中可见，`envs`变量通过`make_env`、`SubprocVecEnv`和`VecNormalize`得到，接下来分别介绍这三个函数。\n\n#### make_env\n\n```py\n# PPO_ROOT/envs.py\n\ndef make_env(env_id, seed, rank, log_dir, add_timestep):\n    def _thunk():\n    \t# 最基本的gym env\n        if env_id.startswith(\"dm\"):\n        \t...\n        else:\n            env = gym.make(env_id)\n        \n        ...\n\n        # 加了一个Monitor wrapper（注意这个Monitor不是保存视频的gym.Wrappers.Monitor）来记录信息（默认是/tmp/gym/）\n        if log_dir is not None:\n            env = bench.Monitor(env, os.path.join(log_dir, str(rank)))\n\n        ...\n\n        return env\n\n    # 返回的是一个函数而不是env\n    return _thunk\n```\n\n从上述代码可以看出，`make_env`函数返回了一个函数`_thunk`，调用该函数可以得到一个gym env。（`make_env`选择返回一个函数而不直接返回一个gym env的原因我不太清楚，我推测是跟**序列化和反序列化**有关。从下面的`SubprocVecEnv`可见，`make_env`的返回结果要传给一个在另一个进程运行的函数`worker`，这个过程应该是需要做序列化和反序列化的，可能传函数比较好实现或者比较高效？）\n\n#### SubprocVecEnv\n\n```py\n# BASELINE_ROOT/common/vec_env/subproc_vec_env.py\n\ndef worker(remote, parent_remote, env_fn_wrapper):\n    parent_remote.close()\n    # 实例化env，相当于_thunk()（之所以需要.x()是因为用了CloudpickleWrapper，估计是为了处理函数序列化和反序列化的一些问题）\n    env = env_fn_wrapper.x()\n    # 相当于一个一直在跑的env服务\n    while True:\n        cmd, data = remote.recv()\n        if cmd == 'step':\n            ob, reward, done, info = env.step(data)\n            if done:\n                ob = env.reset()\n            remote.send((ob, reward, done, info))\n        elif cmd == 'reset':\n            ob = env.reset()\n            remote.send(ob)\n        elif cmd == 'render':\n            remote.send(env.render(mode='rgb_array'))\n        elif cmd == 'close':\n            remote.close()\n            break\n        elif cmd == 'get_spaces':\n            remote.send((env.observation_space, env.action_space))\n        else:\n            raise NotImplementedError\n```\n\n`SubprocVecEnv`首先创建不同的subprocess去运行`worker`，每一个`worker`基本上相当于一个**env服务**，每收到一个指令就对env执行相应的操作并且返回信息。`worker`的参数`env_fn_wrapper`就是`_thunk`加了一个`CloudpickleWrapper`，该`wrapper`好像是用来辅助序列化和反序列化的。\n\n```py\n# BASELINE_ROOT/common/vec_env/subproc_vec_env.py\n\nclass SubprocVecEnv(VecEnv):\n    ...\n\n    # 给subprocess发送step指令\n    def step_async(self, actions):\n        for remote, action in zip(self.remotes, actions):\n            remote.send(('step', action))\n        self.waiting = True\n\n\n    # 接收并拼接subprocess返回的交互信息\n    def step_wait(self):\n        results = [remote.recv() for remote in self.remotes]\n        self.waiting = False\n        obs, rews, dones, infos = zip(*results)\n        return np.stack(obs), np.stack(rews), np.stack(dones), infos\n\n    ...\n\n    # 这个函数在基类VecEnv中\n    def step(self, actions):\n        self.step_async(actions)\n        return self.step_wait()\n```\n\n有了上面的subprocee，主进程中的`SubprocVecEnv`只需要**重载**`step`, `reset`等关键函数为发送相应指令给subprocess，然后将数据拼接起来，就实现了跟环境的并行交互。\n\n#### VecNormalize\n\n```py\n# BASELINE_ROOT/common/vec_env/vec_normalize.py\n\nclass VecNormalize(VecEnvWrapper):\n    def __init__(self, venv, ob=True, ret=True, clipob=10., cliprew=10., gamma=0.99, epsilon=1e-8):\n        VecEnvWrapper.__init__(self, venv)\n        # mean, std计算器\n        self.ob_rms = RunningMeanStd(shape=self.observation_space.shape) if ob else None\n        self.ret_rms = RunningMeanStd(shape=()) if ret else None\n\n    ...\n\n    def step_wait(self):\n        obs, rews, news, infos = self.venv.step_wait()\n        self.ret = self.ret * self.gamma + rews\n\n        # 对obs做normalization（mean, std），具体代码见下面\n        obs = self._obfilt(obs)\n        # 对reward做normalization（不用mean只用std，而且用的是return的std）\n        if self.ret_rms:\n            self.ret_rms.update(self.ret)\n            rews = np.clip(rews / np.sqrt(self.ret_rms.var + self.epsilon), -self.cliprew, self.cliprew)\n        return obs, rews, news, infos\n\n    def _obfilt(self, obs):\n        if self.ob_rms:\n            self.ob_rms.update(obs)\n            obs = np.clip((obs - self.ob_rms.mean) / np.sqrt(self.ob_rms.var + self.epsilon), -self.clipob, self.clipob)\n            return obs\n        else:\n            return obs\n\n    ...\n```\n\n从上述代码可见，`VecNormalize`也是一个wrapper，主要功能是**对observation和reward做normalization**。\n\n---\n\n### actor_critic\n\n```py\n# PPO_ROOT/model.py\n\nclass Policy(nn.Module):\n    ...\n\n    def act(self, inputs, states, masks, deterministic=False):\n    \t# self.base集actor和critic于一身\n    \t# value：V(o_t)\n    \t# actor_features：actor网络的倒数第二层\n    \t# states：RNN的hidden states\n        value, actor_features, states = self.base(inputs, states, masks)\n        # dist最后的action分布\\pi(A_t | o_t)\n        dist = self.dist(actor_features)\n\n       \t...\n\n    ...\n\n    def evaluate_actions(self, inputs, states, masks, action):\n        ...\n\n        # value: V(o_t)\n        # action_log_probs: \\log(\\pi(a_t | o_t))\n        # dist_entropy: Entropy(\\pi(A_t | o_t))\n        # states：RNN的hidden states\n        return value, action_log_probs, dist_entropy, states\n```\n\n表示parametric policy的`actor_critic`变量对应的类为`Policy`，基本上就是包含actor和critic的神经网络。如上所示，其主要函数为`act`和`evaluate_actions`，前者用于**求action**，后者用于从网络中**获取参数更新要用到的信息**（e.g., $V(o_t), \\log\\pi(a_t \\vert o_t)$）。\n\n---\n\n### rollouts\n\n```py\n# PPO_ROOT/storage.py\n\nclass RolloutStorage(object):\n    ...\n\n    # 保存交互信息\n    # current_obs: o_{t+1}\n    # state: RNN中的hidden state，\n    # action: a_t\n    # action_log_prob: \\pi(a_t | o_t)\n    # value_pred: V(o_t)\n    # reward: r_t\n    # mask: 标识o_{t+1}时刻是否通过gym.reset()得到，是的话为0，否的话为1\n    def insert(self, current_obs, state, action, action_log_prob, value_pred, reward, mask):\n        ...\n\n    ...\n\n    # 计算return\n    # 可以选择使用GAE（GAE+V）还是MC来计算return\n    def compute_returns(self, next_value, use_gae, gamma, tau):\n        if use_gae:\n            ...\n        else:\n            ...\n\n    # 将num_steps * num_processes份transitions随机分成num_mini_batch个mini_batch，每次返回一个mini_batch\n    def feed_forward_generator(self, advantages, num_mini_batch):\n        ...\n\n    # 考虑到RNN的顺序有关性质，以process为单位将num_steps * num_processes份transitions随机分成num_mini_batch个mini_batch，每次返回一个mini_batch\n    def recurrent_generator(self, advantages, num_mini_batch):\n        ...\n```\n\n用于储存trajectory的`rollouts`变量对应的类为`RolloutStorage`，主要功能是**存和取**，其对应的成员函数分别是`insert`和`xxx_generator`。还有一个`compute_returns`函数用于辅助计算更新参数所需的return。\n\n---\n\n### agent\n\n```py\n# PPO_ROOT/algo/ppo.py\n\nclass PPO(object):\n    ...\n\n    def update(self, rollouts):\n    \t# \\hat{A)_t in PPO paper（return的计算可能用的GAE，也可能用的MC）\n        # 并且对advantage做normalization\n        advantages = rollouts.returns[:-1] - rollouts.value_preds[:-1]\n        advantages = (advantages - advantages.mean()) / (\n            advantages.std() + 1e-5)\n\n        ...\n\n        for e in range(self.ppo_epoch):\n            ...\n\n            for sample in data_generator:\n                ...\n\n                # r_t(\\theta) in the PPO paper\n                ratio = torch.exp(action_log_probs - old_action_log_probs_batch)\n                surr1 = ratio * adv_targ\n                surr2 = torch.clamp(ratio, 1.0 - self.clip_param,\n                                           1.0 + self.clip_param) * adv_targ\n                # -L_t^{CLIP}(\\theta) in the PPO paper\n                action_loss = -torch.min(surr1, surr2).mean()\n\n               \t# L_t^{VF}(\\theta) in the PPO paper\n                value_loss = F.mse_loss(return_batch, values)\n\n                self.optimizer.zero_grad()\n                # -L_t^{CLIP+VF+S}(\\theta) in the PPO paper（因为我们想做minization，而lr是正的，因此要加负号）\n                (value_loss * self.value_loss_coef + action_loss -\n                 dist_entropy * self.entropy_coef).backward()\n                nn.utils.clip_grad_norm_(self.actor_critic.parameters(),\n                                         self.max_grad_norm)\n                self.optimizer.step()\n\n                ...\n\n        ...\n```\n\n表示RL algorithm的变量`agent`对应的类是`PPO`，由上可见，就是利用`rollouts`中的信息对`actor_critic`进行参数更新，更新的方式参照PPO的论文。\n\n## Summary\n\n至此，这份PPO代码的核心部分已经描述完毕。可见，代码的实现跟论文所说的还是有很多**细节**上的差异的，比如说对observation和reward的normalization，对return的计算，对advantage的normalization以及对gradient的clip等等。","source":"_posts/source-ppo.md","raw":"---\ntitle: 源码阅读《PyTorch PPO》\ndate: 2018-10-09 11:56:11\ntags: \n  - pytorch-ppo\ndescription:\n  - 基于PyTorch的PPO的源码阅读\ncategories:\n  - 源码阅读\n---\n\n## Introduction\n\n本文介绍的Proximal Policy Optimization (PPO)实现是基于PyTorch的，其Github地址在[这里](https://github.com/ikostrikov/pytorch-a2c-ppo-acktr)。实际上它一共实现了三个算法，包括PPO、A2C以及ACKTR。这份代码的逻辑抽象做得不错，三个算法共用了很多代码，因此看懂了PPO对于理解另外两个算法的实现有很大帮助。\n\n这份PPO代码依赖于[OpenAI baselines](https://github.com/openai/baselines)，主要用到了其并行环境的wrapper。由于PPO和OpenAI baselines的代码一直在更新，所以最新的代码跟本文可能有所出入。**本文所述代码对应的commit id前缀**为：\n\n- PPO：3aea397\n- OpenAI baselines：f272969\n\n下面先介绍代码的**逻辑框架**，然后再看**具体代码**。具体代码部分以一个类似于**深度优先**的方式展开。\n\n## Logical framework\n\n这份代码按照RL的思想，将代码分成了environment和robot（之所以不用agent这个词，主要是为了跟下面的变量名做区分）两大模块。environment部分主要是`envs`这个变量，它通过OpenAI baselines的wrapper实现了多环境并行化。robot部分分为了三个子模块，第一个是parametric policy变量`actor_critic`；第二个是用来保存trajectory的`rollouts`变量；最后一个是用于参数更新的RL algorithm变量`agent`。总结一下，其**逻辑框架**如下:\n\n- environment\n\t- multiprocess wrapper: `envs`\n- robot\n\t- parametric policy: `actor_critic`\n    - trajectory: `rollouts`\n\t- RL algorithm: `agent`\n\n整个**交互流程**基本上是robot从`envs`中得到一个observation，然后根据`actor_critic`作出反应，并且将交互过程记录到`rollouts`中，接着使用`agent`根据`rollouts`中的信息来更新`actor_critic`。\n\n## Source code\n\n### main\n\n```py\n# PPO_ROOT/main.py\n\ndef main():\n    ...\n    \n    # 创建并行交互环境envs\n    envs = [make_env(args.env_name, args.seed, i, args.log_dir, args.add_timestep)\n                for i in range(args.num_processes)]\n    \n    if args.num_processes > 1:\n        envs = SubprocVecEnv(envs)\n    else:\n        ...\n    \n    if len(envs.observation_space.shape) == 1:\n        envs = VecNormalize(envs, gamma=args.gamma)\n    \n    ...\n    \n    for j in range(num_updates):\n        for step in range(args.num_steps):\n            # 通过rollouts获得t时刻的的信息（e.g., o_t），使用actor_critic(i.e., policy)来计算a_t\n            with torch.no_grad():\n                value, action, action_log_prob, states = actor_critic.act(\n                        rollouts.observations[step],\n                        rollouts.states[step],\n                        rollouts.masks[step])\n    \n            ...\n    \n            # 使用a_t跟envs(i.e., environment)进行交互\n            obs, reward, done, info = envs.step(cpu_actions)\n            \n            ...\n    \n            # 将交互信息存入rollouts中\n            rollouts.insert(current_obs, states, action, action_log_prob, value, reward, masks)\n    \n        ...\n        \n        # 根据rollouts提供的信息，使用RL algorithm（i.e., PPO）对actor_critic(i.e., policy)进行参数更新\n        value_loss, action_loss, dist_entropy = agent.update(rollouts)\n    \n        ...\n```\n\n以上代码将`main`函数的核心部分提了出来。可见，`main`函数主要有以下**核心步骤**：\n\n1. 创建并行交互环境`envs`；\n2. 通过`actor_critic`与环境进行交互；\n3. 将交互信息存入`rollouts`；\n4. 使用`agent`进行参数更新。\n\n接下来分别展开介绍这四个变量。\n\n---\n\n### envs\n\n由`main`函数中可见，`envs`变量通过`make_env`、`SubprocVecEnv`和`VecNormalize`得到，接下来分别介绍这三个函数。\n\n#### make_env\n\n```py\n# PPO_ROOT/envs.py\n\ndef make_env(env_id, seed, rank, log_dir, add_timestep):\n    def _thunk():\n    \t# 最基本的gym env\n        if env_id.startswith(\"dm\"):\n        \t...\n        else:\n            env = gym.make(env_id)\n        \n        ...\n\n        # 加了一个Monitor wrapper（注意这个Monitor不是保存视频的gym.Wrappers.Monitor）来记录信息（默认是/tmp/gym/）\n        if log_dir is not None:\n            env = bench.Monitor(env, os.path.join(log_dir, str(rank)))\n\n        ...\n\n        return env\n\n    # 返回的是一个函数而不是env\n    return _thunk\n```\n\n从上述代码可以看出，`make_env`函数返回了一个函数`_thunk`，调用该函数可以得到一个gym env。（`make_env`选择返回一个函数而不直接返回一个gym env的原因我不太清楚，我推测是跟**序列化和反序列化**有关。从下面的`SubprocVecEnv`可见，`make_env`的返回结果要传给一个在另一个进程运行的函数`worker`，这个过程应该是需要做序列化和反序列化的，可能传函数比较好实现或者比较高效？）\n\n#### SubprocVecEnv\n\n```py\n# BASELINE_ROOT/common/vec_env/subproc_vec_env.py\n\ndef worker(remote, parent_remote, env_fn_wrapper):\n    parent_remote.close()\n    # 实例化env，相当于_thunk()（之所以需要.x()是因为用了CloudpickleWrapper，估计是为了处理函数序列化和反序列化的一些问题）\n    env = env_fn_wrapper.x()\n    # 相当于一个一直在跑的env服务\n    while True:\n        cmd, data = remote.recv()\n        if cmd == 'step':\n            ob, reward, done, info = env.step(data)\n            if done:\n                ob = env.reset()\n            remote.send((ob, reward, done, info))\n        elif cmd == 'reset':\n            ob = env.reset()\n            remote.send(ob)\n        elif cmd == 'render':\n            remote.send(env.render(mode='rgb_array'))\n        elif cmd == 'close':\n            remote.close()\n            break\n        elif cmd == 'get_spaces':\n            remote.send((env.observation_space, env.action_space))\n        else:\n            raise NotImplementedError\n```\n\n`SubprocVecEnv`首先创建不同的subprocess去运行`worker`，每一个`worker`基本上相当于一个**env服务**，每收到一个指令就对env执行相应的操作并且返回信息。`worker`的参数`env_fn_wrapper`就是`_thunk`加了一个`CloudpickleWrapper`，该`wrapper`好像是用来辅助序列化和反序列化的。\n\n```py\n# BASELINE_ROOT/common/vec_env/subproc_vec_env.py\n\nclass SubprocVecEnv(VecEnv):\n    ...\n\n    # 给subprocess发送step指令\n    def step_async(self, actions):\n        for remote, action in zip(self.remotes, actions):\n            remote.send(('step', action))\n        self.waiting = True\n\n\n    # 接收并拼接subprocess返回的交互信息\n    def step_wait(self):\n        results = [remote.recv() for remote in self.remotes]\n        self.waiting = False\n        obs, rews, dones, infos = zip(*results)\n        return np.stack(obs), np.stack(rews), np.stack(dones), infos\n\n    ...\n\n    # 这个函数在基类VecEnv中\n    def step(self, actions):\n        self.step_async(actions)\n        return self.step_wait()\n```\n\n有了上面的subprocee，主进程中的`SubprocVecEnv`只需要**重载**`step`, `reset`等关键函数为发送相应指令给subprocess，然后将数据拼接起来，就实现了跟环境的并行交互。\n\n#### VecNormalize\n\n```py\n# BASELINE_ROOT/common/vec_env/vec_normalize.py\n\nclass VecNormalize(VecEnvWrapper):\n    def __init__(self, venv, ob=True, ret=True, clipob=10., cliprew=10., gamma=0.99, epsilon=1e-8):\n        VecEnvWrapper.__init__(self, venv)\n        # mean, std计算器\n        self.ob_rms = RunningMeanStd(shape=self.observation_space.shape) if ob else None\n        self.ret_rms = RunningMeanStd(shape=()) if ret else None\n\n    ...\n\n    def step_wait(self):\n        obs, rews, news, infos = self.venv.step_wait()\n        self.ret = self.ret * self.gamma + rews\n\n        # 对obs做normalization（mean, std），具体代码见下面\n        obs = self._obfilt(obs)\n        # 对reward做normalization（不用mean只用std，而且用的是return的std）\n        if self.ret_rms:\n            self.ret_rms.update(self.ret)\n            rews = np.clip(rews / np.sqrt(self.ret_rms.var + self.epsilon), -self.cliprew, self.cliprew)\n        return obs, rews, news, infos\n\n    def _obfilt(self, obs):\n        if self.ob_rms:\n            self.ob_rms.update(obs)\n            obs = np.clip((obs - self.ob_rms.mean) / np.sqrt(self.ob_rms.var + self.epsilon), -self.clipob, self.clipob)\n            return obs\n        else:\n            return obs\n\n    ...\n```\n\n从上述代码可见，`VecNormalize`也是一个wrapper，主要功能是**对observation和reward做normalization**。\n\n---\n\n### actor_critic\n\n```py\n# PPO_ROOT/model.py\n\nclass Policy(nn.Module):\n    ...\n\n    def act(self, inputs, states, masks, deterministic=False):\n    \t# self.base集actor和critic于一身\n    \t# value：V(o_t)\n    \t# actor_features：actor网络的倒数第二层\n    \t# states：RNN的hidden states\n        value, actor_features, states = self.base(inputs, states, masks)\n        # dist最后的action分布\\pi(A_t | o_t)\n        dist = self.dist(actor_features)\n\n       \t...\n\n    ...\n\n    def evaluate_actions(self, inputs, states, masks, action):\n        ...\n\n        # value: V(o_t)\n        # action_log_probs: \\log(\\pi(a_t | o_t))\n        # dist_entropy: Entropy(\\pi(A_t | o_t))\n        # states：RNN的hidden states\n        return value, action_log_probs, dist_entropy, states\n```\n\n表示parametric policy的`actor_critic`变量对应的类为`Policy`，基本上就是包含actor和critic的神经网络。如上所示，其主要函数为`act`和`evaluate_actions`，前者用于**求action**，后者用于从网络中**获取参数更新要用到的信息**（e.g., $V(o_t), \\log\\pi(a_t \\vert o_t)$）。\n\n---\n\n### rollouts\n\n```py\n# PPO_ROOT/storage.py\n\nclass RolloutStorage(object):\n    ...\n\n    # 保存交互信息\n    # current_obs: o_{t+1}\n    # state: RNN中的hidden state，\n    # action: a_t\n    # action_log_prob: \\pi(a_t | o_t)\n    # value_pred: V(o_t)\n    # reward: r_t\n    # mask: 标识o_{t+1}时刻是否通过gym.reset()得到，是的话为0，否的话为1\n    def insert(self, current_obs, state, action, action_log_prob, value_pred, reward, mask):\n        ...\n\n    ...\n\n    # 计算return\n    # 可以选择使用GAE（GAE+V）还是MC来计算return\n    def compute_returns(self, next_value, use_gae, gamma, tau):\n        if use_gae:\n            ...\n        else:\n            ...\n\n    # 将num_steps * num_processes份transitions随机分成num_mini_batch个mini_batch，每次返回一个mini_batch\n    def feed_forward_generator(self, advantages, num_mini_batch):\n        ...\n\n    # 考虑到RNN的顺序有关性质，以process为单位将num_steps * num_processes份transitions随机分成num_mini_batch个mini_batch，每次返回一个mini_batch\n    def recurrent_generator(self, advantages, num_mini_batch):\n        ...\n```\n\n用于储存trajectory的`rollouts`变量对应的类为`RolloutStorage`，主要功能是**存和取**，其对应的成员函数分别是`insert`和`xxx_generator`。还有一个`compute_returns`函数用于辅助计算更新参数所需的return。\n\n---\n\n### agent\n\n```py\n# PPO_ROOT/algo/ppo.py\n\nclass PPO(object):\n    ...\n\n    def update(self, rollouts):\n    \t# \\hat{A)_t in PPO paper（return的计算可能用的GAE，也可能用的MC）\n        # 并且对advantage做normalization\n        advantages = rollouts.returns[:-1] - rollouts.value_preds[:-1]\n        advantages = (advantages - advantages.mean()) / (\n            advantages.std() + 1e-5)\n\n        ...\n\n        for e in range(self.ppo_epoch):\n            ...\n\n            for sample in data_generator:\n                ...\n\n                # r_t(\\theta) in the PPO paper\n                ratio = torch.exp(action_log_probs - old_action_log_probs_batch)\n                surr1 = ratio * adv_targ\n                surr2 = torch.clamp(ratio, 1.0 - self.clip_param,\n                                           1.0 + self.clip_param) * adv_targ\n                # -L_t^{CLIP}(\\theta) in the PPO paper\n                action_loss = -torch.min(surr1, surr2).mean()\n\n               \t# L_t^{VF}(\\theta) in the PPO paper\n                value_loss = F.mse_loss(return_batch, values)\n\n                self.optimizer.zero_grad()\n                # -L_t^{CLIP+VF+S}(\\theta) in the PPO paper（因为我们想做minization，而lr是正的，因此要加负号）\n                (value_loss * self.value_loss_coef + action_loss -\n                 dist_entropy * self.entropy_coef).backward()\n                nn.utils.clip_grad_norm_(self.actor_critic.parameters(),\n                                         self.max_grad_norm)\n                self.optimizer.step()\n\n                ...\n\n        ...\n```\n\n表示RL algorithm的变量`agent`对应的类是`PPO`，由上可见，就是利用`rollouts`中的信息对`actor_critic`进行参数更新，更新的方式参照PPO的论文。\n\n## Summary\n\n至此，这份PPO代码的核心部分已经描述完毕。可见，代码的实现跟论文所说的还是有很多**细节**上的差异的，比如说对observation和reward的normalization，对return的计算，对advantage的normalization以及对gradient的clip等等。","slug":"source-ppo","published":1,"updated":"2024-08-13T16:03:47.872Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clzvf192g001oeqwojmkhperx","content":"<h2 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h2><p>本文介绍的Proximal Policy Optimization (PPO)实现是基于PyTorch的，其Github地址在<a href=\"https://github.com/ikostrikov/pytorch-a2c-ppo-acktr\" target=\"_blank\" rel=\"external\">这里</a>。实际上它一共实现了三个算法，包括PPO、A2C以及ACKTR。这份代码的逻辑抽象做得不错，三个算法共用了很多代码，因此看懂了PPO对于理解另外两个算法的实现有很大帮助。</p>\n<p>这份PPO代码依赖于<a href=\"https://github.com/openai/baselines\" target=\"_blank\" rel=\"external\">OpenAI baselines</a>，主要用到了其并行环境的wrapper。由于PPO和OpenAI baselines的代码一直在更新，所以最新的代码跟本文可能有所出入。<strong>本文所述代码对应的commit id前缀</strong>为：</p>\n<ul>\n<li>PPO：3aea397</li>\n<li>OpenAI baselines：f272969</li>\n</ul>\n<p>下面先介绍代码的<strong>逻辑框架</strong>，然后再看<strong>具体代码</strong>。具体代码部分以一个类似于<strong>深度优先</strong>的方式展开。</p>\n<h2 id=\"Logical-framework\"><a href=\"#Logical-framework\" class=\"headerlink\" title=\"Logical framework\"></a>Logical framework</h2><p>这份代码按照RL的思想，将代码分成了environment和robot（之所以不用agent这个词，主要是为了跟下面的变量名做区分）两大模块。environment部分主要是<code>envs</code>这个变量，它通过OpenAI baselines的wrapper实现了多环境并行化。robot部分分为了三个子模块，第一个是parametric policy变量<code>actor_critic</code>；第二个是用来保存trajectory的<code>rollouts</code>变量；最后一个是用于参数更新的RL algorithm变量<code>agent</code>。总结一下，其<strong>逻辑框架</strong>如下:</p>\n<ul>\n<li>environment<ul>\n<li>multiprocess wrapper: <code>envs</code></li>\n</ul>\n</li>\n<li>robot<ul>\n<li>parametric policy: <code>actor_critic</code></li>\n<li>trajectory: <code>rollouts</code></li>\n<li>RL algorithm: <code>agent</code></li>\n</ul>\n</li>\n</ul>\n<p>整个<strong>交互流程</strong>基本上是robot从<code>envs</code>中得到一个observation，然后根据<code>actor_critic</code>作出反应，并且将交互过程记录到<code>rollouts</code>中，接着使用<code>agent</code>根据<code>rollouts</code>中的信息来更新<code>actor_critic</code>。</p>\n<h2 id=\"Source-code\"><a href=\"#Source-code\" class=\"headerlink\" title=\"Source code\"></a>Source code</h2><h3 id=\"main\"><a href=\"#main\" class=\"headerlink\" title=\"main\"></a>main</h3><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># PPO_ROOT/main.py</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">main</span><span class=\"params\">()</span>:</span></div><div class=\"line\">    ...</div><div class=\"line\">    </div><div class=\"line\">    <span class=\"comment\"># 创建并行交互环境envs</span></div><div class=\"line\">    envs = [make_env(args.env_name, args.seed, i, args.log_dir, args.add_timestep)</div><div class=\"line\">                <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(args.num_processes)]</div><div class=\"line\">    </div><div class=\"line\">    <span class=\"keyword\">if</span> args.num_processes &gt; <span class=\"number\">1</span>:</div><div class=\"line\">        envs = SubprocVecEnv(envs)</div><div class=\"line\">    <span class=\"keyword\">else</span>:</div><div class=\"line\">        ...</div><div class=\"line\">    </div><div class=\"line\">    <span class=\"keyword\">if</span> len(envs.observation_space.shape) == <span class=\"number\">1</span>:</div><div class=\"line\">        envs = VecNormalize(envs, gamma=args.gamma)</div><div class=\"line\">    </div><div class=\"line\">    ...</div><div class=\"line\">    </div><div class=\"line\">    <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(num_updates):</div><div class=\"line\">        <span class=\"keyword\">for</span> step <span class=\"keyword\">in</span> range(args.num_steps):</div><div class=\"line\">            <span class=\"comment\"># 通过rollouts获得t时刻的的信息（e.g., o_t），使用actor_critic(i.e., policy)来计算a_t</span></div><div class=\"line\">            <span class=\"keyword\">with</span> torch.no_grad():</div><div class=\"line\">                value, action, action_log_prob, states = actor_critic.act(</div><div class=\"line\">                        rollouts.observations[step],</div><div class=\"line\">                        rollouts.states[step],</div><div class=\"line\">                        rollouts.masks[step])</div><div class=\"line\">    </div><div class=\"line\">            ...</div><div class=\"line\">    </div><div class=\"line\">            <span class=\"comment\"># 使用a_t跟envs(i.e., environment)进行交互</span></div><div class=\"line\">            obs, reward, done, info = envs.step(cpu_actions)</div><div class=\"line\">            </div><div class=\"line\">            ...</div><div class=\"line\">    </div><div class=\"line\">            <span class=\"comment\"># 将交互信息存入rollouts中</span></div><div class=\"line\">            rollouts.insert(current_obs, states, action, action_log_prob, value, reward, masks)</div><div class=\"line\">    </div><div class=\"line\">        ...</div><div class=\"line\">        </div><div class=\"line\">        <span class=\"comment\"># 根据rollouts提供的信息，使用RL algorithm（i.e., PPO）对actor_critic(i.e., policy)进行参数更新</span></div><div class=\"line\">        value_loss, action_loss, dist_entropy = agent.update(rollouts)</div><div class=\"line\">    </div><div class=\"line\">        ...</div></pre></td></tr></table></figure>\n<p>以上代码将<code>main</code>函数的核心部分提了出来。可见，<code>main</code>函数主要有以下<strong>核心步骤</strong>：</p>\n<ol>\n<li>创建并行交互环境<code>envs</code>；</li>\n<li>通过<code>actor_critic</code>与环境进行交互；</li>\n<li>将交互信息存入<code>rollouts</code>；</li>\n<li>使用<code>agent</code>进行参数更新。</li>\n</ol>\n<p>接下来分别展开介绍这四个变量。</p>\n<hr>\n<h3 id=\"envs\"><a href=\"#envs\" class=\"headerlink\" title=\"envs\"></a>envs</h3><p>由<code>main</code>函数中可见，<code>envs</code>变量通过<code>make_env</code>、<code>SubprocVecEnv</code>和<code>VecNormalize</code>得到，接下来分别介绍这三个函数。</p>\n<h4 id=\"make-env\"><a href=\"#make-env\" class=\"headerlink\" title=\"make_env\"></a>make_env</h4><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># PPO_ROOT/envs.py</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">make_env</span><span class=\"params\">(env_id, seed, rank, log_dir, add_timestep)</span>:</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_thunk</span><span class=\"params\">()</span>:</span></div><div class=\"line\">    \t<span class=\"comment\"># 最基本的gym env</span></div><div class=\"line\">        <span class=\"keyword\">if</span> env_id.startswith(<span class=\"string\">\"dm\"</span>):</div><div class=\"line\">        \t...</div><div class=\"line\">        <span class=\"keyword\">else</span>:</div><div class=\"line\">            env = gym.make(env_id)</div><div class=\"line\">        </div><div class=\"line\">        ...</div><div class=\"line\"></div><div class=\"line\">        <span class=\"comment\"># 加了一个Monitor wrapper（注意这个Monitor不是保存视频的gym.Wrappers.Monitor）来记录信息（默认是/tmp/gym/）</span></div><div class=\"line\">        <span class=\"keyword\">if</span> log_dir <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"keyword\">None</span>:</div><div class=\"line\">            env = bench.Monitor(env, os.path.join(log_dir, str(rank)))</div><div class=\"line\"></div><div class=\"line\">        ...</div><div class=\"line\"></div><div class=\"line\">        <span class=\"keyword\">return</span> env</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\"># 返回的是一个函数而不是env</span></div><div class=\"line\">    <span class=\"keyword\">return</span> _thunk</div></pre></td></tr></table></figure>\n<p>从上述代码可以看出，<code>make_env</code>函数返回了一个函数<code>_thunk</code>，调用该函数可以得到一个gym env。（<code>make_env</code>选择返回一个函数而不直接返回一个gym env的原因我不太清楚，我推测是跟<strong>序列化和反序列化</strong>有关。从下面的<code>SubprocVecEnv</code>可见，<code>make_env</code>的返回结果要传给一个在另一个进程运行的函数<code>worker</code>，这个过程应该是需要做序列化和反序列化的，可能传函数比较好实现或者比较高效？）</p>\n<h4 id=\"SubprocVecEnv\"><a href=\"#SubprocVecEnv\" class=\"headerlink\" title=\"SubprocVecEnv\"></a>SubprocVecEnv</h4><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># BASELINE_ROOT/common/vec_env/subproc_vec_env.py</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">worker</span><span class=\"params\">(remote, parent_remote, env_fn_wrapper)</span>:</span></div><div class=\"line\">    parent_remote.close()</div><div class=\"line\">    <span class=\"comment\"># 实例化env，相当于_thunk()（之所以需要.x()是因为用了CloudpickleWrapper，估计是为了处理函数序列化和反序列化的一些问题）</span></div><div class=\"line\">    env = env_fn_wrapper.x()</div><div class=\"line\">    <span class=\"comment\"># 相当于一个一直在跑的env服务</span></div><div class=\"line\">    <span class=\"keyword\">while</span> <span class=\"keyword\">True</span>:</div><div class=\"line\">        cmd, data = remote.recv()</div><div class=\"line\">        <span class=\"keyword\">if</span> cmd == <span class=\"string\">'step'</span>:</div><div class=\"line\">            ob, reward, done, info = env.step(data)</div><div class=\"line\">            <span class=\"keyword\">if</span> done:</div><div class=\"line\">                ob = env.reset()</div><div class=\"line\">            remote.send((ob, reward, done, info))</div><div class=\"line\">        <span class=\"keyword\">elif</span> cmd == <span class=\"string\">'reset'</span>:</div><div class=\"line\">            ob = env.reset()</div><div class=\"line\">            remote.send(ob)</div><div class=\"line\">        <span class=\"keyword\">elif</span> cmd == <span class=\"string\">'render'</span>:</div><div class=\"line\">            remote.send(env.render(mode=<span class=\"string\">'rgb_array'</span>))</div><div class=\"line\">        <span class=\"keyword\">elif</span> cmd == <span class=\"string\">'close'</span>:</div><div class=\"line\">            remote.close()</div><div class=\"line\">            <span class=\"keyword\">break</span></div><div class=\"line\">        <span class=\"keyword\">elif</span> cmd == <span class=\"string\">'get_spaces'</span>:</div><div class=\"line\">            remote.send((env.observation_space, env.action_space))</div><div class=\"line\">        <span class=\"keyword\">else</span>:</div><div class=\"line\">            <span class=\"keyword\">raise</span> NotImplementedError</div></pre></td></tr></table></figure>\n<p><code>SubprocVecEnv</code>首先创建不同的subprocess去运行<code>worker</code>，每一个<code>worker</code>基本上相当于一个<strong>env服务</strong>，每收到一个指令就对env执行相应的操作并且返回信息。<code>worker</code>的参数<code>env_fn_wrapper</code>就是<code>_thunk</code>加了一个<code>CloudpickleWrapper</code>，该<code>wrapper</code>好像是用来辅助序列化和反序列化的。</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># BASELINE_ROOT/common/vec_env/subproc_vec_env.py</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">SubprocVecEnv</span><span class=\"params\">(VecEnv)</span>:</span></div><div class=\"line\">    ...</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\"># 给subprocess发送step指令</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">step_async</span><span class=\"params\">(self, actions)</span>:</span></div><div class=\"line\">        <span class=\"keyword\">for</span> remote, action <span class=\"keyword\">in</span> zip(self.remotes, actions):</div><div class=\"line\">            remote.send((<span class=\"string\">'step'</span>, action))</div><div class=\"line\">        self.waiting = <span class=\"keyword\">True</span></div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\"># 接收并拼接subprocess返回的交互信息</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">step_wait</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        results = [remote.recv() <span class=\"keyword\">for</span> remote <span class=\"keyword\">in</span> self.remotes]</div><div class=\"line\">        self.waiting = <span class=\"keyword\">False</span></div><div class=\"line\">        obs, rews, dones, infos = zip(*results)</div><div class=\"line\">        <span class=\"keyword\">return</span> np.stack(obs), np.stack(rews), np.stack(dones), infos</div><div class=\"line\"></div><div class=\"line\">    ...</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\"># 这个函数在基类VecEnv中</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">step</span><span class=\"params\">(self, actions)</span>:</span></div><div class=\"line\">        self.step_async(actions)</div><div class=\"line\">        <span class=\"keyword\">return</span> self.step_wait()</div></pre></td></tr></table></figure>\n<p>有了上面的subprocee，主进程中的<code>SubprocVecEnv</code>只需要<strong>重载</strong><code>step</code>, <code>reset</code>等关键函数为发送相应指令给subprocess，然后将数据拼接起来，就实现了跟环境的并行交互。</p>\n<h4 id=\"VecNormalize\"><a href=\"#VecNormalize\" class=\"headerlink\" title=\"VecNormalize\"></a>VecNormalize</h4><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># BASELINE_ROOT/common/vec_env/vec_normalize.py</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">VecNormalize</span><span class=\"params\">(VecEnvWrapper)</span>:</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, venv, ob=True, ret=True, clipob=<span class=\"number\">10.</span>, cliprew=<span class=\"number\">10.</span>, gamma=<span class=\"number\">0.99</span>, epsilon=<span class=\"number\">1e-8</span>)</span>:</span></div><div class=\"line\">        VecEnvWrapper.__init__(self, venv)</div><div class=\"line\">        <span class=\"comment\"># mean, std计算器</span></div><div class=\"line\">        self.ob_rms = RunningMeanStd(shape=self.observation_space.shape) <span class=\"keyword\">if</span> ob <span class=\"keyword\">else</span> <span class=\"keyword\">None</span></div><div class=\"line\">        self.ret_rms = RunningMeanStd(shape=()) <span class=\"keyword\">if</span> ret <span class=\"keyword\">else</span> <span class=\"keyword\">None</span></div><div class=\"line\"></div><div class=\"line\">    ...</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">step_wait</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        obs, rews, news, infos = self.venv.step_wait()</div><div class=\"line\">        self.ret = self.ret * self.gamma + rews</div><div class=\"line\"></div><div class=\"line\">        <span class=\"comment\"># 对obs做normalization（mean, std），具体代码见下面</span></div><div class=\"line\">        obs = self._obfilt(obs)</div><div class=\"line\">        <span class=\"comment\"># 对reward做normalization（不用mean只用std，而且用的是return的std）</span></div><div class=\"line\">        <span class=\"keyword\">if</span> self.ret_rms:</div><div class=\"line\">            self.ret_rms.update(self.ret)</div><div class=\"line\">            rews = np.clip(rews / np.sqrt(self.ret_rms.var + self.epsilon), -self.cliprew, self.cliprew)</div><div class=\"line\">        <span class=\"keyword\">return</span> obs, rews, news, infos</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_obfilt</span><span class=\"params\">(self, obs)</span>:</span></div><div class=\"line\">        <span class=\"keyword\">if</span> self.ob_rms:</div><div class=\"line\">            self.ob_rms.update(obs)</div><div class=\"line\">            obs = np.clip((obs - self.ob_rms.mean) / np.sqrt(self.ob_rms.var + self.epsilon), -self.clipob, self.clipob)</div><div class=\"line\">            <span class=\"keyword\">return</span> obs</div><div class=\"line\">        <span class=\"keyword\">else</span>:</div><div class=\"line\">            <span class=\"keyword\">return</span> obs</div><div class=\"line\"></div><div class=\"line\">    ...</div></pre></td></tr></table></figure>\n<p>从上述代码可见，<code>VecNormalize</code>也是一个wrapper，主要功能是<strong>对observation和reward做normalization</strong>。</p>\n<hr>\n<h3 id=\"actor-critic\"><a href=\"#actor-critic\" class=\"headerlink\" title=\"actor_critic\"></a>actor_critic</h3><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># PPO_ROOT/model.py</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Policy</span><span class=\"params\">(nn.Module)</span>:</span></div><div class=\"line\">    ...</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">act</span><span class=\"params\">(self, inputs, states, masks, deterministic=False)</span>:</span></div><div class=\"line\">    \t<span class=\"comment\"># self.base集actor和critic于一身</span></div><div class=\"line\">    \t<span class=\"comment\"># value：V(o_t)</span></div><div class=\"line\">    \t<span class=\"comment\"># actor_features：actor网络的倒数第二层</span></div><div class=\"line\">    \t<span class=\"comment\"># states：RNN的hidden states</span></div><div class=\"line\">        value, actor_features, states = self.base(inputs, states, masks)</div><div class=\"line\">        <span class=\"comment\"># dist最后的action分布\\pi(A_t | o_t)</span></div><div class=\"line\">        dist = self.dist(actor_features)</div><div class=\"line\"></div><div class=\"line\">       \t...</div><div class=\"line\"></div><div class=\"line\">    ...</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">evaluate_actions</span><span class=\"params\">(self, inputs, states, masks, action)</span>:</span></div><div class=\"line\">        ...</div><div class=\"line\"></div><div class=\"line\">        <span class=\"comment\"># value: V(o_t)</span></div><div class=\"line\">        <span class=\"comment\"># action_log_probs: \\log(\\pi(a_t | o_t))</span></div><div class=\"line\">        <span class=\"comment\"># dist_entropy: Entropy(\\pi(A_t | o_t))</span></div><div class=\"line\">        <span class=\"comment\"># states：RNN的hidden states</span></div><div class=\"line\">        <span class=\"keyword\">return</span> value, action_log_probs, dist_entropy, states</div></pre></td></tr></table></figure>\n<p>表示parametric policy的<code>actor_critic</code>变量对应的类为<code>Policy</code>，基本上就是包含actor和critic的神经网络。如上所示，其主要函数为<code>act</code>和<code>evaluate_actions</code>，前者用于<strong>求action</strong>，后者用于从网络中<strong>获取参数更新要用到的信息</strong>（e.g., $V(o_t), \\log\\pi(a_t \\vert o_t)$）。</p>\n<hr>\n<h3 id=\"rollouts\"><a href=\"#rollouts\" class=\"headerlink\" title=\"rollouts\"></a>rollouts</h3><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># PPO_ROOT/storage.py</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">RolloutStorage</span><span class=\"params\">(object)</span>:</span></div><div class=\"line\">    ...</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\"># 保存交互信息</span></div><div class=\"line\">    <span class=\"comment\"># current_obs: o_&#123;t+1&#125;</span></div><div class=\"line\">    <span class=\"comment\"># state: RNN中的hidden state，</span></div><div class=\"line\">    <span class=\"comment\"># action: a_t</span></div><div class=\"line\">    <span class=\"comment\"># action_log_prob: \\pi(a_t | o_t)</span></div><div class=\"line\">    <span class=\"comment\"># value_pred: V(o_t)</span></div><div class=\"line\">    <span class=\"comment\"># reward: r_t</span></div><div class=\"line\">    <span class=\"comment\"># mask: 标识o_&#123;t+1&#125;时刻是否通过gym.reset()得到，是的话为0，否的话为1</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">insert</span><span class=\"params\">(self, current_obs, state, action, action_log_prob, value_pred, reward, mask)</span>:</span></div><div class=\"line\">        ...</div><div class=\"line\"></div><div class=\"line\">    ...</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\"># 计算return</span></div><div class=\"line\">    <span class=\"comment\"># 可以选择使用GAE（GAE+V）还是MC来计算return</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">compute_returns</span><span class=\"params\">(self, next_value, use_gae, gamma, tau)</span>:</span></div><div class=\"line\">        <span class=\"keyword\">if</span> use_gae:</div><div class=\"line\">            ...</div><div class=\"line\">        <span class=\"keyword\">else</span>:</div><div class=\"line\">            ...</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\"># 将num_steps * num_processes份transitions随机分成num_mini_batch个mini_batch，每次返回一个mini_batch</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">feed_forward_generator</span><span class=\"params\">(self, advantages, num_mini_batch)</span>:</span></div><div class=\"line\">        ...</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\"># 考虑到RNN的顺序有关性质，以process为单位将num_steps * num_processes份transitions随机分成num_mini_batch个mini_batch，每次返回一个mini_batch</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">recurrent_generator</span><span class=\"params\">(self, advantages, num_mini_batch)</span>:</span></div><div class=\"line\">        ...</div></pre></td></tr></table></figure>\n<p>用于储存trajectory的<code>rollouts</code>变量对应的类为<code>RolloutStorage</code>，主要功能是<strong>存和取</strong>，其对应的成员函数分别是<code>insert</code>和<code>xxx_generator</code>。还有一个<code>compute_returns</code>函数用于辅助计算更新参数所需的return。</p>\n<hr>\n<h3 id=\"agent\"><a href=\"#agent\" class=\"headerlink\" title=\"agent\"></a>agent</h3><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># PPO_ROOT/algo/ppo.py</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">PPO</span><span class=\"params\">(object)</span>:</span></div><div class=\"line\">    ...</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">update</span><span class=\"params\">(self, rollouts)</span>:</span></div><div class=\"line\">    \t<span class=\"comment\"># \\hat&#123;A)_t in PPO paper（return的计算可能用的GAE，也可能用的MC）</span></div><div class=\"line\">        <span class=\"comment\"># 并且对advantage做normalization</span></div><div class=\"line\">        advantages = rollouts.returns[:<span class=\"number\">-1</span>] - rollouts.value_preds[:<span class=\"number\">-1</span>]</div><div class=\"line\">        advantages = (advantages - advantages.mean()) / (</div><div class=\"line\">            advantages.std() + <span class=\"number\">1e-5</span>)</div><div class=\"line\"></div><div class=\"line\">        ...</div><div class=\"line\"></div><div class=\"line\">        <span class=\"keyword\">for</span> e <span class=\"keyword\">in</span> range(self.ppo_epoch):</div><div class=\"line\">            ...</div><div class=\"line\"></div><div class=\"line\">            <span class=\"keyword\">for</span> sample <span class=\"keyword\">in</span> data_generator:</div><div class=\"line\">                ...</div><div class=\"line\"></div><div class=\"line\">                <span class=\"comment\"># r_t(\\theta) in the PPO paper</span></div><div class=\"line\">                ratio = torch.exp(action_log_probs - old_action_log_probs_batch)</div><div class=\"line\">                surr1 = ratio * adv_targ</div><div class=\"line\">                surr2 = torch.clamp(ratio, <span class=\"number\">1.0</span> - self.clip_param,</div><div class=\"line\">                                           <span class=\"number\">1.0</span> + self.clip_param) * adv_targ</div><div class=\"line\">                <span class=\"comment\"># -L_t^&#123;CLIP&#125;(\\theta) in the PPO paper</span></div><div class=\"line\">                action_loss = -torch.min(surr1, surr2).mean()</div><div class=\"line\"></div><div class=\"line\">               \t<span class=\"comment\"># L_t^&#123;VF&#125;(\\theta) in the PPO paper</span></div><div class=\"line\">                value_loss = F.mse_loss(return_batch, values)</div><div class=\"line\"></div><div class=\"line\">                self.optimizer.zero_grad()</div><div class=\"line\">                <span class=\"comment\"># -L_t^&#123;CLIP+VF+S&#125;(\\theta) in the PPO paper（因为我们想做minization，而lr是正的，因此要加负号）</span></div><div class=\"line\">                (value_loss * self.value_loss_coef + action_loss -</div><div class=\"line\">                 dist_entropy * self.entropy_coef).backward()</div><div class=\"line\">                nn.utils.clip_grad_norm_(self.actor_critic.parameters(),</div><div class=\"line\">                                         self.max_grad_norm)</div><div class=\"line\">                self.optimizer.step()</div><div class=\"line\"></div><div class=\"line\">                ...</div><div class=\"line\"></div><div class=\"line\">        ...</div></pre></td></tr></table></figure>\n<p>表示RL algorithm的变量<code>agent</code>对应的类是<code>PPO</code>，由上可见，就是利用<code>rollouts</code>中的信息对<code>actor_critic</code>进行参数更新，更新的方式参照PPO的论文。</p>\n<h2 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h2><p>至此，这份PPO代码的核心部分已经描述完毕。可见，代码的实现跟论文所说的还是有很多<strong>细节</strong>上的差异的，比如说对observation和reward的normalization，对return的计算，对advantage的normalization以及对gradient的clip等等。</p>\n","excerpt":"","more":"<h2 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h2><p>本文介绍的Proximal Policy Optimization (PPO)实现是基于PyTorch的，其Github地址在<a href=\"https://github.com/ikostrikov/pytorch-a2c-ppo-acktr\">这里</a>。实际上它一共实现了三个算法，包括PPO、A2C以及ACKTR。这份代码的逻辑抽象做得不错，三个算法共用了很多代码，因此看懂了PPO对于理解另外两个算法的实现有很大帮助。</p>\n<p>这份PPO代码依赖于<a href=\"https://github.com/openai/baselines\">OpenAI baselines</a>，主要用到了其并行环境的wrapper。由于PPO和OpenAI baselines的代码一直在更新，所以最新的代码跟本文可能有所出入。<strong>本文所述代码对应的commit id前缀</strong>为：</p>\n<ul>\n<li>PPO：3aea397</li>\n<li>OpenAI baselines：f272969</li>\n</ul>\n<p>下面先介绍代码的<strong>逻辑框架</strong>，然后再看<strong>具体代码</strong>。具体代码部分以一个类似于<strong>深度优先</strong>的方式展开。</p>\n<h2 id=\"Logical-framework\"><a href=\"#Logical-framework\" class=\"headerlink\" title=\"Logical framework\"></a>Logical framework</h2><p>这份代码按照RL的思想，将代码分成了environment和robot（之所以不用agent这个词，主要是为了跟下面的变量名做区分）两大模块。environment部分主要是<code>envs</code>这个变量，它通过OpenAI baselines的wrapper实现了多环境并行化。robot部分分为了三个子模块，第一个是parametric policy变量<code>actor_critic</code>；第二个是用来保存trajectory的<code>rollouts</code>变量；最后一个是用于参数更新的RL algorithm变量<code>agent</code>。总结一下，其<strong>逻辑框架</strong>如下:</p>\n<ul>\n<li>environment<ul>\n<li>multiprocess wrapper: <code>envs</code></li>\n</ul>\n</li>\n<li>robot<ul>\n<li>parametric policy: <code>actor_critic</code></li>\n<li>trajectory: <code>rollouts</code></li>\n<li>RL algorithm: <code>agent</code></li>\n</ul>\n</li>\n</ul>\n<p>整个<strong>交互流程</strong>基本上是robot从<code>envs</code>中得到一个observation，然后根据<code>actor_critic</code>作出反应，并且将交互过程记录到<code>rollouts</code>中，接着使用<code>agent</code>根据<code>rollouts</code>中的信息来更新<code>actor_critic</code>。</p>\n<h2 id=\"Source-code\"><a href=\"#Source-code\" class=\"headerlink\" title=\"Source code\"></a>Source code</h2><h3 id=\"main\"><a href=\"#main\" class=\"headerlink\" title=\"main\"></a>main</h3><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># PPO_ROOT/main.py</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">main</span><span class=\"params\">()</span>:</span></div><div class=\"line\">    ...</div><div class=\"line\">    </div><div class=\"line\">    <span class=\"comment\"># 创建并行交互环境envs</span></div><div class=\"line\">    envs = [make_env(args.env_name, args.seed, i, args.log_dir, args.add_timestep)</div><div class=\"line\">                <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(args.num_processes)]</div><div class=\"line\">    </div><div class=\"line\">    <span class=\"keyword\">if</span> args.num_processes &gt; <span class=\"number\">1</span>:</div><div class=\"line\">        envs = SubprocVecEnv(envs)</div><div class=\"line\">    <span class=\"keyword\">else</span>:</div><div class=\"line\">        ...</div><div class=\"line\">    </div><div class=\"line\">    <span class=\"keyword\">if</span> len(envs.observation_space.shape) == <span class=\"number\">1</span>:</div><div class=\"line\">        envs = VecNormalize(envs, gamma=args.gamma)</div><div class=\"line\">    </div><div class=\"line\">    ...</div><div class=\"line\">    </div><div class=\"line\">    <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(num_updates):</div><div class=\"line\">        <span class=\"keyword\">for</span> step <span class=\"keyword\">in</span> range(args.num_steps):</div><div class=\"line\">            <span class=\"comment\"># 通过rollouts获得t时刻的的信息（e.g., o_t），使用actor_critic(i.e., policy)来计算a_t</span></div><div class=\"line\">            <span class=\"keyword\">with</span> torch.no_grad():</div><div class=\"line\">                value, action, action_log_prob, states = actor_critic.act(</div><div class=\"line\">                        rollouts.observations[step],</div><div class=\"line\">                        rollouts.states[step],</div><div class=\"line\">                        rollouts.masks[step])</div><div class=\"line\">    </div><div class=\"line\">            ...</div><div class=\"line\">    </div><div class=\"line\">            <span class=\"comment\"># 使用a_t跟envs(i.e., environment)进行交互</span></div><div class=\"line\">            obs, reward, done, info = envs.step(cpu_actions)</div><div class=\"line\">            </div><div class=\"line\">            ...</div><div class=\"line\">    </div><div class=\"line\">            <span class=\"comment\"># 将交互信息存入rollouts中</span></div><div class=\"line\">            rollouts.insert(current_obs, states, action, action_log_prob, value, reward, masks)</div><div class=\"line\">    </div><div class=\"line\">        ...</div><div class=\"line\">        </div><div class=\"line\">        <span class=\"comment\"># 根据rollouts提供的信息，使用RL algorithm（i.e., PPO）对actor_critic(i.e., policy)进行参数更新</span></div><div class=\"line\">        value_loss, action_loss, dist_entropy = agent.update(rollouts)</div><div class=\"line\">    </div><div class=\"line\">        ...</div></pre></td></tr></table></figure>\n<p>以上代码将<code>main</code>函数的核心部分提了出来。可见，<code>main</code>函数主要有以下<strong>核心步骤</strong>：</p>\n<ol>\n<li>创建并行交互环境<code>envs</code>；</li>\n<li>通过<code>actor_critic</code>与环境进行交互；</li>\n<li>将交互信息存入<code>rollouts</code>；</li>\n<li>使用<code>agent</code>进行参数更新。</li>\n</ol>\n<p>接下来分别展开介绍这四个变量。</p>\n<hr>\n<h3 id=\"envs\"><a href=\"#envs\" class=\"headerlink\" title=\"envs\"></a>envs</h3><p>由<code>main</code>函数中可见，<code>envs</code>变量通过<code>make_env</code>、<code>SubprocVecEnv</code>和<code>VecNormalize</code>得到，接下来分别介绍这三个函数。</p>\n<h4 id=\"make-env\"><a href=\"#make-env\" class=\"headerlink\" title=\"make_env\"></a>make_env</h4><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># PPO_ROOT/envs.py</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">make_env</span><span class=\"params\">(env_id, seed, rank, log_dir, add_timestep)</span>:</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_thunk</span><span class=\"params\">()</span>:</span></div><div class=\"line\">    \t<span class=\"comment\"># 最基本的gym env</span></div><div class=\"line\">        <span class=\"keyword\">if</span> env_id.startswith(<span class=\"string\">\"dm\"</span>):</div><div class=\"line\">        \t...</div><div class=\"line\">        <span class=\"keyword\">else</span>:</div><div class=\"line\">            env = gym.make(env_id)</div><div class=\"line\">        </div><div class=\"line\">        ...</div><div class=\"line\"></div><div class=\"line\">        <span class=\"comment\"># 加了一个Monitor wrapper（注意这个Monitor不是保存视频的gym.Wrappers.Monitor）来记录信息（默认是/tmp/gym/）</span></div><div class=\"line\">        <span class=\"keyword\">if</span> log_dir <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"keyword\">None</span>:</div><div class=\"line\">            env = bench.Monitor(env, os.path.join(log_dir, str(rank)))</div><div class=\"line\"></div><div class=\"line\">        ...</div><div class=\"line\"></div><div class=\"line\">        <span class=\"keyword\">return</span> env</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\"># 返回的是一个函数而不是env</span></div><div class=\"line\">    <span class=\"keyword\">return</span> _thunk</div></pre></td></tr></table></figure>\n<p>从上述代码可以看出，<code>make_env</code>函数返回了一个函数<code>_thunk</code>，调用该函数可以得到一个gym env。（<code>make_env</code>选择返回一个函数而不直接返回一个gym env的原因我不太清楚，我推测是跟<strong>序列化和反序列化</strong>有关。从下面的<code>SubprocVecEnv</code>可见，<code>make_env</code>的返回结果要传给一个在另一个进程运行的函数<code>worker</code>，这个过程应该是需要做序列化和反序列化的，可能传函数比较好实现或者比较高效？）</p>\n<h4 id=\"SubprocVecEnv\"><a href=\"#SubprocVecEnv\" class=\"headerlink\" title=\"SubprocVecEnv\"></a>SubprocVecEnv</h4><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># BASELINE_ROOT/common/vec_env/subproc_vec_env.py</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">worker</span><span class=\"params\">(remote, parent_remote, env_fn_wrapper)</span>:</span></div><div class=\"line\">    parent_remote.close()</div><div class=\"line\">    <span class=\"comment\"># 实例化env，相当于_thunk()（之所以需要.x()是因为用了CloudpickleWrapper，估计是为了处理函数序列化和反序列化的一些问题）</span></div><div class=\"line\">    env = env_fn_wrapper.x()</div><div class=\"line\">    <span class=\"comment\"># 相当于一个一直在跑的env服务</span></div><div class=\"line\">    <span class=\"keyword\">while</span> <span class=\"keyword\">True</span>:</div><div class=\"line\">        cmd, data = remote.recv()</div><div class=\"line\">        <span class=\"keyword\">if</span> cmd == <span class=\"string\">'step'</span>:</div><div class=\"line\">            ob, reward, done, info = env.step(data)</div><div class=\"line\">            <span class=\"keyword\">if</span> done:</div><div class=\"line\">                ob = env.reset()</div><div class=\"line\">            remote.send((ob, reward, done, info))</div><div class=\"line\">        <span class=\"keyword\">elif</span> cmd == <span class=\"string\">'reset'</span>:</div><div class=\"line\">            ob = env.reset()</div><div class=\"line\">            remote.send(ob)</div><div class=\"line\">        <span class=\"keyword\">elif</span> cmd == <span class=\"string\">'render'</span>:</div><div class=\"line\">            remote.send(env.render(mode=<span class=\"string\">'rgb_array'</span>))</div><div class=\"line\">        <span class=\"keyword\">elif</span> cmd == <span class=\"string\">'close'</span>:</div><div class=\"line\">            remote.close()</div><div class=\"line\">            <span class=\"keyword\">break</span></div><div class=\"line\">        <span class=\"keyword\">elif</span> cmd == <span class=\"string\">'get_spaces'</span>:</div><div class=\"line\">            remote.send((env.observation_space, env.action_space))</div><div class=\"line\">        <span class=\"keyword\">else</span>:</div><div class=\"line\">            <span class=\"keyword\">raise</span> NotImplementedError</div></pre></td></tr></table></figure>\n<p><code>SubprocVecEnv</code>首先创建不同的subprocess去运行<code>worker</code>，每一个<code>worker</code>基本上相当于一个<strong>env服务</strong>，每收到一个指令就对env执行相应的操作并且返回信息。<code>worker</code>的参数<code>env_fn_wrapper</code>就是<code>_thunk</code>加了一个<code>CloudpickleWrapper</code>，该<code>wrapper</code>好像是用来辅助序列化和反序列化的。</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># BASELINE_ROOT/common/vec_env/subproc_vec_env.py</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">SubprocVecEnv</span><span class=\"params\">(VecEnv)</span>:</span></div><div class=\"line\">    ...</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\"># 给subprocess发送step指令</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">step_async</span><span class=\"params\">(self, actions)</span>:</span></div><div class=\"line\">        <span class=\"keyword\">for</span> remote, action <span class=\"keyword\">in</span> zip(self.remotes, actions):</div><div class=\"line\">            remote.send((<span class=\"string\">'step'</span>, action))</div><div class=\"line\">        self.waiting = <span class=\"keyword\">True</span></div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\"># 接收并拼接subprocess返回的交互信息</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">step_wait</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        results = [remote.recv() <span class=\"keyword\">for</span> remote <span class=\"keyword\">in</span> self.remotes]</div><div class=\"line\">        self.waiting = <span class=\"keyword\">False</span></div><div class=\"line\">        obs, rews, dones, infos = zip(*results)</div><div class=\"line\">        <span class=\"keyword\">return</span> np.stack(obs), np.stack(rews), np.stack(dones), infos</div><div class=\"line\"></div><div class=\"line\">    ...</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\"># 这个函数在基类VecEnv中</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">step</span><span class=\"params\">(self, actions)</span>:</span></div><div class=\"line\">        self.step_async(actions)</div><div class=\"line\">        <span class=\"keyword\">return</span> self.step_wait()</div></pre></td></tr></table></figure>\n<p>有了上面的subprocee，主进程中的<code>SubprocVecEnv</code>只需要<strong>重载</strong><code>step</code>, <code>reset</code>等关键函数为发送相应指令给subprocess，然后将数据拼接起来，就实现了跟环境的并行交互。</p>\n<h4 id=\"VecNormalize\"><a href=\"#VecNormalize\" class=\"headerlink\" title=\"VecNormalize\"></a>VecNormalize</h4><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># BASELINE_ROOT/common/vec_env/vec_normalize.py</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">VecNormalize</span><span class=\"params\">(VecEnvWrapper)</span>:</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, venv, ob=True, ret=True, clipob=<span class=\"number\">10.</span>, cliprew=<span class=\"number\">10.</span>, gamma=<span class=\"number\">0.99</span>, epsilon=<span class=\"number\">1e-8</span>)</span>:</span></div><div class=\"line\">        VecEnvWrapper.__init__(self, venv)</div><div class=\"line\">        <span class=\"comment\"># mean, std计算器</span></div><div class=\"line\">        self.ob_rms = RunningMeanStd(shape=self.observation_space.shape) <span class=\"keyword\">if</span> ob <span class=\"keyword\">else</span> <span class=\"keyword\">None</span></div><div class=\"line\">        self.ret_rms = RunningMeanStd(shape=()) <span class=\"keyword\">if</span> ret <span class=\"keyword\">else</span> <span class=\"keyword\">None</span></div><div class=\"line\"></div><div class=\"line\">    ...</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">step_wait</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        obs, rews, news, infos = self.venv.step_wait()</div><div class=\"line\">        self.ret = self.ret * self.gamma + rews</div><div class=\"line\"></div><div class=\"line\">        <span class=\"comment\"># 对obs做normalization（mean, std），具体代码见下面</span></div><div class=\"line\">        obs = self._obfilt(obs)</div><div class=\"line\">        <span class=\"comment\"># 对reward做normalization（不用mean只用std，而且用的是return的std）</span></div><div class=\"line\">        <span class=\"keyword\">if</span> self.ret_rms:</div><div class=\"line\">            self.ret_rms.update(self.ret)</div><div class=\"line\">            rews = np.clip(rews / np.sqrt(self.ret_rms.var + self.epsilon), -self.cliprew, self.cliprew)</div><div class=\"line\">        <span class=\"keyword\">return</span> obs, rews, news, infos</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_obfilt</span><span class=\"params\">(self, obs)</span>:</span></div><div class=\"line\">        <span class=\"keyword\">if</span> self.ob_rms:</div><div class=\"line\">            self.ob_rms.update(obs)</div><div class=\"line\">            obs = np.clip((obs - self.ob_rms.mean) / np.sqrt(self.ob_rms.var + self.epsilon), -self.clipob, self.clipob)</div><div class=\"line\">            <span class=\"keyword\">return</span> obs</div><div class=\"line\">        <span class=\"keyword\">else</span>:</div><div class=\"line\">            <span class=\"keyword\">return</span> obs</div><div class=\"line\"></div><div class=\"line\">    ...</div></pre></td></tr></table></figure>\n<p>从上述代码可见，<code>VecNormalize</code>也是一个wrapper，主要功能是<strong>对observation和reward做normalization</strong>。</p>\n<hr>\n<h3 id=\"actor-critic\"><a href=\"#actor-critic\" class=\"headerlink\" title=\"actor_critic\"></a>actor_critic</h3><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># PPO_ROOT/model.py</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Policy</span><span class=\"params\">(nn.Module)</span>:</span></div><div class=\"line\">    ...</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">act</span><span class=\"params\">(self, inputs, states, masks, deterministic=False)</span>:</span></div><div class=\"line\">    \t<span class=\"comment\"># self.base集actor和critic于一身</span></div><div class=\"line\">    \t<span class=\"comment\"># value：V(o_t)</span></div><div class=\"line\">    \t<span class=\"comment\"># actor_features：actor网络的倒数第二层</span></div><div class=\"line\">    \t<span class=\"comment\"># states：RNN的hidden states</span></div><div class=\"line\">        value, actor_features, states = self.base(inputs, states, masks)</div><div class=\"line\">        <span class=\"comment\"># dist最后的action分布\\pi(A_t | o_t)</span></div><div class=\"line\">        dist = self.dist(actor_features)</div><div class=\"line\"></div><div class=\"line\">       \t...</div><div class=\"line\"></div><div class=\"line\">    ...</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">evaluate_actions</span><span class=\"params\">(self, inputs, states, masks, action)</span>:</span></div><div class=\"line\">        ...</div><div class=\"line\"></div><div class=\"line\">        <span class=\"comment\"># value: V(o_t)</span></div><div class=\"line\">        <span class=\"comment\"># action_log_probs: \\log(\\pi(a_t | o_t))</span></div><div class=\"line\">        <span class=\"comment\"># dist_entropy: Entropy(\\pi(A_t | o_t))</span></div><div class=\"line\">        <span class=\"comment\"># states：RNN的hidden states</span></div><div class=\"line\">        <span class=\"keyword\">return</span> value, action_log_probs, dist_entropy, states</div></pre></td></tr></table></figure>\n<p>表示parametric policy的<code>actor_critic</code>变量对应的类为<code>Policy</code>，基本上就是包含actor和critic的神经网络。如上所示，其主要函数为<code>act</code>和<code>evaluate_actions</code>，前者用于<strong>求action</strong>，后者用于从网络中<strong>获取参数更新要用到的信息</strong>（e.g., $V(o_t), \\log\\pi(a_t \\vert o_t)$）。</p>\n<hr>\n<h3 id=\"rollouts\"><a href=\"#rollouts\" class=\"headerlink\" title=\"rollouts\"></a>rollouts</h3><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># PPO_ROOT/storage.py</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">RolloutStorage</span><span class=\"params\">(object)</span>:</span></div><div class=\"line\">    ...</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\"># 保存交互信息</span></div><div class=\"line\">    <span class=\"comment\"># current_obs: o_&#123;t+1&#125;</span></div><div class=\"line\">    <span class=\"comment\"># state: RNN中的hidden state，</span></div><div class=\"line\">    <span class=\"comment\"># action: a_t</span></div><div class=\"line\">    <span class=\"comment\"># action_log_prob: \\pi(a_t | o_t)</span></div><div class=\"line\">    <span class=\"comment\"># value_pred: V(o_t)</span></div><div class=\"line\">    <span class=\"comment\"># reward: r_t</span></div><div class=\"line\">    <span class=\"comment\"># mask: 标识o_&#123;t+1&#125;时刻是否通过gym.reset()得到，是的话为0，否的话为1</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">insert</span><span class=\"params\">(self, current_obs, state, action, action_log_prob, value_pred, reward, mask)</span>:</span></div><div class=\"line\">        ...</div><div class=\"line\"></div><div class=\"line\">    ...</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\"># 计算return</span></div><div class=\"line\">    <span class=\"comment\"># 可以选择使用GAE（GAE+V）还是MC来计算return</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">compute_returns</span><span class=\"params\">(self, next_value, use_gae, gamma, tau)</span>:</span></div><div class=\"line\">        <span class=\"keyword\">if</span> use_gae:</div><div class=\"line\">            ...</div><div class=\"line\">        <span class=\"keyword\">else</span>:</div><div class=\"line\">            ...</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\"># 将num_steps * num_processes份transitions随机分成num_mini_batch个mini_batch，每次返回一个mini_batch</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">feed_forward_generator</span><span class=\"params\">(self, advantages, num_mini_batch)</span>:</span></div><div class=\"line\">        ...</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\"># 考虑到RNN的顺序有关性质，以process为单位将num_steps * num_processes份transitions随机分成num_mini_batch个mini_batch，每次返回一个mini_batch</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">recurrent_generator</span><span class=\"params\">(self, advantages, num_mini_batch)</span>:</span></div><div class=\"line\">        ...</div></pre></td></tr></table></figure>\n<p>用于储存trajectory的<code>rollouts</code>变量对应的类为<code>RolloutStorage</code>，主要功能是<strong>存和取</strong>，其对应的成员函数分别是<code>insert</code>和<code>xxx_generator</code>。还有一个<code>compute_returns</code>函数用于辅助计算更新参数所需的return。</p>\n<hr>\n<h3 id=\"agent\"><a href=\"#agent\" class=\"headerlink\" title=\"agent\"></a>agent</h3><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># PPO_ROOT/algo/ppo.py</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">PPO</span><span class=\"params\">(object)</span>:</span></div><div class=\"line\">    ...</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">update</span><span class=\"params\">(self, rollouts)</span>:</span></div><div class=\"line\">    \t<span class=\"comment\"># \\hat&#123;A)_t in PPO paper（return的计算可能用的GAE，也可能用的MC）</span></div><div class=\"line\">        <span class=\"comment\"># 并且对advantage做normalization</span></div><div class=\"line\">        advantages = rollouts.returns[:<span class=\"number\">-1</span>] - rollouts.value_preds[:<span class=\"number\">-1</span>]</div><div class=\"line\">        advantages = (advantages - advantages.mean()) / (</div><div class=\"line\">            advantages.std() + <span class=\"number\">1e-5</span>)</div><div class=\"line\"></div><div class=\"line\">        ...</div><div class=\"line\"></div><div class=\"line\">        <span class=\"keyword\">for</span> e <span class=\"keyword\">in</span> range(self.ppo_epoch):</div><div class=\"line\">            ...</div><div class=\"line\"></div><div class=\"line\">            <span class=\"keyword\">for</span> sample <span class=\"keyword\">in</span> data_generator:</div><div class=\"line\">                ...</div><div class=\"line\"></div><div class=\"line\">                <span class=\"comment\"># r_t(\\theta) in the PPO paper</span></div><div class=\"line\">                ratio = torch.exp(action_log_probs - old_action_log_probs_batch)</div><div class=\"line\">                surr1 = ratio * adv_targ</div><div class=\"line\">                surr2 = torch.clamp(ratio, <span class=\"number\">1.0</span> - self.clip_param,</div><div class=\"line\">                                           <span class=\"number\">1.0</span> + self.clip_param) * adv_targ</div><div class=\"line\">                <span class=\"comment\"># -L_t^&#123;CLIP&#125;(\\theta) in the PPO paper</span></div><div class=\"line\">                action_loss = -torch.min(surr1, surr2).mean()</div><div class=\"line\"></div><div class=\"line\">               \t<span class=\"comment\"># L_t^&#123;VF&#125;(\\theta) in the PPO paper</span></div><div class=\"line\">                value_loss = F.mse_loss(return_batch, values)</div><div class=\"line\"></div><div class=\"line\">                self.optimizer.zero_grad()</div><div class=\"line\">                <span class=\"comment\"># -L_t^&#123;CLIP+VF+S&#125;(\\theta) in the PPO paper（因为我们想做minization，而lr是正的，因此要加负号）</span></div><div class=\"line\">                (value_loss * self.value_loss_coef + action_loss -</div><div class=\"line\">                 dist_entropy * self.entropy_coef).backward()</div><div class=\"line\">                nn.utils.clip_grad_norm_(self.actor_critic.parameters(),</div><div class=\"line\">                                         self.max_grad_norm)</div><div class=\"line\">                self.optimizer.step()</div><div class=\"line\"></div><div class=\"line\">                ...</div><div class=\"line\"></div><div class=\"line\">        ...</div></pre></td></tr></table></figure>\n<p>表示RL algorithm的变量<code>agent</code>对应的类是<code>PPO</code>，由上可见，就是利用<code>rollouts</code>中的信息对<code>actor_critic</code>进行参数更新，更新的方式参照PPO的论文。</p>\n<h2 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h2><p>至此，这份PPO代码的核心部分已经描述完毕。可见，代码的实现跟论文所说的还是有很多<strong>细节</strong>上的差异的，比如说对observation和reward的normalization，对return的计算，对advantage的normalization以及对gradient的clip等等。</p>\n"},{"title":"学习总结《神经网络常用求导》","date":"2018-03-31T11:18:11.000Z","description":["神经网络常用求导"],"_content":"\n## derivative of softmax\n\n### derivative of softmax\n\n一般来说，分类模型的最后一层都是softmax层，假设我们有一个$3$分类问题，那对应的softmax层结构如下图所示（一般认为输出的结果$y_i$即为输入$x$属于第$i$类的概率）：\n\n<div style=\"width:600px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img softmax.png  %}\n</div>\n\n假设给定训练集$\\\\{ (x_1, c_1), \\dots, (x_m, c_m) \\\\}$，分类模型的**目标是最大化对数似然函数**$L(\\theta)$，即\n\n$$\n\\mathop{\\text{maximize}}_\\theta \\sum_{j=1}^m \\ln  P(c_j \\ \\vert \\ x_j ; \\theta).\n$$通常来说，我们采取的优化方法都是**gradient based**的（e.g., SGD），也就是说，需要求解$\\frac{\\partial L(\\theta)}{\\partial \\theta}$。而我们只要求得$\\frac{\\partial L(\\theta)}{\\partial z_i}$，之后根据链式法则，就可以求得$\\frac{\\partial L(\\theta)}{\\partial \\theta}$，因此我们的核心在于求解$\\frac{\\partial L(\\theta)}{\\partial z_i}$，即\n\n$$\n\\begin{aligned}\n\\frac{\\partial L(\\theta)}{\\partial z_i} &= \\frac{\\partial}{\\partial z_i}\\sum_{j=1}^m \\ln  P(c_j \\ \\vert \\ x_j ; \\theta) \\\\\n&= \\sum_{j=1}^m\\frac{\\partial}{\\partial z_i} \\ln  P(c_j \\ \\vert \\ x_j ; \\theta).\n\\end{aligned}\n$$由上式可知，我们只需要知道各个样本$j$的$\\frac{\\partial}{\\partial z_i} \\ln  P(c_j \\ \\vert \\ x_j ; \\theta)$，即可通过求和求得$\\frac{\\partial L(\\theta)}{\\partial z_i}$，进而通过链式法则求得$\\frac{\\partial L(\\theta)}{\\partial \\theta}$。因此下面**省略样本下标$j$，仅讨论某个样本$(x, c)$**。\n\n实际上对于如何表示$x$属于第几个类，有两种比较直观的方法：\n\n- 一种是**直接法**（i.e., 用$c=3$来表示$x$属于第$3$类），则$P(c \\ \\vert \\ x ; \\theta)=\\prod_n {y_n}^{\\mathbb{1}(c=n)}$，其中$\\mathbb{1}(\\bullet)$为指示函数；\n- 另一种是**one-hot法**（i.e., 用$c= [0 \\quad 0 \\quad 1]^T$来表示$x$属于第三类），则$P(c \\ \\vert \\ x ; \\theta)=\\prod_n {y_n}^{c_n}$，其中$c_n$为向量$c$的第$n$个元素。\n- p.s., 也可以将one-hot法理解为直接法的**实现形式**，因为one-hot向量实际上就是$\\mathbb{1}(c=n)$。\n\n为了方便，**本文采用one-hot法**。于是，我们有：\n\n$$\n\\begin{aligned}\n\\frac{\\partial}{\\partial z_i} \\ln  P(c \\ \\vert \\ x ; \\theta) &= \\frac{\\partial}{\\partial z_i} \\ln \\prod_n {y_n}^{c_n} \\\\\n&= \\frac{\\partial}{\\partial z_i} \\sum_n \\ln {y_n}^{c_n} \\\\\n&= \\frac{\\partial}{\\partial z_i} \\sum_n {c_n} \\ln \\frac{e^{z_n}}{\\sum_j e^{z_j}} \\\\\n&= \\sum_n {c_n} \\frac{\\partial}{\\partial z_i} (\\ln {e^{z_n}} - \\ln{\\sum_j e^{z_j}}) \\\\\n&= \\sum_n {c_n} \\frac{\\partial}{\\partial z_i} ({z_n} - \\ln{\\sum_j e^{z_j}}) \\\\\n&= \\sum_n {c_n} (\\frac{\\partial z_n}{\\partial z_i}  - \\frac{\\partial}{\\partial z_i} \\ln{\\sum_j e^{z_j}}) \\\\\n&= \\sum_n {c_n} (\\frac{\\partial z_n}{\\partial z_i}  - \\frac{e^{z_i}}{\\sum_j e^{z_j}} ) \\\\\n&= \\sum_n {c_n} (\\frac{\\partial z_n}{\\partial z_i}  - y_i ) \\\\\n&= \\sum_n {c_n} \\frac{\\partial z_n}{\\partial z_i}  - \\sum_n {c_n} y_i  \\\\\n&= c_i  - y_i . \\\\\n\\end{aligned}\n$$\n\n### softmax & sigmoid\n\n再补充一下**softmax与sigmoid的联系**。当分类问题是二分类的时候，我们一般使用sigmoid function作为输出层，表示输入$x$属于第$1$类的概率，即\n$$\nP(1 \\ \\vert \\ x ; \\theta) = \\frac{1}{1+e^{-z}}. \n$$然后利用概率和为$1$来求解$x$属于第$2$类的概率，即\n\n$$\nP(2 \\ \\vert \\ x ; \\theta) = 1 - P(1 \\ \\vert \\ x ; \\theta).\n$$乍一看会觉得用sigmoid做二分类跟用softmax做二分类不一样：\n\n- 在用softmax时，**output的维数**跟类的数量一致，而用sigmoid时，output的维数比类的数量少；\n- 在用softmax时，各类的**概率表达式**跟sigmoid中的表达式不相同。\n\n但实际上，**用sigmoid做二分类跟用softmax做二分类是等价的**。我们可以让sigmoid的output维数跟类的数量一致，并且在形式上逼近softmax。\n\n$$\n\\begin{aligned}\nP(1 \\ \\vert \\ x ; \\theta) &= \\frac{1}{1+e^{-z}} \\\\\n&= \\frac{e^{z}}{e^{z}+e^{0}} \\\\\nP(2 \\ \\vert \\ x ; \\theta) &= \\frac{e^{-z}}{1+e^{-z}} \\\\\n&= \\frac{e^{0}}{e^{z}+e^{0}}. \\\\\n\\end{aligned}\n$$通过上述变化，sigmoid跟softmax已经很相似了，只不过sigmoid的input的第二个元素恒等于$0$（i.e., intput为$[z \\quad 0]^T$），而softmax的input为$[z_1 \\quad z_2]^T$，下面就来说明这两者存在一个mapping的关系（i.e., 每一个$[z_1 \\quad z_2]^T$都可以找到一个对应的$[z \\quad 0]^T$来表示相同的softmax结果。不过值得注意的是，反过来并不成立，也就是说并不是每个$[z \\quad 0]^T$仅仅对应一个$[z_1 \\quad z_2]^T$）。\n\n$$\n\\begin{aligned}\nP(1 \\ \\vert \\ x ; \\theta) &= \\frac{e^{z_1}}{e^{z_1}+e^{z_2}} \\\\\n&= \\frac{e^{z_1-z_2}}{e^{z_1-z_2}+e^{z_2-z_2}} \\\\\n&= \\frac{e^{z}}{e^{z}+e^{0}}. \\\\\n\\end{aligned}\n$$因此，用sigmoid做二分类跟用softmax做二分类是等价的。\n\n## backpropagation\n\n一般来说，在train一个神经网络时（i.e., 更新网络的参数），我们都需要loss function对各参数的gradient，*backpropagation*就是求解gradient的一种方法。\n\n<div style=\"width:600px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img bp1.png  %}\n</div>\n\n假设我们有一个如上图所示的神经网络，我们想求损失函数$C$对$w_1$的gradient，那么根据链式法则，我们有\n\n$$\n\\frac{\\partial C}{\\partial w_1} = \\frac{\\partial C}{\\partial z}\\frac{\\partial z}{\\partial w_1}.\n$$而我们可以很容易得到上述式子右边的第二项，因为$z = x_1 w_1 + x_2 w_2 +b$，所以有\n\n$$\n\\frac{\\partial z}{\\partial w_1} = x_1,\n$$其中，$x_1$是上层的输出。\n\n---\n\n而对于式子右边的的第一项，可以进一步拆分得到\n\n$$\n\\frac{\\partial C}{\\partial z} = \\frac{\\partial C}{\\partial a}\\frac{\\partial a}{\\partial z}.\n$$我们很容易得到上式右边第二项，因为$a=\\sigma(z)$，而激活函数$\\sigma$（e.g., sigmoid function）是我们自己定义的，所以有\n\n$$\n\\frac{\\partial a}{\\partial z} = \\sigma^\\prime(z)，\n$$其中，$z$是本层的线性输出（未经激活函数）。\n\n---\n\n<div style=\"width:600px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img bp2.png  %}\n</div>\n观察上图，我们根据链式法则可以得到\n$$\n\\frac{\\partial C}{\\partial a} = \\frac{\\partial C}{\\partial z^\\prime}\\frac{\\partial z^\\prime}{\\partial a} + \\frac{\\partial C}{\\partial z^{\\prime\\prime}}\\frac{\\partial z^{\\prime\\prime}}{\\partial a}.\n$$其中，根据$z^\\prime = aw_3 + \\dots$可知$$\n\\begin{aligned}\n\\frac{\\partial z^\\prime}{\\partial a} &= w_3 \\\\\n\\frac{\\partial z^{\\prime\\prime}}{\\partial a} &= w_4.\n\\end{aligned}\n$$而$w_3$和$w_4$的值是已知的，因此，我们离目标$\\frac{\\partial C}{\\partial a}$仅差$\\frac{\\partial C}{\\partial z^\\prime}$和$\\frac{\\partial C}{\\partial z^{\\prime\\prime}}$了。接下来我们采用**动态规划（或者说递归）的思路**，假设下一层的$\\frac{\\partial C}{\\partial z^\\prime}$和$\\frac{\\partial C}{\\partial z^{\\prime\\prime}}$是已知的，那么我们只需要最后一层的graident，就可以求得各层的gradient了。而通过softmax的例子，我们知道最后一层的gradient确实可求，因此只要从最后一层开始，逐层向前，即可求得各层gradient。\n\n因此我们求$\\frac{\\partial C}{\\partial z}$的过程实际上对应下图所示的神经网络（**原神经网络的反向神经网络**）：\n\n<div style=\"width:300px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img bp3.png  %}\n</div>\n\n---\n\n综上，我们先通过神经网络的正向计算，得到$x_1$以及$z$，进而求得$\\frac{\\partial z}{\\partial w_1}$和$\\frac{\\partial a}{\\partial z}$；然后通过神经网络的反向计算，得到$\\frac{\\partial C}{\\partial z^\\prime}$和$\\frac{\\partial C}{\\partial z^{\\prime\\prime}}$，进而求得$\\frac{\\partial C}{\\partial a}$；然后根据链式法则求得$\\frac{\\partial C}{\\partial w_1}$。这整个过程就叫做*backpropagation*，其中正向计算的过程叫做*forward pass*，反向计算的过程叫做*backward pass*。\n\n## derivative of CNN\n\n卷积层实际上是特殊的全连接层，只不过：\n\n- 神经元中的某些$w$为$0$；\n- 神经元之间共享$w$。\n\n具体来说，如下图所示，没有连线的表示对应的$w$为$0$：\n\n<div style=\"width:600px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img cnn1.png  %}\n</div>\n\n如下图所示，相同颜色的代表相同的$w$：\n\n<div style=\"width:600px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img cnn2.png  %}\n</div>\n\n因此，我们可以**把loss function理解为$C(z_1, z_2, \\dots)$**，然后求导的时候，根据链式法则，将相同$w$的gradient加起来就好了，即\n\n$$\n\\frac{\\partial C}{\\partial w} = \\sum_i \\frac{\\partial C}{\\partial z_i}\\frac{\\partial z_i}{\\partial w}.\n$$在求各个$\\frac{\\partial C}{\\partial z_i}\\frac{\\partial z_i}{\\partial w}$时，可以把他们看成是相互独立的$w$，那这样就跟普通的全连接层一样了，因此也就可以用backpropagation来求。\n\n## derivative of RNN\n\nRNN按照时序展开之后如下图所示（红线表示了求gradient的路线）：\n\n<div style=\"width:600px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img rnn.png  %}\n</div>\n\n跟处理卷积层的思路一样，首先**将loss function理解为$L(s_0, s_1, \\dots)$**，然后把各个$w$看成相互独立，最后根据链式法则求得对应的gradient，即\n\n$$\n\\frac{\\partial L}{\\partial w} = \\sum_i\\frac{\\partial L}{\\partial s_i}\\frac{\\partial s_i}{\\partial w}.\n$$由于这里是将RNN按照时序展开成为一个神经网络，所以这种求gradient的方法叫*Backpropagation Through Time(BPTT)*。\n\n## derivative of max pooling\n\n一般来说，函数$max(x, y, \\dots)$是不可导的，但**假如我们已经知道哪个自变量会是最大值，那么该函数就是可导的**（e.g., 假如知道$y$是最大的，那对$y$的偏导为$1$，对其他自变量的偏导为$0$）。\n\n而在train一个神经网络的时候，我们会先进行*forward pass*，之后再进行*backward pass*，因此我们在对max pooling求导的时候，已经知道哪个自变量是最大的，于是也就能够给出对应的gradient了。\n\n## references\n\n- [Hung-yi Lee Machine Learning](http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML17_2.html)\n- [RNN Tutorial](http://www.wildml.com/2015/10/recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/)","source":"_posts/summary-derivative.md","raw":"---\ntitle: 学习总结《神经网络常用求导》\ndate: 2018-03-31 19:18:11\ntags:\n\t- derivative\n\t- softmax\n\t- backpropagation\n\t- cnn\n\t- bptt\n\t- max pooling\ncategories:\n\t- 学习总结\ndescription:\n\t- 神经网络常用求导\n---\n\n## derivative of softmax\n\n### derivative of softmax\n\n一般来说，分类模型的最后一层都是softmax层，假设我们有一个$3$分类问题，那对应的softmax层结构如下图所示（一般认为输出的结果$y_i$即为输入$x$属于第$i$类的概率）：\n\n<div style=\"width:600px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img softmax.png  %}\n</div>\n\n假设给定训练集$\\\\{ (x_1, c_1), \\dots, (x_m, c_m) \\\\}$，分类模型的**目标是最大化对数似然函数**$L(\\theta)$，即\n\n$$\n\\mathop{\\text{maximize}}_\\theta \\sum_{j=1}^m \\ln  P(c_j \\ \\vert \\ x_j ; \\theta).\n$$通常来说，我们采取的优化方法都是**gradient based**的（e.g., SGD），也就是说，需要求解$\\frac{\\partial L(\\theta)}{\\partial \\theta}$。而我们只要求得$\\frac{\\partial L(\\theta)}{\\partial z_i}$，之后根据链式法则，就可以求得$\\frac{\\partial L(\\theta)}{\\partial \\theta}$，因此我们的核心在于求解$\\frac{\\partial L(\\theta)}{\\partial z_i}$，即\n\n$$\n\\begin{aligned}\n\\frac{\\partial L(\\theta)}{\\partial z_i} &= \\frac{\\partial}{\\partial z_i}\\sum_{j=1}^m \\ln  P(c_j \\ \\vert \\ x_j ; \\theta) \\\\\n&= \\sum_{j=1}^m\\frac{\\partial}{\\partial z_i} \\ln  P(c_j \\ \\vert \\ x_j ; \\theta).\n\\end{aligned}\n$$由上式可知，我们只需要知道各个样本$j$的$\\frac{\\partial}{\\partial z_i} \\ln  P(c_j \\ \\vert \\ x_j ; \\theta)$，即可通过求和求得$\\frac{\\partial L(\\theta)}{\\partial z_i}$，进而通过链式法则求得$\\frac{\\partial L(\\theta)}{\\partial \\theta}$。因此下面**省略样本下标$j$，仅讨论某个样本$(x, c)$**。\n\n实际上对于如何表示$x$属于第几个类，有两种比较直观的方法：\n\n- 一种是**直接法**（i.e., 用$c=3$来表示$x$属于第$3$类），则$P(c \\ \\vert \\ x ; \\theta)=\\prod_n {y_n}^{\\mathbb{1}(c=n)}$，其中$\\mathbb{1}(\\bullet)$为指示函数；\n- 另一种是**one-hot法**（i.e., 用$c= [0 \\quad 0 \\quad 1]^T$来表示$x$属于第三类），则$P(c \\ \\vert \\ x ; \\theta)=\\prod_n {y_n}^{c_n}$，其中$c_n$为向量$c$的第$n$个元素。\n- p.s., 也可以将one-hot法理解为直接法的**实现形式**，因为one-hot向量实际上就是$\\mathbb{1}(c=n)$。\n\n为了方便，**本文采用one-hot法**。于是，我们有：\n\n$$\n\\begin{aligned}\n\\frac{\\partial}{\\partial z_i} \\ln  P(c \\ \\vert \\ x ; \\theta) &= \\frac{\\partial}{\\partial z_i} \\ln \\prod_n {y_n}^{c_n} \\\\\n&= \\frac{\\partial}{\\partial z_i} \\sum_n \\ln {y_n}^{c_n} \\\\\n&= \\frac{\\partial}{\\partial z_i} \\sum_n {c_n} \\ln \\frac{e^{z_n}}{\\sum_j e^{z_j}} \\\\\n&= \\sum_n {c_n} \\frac{\\partial}{\\partial z_i} (\\ln {e^{z_n}} - \\ln{\\sum_j e^{z_j}}) \\\\\n&= \\sum_n {c_n} \\frac{\\partial}{\\partial z_i} ({z_n} - \\ln{\\sum_j e^{z_j}}) \\\\\n&= \\sum_n {c_n} (\\frac{\\partial z_n}{\\partial z_i}  - \\frac{\\partial}{\\partial z_i} \\ln{\\sum_j e^{z_j}}) \\\\\n&= \\sum_n {c_n} (\\frac{\\partial z_n}{\\partial z_i}  - \\frac{e^{z_i}}{\\sum_j e^{z_j}} ) \\\\\n&= \\sum_n {c_n} (\\frac{\\partial z_n}{\\partial z_i}  - y_i ) \\\\\n&= \\sum_n {c_n} \\frac{\\partial z_n}{\\partial z_i}  - \\sum_n {c_n} y_i  \\\\\n&= c_i  - y_i . \\\\\n\\end{aligned}\n$$\n\n### softmax & sigmoid\n\n再补充一下**softmax与sigmoid的联系**。当分类问题是二分类的时候，我们一般使用sigmoid function作为输出层，表示输入$x$属于第$1$类的概率，即\n$$\nP(1 \\ \\vert \\ x ; \\theta) = \\frac{1}{1+e^{-z}}. \n$$然后利用概率和为$1$来求解$x$属于第$2$类的概率，即\n\n$$\nP(2 \\ \\vert \\ x ; \\theta) = 1 - P(1 \\ \\vert \\ x ; \\theta).\n$$乍一看会觉得用sigmoid做二分类跟用softmax做二分类不一样：\n\n- 在用softmax时，**output的维数**跟类的数量一致，而用sigmoid时，output的维数比类的数量少；\n- 在用softmax时，各类的**概率表达式**跟sigmoid中的表达式不相同。\n\n但实际上，**用sigmoid做二分类跟用softmax做二分类是等价的**。我们可以让sigmoid的output维数跟类的数量一致，并且在形式上逼近softmax。\n\n$$\n\\begin{aligned}\nP(1 \\ \\vert \\ x ; \\theta) &= \\frac{1}{1+e^{-z}} \\\\\n&= \\frac{e^{z}}{e^{z}+e^{0}} \\\\\nP(2 \\ \\vert \\ x ; \\theta) &= \\frac{e^{-z}}{1+e^{-z}} \\\\\n&= \\frac{e^{0}}{e^{z}+e^{0}}. \\\\\n\\end{aligned}\n$$通过上述变化，sigmoid跟softmax已经很相似了，只不过sigmoid的input的第二个元素恒等于$0$（i.e., intput为$[z \\quad 0]^T$），而softmax的input为$[z_1 \\quad z_2]^T$，下面就来说明这两者存在一个mapping的关系（i.e., 每一个$[z_1 \\quad z_2]^T$都可以找到一个对应的$[z \\quad 0]^T$来表示相同的softmax结果。不过值得注意的是，反过来并不成立，也就是说并不是每个$[z \\quad 0]^T$仅仅对应一个$[z_1 \\quad z_2]^T$）。\n\n$$\n\\begin{aligned}\nP(1 \\ \\vert \\ x ; \\theta) &= \\frac{e^{z_1}}{e^{z_1}+e^{z_2}} \\\\\n&= \\frac{e^{z_1-z_2}}{e^{z_1-z_2}+e^{z_2-z_2}} \\\\\n&= \\frac{e^{z}}{e^{z}+e^{0}}. \\\\\n\\end{aligned}\n$$因此，用sigmoid做二分类跟用softmax做二分类是等价的。\n\n## backpropagation\n\n一般来说，在train一个神经网络时（i.e., 更新网络的参数），我们都需要loss function对各参数的gradient，*backpropagation*就是求解gradient的一种方法。\n\n<div style=\"width:600px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img bp1.png  %}\n</div>\n\n假设我们有一个如上图所示的神经网络，我们想求损失函数$C$对$w_1$的gradient，那么根据链式法则，我们有\n\n$$\n\\frac{\\partial C}{\\partial w_1} = \\frac{\\partial C}{\\partial z}\\frac{\\partial z}{\\partial w_1}.\n$$而我们可以很容易得到上述式子右边的第二项，因为$z = x_1 w_1 + x_2 w_2 +b$，所以有\n\n$$\n\\frac{\\partial z}{\\partial w_1} = x_1,\n$$其中，$x_1$是上层的输出。\n\n---\n\n而对于式子右边的的第一项，可以进一步拆分得到\n\n$$\n\\frac{\\partial C}{\\partial z} = \\frac{\\partial C}{\\partial a}\\frac{\\partial a}{\\partial z}.\n$$我们很容易得到上式右边第二项，因为$a=\\sigma(z)$，而激活函数$\\sigma$（e.g., sigmoid function）是我们自己定义的，所以有\n\n$$\n\\frac{\\partial a}{\\partial z} = \\sigma^\\prime(z)，\n$$其中，$z$是本层的线性输出（未经激活函数）。\n\n---\n\n<div style=\"width:600px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img bp2.png  %}\n</div>\n观察上图，我们根据链式法则可以得到\n$$\n\\frac{\\partial C}{\\partial a} = \\frac{\\partial C}{\\partial z^\\prime}\\frac{\\partial z^\\prime}{\\partial a} + \\frac{\\partial C}{\\partial z^{\\prime\\prime}}\\frac{\\partial z^{\\prime\\prime}}{\\partial a}.\n$$其中，根据$z^\\prime = aw_3 + \\dots$可知$$\n\\begin{aligned}\n\\frac{\\partial z^\\prime}{\\partial a} &= w_3 \\\\\n\\frac{\\partial z^{\\prime\\prime}}{\\partial a} &= w_4.\n\\end{aligned}\n$$而$w_3$和$w_4$的值是已知的，因此，我们离目标$\\frac{\\partial C}{\\partial a}$仅差$\\frac{\\partial C}{\\partial z^\\prime}$和$\\frac{\\partial C}{\\partial z^{\\prime\\prime}}$了。接下来我们采用**动态规划（或者说递归）的思路**，假设下一层的$\\frac{\\partial C}{\\partial z^\\prime}$和$\\frac{\\partial C}{\\partial z^{\\prime\\prime}}$是已知的，那么我们只需要最后一层的graident，就可以求得各层的gradient了。而通过softmax的例子，我们知道最后一层的gradient确实可求，因此只要从最后一层开始，逐层向前，即可求得各层gradient。\n\n因此我们求$\\frac{\\partial C}{\\partial z}$的过程实际上对应下图所示的神经网络（**原神经网络的反向神经网络**）：\n\n<div style=\"width:300px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img bp3.png  %}\n</div>\n\n---\n\n综上，我们先通过神经网络的正向计算，得到$x_1$以及$z$，进而求得$\\frac{\\partial z}{\\partial w_1}$和$\\frac{\\partial a}{\\partial z}$；然后通过神经网络的反向计算，得到$\\frac{\\partial C}{\\partial z^\\prime}$和$\\frac{\\partial C}{\\partial z^{\\prime\\prime}}$，进而求得$\\frac{\\partial C}{\\partial a}$；然后根据链式法则求得$\\frac{\\partial C}{\\partial w_1}$。这整个过程就叫做*backpropagation*，其中正向计算的过程叫做*forward pass*，反向计算的过程叫做*backward pass*。\n\n## derivative of CNN\n\n卷积层实际上是特殊的全连接层，只不过：\n\n- 神经元中的某些$w$为$0$；\n- 神经元之间共享$w$。\n\n具体来说，如下图所示，没有连线的表示对应的$w$为$0$：\n\n<div style=\"width:600px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img cnn1.png  %}\n</div>\n\n如下图所示，相同颜色的代表相同的$w$：\n\n<div style=\"width:600px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img cnn2.png  %}\n</div>\n\n因此，我们可以**把loss function理解为$C(z_1, z_2, \\dots)$**，然后求导的时候，根据链式法则，将相同$w$的gradient加起来就好了，即\n\n$$\n\\frac{\\partial C}{\\partial w} = \\sum_i \\frac{\\partial C}{\\partial z_i}\\frac{\\partial z_i}{\\partial w}.\n$$在求各个$\\frac{\\partial C}{\\partial z_i}\\frac{\\partial z_i}{\\partial w}$时，可以把他们看成是相互独立的$w$，那这样就跟普通的全连接层一样了，因此也就可以用backpropagation来求。\n\n## derivative of RNN\n\nRNN按照时序展开之后如下图所示（红线表示了求gradient的路线）：\n\n<div style=\"width:600px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img rnn.png  %}\n</div>\n\n跟处理卷积层的思路一样，首先**将loss function理解为$L(s_0, s_1, \\dots)$**，然后把各个$w$看成相互独立，最后根据链式法则求得对应的gradient，即\n\n$$\n\\frac{\\partial L}{\\partial w} = \\sum_i\\frac{\\partial L}{\\partial s_i}\\frac{\\partial s_i}{\\partial w}.\n$$由于这里是将RNN按照时序展开成为一个神经网络，所以这种求gradient的方法叫*Backpropagation Through Time(BPTT)*。\n\n## derivative of max pooling\n\n一般来说，函数$max(x, y, \\dots)$是不可导的，但**假如我们已经知道哪个自变量会是最大值，那么该函数就是可导的**（e.g., 假如知道$y$是最大的，那对$y$的偏导为$1$，对其他自变量的偏导为$0$）。\n\n而在train一个神经网络的时候，我们会先进行*forward pass*，之后再进行*backward pass*，因此我们在对max pooling求导的时候，已经知道哪个自变量是最大的，于是也就能够给出对应的gradient了。\n\n## references\n\n- [Hung-yi Lee Machine Learning](http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML17_2.html)\n- [RNN Tutorial](http://www.wildml.com/2015/10/recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/)","slug":"summary-derivative","published":1,"updated":"2024-08-13T16:03:47.872Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clzvf192h001qeqwoz7se07e4","content":"<h2 id=\"derivative-of-softmax\"><a href=\"#derivative-of-softmax\" class=\"headerlink\" title=\"derivative of softmax\"></a>derivative of softmax</h2><h3 id=\"derivative-of-softmax-1\"><a href=\"#derivative-of-softmax-1\" class=\"headerlink\" title=\"derivative of softmax\"></a>derivative of softmax</h3><p>一般来说，分类模型的最后一层都是softmax层，假设我们有一个$3$分类问题，那对应的softmax层结构如下图所示（一般认为输出的结果$y_i$即为输入$x$属于第$i$类的概率）：</p>\n<div style=\"width:600px; margin-left:auto; margin-right:auto;\"><br>  <img src=\"/2018/03/31/summary-derivative/softmax.png\" alt=\"softmax.png\" title=\"\"><br></div>\n\n<p>假设给定训练集$\\{ (x_1, c_1), \\dots, (x_m, c_m) \\}$，分类模型的<strong>目标是最大化对数似然函数</strong>$L(\\theta)$，即</p>\n<p>$$<br>\\mathop{\\text{maximize}}_\\theta \\sum_{j=1}^m \\ln  P(c_j  \\vert  x_j ; \\theta).<br>$$通常来说，我们采取的优化方法都是<strong>gradient based</strong>的（e.g., SGD），也就是说，需要求解$\\frac{\\partial L(\\theta)}{\\partial \\theta}$。而我们只要求得$\\frac{\\partial L(\\theta)}{\\partial z_i}$，之后根据链式法则，就可以求得$\\frac{\\partial L(\\theta)}{\\partial \\theta}$，因此我们的核心在于求解$\\frac{\\partial L(\\theta)}{\\partial z_i}$，即</p>\n<p>$$<br>\\begin{aligned}<br>\\frac{\\partial L(\\theta)}{\\partial z_i} &amp;= \\frac{\\partial}{\\partial z_i}\\sum_{j=1}^m \\ln  P(c_j  \\vert  x_j ; \\theta) \\\\<br>&amp;= \\sum_{j=1}^m\\frac{\\partial}{\\partial z_i} \\ln  P(c_j  \\vert  x_j ; \\theta).<br>\\end{aligned}<br>$$由上式可知，我们只需要知道各个样本$j$的$\\frac{\\partial}{\\partial z_i} \\ln  P(c_j  \\vert  x_j ; \\theta)$，即可通过求和求得$\\frac{\\partial L(\\theta)}{\\partial z_i}$，进而通过链式法则求得$\\frac{\\partial L(\\theta)}{\\partial \\theta}$。因此下面<strong>省略样本下标$j$，仅讨论某个样本$(x, c)$</strong>。</p>\n<p>实际上对于如何表示$x$属于第几个类，有两种比较直观的方法：</p>\n<ul>\n<li>一种是<strong>直接法</strong>（i.e., 用$c=3$来表示$x$属于第$3$类），则$P(c  \\vert  x ; \\theta)=\\prod_n {y_n}^{\\mathbb{1}(c=n)}$，其中$\\mathbb{1}(\\bullet)$为指示函数；</li>\n<li>另一种是<strong>one-hot法</strong>（i.e., 用$c= [0 \\quad 0 \\quad 1]^T$来表示$x$属于第三类），则$P(c  \\vert  x ; \\theta)=\\prod_n {y_n}^{c_n}$，其中$c_n$为向量$c$的第$n$个元素。</li>\n<li>p.s., 也可以将one-hot法理解为直接法的<strong>实现形式</strong>，因为one-hot向量实际上就是$\\mathbb{1}(c=n)$。</li>\n</ul>\n<p>为了方便，<strong>本文采用one-hot法</strong>。于是，我们有：</p>\n<p>$$<br>\\begin{aligned}<br>\\frac{\\partial}{\\partial z_i} \\ln  P(c  \\vert  x ; \\theta) &amp;= \\frac{\\partial}{\\partial z_i} \\ln \\prod_n {y_n}^{c_n} \\\\<br>&amp;= \\frac{\\partial}{\\partial z_i} \\sum_n \\ln {y_n}^{c_n} \\\\<br>&amp;= \\frac{\\partial}{\\partial z_i} \\sum_n {c_n} \\ln \\frac{e^{z_n}}{\\sum_j e^{z_j}} \\\\<br>&amp;= \\sum_n {c_n} \\frac{\\partial}{\\partial z_i} (\\ln {e^{z_n}} - \\ln{\\sum_j e^{z_j}}) \\\\<br>&amp;= \\sum_n {c_n} \\frac{\\partial}{\\partial z_i} ({z_n} - \\ln{\\sum_j e^{z_j}}) \\\\<br>&amp;= \\sum_n {c_n} (\\frac{\\partial z_n}{\\partial z_i}  - \\frac{\\partial}{\\partial z_i} \\ln{\\sum_j e^{z_j}}) \\\\<br>&amp;= \\sum_n {c_n} (\\frac{\\partial z_n}{\\partial z_i}  - \\frac{e^{z_i}}{\\sum_j e^{z_j}} ) \\\\<br>&amp;= \\sum_n {c_n} (\\frac{\\partial z_n}{\\partial z_i}  - y_i ) \\\\<br>&amp;= \\sum_n {c_n} \\frac{\\partial z_n}{\\partial z_i}  - \\sum_n {c_n} y_i  \\\\<br>&amp;= c_i  - y_i . \\\\<br>\\end{aligned}<br>$$</p>\n<h3 id=\"softmax-amp-sigmoid\"><a href=\"#softmax-amp-sigmoid\" class=\"headerlink\" title=\"softmax &amp; sigmoid\"></a>softmax &amp; sigmoid</h3><p>再补充一下<strong>softmax与sigmoid的联系</strong>。当分类问题是二分类的时候，我们一般使用sigmoid function作为输出层，表示输入$x$属于第$1$类的概率，即<br>$$<br>P(1  \\vert  x ; \\theta) = \\frac{1}{1+e^{-z}}.<br>$$然后利用概率和为$1$来求解$x$属于第$2$类的概率，即</p>\n<p>$$<br>P(2  \\vert  x ; \\theta) = 1 - P(1  \\vert  x ; \\theta).<br>$$乍一看会觉得用sigmoid做二分类跟用softmax做二分类不一样：</p>\n<ul>\n<li>在用softmax时，<strong>output的维数</strong>跟类的数量一致，而用sigmoid时，output的维数比类的数量少；</li>\n<li>在用softmax时，各类的<strong>概率表达式</strong>跟sigmoid中的表达式不相同。</li>\n</ul>\n<p>但实际上，<strong>用sigmoid做二分类跟用softmax做二分类是等价的</strong>。我们可以让sigmoid的output维数跟类的数量一致，并且在形式上逼近softmax。</p>\n<p>$$<br>\\begin{aligned}<br>P(1  \\vert  x ; \\theta) &amp;= \\frac{1}{1+e^{-z}} \\\\<br>&amp;= \\frac{e^{z}}{e^{z}+e^{0}} \\\\<br>P(2  \\vert  x ; \\theta) &amp;= \\frac{e^{-z}}{1+e^{-z}} \\\\<br>&amp;= \\frac{e^{0}}{e^{z}+e^{0}}. \\\\<br>\\end{aligned}<br>$$通过上述变化，sigmoid跟softmax已经很相似了，只不过sigmoid的input的第二个元素恒等于$0$（i.e., intput为$[z \\quad 0]^T$），而softmax的input为$[z_1 \\quad z_2]^T$，下面就来说明这两者存在一个mapping的关系（i.e., 每一个$[z_1 \\quad z_2]^T$都可以找到一个对应的$[z \\quad 0]^T$来表示相同的softmax结果。不过值得注意的是，反过来并不成立，也就是说并不是每个$[z \\quad 0]^T$仅仅对应一个$[z_1 \\quad z_2]^T$）。</p>\n<p>$$<br>\\begin{aligned}<br>P(1  \\vert  x ; \\theta) &amp;= \\frac{e^{z_1}}{e^{z_1}+e^{z_2}} \\\\<br>&amp;= \\frac{e^{z_1-z_2}}{e^{z_1-z_2}+e^{z_2-z_2}} \\\\<br>&amp;= \\frac{e^{z}}{e^{z}+e^{0}}. \\\\<br>\\end{aligned}<br>$$因此，用sigmoid做二分类跟用softmax做二分类是等价的。</p>\n<h2 id=\"backpropagation\"><a href=\"#backpropagation\" class=\"headerlink\" title=\"backpropagation\"></a>backpropagation</h2><p>一般来说，在train一个神经网络时（i.e., 更新网络的参数），我们都需要loss function对各参数的gradient，<em>backpropagation</em>就是求解gradient的一种方法。</p>\n<div style=\"width:600px; margin-left:auto; margin-right:auto;\"><br>  <img src=\"/2018/03/31/summary-derivative/bp1.png\" alt=\"bp1.png\" title=\"\"><br></div>\n\n<p>假设我们有一个如上图所示的神经网络，我们想求损失函数$C$对$w_1$的gradient，那么根据链式法则，我们有</p>\n<p>$$<br>\\frac{\\partial C}{\\partial w_1} = \\frac{\\partial C}{\\partial z}\\frac{\\partial z}{\\partial w_1}.<br>$$而我们可以很容易得到上述式子右边的第二项，因为$z = x_1 w_1 + x_2 w_2 +b$，所以有</p>\n<p>$$<br>\\frac{\\partial z}{\\partial w_1} = x_1,<br>$$其中，$x_1$是上层的输出。</p>\n<hr>\n<p>而对于式子右边的的第一项，可以进一步拆分得到</p>\n<p>$$<br>\\frac{\\partial C}{\\partial z} = \\frac{\\partial C}{\\partial a}\\frac{\\partial a}{\\partial z}.<br>$$我们很容易得到上式右边第二项，因为$a=\\sigma(z)$，而激活函数$\\sigma$（e.g., sigmoid function）是我们自己定义的，所以有</p>\n<p>$$<br>\\frac{\\partial a}{\\partial z} = \\sigma^\\prime(z)，<br>$$其中，$z$是本层的线性输出（未经激活函数）。</p>\n<hr>\n<div style=\"width:600px; margin-left:auto; margin-right:auto;\"><br>  <img src=\"/2018/03/31/summary-derivative/bp2.png\" alt=\"bp2.png\" title=\"\"><br></div><br>观察上图，我们根据链式法则可以得到<br>$$<br>\\frac{\\partial C}{\\partial a} = \\frac{\\partial C}{\\partial z^\\prime}\\frac{\\partial z^\\prime}{\\partial a} + \\frac{\\partial C}{\\partial z^{\\prime\\prime}}\\frac{\\partial z^{\\prime\\prime}}{\\partial a}.<br>$$其中，根据$z^\\prime = aw_3 + \\dots$可知$$<br>\\begin{aligned}<br>\\frac{\\partial z^\\prime}{\\partial a} &amp;= w_3 \\\\<br>\\frac{\\partial z^{\\prime\\prime}}{\\partial a} &amp;= w_4.<br>\\end{aligned}<br>$$而$w_3$和$w_4$的值是已知的，因此，我们离目标$\\frac{\\partial C}{\\partial a}$仅差$\\frac{\\partial C}{\\partial z^\\prime}$和$\\frac{\\partial C}{\\partial z^{\\prime\\prime}}$了。接下来我们采用<strong>动态规划（或者说递归）的思路</strong>，假设下一层的$\\frac{\\partial C}{\\partial z^\\prime}$和$\\frac{\\partial C}{\\partial z^{\\prime\\prime}}$是已知的，那么我们只需要最后一层的graident，就可以求得各层的gradient了。而通过softmax的例子，我们知道最后一层的gradient确实可求，因此只要从最后一层开始，逐层向前，即可求得各层gradient。<br><br>因此我们求$\\frac{\\partial C}{\\partial z}$的过程实际上对应下图所示的神经网络（<strong>原神经网络的反向神经网络</strong>）：<br><br><div style=\"width:300px; margin-left:auto; margin-right:auto;\"><br>  <img src=\"/2018/03/31/summary-derivative/bp3.png\" alt=\"bp3.png\" title=\"\"><br></div>\n\n<hr>\n<p>综上，我们先通过神经网络的正向计算，得到$x_1$以及$z$，进而求得$\\frac{\\partial z}{\\partial w_1}$和$\\frac{\\partial a}{\\partial z}$；然后通过神经网络的反向计算，得到$\\frac{\\partial C}{\\partial z^\\prime}$和$\\frac{\\partial C}{\\partial z^{\\prime\\prime}}$，进而求得$\\frac{\\partial C}{\\partial a}$；然后根据链式法则求得$\\frac{\\partial C}{\\partial w_1}$。这整个过程就叫做<em>backpropagation</em>，其中正向计算的过程叫做<em>forward pass</em>，反向计算的过程叫做<em>backward pass</em>。</p>\n<h2 id=\"derivative-of-CNN\"><a href=\"#derivative-of-CNN\" class=\"headerlink\" title=\"derivative of CNN\"></a>derivative of CNN</h2><p>卷积层实际上是特殊的全连接层，只不过：</p>\n<ul>\n<li>神经元中的某些$w$为$0$；</li>\n<li>神经元之间共享$w$。</li>\n</ul>\n<p>具体来说，如下图所示，没有连线的表示对应的$w$为$0$：</p>\n<div style=\"width:600px; margin-left:auto; margin-right:auto;\"><br>  <img src=\"/2018/03/31/summary-derivative/cnn1.png\" alt=\"cnn1.png\" title=\"\"><br></div>\n\n<p>如下图所示，相同颜色的代表相同的$w$：</p>\n<div style=\"width:600px; margin-left:auto; margin-right:auto;\"><br>  <img src=\"/2018/03/31/summary-derivative/cnn2.png\" alt=\"cnn2.png\" title=\"\"><br></div>\n\n<p>因此，我们可以<strong>把loss function理解为$C(z_1, z_2, \\dots)$</strong>，然后求导的时候，根据链式法则，将相同$w$的gradient加起来就好了，即</p>\n<p>$$<br>\\frac{\\partial C}{\\partial w} = \\sum_i \\frac{\\partial C}{\\partial z_i}\\frac{\\partial z_i}{\\partial w}.<br>$$在求各个$\\frac{\\partial C}{\\partial z_i}\\frac{\\partial z_i}{\\partial w}$时，可以把他们看成是相互独立的$w$，那这样就跟普通的全连接层一样了，因此也就可以用backpropagation来求。</p>\n<h2 id=\"derivative-of-RNN\"><a href=\"#derivative-of-RNN\" class=\"headerlink\" title=\"derivative of RNN\"></a>derivative of RNN</h2><p>RNN按照时序展开之后如下图所示（红线表示了求gradient的路线）：</p>\n<div style=\"width:600px; margin-left:auto; margin-right:auto;\"><br>  <img src=\"/2018/03/31/summary-derivative/rnn.png\" alt=\"rnn.png\" title=\"\"><br></div>\n\n<p>跟处理卷积层的思路一样，首先<strong>将loss function理解为$L(s_0, s_1, \\dots)$</strong>，然后把各个$w$看成相互独立，最后根据链式法则求得对应的gradient，即</p>\n<p>$$<br>\\frac{\\partial L}{\\partial w} = \\sum_i\\frac{\\partial L}{\\partial s_i}\\frac{\\partial s_i}{\\partial w}.<br>$$由于这里是将RNN按照时序展开成为一个神经网络，所以这种求gradient的方法叫<em>Backpropagation Through Time(BPTT)</em>。</p>\n<h2 id=\"derivative-of-max-pooling\"><a href=\"#derivative-of-max-pooling\" class=\"headerlink\" title=\"derivative of max pooling\"></a>derivative of max pooling</h2><p>一般来说，函数$max(x, y, \\dots)$是不可导的，但<strong>假如我们已经知道哪个自变量会是最大值，那么该函数就是可导的</strong>（e.g., 假如知道$y$是最大的，那对$y$的偏导为$1$，对其他自变量的偏导为$0$）。</p>\n<p>而在train一个神经网络的时候，我们会先进行<em>forward pass</em>，之后再进行<em>backward pass</em>，因此我们在对max pooling求导的时候，已经知道哪个自变量是最大的，于是也就能够给出对应的gradient了。</p>\n<h2 id=\"references\"><a href=\"#references\" class=\"headerlink\" title=\"references\"></a>references</h2><ul>\n<li><a href=\"http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML17_2.html\" target=\"_blank\" rel=\"external\">Hung-yi Lee Machine Learning</a></li>\n<li><a href=\"http://www.wildml.com/2015/10/recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/\" target=\"_blank\" rel=\"external\">RNN Tutorial</a></li>\n</ul>\n","excerpt":"","more":"<h2 id=\"derivative-of-softmax\"><a href=\"#derivative-of-softmax\" class=\"headerlink\" title=\"derivative of softmax\"></a>derivative of softmax</h2><h3 id=\"derivative-of-softmax-1\"><a href=\"#derivative-of-softmax-1\" class=\"headerlink\" title=\"derivative of softmax\"></a>derivative of softmax</h3><p>一般来说，分类模型的最后一层都是softmax层，假设我们有一个$3$分类问题，那对应的softmax层结构如下图所示（一般认为输出的结果$y_i$即为输入$x$属于第$i$类的概率）：</p>\n<div style=\"width:600px; margin-left:auto; margin-right:auto;\" ><br>  <img src=\"/2018/03/31/summary-derivative/softmax.png\" alt=\"softmax.png\" title=\"\"><br></div>\n\n<p>假设给定训练集$\\{ (x_1, c_1), \\dots, (x_m, c_m) \\}$，分类模型的<strong>目标是最大化对数似然函数</strong>$L(\\theta)$，即</p>\n<p>$$<br>\\mathop{\\text{maximize}}_\\theta \\sum_{j=1}^m \\ln  P(c_j  \\vert  x_j ; \\theta).<br>$$通常来说，我们采取的优化方法都是<strong>gradient based</strong>的（e.g., SGD），也就是说，需要求解$\\frac{\\partial L(\\theta)}{\\partial \\theta}$。而我们只要求得$\\frac{\\partial L(\\theta)}{\\partial z_i}$，之后根据链式法则，就可以求得$\\frac{\\partial L(\\theta)}{\\partial \\theta}$，因此我们的核心在于求解$\\frac{\\partial L(\\theta)}{\\partial z_i}$，即</p>\n<p>$$<br>\\begin{aligned}<br>\\frac{\\partial L(\\theta)}{\\partial z_i} &amp;= \\frac{\\partial}{\\partial z_i}\\sum_{j=1}^m \\ln  P(c_j  \\vert  x_j ; \\theta) \\\\<br>&amp;= \\sum_{j=1}^m\\frac{\\partial}{\\partial z_i} \\ln  P(c_j  \\vert  x_j ; \\theta).<br>\\end{aligned}<br>$$由上式可知，我们只需要知道各个样本$j$的$\\frac{\\partial}{\\partial z_i} \\ln  P(c_j  \\vert  x_j ; \\theta)$，即可通过求和求得$\\frac{\\partial L(\\theta)}{\\partial z_i}$，进而通过链式法则求得$\\frac{\\partial L(\\theta)}{\\partial \\theta}$。因此下面<strong>省略样本下标$j$，仅讨论某个样本$(x, c)$</strong>。</p>\n<p>实际上对于如何表示$x$属于第几个类，有两种比较直观的方法：</p>\n<ul>\n<li>一种是<strong>直接法</strong>（i.e., 用$c=3$来表示$x$属于第$3$类），则$P(c  \\vert  x ; \\theta)=\\prod_n {y_n}^{\\mathbb{1}(c=n)}$，其中$\\mathbb{1}(\\bullet)$为指示函数；</li>\n<li>另一种是<strong>one-hot法</strong>（i.e., 用$c= [0 \\quad 0 \\quad 1]^T$来表示$x$属于第三类），则$P(c  \\vert  x ; \\theta)=\\prod_n {y_n}^{c_n}$，其中$c_n$为向量$c$的第$n$个元素。</li>\n<li>p.s., 也可以将one-hot法理解为直接法的<strong>实现形式</strong>，因为one-hot向量实际上就是$\\mathbb{1}(c=n)$。</li>\n</ul>\n<p>为了方便，<strong>本文采用one-hot法</strong>。于是，我们有：</p>\n<p>$$<br>\\begin{aligned}<br>\\frac{\\partial}{\\partial z_i} \\ln  P(c  \\vert  x ; \\theta) &amp;= \\frac{\\partial}{\\partial z_i} \\ln \\prod_n {y_n}^{c_n} \\\\<br>&amp;= \\frac{\\partial}{\\partial z_i} \\sum_n \\ln {y_n}^{c_n} \\\\<br>&amp;= \\frac{\\partial}{\\partial z_i} \\sum_n {c_n} \\ln \\frac{e^{z_n}}{\\sum_j e^{z_j}} \\\\<br>&amp;= \\sum_n {c_n} \\frac{\\partial}{\\partial z_i} (\\ln {e^{z_n}} - \\ln{\\sum_j e^{z_j}}) \\\\<br>&amp;= \\sum_n {c_n} \\frac{\\partial}{\\partial z_i} ({z_n} - \\ln{\\sum_j e^{z_j}}) \\\\<br>&amp;= \\sum_n {c_n} (\\frac{\\partial z_n}{\\partial z_i}  - \\frac{\\partial}{\\partial z_i} \\ln{\\sum_j e^{z_j}}) \\\\<br>&amp;= \\sum_n {c_n} (\\frac{\\partial z_n}{\\partial z_i}  - \\frac{e^{z_i}}{\\sum_j e^{z_j}} ) \\\\<br>&amp;= \\sum_n {c_n} (\\frac{\\partial z_n}{\\partial z_i}  - y_i ) \\\\<br>&amp;= \\sum_n {c_n} \\frac{\\partial z_n}{\\partial z_i}  - \\sum_n {c_n} y_i  \\\\<br>&amp;= c_i  - y_i . \\\\<br>\\end{aligned}<br>$$</p>\n<h3 id=\"softmax-amp-sigmoid\"><a href=\"#softmax-amp-sigmoid\" class=\"headerlink\" title=\"softmax &amp; sigmoid\"></a>softmax &amp; sigmoid</h3><p>再补充一下<strong>softmax与sigmoid的联系</strong>。当分类问题是二分类的时候，我们一般使用sigmoid function作为输出层，表示输入$x$属于第$1$类的概率，即<br>$$<br>P(1  \\vert  x ; \\theta) = \\frac{1}{1+e^{-z}}.<br>$$然后利用概率和为$1$来求解$x$属于第$2$类的概率，即</p>\n<p>$$<br>P(2  \\vert  x ; \\theta) = 1 - P(1  \\vert  x ; \\theta).<br>$$乍一看会觉得用sigmoid做二分类跟用softmax做二分类不一样：</p>\n<ul>\n<li>在用softmax时，<strong>output的维数</strong>跟类的数量一致，而用sigmoid时，output的维数比类的数量少；</li>\n<li>在用softmax时，各类的<strong>概率表达式</strong>跟sigmoid中的表达式不相同。</li>\n</ul>\n<p>但实际上，<strong>用sigmoid做二分类跟用softmax做二分类是等价的</strong>。我们可以让sigmoid的output维数跟类的数量一致，并且在形式上逼近softmax。</p>\n<p>$$<br>\\begin{aligned}<br>P(1  \\vert  x ; \\theta) &amp;= \\frac{1}{1+e^{-z}} \\\\<br>&amp;= \\frac{e^{z}}{e^{z}+e^{0}} \\\\<br>P(2  \\vert  x ; \\theta) &amp;= \\frac{e^{-z}}{1+e^{-z}} \\\\<br>&amp;= \\frac{e^{0}}{e^{z}+e^{0}}. \\\\<br>\\end{aligned}<br>$$通过上述变化，sigmoid跟softmax已经很相似了，只不过sigmoid的input的第二个元素恒等于$0$（i.e., intput为$[z \\quad 0]^T$），而softmax的input为$[z_1 \\quad z_2]^T$，下面就来说明这两者存在一个mapping的关系（i.e., 每一个$[z_1 \\quad z_2]^T$都可以找到一个对应的$[z \\quad 0]^T$来表示相同的softmax结果。不过值得注意的是，反过来并不成立，也就是说并不是每个$[z \\quad 0]^T$仅仅对应一个$[z_1 \\quad z_2]^T$）。</p>\n<p>$$<br>\\begin{aligned}<br>P(1  \\vert  x ; \\theta) &amp;= \\frac{e^{z_1}}{e^{z_1}+e^{z_2}} \\\\<br>&amp;= \\frac{e^{z_1-z_2}}{e^{z_1-z_2}+e^{z_2-z_2}} \\\\<br>&amp;= \\frac{e^{z}}{e^{z}+e^{0}}. \\\\<br>\\end{aligned}<br>$$因此，用sigmoid做二分类跟用softmax做二分类是等价的。</p>\n<h2 id=\"backpropagation\"><a href=\"#backpropagation\" class=\"headerlink\" title=\"backpropagation\"></a>backpropagation</h2><p>一般来说，在train一个神经网络时（i.e., 更新网络的参数），我们都需要loss function对各参数的gradient，<em>backpropagation</em>就是求解gradient的一种方法。</p>\n<div style=\"width:600px; margin-left:auto; margin-right:auto;\" ><br>  <img src=\"/2018/03/31/summary-derivative/bp1.png\" alt=\"bp1.png\" title=\"\"><br></div>\n\n<p>假设我们有一个如上图所示的神经网络，我们想求损失函数$C$对$w_1$的gradient，那么根据链式法则，我们有</p>\n<p>$$<br>\\frac{\\partial C}{\\partial w_1} = \\frac{\\partial C}{\\partial z}\\frac{\\partial z}{\\partial w_1}.<br>$$而我们可以很容易得到上述式子右边的第二项，因为$z = x_1 w_1 + x_2 w_2 +b$，所以有</p>\n<p>$$<br>\\frac{\\partial z}{\\partial w_1} = x_1,<br>$$其中，$x_1$是上层的输出。</p>\n<hr>\n<p>而对于式子右边的的第一项，可以进一步拆分得到</p>\n<p>$$<br>\\frac{\\partial C}{\\partial z} = \\frac{\\partial C}{\\partial a}\\frac{\\partial a}{\\partial z}.<br>$$我们很容易得到上式右边第二项，因为$a=\\sigma(z)$，而激活函数$\\sigma$（e.g., sigmoid function）是我们自己定义的，所以有</p>\n<p>$$<br>\\frac{\\partial a}{\\partial z} = \\sigma^\\prime(z)，<br>$$其中，$z$是本层的线性输出（未经激活函数）。</p>\n<hr>\n<div style=\"width:600px; margin-left:auto; margin-right:auto;\" ><br>  <img src=\"/2018/03/31/summary-derivative/bp2.png\" alt=\"bp2.png\" title=\"\"><br></div><br>观察上图，我们根据链式法则可以得到<br>$$<br>\\frac{\\partial C}{\\partial a} = \\frac{\\partial C}{\\partial z^\\prime}\\frac{\\partial z^\\prime}{\\partial a} + \\frac{\\partial C}{\\partial z^{\\prime\\prime}}\\frac{\\partial z^{\\prime\\prime}}{\\partial a}.<br>$$其中，根据$z^\\prime = aw_3 + \\dots$可知$$<br>\\begin{aligned}<br>\\frac{\\partial z^\\prime}{\\partial a} &amp;= w_3 \\\\<br>\\frac{\\partial z^{\\prime\\prime}}{\\partial a} &amp;= w_4.<br>\\end{aligned}<br>$$而$w_3$和$w_4$的值是已知的，因此，我们离目标$\\frac{\\partial C}{\\partial a}$仅差$\\frac{\\partial C}{\\partial z^\\prime}$和$\\frac{\\partial C}{\\partial z^{\\prime\\prime}}$了。接下来我们采用<strong>动态规划（或者说递归）的思路</strong>，假设下一层的$\\frac{\\partial C}{\\partial z^\\prime}$和$\\frac{\\partial C}{\\partial z^{\\prime\\prime}}$是已知的，那么我们只需要最后一层的graident，就可以求得各层的gradient了。而通过softmax的例子，我们知道最后一层的gradient确实可求，因此只要从最后一层开始，逐层向前，即可求得各层gradient。<br><br>因此我们求$\\frac{\\partial C}{\\partial z}$的过程实际上对应下图所示的神经网络（<strong>原神经网络的反向神经网络</strong>）：<br><br><div style=\"width:300px; margin-left:auto; margin-right:auto;\" ><br>  <img src=\"/2018/03/31/summary-derivative/bp3.png\" alt=\"bp3.png\" title=\"\"><br></div>\n\n<hr>\n<p>综上，我们先通过神经网络的正向计算，得到$x_1$以及$z$，进而求得$\\frac{\\partial z}{\\partial w_1}$和$\\frac{\\partial a}{\\partial z}$；然后通过神经网络的反向计算，得到$\\frac{\\partial C}{\\partial z^\\prime}$和$\\frac{\\partial C}{\\partial z^{\\prime\\prime}}$，进而求得$\\frac{\\partial C}{\\partial a}$；然后根据链式法则求得$\\frac{\\partial C}{\\partial w_1}$。这整个过程就叫做<em>backpropagation</em>，其中正向计算的过程叫做<em>forward pass</em>，反向计算的过程叫做<em>backward pass</em>。</p>\n<h2 id=\"derivative-of-CNN\"><a href=\"#derivative-of-CNN\" class=\"headerlink\" title=\"derivative of CNN\"></a>derivative of CNN</h2><p>卷积层实际上是特殊的全连接层，只不过：</p>\n<ul>\n<li>神经元中的某些$w$为$0$；</li>\n<li>神经元之间共享$w$。</li>\n</ul>\n<p>具体来说，如下图所示，没有连线的表示对应的$w$为$0$：</p>\n<div style=\"width:600px; margin-left:auto; margin-right:auto;\" ><br>  <img src=\"/2018/03/31/summary-derivative/cnn1.png\" alt=\"cnn1.png\" title=\"\"><br></div>\n\n<p>如下图所示，相同颜色的代表相同的$w$：</p>\n<div style=\"width:600px; margin-left:auto; margin-right:auto;\" ><br>  <img src=\"/2018/03/31/summary-derivative/cnn2.png\" alt=\"cnn2.png\" title=\"\"><br></div>\n\n<p>因此，我们可以<strong>把loss function理解为$C(z_1, z_2, \\dots)$</strong>，然后求导的时候，根据链式法则，将相同$w$的gradient加起来就好了，即</p>\n<p>$$<br>\\frac{\\partial C}{\\partial w} = \\sum_i \\frac{\\partial C}{\\partial z_i}\\frac{\\partial z_i}{\\partial w}.<br>$$在求各个$\\frac{\\partial C}{\\partial z_i}\\frac{\\partial z_i}{\\partial w}$时，可以把他们看成是相互独立的$w$，那这样就跟普通的全连接层一样了，因此也就可以用backpropagation来求。</p>\n<h2 id=\"derivative-of-RNN\"><a href=\"#derivative-of-RNN\" class=\"headerlink\" title=\"derivative of RNN\"></a>derivative of RNN</h2><p>RNN按照时序展开之后如下图所示（红线表示了求gradient的路线）：</p>\n<div style=\"width:600px; margin-left:auto; margin-right:auto;\" ><br>  <img src=\"/2018/03/31/summary-derivative/rnn.png\" alt=\"rnn.png\" title=\"\"><br></div>\n\n<p>跟处理卷积层的思路一样，首先<strong>将loss function理解为$L(s_0, s_1, \\dots)$</strong>，然后把各个$w$看成相互独立，最后根据链式法则求得对应的gradient，即</p>\n<p>$$<br>\\frac{\\partial L}{\\partial w} = \\sum_i\\frac{\\partial L}{\\partial s_i}\\frac{\\partial s_i}{\\partial w}.<br>$$由于这里是将RNN按照时序展开成为一个神经网络，所以这种求gradient的方法叫<em>Backpropagation Through Time(BPTT)</em>。</p>\n<h2 id=\"derivative-of-max-pooling\"><a href=\"#derivative-of-max-pooling\" class=\"headerlink\" title=\"derivative of max pooling\"></a>derivative of max pooling</h2><p>一般来说，函数$max(x, y, \\dots)$是不可导的，但<strong>假如我们已经知道哪个自变量会是最大值，那么该函数就是可导的</strong>（e.g., 假如知道$y$是最大的，那对$y$的偏导为$1$，对其他自变量的偏导为$0$）。</p>\n<p>而在train一个神经网络的时候，我们会先进行<em>forward pass</em>，之后再进行<em>backward pass</em>，因此我们在对max pooling求导的时候，已经知道哪个自变量是最大的，于是也就能够给出对应的gradient了。</p>\n<h2 id=\"references\"><a href=\"#references\" class=\"headerlink\" title=\"references\"></a>references</h2><ul>\n<li><a href=\"http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML17_2.html\">Hung-yi Lee Machine Learning</a></li>\n<li><a href=\"http://www.wildml.com/2015/10/recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/\">RNN Tutorial</a></li>\n</ul>\n"},{"title":"学习总结《Guided Policy Search》","date":"2018-05-17T10:49:29.000Z","description":["一种Model-Based的强化学习算法"],"_content":"\n# Overivew\n\n本文将介绍*Guided Policy Search(GPS)*这种Model-Based的强化学习算法，并会按以下方式展开：\n\n1. Motivation：介绍*GPS*这种方法的**特点**；\n2. Problem formulation：介绍*GPS*所解决**问题的具体形式**；\n3. Framework：介绍*GPS*的**整体框架**；\n4. Deterministic policy case：从相对简单的deterministic policy case开始介绍*GPS*的**具体流程**；\n5. Stochastic policy case：从deterministic policy case过渡到stochastic policy case，介绍**完整**的*GPS*算法。\n\n---\n\n# Motivation\n\n下面通过将*GPS*跟不同类型的算法进行比较来说明*GPS*的特点。\n\n- 与Model-Free算法相比：由于*GPS*对环境建立了模型（i.e., model/dynamics），在计算q value时，不仅仅是“记录”，还能进行“推算”，因此**sample efficiency会比较高，收敛速度会比较快**；\n- 与其他Model-Based算法相比：在test的时候，部分Model-Based算法需要进行online optimization（i.e., 根据当前拟合的模型，使用某种优化算法，得到当前的action）；而由于*GPS*最终得到的是一个parametric policy（e.g., 神经网络），因此**在test的时候会比较快**（无需做online optimization，只需要做一次forward pass）；\n- 与简单的Imitation Learning算法相比：在简单的IL中，teacher单方面地给student传授知识（i.e., supervised learning），而不管student的学习能力如何；而在*GPS*中，**除了teacher给student传授知识以外，student还会给teacher反馈**，要求teacher适配student的学习能力，形成闭环，因此train的效果会更好。\n\n---\n\n# Problem Formulation\n\n下面对我们所讨论的问题做一个界定。\n\n- setting\n\t- **fixed time length** task（e.g, 完成任务的时长限定在20s内，决策的频率是20Hz，则总步长$T$为400）\n- assumption\n\t- deterministic dynamics：$x_t = f(x_{t-1}, u_{t-1})$\n- input\n\t- environment\n\t- immediate cost(reward) function：$c(x_t, u_t)$\n- output\n\t- parametric policy\n\t\t- deterministic case：$u_t = \\pi_\\theta(x_t)$\n\t\t- stochastic case：$\\pi_\\theta(u_t \\vert x_t) \\sim \\mathcal{N}(\\mu_t, \\Sigma_t)$\n\n---\n\n# Framework\n\n下面介绍*GPS*的整体框架。\n\n1. collect data：通过controller与environment进行交互，收集数据；\n<div style=\"width:300px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img 1.png  %}\n</div>\n2. fit dynamics：根据第一步收集到的数据，拟合dynamics；\n<div style=\"width:300px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img 2.png  %}\n</div>\n3. optimization：优化controller（最优控制器）与policy（最终输出的parametric policy）；\n<div style=\"width:400px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img 3.png  %}\n</div>\n4. next iteration：迭代。\n<div style=\"width:500px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img 4.png  %}\n</div>\n\n---\n\n# Deterministic policy case\n\n下面开始介绍Deterministic policy case下*GPS*的具体流程。\n\n## Collect data\n\n使用controller与environment进行交互，得到轨迹数据集$\\mathcal{D} = \\{ \\tau_i \\}$，其中轨迹$\\tau_i = \\{ x_{1i}, u_{1i}, \\dots , x_{1T}, u_{1T} \\}$。\n\n## Fit dynamics\n\n使用第一步得到的轨迹数据集来拟合一个time-varying linear model：$x_{t+1} = f(x_t, u_t) = A_tx_t + B_tu_t + c_t$，也就是说这个model**对于不同时刻$t$的input会使用不同的linear model**。\n\n具体的拟合方法是使用同一时刻$t$，不同轨迹$\\tau_i$的数据$\\{ (x_{t1}, u_{t1}, x_{t+1,1}), \\dots , (x_{ti}, u_{ti}, x_{t+1,i}) \\}$来做linear regression。\n\n## Optimization\n\n### Controller\n\n- big picture\n\n<div style=\"width:250px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img 3_1.png  %}\n</div>\n\n- optimization problem\n\t- 我们想要在满足dynamics约束的条件下，最小化总cost，因此对应的轨迹优化问题为：\n$$\n\\begin{aligned}\n\\mathop{\\text{min }}_{x_1, u_1, \\dots, x_T, u_T} &\\sum_{t=1}^T c(x_t, u_t) \\\\\n\\text{s.t. } &x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.\n\\end{aligned}\n$$\n- solution\n\t- 假如上述轨迹优化问题中$f(x_t, u_t) = F_t \\begin{bmatrix} x_t \\\\\\\\ u_t \\end{bmatrix} + f_t$， $c(x_t, u_t) = \\frac{1}{2} \\begin{bmatrix} x_t \\\\\\\\ u_t \\end{bmatrix}^T C_t \\begin{bmatrix} x_t \\\\\\\\ u_t \\end{bmatrix} + \\begin{bmatrix} x_t \\\\\\\\ u_t \\end{bmatrix}^T c_t$，则有一个叫做*Linear Quadratic Regulator(LQR)*的优化方法可以对该轨迹优化问题进行求解。\n\t- *LQR*基本原理如下：\n\t\t- input：\n\t\t\t- linear model（$F_t, f_t$）\n\t\t\t- quadratic cost（$C_t, c_t$）\n\t\t- output：$K_t, k_t$\n\t\t- optimal control（上述轨迹优化问题的解）：$u_t=K_tx_t+k_t$，$x_{t+1}=f(x_t, u_t)$\n<div style=\"width:500px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img lqr.png  %}\n</div>\n\t- 由于我们在fit dynamics中拟合的就是一个linear model，因此只要我们设置的cost function是quadratic的话就可以使用*LQR*来求解。\n\t- 即使我们的cost function不是quadratic，也还可以使用*iterative LQR(iLQR)*来进行求解。*iLQR*可以求解nonlinear dynamics，nonquadratic cost下的轨迹优化问题，它的核心思想是对dynamics和cost分别进行linear及quadratic展开，然后用*LQR*进行求解。\n\n### Policy\n\n- big picture\n\n<div style=\"width:400px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img 3.png  %}\n</div>\n\n- optimization problem\n\t- 因为*GPS*最后想要的是一个policy，因此在上述轨迹优化问题的基础上，加上一个优化变量$\\theta$以及约束条件$u_t = \\pi_\\theta(x_t)$，来表示我们希望policy能够“学习”optimal control：\n\t$$\n\t\\begin{aligned}\n\t\\mathop{\\text{min }}_{x_1, u_1, \\dots, x_T, u_T, \\theta} &\\sum_{t=1}^T c(x_t, u_t) \\\\\n\t\\text{s.t. } &u_t = \\pi_\\theta(x_t) \\quad t=1, \\dots, T\\\\\n\t&x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.\n\t\\end{aligned}\n\t$$\n- solution\n\t- 求解上述优化问题用到了一种叫做*Dual Gradient Descent(DGD)*的优化方法。*DGD*是一种求解形如以下优化问题的方法：\n\t$$\n\t\\begin{aligned}\n\t\\mathop{\\text{min }}_x &f(x) \\\\\n\t\\text{s.t. } & C(x)=0.\n\t\\end{aligned}\n\t$$其具体求解过程为：\n\t\t1. 写出对应的Lagrangian函数：$\\mathcal{L}(x, \\lambda) = f(x) + \\lambda C(x)$；\n\t\t2. 求解最小化Lagrangian函数的$x$：$x^\\* = \\mathop{\\text{argmin }}_x \\mathcal{L}(x, \\lambda)$；\n\t\t3. 将$x^\\*$代入$\\mathcal{L}(x, \\lambda)$得到原问题的下界函数$g(\\lambda) = \\mathcal{L}(x^\\*, \\lambda)$；\n\t\t4. 更新$\\lambda$（类似对$\\lambda$做gradient ascent）：$\\lambda = \\lambda + \\alpha \\frac{\\partial g}{\\partial \\lambda}$；\n\t\t5. 回到第二步，求新$\\lambda$下对应的$x^\\*$，迭代。\n\t- 接下来改变一下优化问题的表述方式，**将dynamics约束单独提出来**（之所以这么做，是**为了将问题化归为会解的问题**，下面会详细说），也就是说现在把问题理解为在满足dynamics约束下求解一个约束优化问题（i.e., 满足policy约束下最小化cost），而原来是满足dynamics和policy约束下求解一个无约束优化问题（i.e., 最小化cost）：\n\t$$\n\t\\begin{aligned}\n\t\\mathop{\\text{min }}_{x_1, u_1, \\dots, x_T, u_T, \\theta} &\\sum_{t=1}^T c(x_t, u_t) \\\\\n\t\\text{s.t. } &u_t = \\pi_\\theta(x_t) \\quad t=1, \\dots, T\\\\\n\t\\\\\n\t\\text{s.t. } x_t = f&(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.\n\t\\end{aligned}\n\t$$\n\t- 然后进行**约束条件下的*DGD***（i.e., 整个*DGD*的过程都要满足约束）：\n\t\t1. 仅将policy约束写进Lagrangian函数：\n\t\t$$\n\t\t\\begin{aligned}\n\t\t\\mathcal{L}(\\tau, \\theta, \\lambda) \n\t\t&= \\mathcal{L}(x_1, u_1, \\dots, x_T, u_T, \\theta, \\lambda_1, \\dots, \\lambda_T) \\\\\n\t\t&=  \\sum_{t=1}^T c(x_t, u_t) + \\sum_{t=1}^T\\lambda_t [u_t - \\pi_\\theta(x_t)] \\\\\n\t\t&= \\sum_{t=1}^T \\{ c(x_t, u_t) + \\lambda_t [u_t - \\pi_\\theta(x_t)] \\}.\n\t\t\\end{aligned}\n\t\t$$\n\t\t2. 本来应该将$\\begin{bmatrix}\\tau \\\\\\\\ \\theta\\end{bmatrix}$这一整个向量看作优化变量（对应*DGD*中的$x$），然后求解$\\begin{bmatrix}\\tau \\\\\\\\ \\theta\\end{bmatrix}^\\*$（对应*DGD*中的$x^\\*$）。但这里**假设$\\tau$和$\\theta$相互独立**（为了能够求解），因此下面可以分别单独对$\\tau$与$\\theta$做优化，求得对应的$\\tau^\\*$和$\\theta^\\*$，然后用$\\begin{bmatrix}\\tau^\\* \\\\\\\\ \\theta^\\*\\end{bmatrix}$来近似$\\begin{bmatrix}\\tau \\\\\\\\ \\theta\\end{bmatrix}^\\*$。\n\t\t3. 求解$\\tau^\\*$：对应的优化问题为：\n\t\t$$\n\t\t\\begin{aligned}\n\t\t\\mathop{\\text{min }}_\\tau &\\sum_{t=1}^T \\{ c(x_t, u_t) + \\lambda_t [u_t - \\pi_\\theta(x_t)] \\} \\\\\n\t\t\\text{s.t. } &x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.\n\t\t\\end{aligned}\n\t\t$$设$\\tilde{c}(x_t, u_t)=c(x_t, u_t) + \\lambda_t [u_t - \\pi_\\theta(x_t)]$，我们有：\n\t\t$$\n\t\t\\begin{aligned}\n\t\t\\mathop{\\text{min }}_\\tau &\\sum_{t=1}^T \\tilde{c}(x_t, u_t)\\\\\n\t\t\\text{s.t. } &x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.\n\t\t\\end{aligned}\n\t\t$$而**这个形式的优化问题我们能够通过*iLQR*进行求解**，因此能够求得$\\tau^\\*$。\n\t\t4. 求解$\\theta^\\*$：对应的优化问题为：\n\t\t$$\n\t\t\\begin{aligned}\n\t\t\\mathop{\\text{min }}_\\theta &\\sum_{t=1}^T \\{ c(x_t, u_t) + \\lambda_t [u_t - \\pi_\\theta(x_t)] \\} \\\\\n\t\t\\text{s.t. } &x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.\n\t\t\\end{aligned}\n\t\t$$由于优化变量是$\\theta$，所以约束条件可以去掉，而且目标函数也可以简化，等价的优化问题为：\n\t\t$$\n\t\t\\begin{aligned}\n\t\t\\mathop{\\text{min }}_\\theta &\\sum_{t=1}^T \\lambda_t [u_t - \\pi_\\theta(x_t)].\n\t\t\\end{aligned}\n\t\t$$这是一个无约束优化问题（带权拟合问题），可以用诸如*SGD*等方法进行优化，因此也能够求得$\\theta^\\*$。\n\t\t5. 将$\\tau^\\*$和$\\theta^\\*$代入Lagrangian函数，得到$g(\\lambda) = \\mathcal{L}(\\tau^\\*, \\theta^\\*, \\lambda)$。\n\t\t6. 对$\\lambda$做单步gradient ascent（跟求解$\\theta^\\*$时一样，由于约束条件跟优化变量无关，所以等价于无约束优化），更新$\\lambda$，迭代。\n\n## Next iteration\n\n回到第一步collect data，即用新的controller跟environment交互，迭代。\n\n## Summary\n\n至此我们已经通过相对简单的deterministic policy case过了一遍*GPS*的整个流程，下面补充一些小小的细节：\n\n- 为什么称之为*GPS*：guided主要体现在最后优化问题的约束$u_t = \\pi_\\theta(x_t)$，相当于有一个teacher（controller）在“指引”我们的policy。\n- collect data使用controller还是policy：应该是使用controller，因为policy仅仅拟合了某些具体的$(x_t, u_t)$，而controller对各个$x_t$都是“最优”的。\n- 为什么流程图中，train policy部分会跟$\\tau_i$相关：这是因为在求解$\\theta^\\*$时，$\\tau^\\*$还没代入Lagrangian函数，也就是说Lagrangian函数中用的是$\\tau$而不是$\\tau^\\*$。\n\n---\n\n# Stochastic policy case\n\ndeterministic controller对于一个起始点只能采集到一条轨迹，**不利于拟合一个robust的dynamics**，因此我们想要一个stochastic的controller。之后通过对stochastic controller进行supervised learning，我们最后会得到一个stochastic policy。\n\nstochastic policy case跟deterministic policy case的**唯一区别在于optimization这步**（如红框所示），其他都是一样的。因此下面仅介绍stochastic policy case如何做optimization。\n\n<div style=\"width:400px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img 3.png  %}\n</div>\n\n## Using stochastic controller\n\n首先介绍一个过渡性的内容，是关于使用stochastic controller的。\n\n- 最直观的想法：把原来的约束问题（暂时先不考虑policy）改一下，将controller表示为$p(u_t \\vert x_t) \\sim \\mathcal{N}(\\mu_t, \\Sigma_t)$，然后求解优化问题：\n$$\n\\begin{aligned}\n\\mathop{\\text{min }}_{\\tau, p} &\\mathbb{E}_\\tau[\\sum_{t=1}^T c(x_t, u_t)] \\\\\n\\text{s.t. } &x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T,\n\\end{aligned}\n$$其中$p = \\mu_1, \\Sigma_1, \\dots, \\mu_T, \\Sigma_T$。但这样子是不work的，因为**最后求出来的还是一个determinisitc controller**（因为贪婪地采取最优策略效果是最好的）。\n- 于是就强行把controller设成linear-gaussian的形式：\n$$\np(u_t \\vert x_t) = \\mathcal{N}(K_t(x_t - \\hat{x}_t) + k_t + \\hat{u}_t, Q^{-1}_{u_t,u_t}),\n$$其中，gaussian的均值为*iLQR*的解，方差为*iLQR*中的某个矩阵的逆，具体含义可以不用管，只需要知道这些东西都可以通过*iLQR*得到。\n- 而该形式的controller恰好是以下优化问题的最优解：\n$$\n\\begin{aligned}\n\\mathop{\\text{min }}_{\\tau, p} &\\sum_{t=1}^T\\mathbb{E}_{p(x_t, u_t)}[ c(x_t, u_t) - \\mathcal{H}(p(u_t \\vert x_t))] \\\\\n\\text{s.t. } &x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.\n\\end{aligned}\n$$\n- 这部分主要为下面做铺垫，核心在于**我们现在知道了某种形式的优化问题的最优解**。\n\n## Constrain controller in trust region\n\n- motivation\n\t- 在*GPS*中我们所fit的dynamics是local dynamics，也就是说它**仅在当前controller“附近”是有效的**；\n\t- 在优化问题中，我们评价controller好坏会用到该local dynamics；\n\t- 因此，为了确保评价的有效性，我们要**限定controller在当前controller“附近”**；\n\t- 否则，即使contoller评价很高，也是虚假的/无效的/没有意义的。\n- solution\n\t- 将controller在当前controller“附近”用数学语言表述出来，即\n\t$$\n\tD_{KL}(p(\\tau) \\Vert \\bar{p}(\\tau) ) \\leq \\epsilon,\n\t$$其中$p(\\tau)$表示轨迹$\\tau$在新controller下发生的概率，$\\bar{p}(\\tau)$表示轨迹$\\tau$在当前controller下发生的概率，$D_{KL}$表示KL-divergence，用于衡量两个分布的“相似程度”，KL-divergence越小，两个分布越相似。\n\t\t- 这个表示能够**间接地限制controller和当前controller比较相似**，因为$p(\\tau) = p(x_1)\\prod_{t=1}^{T-1} p(u_t \\vert x_t)f(x_{t+1} \\vert x_t, u_t)$，而对于新旧controller来说，$p(x_1)$以及$f(x_{t+1} \\vert x_t, u_t)$都是一样的，因此区别仅仅在于$p(u_t \\vert x_t)$。换句话说，$p(\\tau)$和$\\bar{p}(\\tau)$的区别仅仅在于controller，因此控制$p(\\tau)$和$\\bar{p}(\\tau)$的相似程度就可以间接地控制controller的相似程度。\n\t- new optimization problem\n\t$$\n\t\\begin{aligned}\n\t\\mathop{\\text{min }}_{\\tau, p} &\\mathbb{E}_\\tau[\\sum_{t=1}^T c(x_t, u_t)] \\\\\n\t\\text{s.t. } &D_{KL}(p(\\tau) \\Vert \\bar{p}(\\tau) ) \\leq \\epsilon \\\\\n\t&x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.\n\t\\end{aligned}\n\t$$\n\t- 进行约束条件下的*DGD*（这里我不太懂为什么可以对不等式约束做*DGD*，逻辑上来讲对于不等式约束，需要限定$\\lambda \\geq 0$才能保证$g(\\lambda)$是原问题的下界函数）：\n\t\t1. 仅将$D_{KL}$约束写进Lagrangian函数：\n\t\t$$\n\t\t\\begin{aligned}\n\t\t\\mathcal{L}(\\tau, p, \\lambda) &= \\mathbb{E}_\\tau[\\sum_{t=1}^T c(x_t, u_t)] + \\lambda (D_{KL}(p(\\tau) \\Vert \\bar{p}(\\tau) ) - \\epsilon) \\\\\n\t\t&// D_{KL}(p(\\tau) \\Vert \\bar{p}(\\tau) ) = \\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)} [- \\log \\bar{p}(u_t \\vert x_t) - \\mathcal{H}(p(u_t \\vert x_t))]  \\\\\n\t\t&= \\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)}[c(x_t, u_t) - \\lambda \\log \\bar{p}(u_t \\vert x_t) - \\lambda \\mathcal{H}(p(u_t \\vert x_t))] - \\lambda \\epsilon \\\\\n\t\t&//提\\lambda \\\\\n\t\t&= \\lambda \\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)}[\\frac{1}{\\lambda} c(x_t, u_t) - \\log \\bar{p}(u_t \\vert x_t) - \\mathcal{H}(p(u_t \\vert x_t))] - \\epsilon\n\t\t\\end{aligned}\n\t\t$$\n\t\t2. 求解$\\begin{bmatrix} \\tau \\\\\\\\ p \\end{bmatrix}^\\*$：对应的优化问题为：\n\t\t$$\n\t\t\\begin{aligned}\n\t\t\\mathop{\\text{min }}_{\\tau, p} &\\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)}[\\frac{1}{\\lambda} c(x_t, u_t) - \\log \\bar{p}(u_t \\vert x_t) - \\mathcal{H}(p(u_t \\vert x_t))] \\\\\n\t\t\\text{s.t. } &x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.\n\t\t\\end{aligned}\n\t\t$$假如我们设$\\tilde{c}(x_t, u_t) = \\frac{1}{\\lambda} c(x_t, u_t) - \\log \\bar{p}(u_t \\vert x_t)$，则该优化问题为：\n\t\t$$\n\t\t\\begin{aligned}\n\t\t\\mathop{\\text{min }}_{\\tau, p} &\\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)}[\\tilde{c}(x_t, u_t) - \\mathcal{H}(p(u_t \\vert x_t))] \\\\\n\t\t\\text{s.t. } &x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.\n\t\t\\end{aligned}\n\t\t$$而**这个形式的优化问题我们知道其最优解的形式是什么**（回忆Using stochastic controller部分），因此我们能够用*iLQR*求解$\\begin{bmatrix} \\tau \\\\\\\\ p \\end{bmatrix}^\\*$。\n\t\t3. 对$\\lambda$做单步gradient ascent，迭代。\n\n## Introduce stochastic policy\n\n- statement\n\t- **这部分由于没有细看论文，所以有些地方我也不是很清楚，只是介绍我自己的理解，希望谅解：）**。\n- motivation\n\t- 我们想要得到的是一个parametric policy，因此采用跟deterministic policy case一样的思路，添加一个policy约束。\n- solution\n\t- optimization problem\n\t$$\n\t\\begin{aligned}\n\t\\mathop{\\text{min }}_{\\tau, p} &\\mathbb{E}_\\tau[\\sum_{t=1}^T c(x_t, u_t)] \\\\\n\t\\text{s.t. } &p(u_t \\vert x_t) = \\pi_\\theta(u_t \\vert x_t) \\quad t=1, \\dots, T \\\\\n\t&D_{KL}(p(\\tau) \\Vert \\bar{p}(\\tau) ) \\leq \\epsilon \\\\\n\t&x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.\n\t\\end{aligned}\n\t$$\n\t- 进行约束条件下的*DGD*：\n\t\t1. 仅将policy约束和$D_{KL}$约束写进Lagrangian函数：\n\t\t$$\n\t\t\\begin{aligned}\n\t\t\\mathcal{L}(\\tau, p, \\theta, \\lambda, \\eta) &= \\mathbb{E}_\\tau[\\sum_{t=1}^T c(x_t, u_t)] + \\sum_{t=1}^T \\lambda_t [p(u_t \\vert x_t) - \\pi_\\theta(u_t \\vert x_t)] + \\eta (D_{KL}(p(\\tau) \\Vert \\bar{p}(\\tau) ) - \\epsilon) \\\\\n\t\t&// \\sum_{t=1}^T \\lambda_t [p(u_t \\vert x_t) - \\pi_\\theta(u_t \\vert x_t)] \\overset{?}{\\approx} \\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)}[u_t^T\\lambda_t + \\rho_t D_{KL}(p(u_t \\vert x_t) \\Vert \\pi_\\theta(u_t \\vert x_t))]\\\\\n\t\t&\\approx \\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)}[c(x_t, u_t) + u_t^T\\lambda_t + \\rho_t D_{KL}(p(u_t \\vert x_t) \\Vert \\pi_\\theta(u_t \\vert x_t))] + \\eta (D_{KL}(p(\\tau) \\Vert \\bar{p}(\\tau) ) - \\epsilon) \\\\\n\t\t&// \\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)}[D_{KL}(p(u_t \\vert x_t) \\Vert \\pi_\\theta(u_t \\vert x_t))] = \\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)}[- \\log \\pi_\\theta(u_t \\vert x_t) - \\mathcal{H}(p(u_t \\vert x_t))] \\\\\n\t\t&// D_{KL}(p(\\tau) \\Vert \\bar{p}(\\tau) ) = \\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)} [- \\log \\bar{p}(u_t \\vert x_t) - \\mathcal{H}(p(u_t \\vert x_t))]  \\\\\n\t\t&= \\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)}[c(x_t, u_t) + u_t^T\\lambda_t - \\rho_t \\log\\pi_\\theta(u_t \\vert x_t) - \\eta \\log \\bar{p}(u_t \\vert x_t) - ( \\rho_t + \\eta) \\mathcal{H}(p(u_t \\vert x_t))] - \\eta \\epsilon \n\t\t\\end{aligned}\n\t\t$$\n\t\t2. 求解$\\begin{bmatrix} \\tau \\\\\\\\ p \\end{bmatrix}^\\*$：对应的优化问题为：\n\t\t$$\n\t\t\\begin{aligned}\n\t\t\\mathop{\\text{min }}_{\\tau, p} &\\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)}[c(x_t, u_t) + u_t^T\\lambda_t - \\rho_t \\log\\pi_\\theta(u_t \\vert x_t) - \\eta \\log \\bar{p}(u_t \\vert x_t) - ( \\rho_t + \\eta) \\mathcal{H}(p(u_t \\vert x_t))] \\\\\n\t\t\\text{s.t. } &x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.\n\t\t\\end{aligned}\n\t\t$$设$\\tilde{c}(x_t, u_t) = c(x_t, u_t) + u_t^T\\lambda_t - \\rho_t \\log\\pi_\\theta(u_t \\vert x_t) - \\eta \\log \\bar{p}(u_t \\vert x_t)$，$\\nu_t = \\rho_t + \\eta$，则上述优化问题可以表示为：\n\t\t$$\n\t\t\\begin{aligned}\n\t\t\\mathop{\\text{min }}_{\\tau, p} &\\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)}[\\tilde{c}(x_t, u_t) - \\nu_t \\mathcal{H}(p(u_t \\vert x_t))] \\\\\n\t\t\\text{s.t. } &x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.\n\t\t\\end{aligned}\n\t\t$$而**这个形式的优化问题我们知道最优解**（回忆Using stochastic controller和Constrain controller in trust region部分），因此得到$\\begin{bmatrix} \\tau \\\\\\\\ p \\end{bmatrix}^\\*$。\n\t\t2. 求解$\\theta^\\*$：跟deterministic policy case一样，由于约束条件跟待优化变量无关，所以实际上是一个无约束优化问题，不过问题是这里并没有用直接用上面的Lagrangian函数，我猜测问题是出在上面我没搞懂的带问号的约等于号那里，也许上面只是为了求解方便做了近似，因此在求解$\\theta^\\*$时没有把Lagrangian函数展开到最后的形式，而是用了以下Lagrangian函数：\n\t\t$$\n\t\t\\begin{aligned}\n\t\t\\mathcal{L}(\\tau, p, \\theta, \\lambda, \\eta) &= \\mathbb{E}_\\tau[\\sum_{t=1}^T c(x_t, u_t)] + \\sum_{t=1}^T \\lambda_t [p(u_t \\vert x_t) - \\pi_\\theta(u_t \\vert x_t)] + \\eta (D_{KL}(p(\\tau) \\Vert \\bar{p}(\\tau) ) - \\epsilon) \\\\\n\t\t&// \\sum_{t=1}^T \\lambda_t [p(u_t \\vert x_t) - \\pi_\\theta(u_t \\vert x_t)] \\overset{?}{=} \\sum_{t=1}^T \\mathbb{E}_{p(x_t)}[\\mathbb{E}_{\\pi_\\theta(u_t \\vert x_t)}[u_t]^T\\lambda_t + \\rho_t D_{KL}(p(u_t \\vert x_t) \\Vert \\pi_\\theta(u_t \\vert x_t))]\\\\\n\t\t&= \\mathbb{E}_\\tau[\\sum_{t=1}^T c(x_t, u_t)] + \\sum_{t=1}^T \\mathbb{E}_{p(x_t)}[\\mathbb{E}_{\\pi_\\theta(u_t \\vert x_t)}[u_t]^T\\lambda_t + \\rho_t D_{KL}(p(u_t \\vert x_t) \\Vert \\pi_\\theta(u_t \\vert x_t))] \\\\\n\t\t&+ \\eta (D_{KL}(p(\\tau) \\Vert \\bar{p}(\\tau) ) - \\epsilon) \\\\\n\t\t\\end{aligned}.\n\t\t$$因此，对应的关于$\\theta$的无约束优化问题为：\n\t\t$$\n\t\t\\mathop{\\text{min }}_{\\theta}\\sum_{t=1}^T \\mathbb{E}_{p(x_t)}[\\mathbb{E}_{\\pi_\\theta(u_t \\vert x_t)}[u_t]^T\\lambda_t + \\rho_t D_{KL}(p(u_t \\vert x_t) \\Vert \\pi_\\theta(u_t \\vert x_t))].\n\t\t$$应该可以使用诸如*SGD*等优化方法进行求解，于是我们得到$\\theta^\\*$\n\t\t3. 对$\\begin{bmatrix} \\lambda \\\\\\\\ \\eta \\end{bmatrix}$做单步gradient ascent，迭代。\n\n---\n\n# Conclusion\n\n至此已经介绍完*GPS*的流程，这个算法给我印象最深刻的地方就是**化归**的思想，即将新构建的问题转化为之前已经知道解决方法的问题，令人叹为观止。\n\n---\n\n# References\n\n- [CS294 Fall 2017 lecture 8-10](http://rll.berkeley.edu/deeprlcourse/)\n- [CS287 Guest Lecture Sergey Levine Slide](https://people.eecs.berkeley.edu/~pabbeel/cs287-fa15/slides/lecture20-guided-policy-search.pdf)\n- [Sergey Levine UCB Talk](https://www.youtube.com/watch?v=CW1s6psByxk)\n- [Sergey Levine UW Talk](https://www.youtube.com/watch?v=EtMyH_--vnU&feature=youtu.be)\n- [Learning neural network policies with guided policy search under unknown dynamics](https://people.eecs.berkeley.edu/~svlevine/papers/mfcgps.pdf)\n- [End-to-end training of deep visuomotor policies](http://www.jmlr.org/papers/volume17/15-522/15-522.pdf)","source":"_posts/summary-gps.md","raw":"---\ntitle: 学习总结《Guided Policy Search》\ndate: 2018-05-17 18:49:29\ntags:\n\t- Guided Policy Search\n\t- GPS\ncategories:\n\t- 学习总结\ndescription:\n\t- 一种Model-Based的强化学习算法\n---\n\n# Overivew\n\n本文将介绍*Guided Policy Search(GPS)*这种Model-Based的强化学习算法，并会按以下方式展开：\n\n1. Motivation：介绍*GPS*这种方法的**特点**；\n2. Problem formulation：介绍*GPS*所解决**问题的具体形式**；\n3. Framework：介绍*GPS*的**整体框架**；\n4. Deterministic policy case：从相对简单的deterministic policy case开始介绍*GPS*的**具体流程**；\n5. Stochastic policy case：从deterministic policy case过渡到stochastic policy case，介绍**完整**的*GPS*算法。\n\n---\n\n# Motivation\n\n下面通过将*GPS*跟不同类型的算法进行比较来说明*GPS*的特点。\n\n- 与Model-Free算法相比：由于*GPS*对环境建立了模型（i.e., model/dynamics），在计算q value时，不仅仅是“记录”，还能进行“推算”，因此**sample efficiency会比较高，收敛速度会比较快**；\n- 与其他Model-Based算法相比：在test的时候，部分Model-Based算法需要进行online optimization（i.e., 根据当前拟合的模型，使用某种优化算法，得到当前的action）；而由于*GPS*最终得到的是一个parametric policy（e.g., 神经网络），因此**在test的时候会比较快**（无需做online optimization，只需要做一次forward pass）；\n- 与简单的Imitation Learning算法相比：在简单的IL中，teacher单方面地给student传授知识（i.e., supervised learning），而不管student的学习能力如何；而在*GPS*中，**除了teacher给student传授知识以外，student还会给teacher反馈**，要求teacher适配student的学习能力，形成闭环，因此train的效果会更好。\n\n---\n\n# Problem Formulation\n\n下面对我们所讨论的问题做一个界定。\n\n- setting\n\t- **fixed time length** task（e.g, 完成任务的时长限定在20s内，决策的频率是20Hz，则总步长$T$为400）\n- assumption\n\t- deterministic dynamics：$x_t = f(x_{t-1}, u_{t-1})$\n- input\n\t- environment\n\t- immediate cost(reward) function：$c(x_t, u_t)$\n- output\n\t- parametric policy\n\t\t- deterministic case：$u_t = \\pi_\\theta(x_t)$\n\t\t- stochastic case：$\\pi_\\theta(u_t \\vert x_t) \\sim \\mathcal{N}(\\mu_t, \\Sigma_t)$\n\n---\n\n# Framework\n\n下面介绍*GPS*的整体框架。\n\n1. collect data：通过controller与environment进行交互，收集数据；\n<div style=\"width:300px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img 1.png  %}\n</div>\n2. fit dynamics：根据第一步收集到的数据，拟合dynamics；\n<div style=\"width:300px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img 2.png  %}\n</div>\n3. optimization：优化controller（最优控制器）与policy（最终输出的parametric policy）；\n<div style=\"width:400px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img 3.png  %}\n</div>\n4. next iteration：迭代。\n<div style=\"width:500px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img 4.png  %}\n</div>\n\n---\n\n# Deterministic policy case\n\n下面开始介绍Deterministic policy case下*GPS*的具体流程。\n\n## Collect data\n\n使用controller与environment进行交互，得到轨迹数据集$\\mathcal{D} = \\{ \\tau_i \\}$，其中轨迹$\\tau_i = \\{ x_{1i}, u_{1i}, \\dots , x_{1T}, u_{1T} \\}$。\n\n## Fit dynamics\n\n使用第一步得到的轨迹数据集来拟合一个time-varying linear model：$x_{t+1} = f(x_t, u_t) = A_tx_t + B_tu_t + c_t$，也就是说这个model**对于不同时刻$t$的input会使用不同的linear model**。\n\n具体的拟合方法是使用同一时刻$t$，不同轨迹$\\tau_i$的数据$\\{ (x_{t1}, u_{t1}, x_{t+1,1}), \\dots , (x_{ti}, u_{ti}, x_{t+1,i}) \\}$来做linear regression。\n\n## Optimization\n\n### Controller\n\n- big picture\n\n<div style=\"width:250px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img 3_1.png  %}\n</div>\n\n- optimization problem\n\t- 我们想要在满足dynamics约束的条件下，最小化总cost，因此对应的轨迹优化问题为：\n$$\n\\begin{aligned}\n\\mathop{\\text{min }}_{x_1, u_1, \\dots, x_T, u_T} &\\sum_{t=1}^T c(x_t, u_t) \\\\\n\\text{s.t. } &x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.\n\\end{aligned}\n$$\n- solution\n\t- 假如上述轨迹优化问题中$f(x_t, u_t) = F_t \\begin{bmatrix} x_t \\\\\\\\ u_t \\end{bmatrix} + f_t$， $c(x_t, u_t) = \\frac{1}{2} \\begin{bmatrix} x_t \\\\\\\\ u_t \\end{bmatrix}^T C_t \\begin{bmatrix} x_t \\\\\\\\ u_t \\end{bmatrix} + \\begin{bmatrix} x_t \\\\\\\\ u_t \\end{bmatrix}^T c_t$，则有一个叫做*Linear Quadratic Regulator(LQR)*的优化方法可以对该轨迹优化问题进行求解。\n\t- *LQR*基本原理如下：\n\t\t- input：\n\t\t\t- linear model（$F_t, f_t$）\n\t\t\t- quadratic cost（$C_t, c_t$）\n\t\t- output：$K_t, k_t$\n\t\t- optimal control（上述轨迹优化问题的解）：$u_t=K_tx_t+k_t$，$x_{t+1}=f(x_t, u_t)$\n<div style=\"width:500px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img lqr.png  %}\n</div>\n\t- 由于我们在fit dynamics中拟合的就是一个linear model，因此只要我们设置的cost function是quadratic的话就可以使用*LQR*来求解。\n\t- 即使我们的cost function不是quadratic，也还可以使用*iterative LQR(iLQR)*来进行求解。*iLQR*可以求解nonlinear dynamics，nonquadratic cost下的轨迹优化问题，它的核心思想是对dynamics和cost分别进行linear及quadratic展开，然后用*LQR*进行求解。\n\n### Policy\n\n- big picture\n\n<div style=\"width:400px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img 3.png  %}\n</div>\n\n- optimization problem\n\t- 因为*GPS*最后想要的是一个policy，因此在上述轨迹优化问题的基础上，加上一个优化变量$\\theta$以及约束条件$u_t = \\pi_\\theta(x_t)$，来表示我们希望policy能够“学习”optimal control：\n\t$$\n\t\\begin{aligned}\n\t\\mathop{\\text{min }}_{x_1, u_1, \\dots, x_T, u_T, \\theta} &\\sum_{t=1}^T c(x_t, u_t) \\\\\n\t\\text{s.t. } &u_t = \\pi_\\theta(x_t) \\quad t=1, \\dots, T\\\\\n\t&x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.\n\t\\end{aligned}\n\t$$\n- solution\n\t- 求解上述优化问题用到了一种叫做*Dual Gradient Descent(DGD)*的优化方法。*DGD*是一种求解形如以下优化问题的方法：\n\t$$\n\t\\begin{aligned}\n\t\\mathop{\\text{min }}_x &f(x) \\\\\n\t\\text{s.t. } & C(x)=0.\n\t\\end{aligned}\n\t$$其具体求解过程为：\n\t\t1. 写出对应的Lagrangian函数：$\\mathcal{L}(x, \\lambda) = f(x) + \\lambda C(x)$；\n\t\t2. 求解最小化Lagrangian函数的$x$：$x^\\* = \\mathop{\\text{argmin }}_x \\mathcal{L}(x, \\lambda)$；\n\t\t3. 将$x^\\*$代入$\\mathcal{L}(x, \\lambda)$得到原问题的下界函数$g(\\lambda) = \\mathcal{L}(x^\\*, \\lambda)$；\n\t\t4. 更新$\\lambda$（类似对$\\lambda$做gradient ascent）：$\\lambda = \\lambda + \\alpha \\frac{\\partial g}{\\partial \\lambda}$；\n\t\t5. 回到第二步，求新$\\lambda$下对应的$x^\\*$，迭代。\n\t- 接下来改变一下优化问题的表述方式，**将dynamics约束单独提出来**（之所以这么做，是**为了将问题化归为会解的问题**，下面会详细说），也就是说现在把问题理解为在满足dynamics约束下求解一个约束优化问题（i.e., 满足policy约束下最小化cost），而原来是满足dynamics和policy约束下求解一个无约束优化问题（i.e., 最小化cost）：\n\t$$\n\t\\begin{aligned}\n\t\\mathop{\\text{min }}_{x_1, u_1, \\dots, x_T, u_T, \\theta} &\\sum_{t=1}^T c(x_t, u_t) \\\\\n\t\\text{s.t. } &u_t = \\pi_\\theta(x_t) \\quad t=1, \\dots, T\\\\\n\t\\\\\n\t\\text{s.t. } x_t = f&(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.\n\t\\end{aligned}\n\t$$\n\t- 然后进行**约束条件下的*DGD***（i.e., 整个*DGD*的过程都要满足约束）：\n\t\t1. 仅将policy约束写进Lagrangian函数：\n\t\t$$\n\t\t\\begin{aligned}\n\t\t\\mathcal{L}(\\tau, \\theta, \\lambda) \n\t\t&= \\mathcal{L}(x_1, u_1, \\dots, x_T, u_T, \\theta, \\lambda_1, \\dots, \\lambda_T) \\\\\n\t\t&=  \\sum_{t=1}^T c(x_t, u_t) + \\sum_{t=1}^T\\lambda_t [u_t - \\pi_\\theta(x_t)] \\\\\n\t\t&= \\sum_{t=1}^T \\{ c(x_t, u_t) + \\lambda_t [u_t - \\pi_\\theta(x_t)] \\}.\n\t\t\\end{aligned}\n\t\t$$\n\t\t2. 本来应该将$\\begin{bmatrix}\\tau \\\\\\\\ \\theta\\end{bmatrix}$这一整个向量看作优化变量（对应*DGD*中的$x$），然后求解$\\begin{bmatrix}\\tau \\\\\\\\ \\theta\\end{bmatrix}^\\*$（对应*DGD*中的$x^\\*$）。但这里**假设$\\tau$和$\\theta$相互独立**（为了能够求解），因此下面可以分别单独对$\\tau$与$\\theta$做优化，求得对应的$\\tau^\\*$和$\\theta^\\*$，然后用$\\begin{bmatrix}\\tau^\\* \\\\\\\\ \\theta^\\*\\end{bmatrix}$来近似$\\begin{bmatrix}\\tau \\\\\\\\ \\theta\\end{bmatrix}^\\*$。\n\t\t3. 求解$\\tau^\\*$：对应的优化问题为：\n\t\t$$\n\t\t\\begin{aligned}\n\t\t\\mathop{\\text{min }}_\\tau &\\sum_{t=1}^T \\{ c(x_t, u_t) + \\lambda_t [u_t - \\pi_\\theta(x_t)] \\} \\\\\n\t\t\\text{s.t. } &x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.\n\t\t\\end{aligned}\n\t\t$$设$\\tilde{c}(x_t, u_t)=c(x_t, u_t) + \\lambda_t [u_t - \\pi_\\theta(x_t)]$，我们有：\n\t\t$$\n\t\t\\begin{aligned}\n\t\t\\mathop{\\text{min }}_\\tau &\\sum_{t=1}^T \\tilde{c}(x_t, u_t)\\\\\n\t\t\\text{s.t. } &x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.\n\t\t\\end{aligned}\n\t\t$$而**这个形式的优化问题我们能够通过*iLQR*进行求解**，因此能够求得$\\tau^\\*$。\n\t\t4. 求解$\\theta^\\*$：对应的优化问题为：\n\t\t$$\n\t\t\\begin{aligned}\n\t\t\\mathop{\\text{min }}_\\theta &\\sum_{t=1}^T \\{ c(x_t, u_t) + \\lambda_t [u_t - \\pi_\\theta(x_t)] \\} \\\\\n\t\t\\text{s.t. } &x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.\n\t\t\\end{aligned}\n\t\t$$由于优化变量是$\\theta$，所以约束条件可以去掉，而且目标函数也可以简化，等价的优化问题为：\n\t\t$$\n\t\t\\begin{aligned}\n\t\t\\mathop{\\text{min }}_\\theta &\\sum_{t=1}^T \\lambda_t [u_t - \\pi_\\theta(x_t)].\n\t\t\\end{aligned}\n\t\t$$这是一个无约束优化问题（带权拟合问题），可以用诸如*SGD*等方法进行优化，因此也能够求得$\\theta^\\*$。\n\t\t5. 将$\\tau^\\*$和$\\theta^\\*$代入Lagrangian函数，得到$g(\\lambda) = \\mathcal{L}(\\tau^\\*, \\theta^\\*, \\lambda)$。\n\t\t6. 对$\\lambda$做单步gradient ascent（跟求解$\\theta^\\*$时一样，由于约束条件跟优化变量无关，所以等价于无约束优化），更新$\\lambda$，迭代。\n\n## Next iteration\n\n回到第一步collect data，即用新的controller跟environment交互，迭代。\n\n## Summary\n\n至此我们已经通过相对简单的deterministic policy case过了一遍*GPS*的整个流程，下面补充一些小小的细节：\n\n- 为什么称之为*GPS*：guided主要体现在最后优化问题的约束$u_t = \\pi_\\theta(x_t)$，相当于有一个teacher（controller）在“指引”我们的policy。\n- collect data使用controller还是policy：应该是使用controller，因为policy仅仅拟合了某些具体的$(x_t, u_t)$，而controller对各个$x_t$都是“最优”的。\n- 为什么流程图中，train policy部分会跟$\\tau_i$相关：这是因为在求解$\\theta^\\*$时，$\\tau^\\*$还没代入Lagrangian函数，也就是说Lagrangian函数中用的是$\\tau$而不是$\\tau^\\*$。\n\n---\n\n# Stochastic policy case\n\ndeterministic controller对于一个起始点只能采集到一条轨迹，**不利于拟合一个robust的dynamics**，因此我们想要一个stochastic的controller。之后通过对stochastic controller进行supervised learning，我们最后会得到一个stochastic policy。\n\nstochastic policy case跟deterministic policy case的**唯一区别在于optimization这步**（如红框所示），其他都是一样的。因此下面仅介绍stochastic policy case如何做optimization。\n\n<div style=\"width:400px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img 3.png  %}\n</div>\n\n## Using stochastic controller\n\n首先介绍一个过渡性的内容，是关于使用stochastic controller的。\n\n- 最直观的想法：把原来的约束问题（暂时先不考虑policy）改一下，将controller表示为$p(u_t \\vert x_t) \\sim \\mathcal{N}(\\mu_t, \\Sigma_t)$，然后求解优化问题：\n$$\n\\begin{aligned}\n\\mathop{\\text{min }}_{\\tau, p} &\\mathbb{E}_\\tau[\\sum_{t=1}^T c(x_t, u_t)] \\\\\n\\text{s.t. } &x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T,\n\\end{aligned}\n$$其中$p = \\mu_1, \\Sigma_1, \\dots, \\mu_T, \\Sigma_T$。但这样子是不work的，因为**最后求出来的还是一个determinisitc controller**（因为贪婪地采取最优策略效果是最好的）。\n- 于是就强行把controller设成linear-gaussian的形式：\n$$\np(u_t \\vert x_t) = \\mathcal{N}(K_t(x_t - \\hat{x}_t) + k_t + \\hat{u}_t, Q^{-1}_{u_t,u_t}),\n$$其中，gaussian的均值为*iLQR*的解，方差为*iLQR*中的某个矩阵的逆，具体含义可以不用管，只需要知道这些东西都可以通过*iLQR*得到。\n- 而该形式的controller恰好是以下优化问题的最优解：\n$$\n\\begin{aligned}\n\\mathop{\\text{min }}_{\\tau, p} &\\sum_{t=1}^T\\mathbb{E}_{p(x_t, u_t)}[ c(x_t, u_t) - \\mathcal{H}(p(u_t \\vert x_t))] \\\\\n\\text{s.t. } &x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.\n\\end{aligned}\n$$\n- 这部分主要为下面做铺垫，核心在于**我们现在知道了某种形式的优化问题的最优解**。\n\n## Constrain controller in trust region\n\n- motivation\n\t- 在*GPS*中我们所fit的dynamics是local dynamics，也就是说它**仅在当前controller“附近”是有效的**；\n\t- 在优化问题中，我们评价controller好坏会用到该local dynamics；\n\t- 因此，为了确保评价的有效性，我们要**限定controller在当前controller“附近”**；\n\t- 否则，即使contoller评价很高，也是虚假的/无效的/没有意义的。\n- solution\n\t- 将controller在当前controller“附近”用数学语言表述出来，即\n\t$$\n\tD_{KL}(p(\\tau) \\Vert \\bar{p}(\\tau) ) \\leq \\epsilon,\n\t$$其中$p(\\tau)$表示轨迹$\\tau$在新controller下发生的概率，$\\bar{p}(\\tau)$表示轨迹$\\tau$在当前controller下发生的概率，$D_{KL}$表示KL-divergence，用于衡量两个分布的“相似程度”，KL-divergence越小，两个分布越相似。\n\t\t- 这个表示能够**间接地限制controller和当前controller比较相似**，因为$p(\\tau) = p(x_1)\\prod_{t=1}^{T-1} p(u_t \\vert x_t)f(x_{t+1} \\vert x_t, u_t)$，而对于新旧controller来说，$p(x_1)$以及$f(x_{t+1} \\vert x_t, u_t)$都是一样的，因此区别仅仅在于$p(u_t \\vert x_t)$。换句话说，$p(\\tau)$和$\\bar{p}(\\tau)$的区别仅仅在于controller，因此控制$p(\\tau)$和$\\bar{p}(\\tau)$的相似程度就可以间接地控制controller的相似程度。\n\t- new optimization problem\n\t$$\n\t\\begin{aligned}\n\t\\mathop{\\text{min }}_{\\tau, p} &\\mathbb{E}_\\tau[\\sum_{t=1}^T c(x_t, u_t)] \\\\\n\t\\text{s.t. } &D_{KL}(p(\\tau) \\Vert \\bar{p}(\\tau) ) \\leq \\epsilon \\\\\n\t&x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.\n\t\\end{aligned}\n\t$$\n\t- 进行约束条件下的*DGD*（这里我不太懂为什么可以对不等式约束做*DGD*，逻辑上来讲对于不等式约束，需要限定$\\lambda \\geq 0$才能保证$g(\\lambda)$是原问题的下界函数）：\n\t\t1. 仅将$D_{KL}$约束写进Lagrangian函数：\n\t\t$$\n\t\t\\begin{aligned}\n\t\t\\mathcal{L}(\\tau, p, \\lambda) &= \\mathbb{E}_\\tau[\\sum_{t=1}^T c(x_t, u_t)] + \\lambda (D_{KL}(p(\\tau) \\Vert \\bar{p}(\\tau) ) - \\epsilon) \\\\\n\t\t&// D_{KL}(p(\\tau) \\Vert \\bar{p}(\\tau) ) = \\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)} [- \\log \\bar{p}(u_t \\vert x_t) - \\mathcal{H}(p(u_t \\vert x_t))]  \\\\\n\t\t&= \\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)}[c(x_t, u_t) - \\lambda \\log \\bar{p}(u_t \\vert x_t) - \\lambda \\mathcal{H}(p(u_t \\vert x_t))] - \\lambda \\epsilon \\\\\n\t\t&//提\\lambda \\\\\n\t\t&= \\lambda \\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)}[\\frac{1}{\\lambda} c(x_t, u_t) - \\log \\bar{p}(u_t \\vert x_t) - \\mathcal{H}(p(u_t \\vert x_t))] - \\epsilon\n\t\t\\end{aligned}\n\t\t$$\n\t\t2. 求解$\\begin{bmatrix} \\tau \\\\\\\\ p \\end{bmatrix}^\\*$：对应的优化问题为：\n\t\t$$\n\t\t\\begin{aligned}\n\t\t\\mathop{\\text{min }}_{\\tau, p} &\\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)}[\\frac{1}{\\lambda} c(x_t, u_t) - \\log \\bar{p}(u_t \\vert x_t) - \\mathcal{H}(p(u_t \\vert x_t))] \\\\\n\t\t\\text{s.t. } &x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.\n\t\t\\end{aligned}\n\t\t$$假如我们设$\\tilde{c}(x_t, u_t) = \\frac{1}{\\lambda} c(x_t, u_t) - \\log \\bar{p}(u_t \\vert x_t)$，则该优化问题为：\n\t\t$$\n\t\t\\begin{aligned}\n\t\t\\mathop{\\text{min }}_{\\tau, p} &\\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)}[\\tilde{c}(x_t, u_t) - \\mathcal{H}(p(u_t \\vert x_t))] \\\\\n\t\t\\text{s.t. } &x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.\n\t\t\\end{aligned}\n\t\t$$而**这个形式的优化问题我们知道其最优解的形式是什么**（回忆Using stochastic controller部分），因此我们能够用*iLQR*求解$\\begin{bmatrix} \\tau \\\\\\\\ p \\end{bmatrix}^\\*$。\n\t\t3. 对$\\lambda$做单步gradient ascent，迭代。\n\n## Introduce stochastic policy\n\n- statement\n\t- **这部分由于没有细看论文，所以有些地方我也不是很清楚，只是介绍我自己的理解，希望谅解：）**。\n- motivation\n\t- 我们想要得到的是一个parametric policy，因此采用跟deterministic policy case一样的思路，添加一个policy约束。\n- solution\n\t- optimization problem\n\t$$\n\t\\begin{aligned}\n\t\\mathop{\\text{min }}_{\\tau, p} &\\mathbb{E}_\\tau[\\sum_{t=1}^T c(x_t, u_t)] \\\\\n\t\\text{s.t. } &p(u_t \\vert x_t) = \\pi_\\theta(u_t \\vert x_t) \\quad t=1, \\dots, T \\\\\n\t&D_{KL}(p(\\tau) \\Vert \\bar{p}(\\tau) ) \\leq \\epsilon \\\\\n\t&x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.\n\t\\end{aligned}\n\t$$\n\t- 进行约束条件下的*DGD*：\n\t\t1. 仅将policy约束和$D_{KL}$约束写进Lagrangian函数：\n\t\t$$\n\t\t\\begin{aligned}\n\t\t\\mathcal{L}(\\tau, p, \\theta, \\lambda, \\eta) &= \\mathbb{E}_\\tau[\\sum_{t=1}^T c(x_t, u_t)] + \\sum_{t=1}^T \\lambda_t [p(u_t \\vert x_t) - \\pi_\\theta(u_t \\vert x_t)] + \\eta (D_{KL}(p(\\tau) \\Vert \\bar{p}(\\tau) ) - \\epsilon) \\\\\n\t\t&// \\sum_{t=1}^T \\lambda_t [p(u_t \\vert x_t) - \\pi_\\theta(u_t \\vert x_t)] \\overset{?}{\\approx} \\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)}[u_t^T\\lambda_t + \\rho_t D_{KL}(p(u_t \\vert x_t) \\Vert \\pi_\\theta(u_t \\vert x_t))]\\\\\n\t\t&\\approx \\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)}[c(x_t, u_t) + u_t^T\\lambda_t + \\rho_t D_{KL}(p(u_t \\vert x_t) \\Vert \\pi_\\theta(u_t \\vert x_t))] + \\eta (D_{KL}(p(\\tau) \\Vert \\bar{p}(\\tau) ) - \\epsilon) \\\\\n\t\t&// \\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)}[D_{KL}(p(u_t \\vert x_t) \\Vert \\pi_\\theta(u_t \\vert x_t))] = \\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)}[- \\log \\pi_\\theta(u_t \\vert x_t) - \\mathcal{H}(p(u_t \\vert x_t))] \\\\\n\t\t&// D_{KL}(p(\\tau) \\Vert \\bar{p}(\\tau) ) = \\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)} [- \\log \\bar{p}(u_t \\vert x_t) - \\mathcal{H}(p(u_t \\vert x_t))]  \\\\\n\t\t&= \\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)}[c(x_t, u_t) + u_t^T\\lambda_t - \\rho_t \\log\\pi_\\theta(u_t \\vert x_t) - \\eta \\log \\bar{p}(u_t \\vert x_t) - ( \\rho_t + \\eta) \\mathcal{H}(p(u_t \\vert x_t))] - \\eta \\epsilon \n\t\t\\end{aligned}\n\t\t$$\n\t\t2. 求解$\\begin{bmatrix} \\tau \\\\\\\\ p \\end{bmatrix}^\\*$：对应的优化问题为：\n\t\t$$\n\t\t\\begin{aligned}\n\t\t\\mathop{\\text{min }}_{\\tau, p} &\\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)}[c(x_t, u_t) + u_t^T\\lambda_t - \\rho_t \\log\\pi_\\theta(u_t \\vert x_t) - \\eta \\log \\bar{p}(u_t \\vert x_t) - ( \\rho_t + \\eta) \\mathcal{H}(p(u_t \\vert x_t))] \\\\\n\t\t\\text{s.t. } &x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.\n\t\t\\end{aligned}\n\t\t$$设$\\tilde{c}(x_t, u_t) = c(x_t, u_t) + u_t^T\\lambda_t - \\rho_t \\log\\pi_\\theta(u_t \\vert x_t) - \\eta \\log \\bar{p}(u_t \\vert x_t)$，$\\nu_t = \\rho_t + \\eta$，则上述优化问题可以表示为：\n\t\t$$\n\t\t\\begin{aligned}\n\t\t\\mathop{\\text{min }}_{\\tau, p} &\\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)}[\\tilde{c}(x_t, u_t) - \\nu_t \\mathcal{H}(p(u_t \\vert x_t))] \\\\\n\t\t\\text{s.t. } &x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.\n\t\t\\end{aligned}\n\t\t$$而**这个形式的优化问题我们知道最优解**（回忆Using stochastic controller和Constrain controller in trust region部分），因此得到$\\begin{bmatrix} \\tau \\\\\\\\ p \\end{bmatrix}^\\*$。\n\t\t2. 求解$\\theta^\\*$：跟deterministic policy case一样，由于约束条件跟待优化变量无关，所以实际上是一个无约束优化问题，不过问题是这里并没有用直接用上面的Lagrangian函数，我猜测问题是出在上面我没搞懂的带问号的约等于号那里，也许上面只是为了求解方便做了近似，因此在求解$\\theta^\\*$时没有把Lagrangian函数展开到最后的形式，而是用了以下Lagrangian函数：\n\t\t$$\n\t\t\\begin{aligned}\n\t\t\\mathcal{L}(\\tau, p, \\theta, \\lambda, \\eta) &= \\mathbb{E}_\\tau[\\sum_{t=1}^T c(x_t, u_t)] + \\sum_{t=1}^T \\lambda_t [p(u_t \\vert x_t) - \\pi_\\theta(u_t \\vert x_t)] + \\eta (D_{KL}(p(\\tau) \\Vert \\bar{p}(\\tau) ) - \\epsilon) \\\\\n\t\t&// \\sum_{t=1}^T \\lambda_t [p(u_t \\vert x_t) - \\pi_\\theta(u_t \\vert x_t)] \\overset{?}{=} \\sum_{t=1}^T \\mathbb{E}_{p(x_t)}[\\mathbb{E}_{\\pi_\\theta(u_t \\vert x_t)}[u_t]^T\\lambda_t + \\rho_t D_{KL}(p(u_t \\vert x_t) \\Vert \\pi_\\theta(u_t \\vert x_t))]\\\\\n\t\t&= \\mathbb{E}_\\tau[\\sum_{t=1}^T c(x_t, u_t)] + \\sum_{t=1}^T \\mathbb{E}_{p(x_t)}[\\mathbb{E}_{\\pi_\\theta(u_t \\vert x_t)}[u_t]^T\\lambda_t + \\rho_t D_{KL}(p(u_t \\vert x_t) \\Vert \\pi_\\theta(u_t \\vert x_t))] \\\\\n\t\t&+ \\eta (D_{KL}(p(\\tau) \\Vert \\bar{p}(\\tau) ) - \\epsilon) \\\\\n\t\t\\end{aligned}.\n\t\t$$因此，对应的关于$\\theta$的无约束优化问题为：\n\t\t$$\n\t\t\\mathop{\\text{min }}_{\\theta}\\sum_{t=1}^T \\mathbb{E}_{p(x_t)}[\\mathbb{E}_{\\pi_\\theta(u_t \\vert x_t)}[u_t]^T\\lambda_t + \\rho_t D_{KL}(p(u_t \\vert x_t) \\Vert \\pi_\\theta(u_t \\vert x_t))].\n\t\t$$应该可以使用诸如*SGD*等优化方法进行求解，于是我们得到$\\theta^\\*$\n\t\t3. 对$\\begin{bmatrix} \\lambda \\\\\\\\ \\eta \\end{bmatrix}$做单步gradient ascent，迭代。\n\n---\n\n# Conclusion\n\n至此已经介绍完*GPS*的流程，这个算法给我印象最深刻的地方就是**化归**的思想，即将新构建的问题转化为之前已经知道解决方法的问题，令人叹为观止。\n\n---\n\n# References\n\n- [CS294 Fall 2017 lecture 8-10](http://rll.berkeley.edu/deeprlcourse/)\n- [CS287 Guest Lecture Sergey Levine Slide](https://people.eecs.berkeley.edu/~pabbeel/cs287-fa15/slides/lecture20-guided-policy-search.pdf)\n- [Sergey Levine UCB Talk](https://www.youtube.com/watch?v=CW1s6psByxk)\n- [Sergey Levine UW Talk](https://www.youtube.com/watch?v=EtMyH_--vnU&feature=youtu.be)\n- [Learning neural network policies with guided policy search under unknown dynamics](https://people.eecs.berkeley.edu/~svlevine/papers/mfcgps.pdf)\n- [End-to-end training of deep visuomotor policies](http://www.jmlr.org/papers/volume17/15-522/15-522.pdf)","slug":"summary-gps","published":1,"updated":"2024-08-13T16:03:47.876Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clzvf192j001ueqwo9b0ueoan","content":"<h1 id=\"Overivew\"><a href=\"#Overivew\" class=\"headerlink\" title=\"Overivew\"></a>Overivew</h1><p>本文将介绍<em>Guided Policy Search(GPS)</em>这种Model-Based的强化学习算法，并会按以下方式展开：</p>\n<ol>\n<li>Motivation：介绍<em>GPS</em>这种方法的<strong>特点</strong>；</li>\n<li>Problem formulation：介绍<em>GPS</em>所解决<strong>问题的具体形式</strong>；</li>\n<li>Framework：介绍<em>GPS</em>的<strong>整体框架</strong>；</li>\n<li>Deterministic policy case：从相对简单的deterministic policy case开始介绍<em>GPS</em>的<strong>具体流程</strong>；</li>\n<li>Stochastic policy case：从deterministic policy case过渡到stochastic policy case，介绍<strong>完整</strong>的<em>GPS</em>算法。</li>\n</ol>\n<hr>\n<h1 id=\"Motivation\"><a href=\"#Motivation\" class=\"headerlink\" title=\"Motivation\"></a>Motivation</h1><p>下面通过将<em>GPS</em>跟不同类型的算法进行比较来说明<em>GPS</em>的特点。</p>\n<ul>\n<li>与Model-Free算法相比：由于<em>GPS</em>对环境建立了模型（i.e., model/dynamics），在计算q value时，不仅仅是“记录”，还能进行“推算”，因此<strong>sample efficiency会比较高，收敛速度会比较快</strong>；</li>\n<li>与其他Model-Based算法相比：在test的时候，部分Model-Based算法需要进行online optimization（i.e., 根据当前拟合的模型，使用某种优化算法，得到当前的action）；而由于<em>GPS</em>最终得到的是一个parametric policy（e.g., 神经网络），因此<strong>在test的时候会比较快</strong>（无需做online optimization，只需要做一次forward pass）；</li>\n<li>与简单的Imitation Learning算法相比：在简单的IL中，teacher单方面地给student传授知识（i.e., supervised learning），而不管student的学习能力如何；而在<em>GPS</em>中，<strong>除了teacher给student传授知识以外，student还会给teacher反馈</strong>，要求teacher适配student的学习能力，形成闭环，因此train的效果会更好。</li>\n</ul>\n<hr>\n<h1 id=\"Problem-Formulation\"><a href=\"#Problem-Formulation\" class=\"headerlink\" title=\"Problem Formulation\"></a>Problem Formulation</h1><p>下面对我们所讨论的问题做一个界定。</p>\n<ul>\n<li>setting<ul>\n<li><strong>fixed time length</strong> task（e.g, 完成任务的时长限定在20s内，决策的频率是20Hz，则总步长$T$为400）</li>\n</ul>\n</li>\n<li>assumption<ul>\n<li>deterministic dynamics：$x_t = f(x_{t-1}, u_{t-1})$</li>\n</ul>\n</li>\n<li>input<ul>\n<li>environment</li>\n<li>immediate cost(reward) function：$c(x_t, u_t)$</li>\n</ul>\n</li>\n<li>output<ul>\n<li>parametric policy<ul>\n<li>deterministic case：$u_t = \\pi_\\theta(x_t)$</li>\n<li>stochastic case：$\\pi_\\theta(u_t \\vert x_t) \\sim \\mathcal{N}(\\mu_t, \\Sigma_t)$</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h1 id=\"Framework\"><a href=\"#Framework\" class=\"headerlink\" title=\"Framework\"></a>Framework</h1><p>下面介绍<em>GPS</em>的整体框架。</p>\n<ol>\n<li>collect data：通过controller与environment进行交互，收集数据；<div style=\"width:300px; margin-left:auto; margin-right:auto;\"><br><img src=\"/2018/05/17/summary-gps/1.png\" alt=\"1.png\" title=\"\"><br></div></li>\n<li>fit dynamics：根据第一步收集到的数据，拟合dynamics；<div style=\"width:300px; margin-left:auto; margin-right:auto;\"><br><img src=\"/2018/05/17/summary-gps/2.png\" alt=\"2.png\" title=\"\"><br></div></li>\n<li>optimization：优化controller（最优控制器）与policy（最终输出的parametric policy）；<div style=\"width:400px; margin-left:auto; margin-right:auto;\"><br><img src=\"/2018/05/17/summary-gps/3.png\" alt=\"3.png\" title=\"\"><br></div></li>\n<li>next iteration：迭代。<div style=\"width:500px; margin-left:auto; margin-right:auto;\"><br><img src=\"/2018/05/17/summary-gps/4.png\" alt=\"4.png\" title=\"\"><br></div>\n\n</li>\n</ol>\n<hr>\n<h1 id=\"Deterministic-policy-case\"><a href=\"#Deterministic-policy-case\" class=\"headerlink\" title=\"Deterministic policy case\"></a>Deterministic policy case</h1><p>下面开始介绍Deterministic policy case下<em>GPS</em>的具体流程。</p>\n<h2 id=\"Collect-data\"><a href=\"#Collect-data\" class=\"headerlink\" title=\"Collect data\"></a>Collect data</h2><p>使用controller与environment进行交互，得到轨迹数据集$\\mathcal{D} = { \\tau_i }$，其中轨迹$\\tau_i = { x_{1i}, u_{1i}, \\dots , x_{1T}, u_{1T} }$。</p>\n<h2 id=\"Fit-dynamics\"><a href=\"#Fit-dynamics\" class=\"headerlink\" title=\"Fit dynamics\"></a>Fit dynamics</h2><p>使用第一步得到的轨迹数据集来拟合一个time-varying linear model：$x_{t+1} = f(x_t, u_t) = A_tx_t + B_tu_t + c_t$，也就是说这个model<strong>对于不同时刻$t$的input会使用不同的linear model</strong>。</p>\n<p>具体的拟合方法是使用同一时刻$t$，不同轨迹$\\tau_i$的数据${ (x_{t1}, u_{t1}, x_{t+1,1}), \\dots , (x_{ti}, u_{ti}, x_{t+1,i}) }$来做linear regression。</p>\n<h2 id=\"Optimization\"><a href=\"#Optimization\" class=\"headerlink\" title=\"Optimization\"></a>Optimization</h2><h3 id=\"Controller\"><a href=\"#Controller\" class=\"headerlink\" title=\"Controller\"></a>Controller</h3><ul>\n<li>big picture</li>\n</ul>\n<div style=\"width:250px; margin-left:auto; margin-right:auto;\"><br>  <img src=\"/2018/05/17/summary-gps/3_1.png\" alt=\"3_1.png\" title=\"\"><br></div>\n\n<ul>\n<li>optimization problem<ul>\n<li>我们想要在满足dynamics约束的条件下，最小化总cost，因此对应的轨迹优化问题为：<br>$$<br>\\begin{aligned}<br>\\mathop{\\text{min }}_{x_1, u_1, \\dots, x_T, u_T} &amp;\\sum_{t=1}^T c(x_t, u_t) \\\\<br>\\text{s.t. } &amp;x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.<br>\\end{aligned}<br>$$</li>\n</ul>\n</li>\n<li>solution<ul>\n<li>假如上述轨迹优化问题中$f(x_t, u_t) = F_t \\begin{bmatrix} x_t \\\\\\ u_t \\end{bmatrix} + f_t$， $c(x_t, u_t) = \\frac{1}{2} \\begin{bmatrix} x_t \\\\\\ u_t \\end{bmatrix}^T C_t \\begin{bmatrix} x_t \\\\\\ u_t \\end{bmatrix} + \\begin{bmatrix} x_t \\\\\\ u_t \\end{bmatrix}^T c_t$，则有一个叫做<em>Linear Quadratic Regulator(LQR)</em>的优化方法可以对该轨迹优化问题进行求解。</li>\n<li><em>LQR</em>基本原理如下：<ul>\n<li>input：<ul>\n<li>linear model（$F_t, f_t$）</li>\n<li>quadratic cost（$C_t, c_t$）</li>\n</ul>\n</li>\n<li>output：$K_t, k_t$</li>\n<li>optimal control（上述轨迹优化问题的解）：$u_t=K_tx_t+k_t$，$x_{t+1}=f(x_t, u_t)$<div style=\"width:500px; margin-left:auto; margin-right:auto;\"><br><img src=\"/2018/05/17/summary-gps/lqr.png\" alt=\"lqr.png\" title=\"\"><br></div></li>\n</ul>\n</li>\n<li>由于我们在fit dynamics中拟合的就是一个linear model，因此只要我们设置的cost function是quadratic的话就可以使用<em>LQR</em>来求解。</li>\n<li>即使我们的cost function不是quadratic，也还可以使用<em>iterative LQR(iLQR)</em>来进行求解。<em>iLQR</em>可以求解nonlinear dynamics，nonquadratic cost下的轨迹优化问题，它的核心思想是对dynamics和cost分别进行linear及quadratic展开，然后用<em>LQR</em>进行求解。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Policy\"><a href=\"#Policy\" class=\"headerlink\" title=\"Policy\"></a>Policy</h3><ul>\n<li>big picture</li>\n</ul>\n<div style=\"width:400px; margin-left:auto; margin-right:auto;\"><br>  <img src=\"/2018/05/17/summary-gps/3.png\" alt=\"3.png\" title=\"\"><br></div>\n\n<ul>\n<li>optimization problem<ul>\n<li>因为<em>GPS</em>最后想要的是一个policy，因此在上述轨迹优化问题的基础上，加上一个优化变量$\\theta$以及约束条件$u_t = \\pi_\\theta(x_t)$，来表示我们希望policy能够“学习”optimal control：<br>$$<br>\\begin{aligned}<br>\\mathop{\\text{min }}_{x_1, u_1, \\dots, x_T, u_T, \\theta} &amp;\\sum_{t=1}^T c(x_t, u_t) \\\\<br>\\text{s.t. } &amp;u_t = \\pi_\\theta(x_t) \\quad t=1, \\dots, T\\\\<br>&amp;x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.<br>\\end{aligned}<br>$$</li>\n</ul>\n</li>\n<li>solution<ul>\n<li>求解上述优化问题用到了一种叫做<em>Dual Gradient Descent(DGD)</em>的优化方法。<em>DGD</em>是一种求解形如以下优化问题的方法：<br>$$<br>\\begin{aligned}<br>\\mathop{\\text{min }}_x &amp;f(x) \\\\<br>\\text{s.t. } &amp; C(x)=0.<br>\\end{aligned}<br>$$其具体求解过程为：<ol>\n<li>写出对应的Lagrangian函数：$\\mathcal{L}(x, \\lambda) = f(x) + \\lambda C(x)$；</li>\n<li>求解最小化Lagrangian函数的$x$：$x^* = \\mathop{\\text{argmin }}_x \\mathcal{L}(x, \\lambda)$；</li>\n<li>将$x^*$代入$\\mathcal{L}(x, \\lambda)$得到原问题的下界函数$g(\\lambda) = \\mathcal{L}(x^*, \\lambda)$；</li>\n<li>更新$\\lambda$（类似对$\\lambda$做gradient ascent）：$\\lambda = \\lambda + \\alpha \\frac{\\partial g}{\\partial \\lambda}$；</li>\n<li>回到第二步，求新$\\lambda$下对应的$x^*$，迭代。</li>\n</ol>\n</li>\n<li>接下来改变一下优化问题的表述方式，<strong>将dynamics约束单独提出来</strong>（之所以这么做，是<strong>为了将问题化归为会解的问题</strong>，下面会详细说），也就是说现在把问题理解为在满足dynamics约束下求解一个约束优化问题（i.e., 满足policy约束下最小化cost），而原来是满足dynamics和policy约束下求解一个无约束优化问题（i.e., 最小化cost）：<br>$$<br>\\begin{aligned}<br>\\mathop{\\text{min }}_{x_1, u_1, \\dots, x_T, u_T, \\theta} &amp;\\sum_{t=1}^T c(x_t, u_t) \\\\<br>\\text{s.t. } &amp;u_t = \\pi_\\theta(x_t) \\quad t=1, \\dots, T\\\\<br>\\\\<br>\\text{s.t. } x_t = f&amp;(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.<br>\\end{aligned}<br>$$</li>\n<li>然后进行<strong>约束条件下的<em>DGD</em></strong>（i.e., 整个<em>DGD</em>的过程都要满足约束）：<ol>\n<li>仅将policy约束写进Lagrangian函数：<br>$$<br>\\begin{aligned}<br>\\mathcal{L}(\\tau, \\theta, \\lambda)<br>&amp;= \\mathcal{L}(x_1, u_1, \\dots, x_T, u_T, \\theta, \\lambda_1, \\dots, \\lambda_T) \\\\<br>&amp;=  \\sum_{t=1}^T c(x_t, u_t) + \\sum_{t=1}^T\\lambda_t [u_t - \\pi_\\theta(x_t)] \\\\<br>&amp;= \\sum_{t=1}^T { c(x_t, u_t) + \\lambda_t [u_t - \\pi_\\theta(x_t)] }.<br>\\end{aligned}<br>$$</li>\n<li>本来应该将$\\begin{bmatrix}\\tau \\\\\\ \\theta\\end{bmatrix}$这一整个向量看作优化变量（对应<em>DGD</em>中的$x$），然后求解$\\begin{bmatrix}\\tau \\\\\\ \\theta\\end{bmatrix}^*$（对应<em>DGD</em>中的$x^*$）。但这里<strong>假设$\\tau$和$\\theta$相互独立</strong>（为了能够求解），因此下面可以分别单独对$\\tau$与$\\theta$做优化，求得对应的$\\tau^*$和$\\theta^*$，然后用$\\begin{bmatrix}\\tau^* \\\\\\ \\theta^*\\end{bmatrix}$来近似$\\begin{bmatrix}\\tau \\\\\\ \\theta\\end{bmatrix}^*$。</li>\n<li>求解$\\tau^*$：对应的优化问题为：<br>$$<br>\\begin{aligned}<br>\\mathop{\\text{min }}_\\tau &amp;\\sum_{t=1}^T { c(x_t, u_t) + \\lambda_t [u_t - \\pi_\\theta(x_t)] } \\\\<br>\\text{s.t. } &amp;x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.<br>\\end{aligned}<br>$$设$\\tilde{c}(x_t, u_t)=c(x_t, u_t) + \\lambda_t [u_t - \\pi_\\theta(x_t)]$，我们有：<br>$$<br>\\begin{aligned}<br>\\mathop{\\text{min }}_\\tau &amp;\\sum_{t=1}^T \\tilde{c}(x_t, u_t)\\\\<br>\\text{s.t. } &amp;x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.<br>\\end{aligned}<br>$$而<strong>这个形式的优化问题我们能够通过<em>iLQR</em>进行求解</strong>，因此能够求得$\\tau^*$。</li>\n<li>求解$\\theta^*$：对应的优化问题为：<br>$$<br>\\begin{aligned}<br>\\mathop{\\text{min }}_\\theta &amp;\\sum_{t=1}^T { c(x_t, u_t) + \\lambda_t [u_t - \\pi_\\theta(x_t)] } \\\\<br>\\text{s.t. } &amp;x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.<br>\\end{aligned}<br>$$由于优化变量是$\\theta$，所以约束条件可以去掉，而且目标函数也可以简化，等价的优化问题为：<br>$$<br>\\begin{aligned}<br>\\mathop{\\text{min }}_\\theta &amp;\\sum_{t=1}^T \\lambda_t [u_t - \\pi_\\theta(x_t)].<br>\\end{aligned}<br>$$这是一个无约束优化问题（带权拟合问题），可以用诸如<em>SGD</em>等方法进行优化，因此也能够求得$\\theta^*$。</li>\n<li>将$\\tau^*$和$\\theta^*$代入Lagrangian函数，得到$g(\\lambda) = \\mathcal{L}(\\tau^*, \\theta^*, \\lambda)$。</li>\n<li>对$\\lambda$做单步gradient ascent（跟求解$\\theta^*$时一样，由于约束条件跟优化变量无关，所以等价于无约束优化），更新$\\lambda$，迭代。</li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Next-iteration\"><a href=\"#Next-iteration\" class=\"headerlink\" title=\"Next iteration\"></a>Next iteration</h2><p>回到第一步collect data，即用新的controller跟environment交互，迭代。</p>\n<h2 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h2><p>至此我们已经通过相对简单的deterministic policy case过了一遍<em>GPS</em>的整个流程，下面补充一些小小的细节：</p>\n<ul>\n<li>为什么称之为<em>GPS</em>：guided主要体现在最后优化问题的约束$u_t = \\pi_\\theta(x_t)$，相当于有一个teacher（controller）在“指引”我们的policy。</li>\n<li>collect data使用controller还是policy：应该是使用controller，因为policy仅仅拟合了某些具体的$(x_t, u_t)$，而controller对各个$x_t$都是“最优”的。</li>\n<li>为什么流程图中，train policy部分会跟$\\tau_i$相关：这是因为在求解$\\theta^*$时，$\\tau^*$还没代入Lagrangian函数，也就是说Lagrangian函数中用的是$\\tau$而不是$\\tau^*$。</li>\n</ul>\n<hr>\n<h1 id=\"Stochastic-policy-case\"><a href=\"#Stochastic-policy-case\" class=\"headerlink\" title=\"Stochastic policy case\"></a>Stochastic policy case</h1><p>deterministic controller对于一个起始点只能采集到一条轨迹，<strong>不利于拟合一个robust的dynamics</strong>，因此我们想要一个stochastic的controller。之后通过对stochastic controller进行supervised learning，我们最后会得到一个stochastic policy。</p>\n<p>stochastic policy case跟deterministic policy case的<strong>唯一区别在于optimization这步</strong>（如红框所示），其他都是一样的。因此下面仅介绍stochastic policy case如何做optimization。</p>\n<div style=\"width:400px; margin-left:auto; margin-right:auto;\"><br>  <img src=\"/2018/05/17/summary-gps/3.png\" alt=\"3.png\" title=\"\"><br></div>\n\n<h2 id=\"Using-stochastic-controller\"><a href=\"#Using-stochastic-controller\" class=\"headerlink\" title=\"Using stochastic controller\"></a>Using stochastic controller</h2><p>首先介绍一个过渡性的内容，是关于使用stochastic controller的。</p>\n<ul>\n<li>最直观的想法：把原来的约束问题（暂时先不考虑policy）改一下，将controller表示为$p(u_t \\vert x_t) \\sim \\mathcal{N}(\\mu_t, \\Sigma_t)$，然后求解优化问题：<br>$$<br>\\begin{aligned}<br>\\mathop{\\text{min }}_{\\tau, p} &amp;\\mathbb{E}_\\tau[\\sum_{t=1}^T c(x_t, u_t)] \\\\<br>\\text{s.t. } &amp;x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T,<br>\\end{aligned}<br>$$其中$p = \\mu_1, \\Sigma_1, \\dots, \\mu_T, \\Sigma_T$。但这样子是不work的，因为<strong>最后求出来的还是一个determinisitc controller</strong>（因为贪婪地采取最优策略效果是最好的）。</li>\n<li>于是就强行把controller设成linear-gaussian的形式：<br>$$<br>p(u_t \\vert x_t) = \\mathcal{N}(K_t(x_t - \\hat{x}_t) + k_t + \\hat{u}_t, Q^{-1}_{u_t,u_t}),<br>$$其中，gaussian的均值为<em>iLQR</em>的解，方差为<em>iLQR</em>中的某个矩阵的逆，具体含义可以不用管，只需要知道这些东西都可以通过<em>iLQR</em>得到。</li>\n<li>而该形式的controller恰好是以下优化问题的最优解：<br>$$<br>\\begin{aligned}<br>\\mathop{\\text{min }}_{\\tau, p} &amp;\\sum_{t=1}^T\\mathbb{E}_{p(x_t, u_t)}[ c(x_t, u_t) - \\mathcal{H}(p(u_t \\vert x_t))] \\\\<br>\\text{s.t. } &amp;x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.<br>\\end{aligned}<br>$$</li>\n<li>这部分主要为下面做铺垫，核心在于<strong>我们现在知道了某种形式的优化问题的最优解</strong>。</li>\n</ul>\n<h2 id=\"Constrain-controller-in-trust-region\"><a href=\"#Constrain-controller-in-trust-region\" class=\"headerlink\" title=\"Constrain controller in trust region\"></a>Constrain controller in trust region</h2><ul>\n<li>motivation<ul>\n<li>在<em>GPS</em>中我们所fit的dynamics是local dynamics，也就是说它<strong>仅在当前controller“附近”是有效的</strong>；</li>\n<li>在优化问题中，我们评价controller好坏会用到该local dynamics；</li>\n<li>因此，为了确保评价的有效性，我们要<strong>限定controller在当前controller“附近”</strong>；</li>\n<li>否则，即使contoller评价很高，也是虚假的/无效的/没有意义的。</li>\n</ul>\n</li>\n<li>solution<ul>\n<li>将controller在当前controller“附近”用数学语言表述出来，即<br>$$<br>D_{KL}(p(\\tau) \\Vert \\bar{p}(\\tau) ) \\leq \\epsilon,<br>$$其中$p(\\tau)$表示轨迹$\\tau$在新controller下发生的概率，$\\bar{p}(\\tau)$表示轨迹$\\tau$在当前controller下发生的概率，$D_{KL}$表示KL-divergence，用于衡量两个分布的“相似程度”，KL-divergence越小，两个分布越相似。<ul>\n<li>这个表示能够<strong>间接地限制controller和当前controller比较相似</strong>，因为$p(\\tau) = p(x_1)\\prod_{t=1}^{T-1} p(u_t \\vert x_t)f(x_{t+1} \\vert x_t, u_t)$，而对于新旧controller来说，$p(x_1)$以及$f(x_{t+1} \\vert x_t, u_t)$都是一样的，因此区别仅仅在于$p(u_t \\vert x_t)$。换句话说，$p(\\tau)$和$\\bar{p}(\\tau)$的区别仅仅在于controller，因此控制$p(\\tau)$和$\\bar{p}(\\tau)$的相似程度就可以间接地控制controller的相似程度。</li>\n</ul>\n</li>\n<li>new optimization problem<br>$$<br>\\begin{aligned}<br>\\mathop{\\text{min }}_{\\tau, p} &amp;\\mathbb{E}_\\tau[\\sum_{t=1}^T c(x_t, u_t)] \\\\<br>\\text{s.t. } &amp;D_{KL}(p(\\tau) \\Vert \\bar{p}(\\tau) ) \\leq \\epsilon \\\\<br>&amp;x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.<br>\\end{aligned}<br>$$</li>\n<li>进行约束条件下的<em>DGD</em>（这里我不太懂为什么可以对不等式约束做<em>DGD</em>，逻辑上来讲对于不等式约束，需要限定$\\lambda \\geq 0$才能保证$g(\\lambda)$是原问题的下界函数）：<ol>\n<li>仅将$D_{KL}$约束写进Lagrangian函数：<br>$$<br>\\begin{aligned}<br>\\mathcal{L}(\\tau, p, \\lambda) &amp;= \\mathbb{E}_\\tau[\\sum_{t=1}^T c(x_t, u_t)] + \\lambda (D_{KL}(p(\\tau) \\Vert \\bar{p}(\\tau) ) - \\epsilon) \\\\<br>&amp;// D_{KL}(p(\\tau) \\Vert \\bar{p}(\\tau) ) = \\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)} [- \\log \\bar{p}(u_t \\vert x_t) - \\mathcal{H}(p(u_t \\vert x_t))]  \\\\<br>&amp;= \\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)}[c(x_t, u_t) - \\lambda \\log \\bar{p}(u_t \\vert x_t) - \\lambda \\mathcal{H}(p(u_t \\vert x_t))] - \\lambda \\epsilon \\\\<br>&amp;//提\\lambda \\\\<br>&amp;= \\lambda \\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)}[\\frac{1}{\\lambda} c(x_t, u_t) - \\log \\bar{p}(u_t \\vert x_t) - \\mathcal{H}(p(u_t \\vert x_t))] - \\epsilon<br>\\end{aligned}<br>$$</li>\n<li>求解$\\begin{bmatrix} \\tau \\\\\\ p \\end{bmatrix}^*$：对应的优化问题为：<br>$$<br>\\begin{aligned}<br>\\mathop{\\text{min }}_{\\tau, p} &amp;\\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)}[\\frac{1}{\\lambda} c(x_t, u_t) - \\log \\bar{p}(u_t \\vert x_t) - \\mathcal{H}(p(u_t \\vert x_t))] \\\\<br>\\text{s.t. } &amp;x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.<br>\\end{aligned}<br>$$假如我们设$\\tilde{c}(x_t, u_t) = \\frac{1}{\\lambda} c(x_t, u_t) - \\log \\bar{p}(u_t \\vert x_t)$，则该优化问题为：<br>$$<br>\\begin{aligned}<br>\\mathop{\\text{min }}_{\\tau, p} &amp;\\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)}[\\tilde{c}(x_t, u_t) - \\mathcal{H}(p(u_t \\vert x_t))] \\\\<br>\\text{s.t. } &amp;x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.<br>\\end{aligned}<br>$$而<strong>这个形式的优化问题我们知道其最优解的形式是什么</strong>（回忆Using stochastic controller部分），因此我们能够用<em>iLQR</em>求解$\\begin{bmatrix} \\tau \\\\\\ p \\end{bmatrix}^*$。</li>\n<li>对$\\lambda$做单步gradient ascent，迭代。</li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Introduce-stochastic-policy\"><a href=\"#Introduce-stochastic-policy\" class=\"headerlink\" title=\"Introduce stochastic policy\"></a>Introduce stochastic policy</h2><ul>\n<li>statement<ul>\n<li><strong>这部分由于没有细看论文，所以有些地方我也不是很清楚，只是介绍我自己的理解，希望谅解：）</strong>。</li>\n</ul>\n</li>\n<li>motivation<ul>\n<li>我们想要得到的是一个parametric policy，因此采用跟deterministic policy case一样的思路，添加一个policy约束。</li>\n</ul>\n</li>\n<li>solution<ul>\n<li>optimization problem<br>$$<br>\\begin{aligned}<br>\\mathop{\\text{min }}_{\\tau, p} &amp;\\mathbb{E}_\\tau[\\sum_{t=1}^T c(x_t, u_t)] \\\\<br>\\text{s.t. } &amp;p(u_t \\vert x_t) = \\pi_\\theta(u_t \\vert x_t) \\quad t=1, \\dots, T \\\\<br>&amp;D_{KL}(p(\\tau) \\Vert \\bar{p}(\\tau) ) \\leq \\epsilon \\\\<br>&amp;x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.<br>\\end{aligned}<br>$$</li>\n<li>进行约束条件下的<em>DGD</em>：<ol>\n<li>仅将policy约束和$D_{KL}$约束写进Lagrangian函数：<br>$$<br>\\begin{aligned}<br>\\mathcal{L}(\\tau, p, \\theta, \\lambda, \\eta) &amp;= \\mathbb{E}_\\tau[\\sum_{t=1}^T c(x_t, u_t)] + \\sum_{t=1}^T \\lambda_t [p(u_t \\vert x_t) - \\pi_\\theta(u_t \\vert x_t)] + \\eta (D_{KL}(p(\\tau) \\Vert \\bar{p}(\\tau) ) - \\epsilon) \\\\<br>&amp;// \\sum_{t=1}^T \\lambda_t [p(u_t \\vert x_t) - \\pi_\\theta(u_t \\vert x_t)] \\overset{?}{\\approx} \\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)}[u_t^T\\lambda_t + \\rho_t D_{KL}(p(u_t \\vert x_t) \\Vert \\pi_\\theta(u_t \\vert x_t))]\\\\<br>&amp;\\approx \\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)}[c(x_t, u_t) + u_t^T\\lambda_t + \\rho_t D_{KL}(p(u_t \\vert x_t) \\Vert \\pi_\\theta(u_t \\vert x_t))] + \\eta (D_{KL}(p(\\tau) \\Vert \\bar{p}(\\tau) ) - \\epsilon) \\\\<br>&amp;// \\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)}[D_{KL}(p(u_t \\vert x_t) \\Vert \\pi_\\theta(u_t \\vert x_t))] = \\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)}[- \\log \\pi_\\theta(u_t \\vert x_t) - \\mathcal{H}(p(u_t \\vert x_t))] \\\\<br>&amp;// D_{KL}(p(\\tau) \\Vert \\bar{p}(\\tau) ) = \\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)} [- \\log \\bar{p}(u_t \\vert x_t) - \\mathcal{H}(p(u_t \\vert x_t))]  \\\\<br>&amp;= \\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)}[c(x_t, u_t) + u_t^T\\lambda_t - \\rho_t \\log\\pi_\\theta(u_t \\vert x_t) - \\eta \\log \\bar{p}(u_t \\vert x_t) - ( \\rho_t + \\eta) \\mathcal{H}(p(u_t \\vert x_t))] - \\eta \\epsilon<br>\\end{aligned}<br>$$</li>\n<li>求解$\\begin{bmatrix} \\tau \\\\\\ p \\end{bmatrix}^*$：对应的优化问题为：<br>$$<br>\\begin{aligned}<br>\\mathop{\\text{min }}_{\\tau, p} &amp;\\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)}[c(x_t, u_t) + u_t^T\\lambda_t - \\rho_t \\log\\pi_\\theta(u_t \\vert x_t) - \\eta \\log \\bar{p}(u_t \\vert x_t) - ( \\rho_t + \\eta) \\mathcal{H}(p(u_t \\vert x_t))] \\\\<br>\\text{s.t. } &amp;x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.<br>\\end{aligned}<br>$$设$\\tilde{c}(x_t, u_t) = c(x_t, u_t) + u_t^T\\lambda_t - \\rho_t \\log\\pi_\\theta(u_t \\vert x_t) - \\eta \\log \\bar{p}(u_t \\vert x_t)$，$\\nu_t = \\rho_t + \\eta$，则上述优化问题可以表示为：<br>$$<br>\\begin{aligned}<br>\\mathop{\\text{min }}_{\\tau, p} &amp;\\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)}[\\tilde{c}(x_t, u_t) - \\nu_t \\mathcal{H}(p(u_t \\vert x_t))] \\\\<br>\\text{s.t. } &amp;x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.<br>\\end{aligned}<br>$$而<strong>这个形式的优化问题我们知道最优解</strong>（回忆Using stochastic controller和Constrain controller in trust region部分），因此得到$\\begin{bmatrix} \\tau \\\\\\ p \\end{bmatrix}^*$。</li>\n<li>求解$\\theta^*$：跟deterministic policy case一样，由于约束条件跟待优化变量无关，所以实际上是一个无约束优化问题，不过问题是这里并没有用直接用上面的Lagrangian函数，我猜测问题是出在上面我没搞懂的带问号的约等于号那里，也许上面只是为了求解方便做了近似，因此在求解$\\theta^*$时没有把Lagrangian函数展开到最后的形式，而是用了以下Lagrangian函数：<br>$$<br>\\begin{aligned}<br>\\mathcal{L}(\\tau, p, \\theta, \\lambda, \\eta) &amp;= \\mathbb{E}_\\tau[\\sum_{t=1}^T c(x_t, u_t)] + \\sum_{t=1}^T \\lambda_t [p(u_t \\vert x_t) - \\pi_\\theta(u_t \\vert x_t)] + \\eta (D_{KL}(p(\\tau) \\Vert \\bar{p}(\\tau) ) - \\epsilon) \\\\<br>&amp;// \\sum_{t=1}^T \\lambda_t [p(u_t \\vert x_t) - \\pi_\\theta(u_t \\vert x_t)] \\overset{?}{=} \\sum_{t=1}^T \\mathbb{E}_{p(x_t)}[\\mathbb{E}_{\\pi_\\theta(u_t \\vert x_t)}[u_t]^T\\lambda_t + \\rho_t D_{KL}(p(u_t \\vert x_t) \\Vert \\pi_\\theta(u_t \\vert x_t))]\\\\<br>&amp;= \\mathbb{E}_\\tau[\\sum_{t=1}^T c(x_t, u_t)] + \\sum_{t=1}^T \\mathbb{E}_{p(x_t)}[\\mathbb{E}_{\\pi_\\theta(u_t \\vert x_t)}[u_t]^T\\lambda_t + \\rho_t D_{KL}(p(u_t \\vert x_t) \\Vert \\pi_\\theta(u_t \\vert x_t))] \\\\<br>&amp;+ \\eta (D_{KL}(p(\\tau) \\Vert \\bar{p}(\\tau) ) - \\epsilon) \\\\<br>\\end{aligned}.<br>$$因此，对应的关于$\\theta$的无约束优化问题为：<br>$$<br>\\mathop{\\text{min }}_{\\theta}\\sum_{t=1}^T \\mathbb{E}_{p(x_t)}[\\mathbb{E}_{\\pi_\\theta(u_t \\vert x_t)}[u_t]^T\\lambda_t + \\rho_t D_{KL}(p(u_t \\vert x_t) \\Vert \\pi_\\theta(u_t \\vert x_t))].<br>$$应该可以使用诸如<em>SGD</em>等优化方法进行求解，于是我们得到$\\theta^*$</li>\n<li>对$\\begin{bmatrix} \\lambda \\\\\\ \\eta \\end{bmatrix}$做单步gradient ascent，迭代。</li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h1 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h1><p>至此已经介绍完<em>GPS</em>的流程，这个算法给我印象最深刻的地方就是<strong>化归</strong>的思想，即将新构建的问题转化为之前已经知道解决方法的问题，令人叹为观止。</p>\n<hr>\n<h1 id=\"References\"><a href=\"#References\" class=\"headerlink\" title=\"References\"></a>References</h1><ul>\n<li><a href=\"http://rll.berkeley.edu/deeprlcourse/\" target=\"_blank\" rel=\"external\">CS294 Fall 2017 lecture 8-10</a></li>\n<li><a href=\"https://people.eecs.berkeley.edu/~pabbeel/cs287-fa15/slides/lecture20-guided-policy-search.pdf\" target=\"_blank\" rel=\"external\">CS287 Guest Lecture Sergey Levine Slide</a></li>\n<li><a href=\"https://www.youtube.com/watch?v=CW1s6psByxk\" target=\"_blank\" rel=\"external\">Sergey Levine UCB Talk</a></li>\n<li><a href=\"https://www.youtube.com/watch?v=EtMyH_--vnU&amp;feature=youtu.be\" target=\"_blank\" rel=\"external\">Sergey Levine UW Talk</a></li>\n<li><a href=\"https://people.eecs.berkeley.edu/~svlevine/papers/mfcgps.pdf\" target=\"_blank\" rel=\"external\">Learning neural network policies with guided policy search under unknown dynamics</a></li>\n<li><a href=\"http://www.jmlr.org/papers/volume17/15-522/15-522.pdf\" target=\"_blank\" rel=\"external\">End-to-end training of deep visuomotor policies</a></li>\n</ul>\n","excerpt":"","more":"<h1 id=\"Overivew\"><a href=\"#Overivew\" class=\"headerlink\" title=\"Overivew\"></a>Overivew</h1><p>本文将介绍<em>Guided Policy Search(GPS)</em>这种Model-Based的强化学习算法，并会按以下方式展开：</p>\n<ol>\n<li>Motivation：介绍<em>GPS</em>这种方法的<strong>特点</strong>；</li>\n<li>Problem formulation：介绍<em>GPS</em>所解决<strong>问题的具体形式</strong>；</li>\n<li>Framework：介绍<em>GPS</em>的<strong>整体框架</strong>；</li>\n<li>Deterministic policy case：从相对简单的deterministic policy case开始介绍<em>GPS</em>的<strong>具体流程</strong>；</li>\n<li>Stochastic policy case：从deterministic policy case过渡到stochastic policy case，介绍<strong>完整</strong>的<em>GPS</em>算法。</li>\n</ol>\n<hr>\n<h1 id=\"Motivation\"><a href=\"#Motivation\" class=\"headerlink\" title=\"Motivation\"></a>Motivation</h1><p>下面通过将<em>GPS</em>跟不同类型的算法进行比较来说明<em>GPS</em>的特点。</p>\n<ul>\n<li>与Model-Free算法相比：由于<em>GPS</em>对环境建立了模型（i.e., model/dynamics），在计算q value时，不仅仅是“记录”，还能进行“推算”，因此<strong>sample efficiency会比较高，收敛速度会比较快</strong>；</li>\n<li>与其他Model-Based算法相比：在test的时候，部分Model-Based算法需要进行online optimization（i.e., 根据当前拟合的模型，使用某种优化算法，得到当前的action）；而由于<em>GPS</em>最终得到的是一个parametric policy（e.g., 神经网络），因此<strong>在test的时候会比较快</strong>（无需做online optimization，只需要做一次forward pass）；</li>\n<li>与简单的Imitation Learning算法相比：在简单的IL中，teacher单方面地给student传授知识（i.e., supervised learning），而不管student的学习能力如何；而在<em>GPS</em>中，<strong>除了teacher给student传授知识以外，student还会给teacher反馈</strong>，要求teacher适配student的学习能力，形成闭环，因此train的效果会更好。</li>\n</ul>\n<hr>\n<h1 id=\"Problem-Formulation\"><a href=\"#Problem-Formulation\" class=\"headerlink\" title=\"Problem Formulation\"></a>Problem Formulation</h1><p>下面对我们所讨论的问题做一个界定。</p>\n<ul>\n<li>setting<ul>\n<li><strong>fixed time length</strong> task（e.g, 完成任务的时长限定在20s内，决策的频率是20Hz，则总步长$T$为400）</li>\n</ul>\n</li>\n<li>assumption<ul>\n<li>deterministic dynamics：$x_t = f(x_{t-1}, u_{t-1})$</li>\n</ul>\n</li>\n<li>input<ul>\n<li>environment</li>\n<li>immediate cost(reward) function：$c(x_t, u_t)$</li>\n</ul>\n</li>\n<li>output<ul>\n<li>parametric policy<ul>\n<li>deterministic case：$u_t = \\pi_\\theta(x_t)$</li>\n<li>stochastic case：$\\pi_\\theta(u_t \\vert x_t) \\sim \\mathcal{N}(\\mu_t, \\Sigma_t)$</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h1 id=\"Framework\"><a href=\"#Framework\" class=\"headerlink\" title=\"Framework\"></a>Framework</h1><p>下面介绍<em>GPS</em>的整体框架。</p>\n<ol>\n<li>collect data：通过controller与environment进行交互，收集数据；<div style=\"width:300px; margin-left:auto; margin-right:auto;\" ><br><img src=\"/2018/05/17/summary-gps/1.png\" alt=\"1.png\" title=\"\"><br></div></li>\n<li>fit dynamics：根据第一步收集到的数据，拟合dynamics；<div style=\"width:300px; margin-left:auto; margin-right:auto;\" ><br><img src=\"/2018/05/17/summary-gps/2.png\" alt=\"2.png\" title=\"\"><br></div></li>\n<li>optimization：优化controller（最优控制器）与policy（最终输出的parametric policy）；<div style=\"width:400px; margin-left:auto; margin-right:auto;\" ><br><img src=\"/2018/05/17/summary-gps/3.png\" alt=\"3.png\" title=\"\"><br></div></li>\n<li>next iteration：迭代。<div style=\"width:500px; margin-left:auto; margin-right:auto;\" ><br><img src=\"/2018/05/17/summary-gps/4.png\" alt=\"4.png\" title=\"\"><br></div>\n\n</li>\n</ol>\n<hr>\n<h1 id=\"Deterministic-policy-case\"><a href=\"#Deterministic-policy-case\" class=\"headerlink\" title=\"Deterministic policy case\"></a>Deterministic policy case</h1><p>下面开始介绍Deterministic policy case下<em>GPS</em>的具体流程。</p>\n<h2 id=\"Collect-data\"><a href=\"#Collect-data\" class=\"headerlink\" title=\"Collect data\"></a>Collect data</h2><p>使用controller与environment进行交互，得到轨迹数据集$\\mathcal{D} = { \\tau_i }$，其中轨迹$\\tau_i = { x_{1i}, u_{1i}, \\dots , x_{1T}, u_{1T} }$。</p>\n<h2 id=\"Fit-dynamics\"><a href=\"#Fit-dynamics\" class=\"headerlink\" title=\"Fit dynamics\"></a>Fit dynamics</h2><p>使用第一步得到的轨迹数据集来拟合一个time-varying linear model：$x_{t+1} = f(x_t, u_t) = A_tx_t + B_tu_t + c_t$，也就是说这个model<strong>对于不同时刻$t$的input会使用不同的linear model</strong>。</p>\n<p>具体的拟合方法是使用同一时刻$t$，不同轨迹$\\tau_i$的数据${ (x_{t1}, u_{t1}, x_{t+1,1}), \\dots , (x_{ti}, u_{ti}, x_{t+1,i}) }$来做linear regression。</p>\n<h2 id=\"Optimization\"><a href=\"#Optimization\" class=\"headerlink\" title=\"Optimization\"></a>Optimization</h2><h3 id=\"Controller\"><a href=\"#Controller\" class=\"headerlink\" title=\"Controller\"></a>Controller</h3><ul>\n<li>big picture</li>\n</ul>\n<div style=\"width:250px; margin-left:auto; margin-right:auto;\" ><br>  <img src=\"/2018/05/17/summary-gps/3_1.png\" alt=\"3_1.png\" title=\"\"><br></div>\n\n<ul>\n<li>optimization problem<ul>\n<li>我们想要在满足dynamics约束的条件下，最小化总cost，因此对应的轨迹优化问题为：<br>$$<br>\\begin{aligned}<br>\\mathop{\\text{min }}_{x_1, u_1, \\dots, x_T, u_T} &amp;\\sum_{t=1}^T c(x_t, u_t) \\\\<br>\\text{s.t. } &amp;x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.<br>\\end{aligned}<br>$$</li>\n</ul>\n</li>\n<li>solution<ul>\n<li>假如上述轨迹优化问题中$f(x_t, u_t) = F_t \\begin{bmatrix} x_t \\\\\\ u_t \\end{bmatrix} + f_t$， $c(x_t, u_t) = \\frac{1}{2} \\begin{bmatrix} x_t \\\\\\ u_t \\end{bmatrix}^T C_t \\begin{bmatrix} x_t \\\\\\ u_t \\end{bmatrix} + \\begin{bmatrix} x_t \\\\\\ u_t \\end{bmatrix}^T c_t$，则有一个叫做<em>Linear Quadratic Regulator(LQR)</em>的优化方法可以对该轨迹优化问题进行求解。</li>\n<li><em>LQR</em>基本原理如下：<ul>\n<li>input：<ul>\n<li>linear model（$F_t, f_t$）</li>\n<li>quadratic cost（$C_t, c_t$）</li>\n</ul>\n</li>\n<li>output：$K_t, k_t$</li>\n<li>optimal control（上述轨迹优化问题的解）：$u_t=K_tx_t+k_t$，$x_{t+1}=f(x_t, u_t)$<div style=\"width:500px; margin-left:auto; margin-right:auto;\" ><br><img src=\"/2018/05/17/summary-gps/lqr.png\" alt=\"lqr.png\" title=\"\"><br></div></li>\n</ul>\n</li>\n<li>由于我们在fit dynamics中拟合的就是一个linear model，因此只要我们设置的cost function是quadratic的话就可以使用<em>LQR</em>来求解。</li>\n<li>即使我们的cost function不是quadratic，也还可以使用<em>iterative LQR(iLQR)</em>来进行求解。<em>iLQR</em>可以求解nonlinear dynamics，nonquadratic cost下的轨迹优化问题，它的核心思想是对dynamics和cost分别进行linear及quadratic展开，然后用<em>LQR</em>进行求解。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Policy\"><a href=\"#Policy\" class=\"headerlink\" title=\"Policy\"></a>Policy</h3><ul>\n<li>big picture</li>\n</ul>\n<div style=\"width:400px; margin-left:auto; margin-right:auto;\" ><br>  <img src=\"/2018/05/17/summary-gps/3.png\" alt=\"3.png\" title=\"\"><br></div>\n\n<ul>\n<li>optimization problem<ul>\n<li>因为<em>GPS</em>最后想要的是一个policy，因此在上述轨迹优化问题的基础上，加上一个优化变量$\\theta$以及约束条件$u_t = \\pi_\\theta(x_t)$，来表示我们希望policy能够“学习”optimal control：<br>$$<br>\\begin{aligned}<br>\\mathop{\\text{min }}_{x_1, u_1, \\dots, x_T, u_T, \\theta} &amp;\\sum_{t=1}^T c(x_t, u_t) \\\\<br>\\text{s.t. } &amp;u_t = \\pi_\\theta(x_t) \\quad t=1, \\dots, T\\\\<br>&amp;x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.<br>\\end{aligned}<br>$$</li>\n</ul>\n</li>\n<li>solution<ul>\n<li>求解上述优化问题用到了一种叫做<em>Dual Gradient Descent(DGD)</em>的优化方法。<em>DGD</em>是一种求解形如以下优化问题的方法：<br>$$<br>\\begin{aligned}<br>\\mathop{\\text{min }}_x &amp;f(x) \\\\<br>\\text{s.t. } &amp; C(x)=0.<br>\\end{aligned}<br>$$其具体求解过程为：<ol>\n<li>写出对应的Lagrangian函数：$\\mathcal{L}(x, \\lambda) = f(x) + \\lambda C(x)$；</li>\n<li>求解最小化Lagrangian函数的$x$：$x^* = \\mathop{\\text{argmin }}_x \\mathcal{L}(x, \\lambda)$；</li>\n<li>将$x^*$代入$\\mathcal{L}(x, \\lambda)$得到原问题的下界函数$g(\\lambda) = \\mathcal{L}(x^*, \\lambda)$；</li>\n<li>更新$\\lambda$（类似对$\\lambda$做gradient ascent）：$\\lambda = \\lambda + \\alpha \\frac{\\partial g}{\\partial \\lambda}$；</li>\n<li>回到第二步，求新$\\lambda$下对应的$x^*$，迭代。</li>\n</ol>\n</li>\n<li>接下来改变一下优化问题的表述方式，<strong>将dynamics约束单独提出来</strong>（之所以这么做，是<strong>为了将问题化归为会解的问题</strong>，下面会详细说），也就是说现在把问题理解为在满足dynamics约束下求解一个约束优化问题（i.e., 满足policy约束下最小化cost），而原来是满足dynamics和policy约束下求解一个无约束优化问题（i.e., 最小化cost）：<br>$$<br>\\begin{aligned}<br>\\mathop{\\text{min }}_{x_1, u_1, \\dots, x_T, u_T, \\theta} &amp;\\sum_{t=1}^T c(x_t, u_t) \\\\<br>\\text{s.t. } &amp;u_t = \\pi_\\theta(x_t) \\quad t=1, \\dots, T\\\\<br>\\\\<br>\\text{s.t. } x_t = f&amp;(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.<br>\\end{aligned}<br>$$</li>\n<li>然后进行<strong>约束条件下的<em>DGD</em></strong>（i.e., 整个<em>DGD</em>的过程都要满足约束）：<ol>\n<li>仅将policy约束写进Lagrangian函数：<br>$$<br>\\begin{aligned}<br>\\mathcal{L}(\\tau, \\theta, \\lambda)<br>&amp;= \\mathcal{L}(x_1, u_1, \\dots, x_T, u_T, \\theta, \\lambda_1, \\dots, \\lambda_T) \\\\<br>&amp;=  \\sum_{t=1}^T c(x_t, u_t) + \\sum_{t=1}^T\\lambda_t [u_t - \\pi_\\theta(x_t)] \\\\<br>&amp;= \\sum_{t=1}^T { c(x_t, u_t) + \\lambda_t [u_t - \\pi_\\theta(x_t)] }.<br>\\end{aligned}<br>$$</li>\n<li>本来应该将$\\begin{bmatrix}\\tau \\\\\\ \\theta\\end{bmatrix}$这一整个向量看作优化变量（对应<em>DGD</em>中的$x$），然后求解$\\begin{bmatrix}\\tau \\\\\\ \\theta\\end{bmatrix}^*$（对应<em>DGD</em>中的$x^*$）。但这里<strong>假设$\\tau$和$\\theta$相互独立</strong>（为了能够求解），因此下面可以分别单独对$\\tau$与$\\theta$做优化，求得对应的$\\tau^*$和$\\theta^*$，然后用$\\begin{bmatrix}\\tau^* \\\\\\ \\theta^*\\end{bmatrix}$来近似$\\begin{bmatrix}\\tau \\\\\\ \\theta\\end{bmatrix}^*$。</li>\n<li>求解$\\tau^*$：对应的优化问题为：<br>$$<br>\\begin{aligned}<br>\\mathop{\\text{min }}_\\tau &amp;\\sum_{t=1}^T { c(x_t, u_t) + \\lambda_t [u_t - \\pi_\\theta(x_t)] } \\\\<br>\\text{s.t. } &amp;x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.<br>\\end{aligned}<br>$$设$\\tilde{c}(x_t, u_t)=c(x_t, u_t) + \\lambda_t [u_t - \\pi_\\theta(x_t)]$，我们有：<br>$$<br>\\begin{aligned}<br>\\mathop{\\text{min }}_\\tau &amp;\\sum_{t=1}^T \\tilde{c}(x_t, u_t)\\\\<br>\\text{s.t. } &amp;x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.<br>\\end{aligned}<br>$$而<strong>这个形式的优化问题我们能够通过<em>iLQR</em>进行求解</strong>，因此能够求得$\\tau^*$。</li>\n<li>求解$\\theta^*$：对应的优化问题为：<br>$$<br>\\begin{aligned}<br>\\mathop{\\text{min }}_\\theta &amp;\\sum_{t=1}^T { c(x_t, u_t) + \\lambda_t [u_t - \\pi_\\theta(x_t)] } \\\\<br>\\text{s.t. } &amp;x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.<br>\\end{aligned}<br>$$由于优化变量是$\\theta$，所以约束条件可以去掉，而且目标函数也可以简化，等价的优化问题为：<br>$$<br>\\begin{aligned}<br>\\mathop{\\text{min }}_\\theta &amp;\\sum_{t=1}^T \\lambda_t [u_t - \\pi_\\theta(x_t)].<br>\\end{aligned}<br>$$这是一个无约束优化问题（带权拟合问题），可以用诸如<em>SGD</em>等方法进行优化，因此也能够求得$\\theta^*$。</li>\n<li>将$\\tau^*$和$\\theta^*$代入Lagrangian函数，得到$g(\\lambda) = \\mathcal{L}(\\tau^*, \\theta^*, \\lambda)$。</li>\n<li>对$\\lambda$做单步gradient ascent（跟求解$\\theta^*$时一样，由于约束条件跟优化变量无关，所以等价于无约束优化），更新$\\lambda$，迭代。</li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Next-iteration\"><a href=\"#Next-iteration\" class=\"headerlink\" title=\"Next iteration\"></a>Next iteration</h2><p>回到第一步collect data，即用新的controller跟environment交互，迭代。</p>\n<h2 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h2><p>至此我们已经通过相对简单的deterministic policy case过了一遍<em>GPS</em>的整个流程，下面补充一些小小的细节：</p>\n<ul>\n<li>为什么称之为<em>GPS</em>：guided主要体现在最后优化问题的约束$u_t = \\pi_\\theta(x_t)$，相当于有一个teacher（controller）在“指引”我们的policy。</li>\n<li>collect data使用controller还是policy：应该是使用controller，因为policy仅仅拟合了某些具体的$(x_t, u_t)$，而controller对各个$x_t$都是“最优”的。</li>\n<li>为什么流程图中，train policy部分会跟$\\tau_i$相关：这是因为在求解$\\theta^*$时，$\\tau^*$还没代入Lagrangian函数，也就是说Lagrangian函数中用的是$\\tau$而不是$\\tau^*$。</li>\n</ul>\n<hr>\n<h1 id=\"Stochastic-policy-case\"><a href=\"#Stochastic-policy-case\" class=\"headerlink\" title=\"Stochastic policy case\"></a>Stochastic policy case</h1><p>deterministic controller对于一个起始点只能采集到一条轨迹，<strong>不利于拟合一个robust的dynamics</strong>，因此我们想要一个stochastic的controller。之后通过对stochastic controller进行supervised learning，我们最后会得到一个stochastic policy。</p>\n<p>stochastic policy case跟deterministic policy case的<strong>唯一区别在于optimization这步</strong>（如红框所示），其他都是一样的。因此下面仅介绍stochastic policy case如何做optimization。</p>\n<div style=\"width:400px; margin-left:auto; margin-right:auto;\" ><br>  <img src=\"/2018/05/17/summary-gps/3.png\" alt=\"3.png\" title=\"\"><br></div>\n\n<h2 id=\"Using-stochastic-controller\"><a href=\"#Using-stochastic-controller\" class=\"headerlink\" title=\"Using stochastic controller\"></a>Using stochastic controller</h2><p>首先介绍一个过渡性的内容，是关于使用stochastic controller的。</p>\n<ul>\n<li>最直观的想法：把原来的约束问题（暂时先不考虑policy）改一下，将controller表示为$p(u_t \\vert x_t) \\sim \\mathcal{N}(\\mu_t, \\Sigma_t)$，然后求解优化问题：<br>$$<br>\\begin{aligned}<br>\\mathop{\\text{min }}_{\\tau, p} &amp;\\mathbb{E}_\\tau[\\sum_{t=1}^T c(x_t, u_t)] \\\\<br>\\text{s.t. } &amp;x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T,<br>\\end{aligned}<br>$$其中$p = \\mu_1, \\Sigma_1, \\dots, \\mu_T, \\Sigma_T$。但这样子是不work的，因为<strong>最后求出来的还是一个determinisitc controller</strong>（因为贪婪地采取最优策略效果是最好的）。</li>\n<li>于是就强行把controller设成linear-gaussian的形式：<br>$$<br>p(u_t \\vert x_t) = \\mathcal{N}(K_t(x_t - \\hat{x}_t) + k_t + \\hat{u}_t, Q^{-1}_{u_t,u_t}),<br>$$其中，gaussian的均值为<em>iLQR</em>的解，方差为<em>iLQR</em>中的某个矩阵的逆，具体含义可以不用管，只需要知道这些东西都可以通过<em>iLQR</em>得到。</li>\n<li>而该形式的controller恰好是以下优化问题的最优解：<br>$$<br>\\begin{aligned}<br>\\mathop{\\text{min }}_{\\tau, p} &amp;\\sum_{t=1}^T\\mathbb{E}_{p(x_t, u_t)}[ c(x_t, u_t) - \\mathcal{H}(p(u_t \\vert x_t))] \\\\<br>\\text{s.t. } &amp;x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.<br>\\end{aligned}<br>$$</li>\n<li>这部分主要为下面做铺垫，核心在于<strong>我们现在知道了某种形式的优化问题的最优解</strong>。</li>\n</ul>\n<h2 id=\"Constrain-controller-in-trust-region\"><a href=\"#Constrain-controller-in-trust-region\" class=\"headerlink\" title=\"Constrain controller in trust region\"></a>Constrain controller in trust region</h2><ul>\n<li>motivation<ul>\n<li>在<em>GPS</em>中我们所fit的dynamics是local dynamics，也就是说它<strong>仅在当前controller“附近”是有效的</strong>；</li>\n<li>在优化问题中，我们评价controller好坏会用到该local dynamics；</li>\n<li>因此，为了确保评价的有效性，我们要<strong>限定controller在当前controller“附近”</strong>；</li>\n<li>否则，即使contoller评价很高，也是虚假的/无效的/没有意义的。</li>\n</ul>\n</li>\n<li>solution<ul>\n<li>将controller在当前controller“附近”用数学语言表述出来，即<br>$$<br>D_{KL}(p(\\tau) \\Vert \\bar{p}(\\tau) ) \\leq \\epsilon,<br>$$其中$p(\\tau)$表示轨迹$\\tau$在新controller下发生的概率，$\\bar{p}(\\tau)$表示轨迹$\\tau$在当前controller下发生的概率，$D_{KL}$表示KL-divergence，用于衡量两个分布的“相似程度”，KL-divergence越小，两个分布越相似。<ul>\n<li>这个表示能够<strong>间接地限制controller和当前controller比较相似</strong>，因为$p(\\tau) = p(x_1)\\prod_{t=1}^{T-1} p(u_t \\vert x_t)f(x_{t+1} \\vert x_t, u_t)$，而对于新旧controller来说，$p(x_1)$以及$f(x_{t+1} \\vert x_t, u_t)$都是一样的，因此区别仅仅在于$p(u_t \\vert x_t)$。换句话说，$p(\\tau)$和$\\bar{p}(\\tau)$的区别仅仅在于controller，因此控制$p(\\tau)$和$\\bar{p}(\\tau)$的相似程度就可以间接地控制controller的相似程度。</li>\n</ul>\n</li>\n<li>new optimization problem<br>$$<br>\\begin{aligned}<br>\\mathop{\\text{min }}_{\\tau, p} &amp;\\mathbb{E}_\\tau[\\sum_{t=1}^T c(x_t, u_t)] \\\\<br>\\text{s.t. } &amp;D_{KL}(p(\\tau) \\Vert \\bar{p}(\\tau) ) \\leq \\epsilon \\\\<br>&amp;x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.<br>\\end{aligned}<br>$$</li>\n<li>进行约束条件下的<em>DGD</em>（这里我不太懂为什么可以对不等式约束做<em>DGD</em>，逻辑上来讲对于不等式约束，需要限定$\\lambda \\geq 0$才能保证$g(\\lambda)$是原问题的下界函数）：<ol>\n<li>仅将$D_{KL}$约束写进Lagrangian函数：<br>$$<br>\\begin{aligned}<br>\\mathcal{L}(\\tau, p, \\lambda) &amp;= \\mathbb{E}_\\tau[\\sum_{t=1}^T c(x_t, u_t)] + \\lambda (D_{KL}(p(\\tau) \\Vert \\bar{p}(\\tau) ) - \\epsilon) \\\\<br>&amp;// D_{KL}(p(\\tau) \\Vert \\bar{p}(\\tau) ) = \\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)} [- \\log \\bar{p}(u_t \\vert x_t) - \\mathcal{H}(p(u_t \\vert x_t))]  \\\\<br>&amp;= \\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)}[c(x_t, u_t) - \\lambda \\log \\bar{p}(u_t \\vert x_t) - \\lambda \\mathcal{H}(p(u_t \\vert x_t))] - \\lambda \\epsilon \\\\<br>&amp;//提\\lambda \\\\<br>&amp;= \\lambda \\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)}[\\frac{1}{\\lambda} c(x_t, u_t) - \\log \\bar{p}(u_t \\vert x_t) - \\mathcal{H}(p(u_t \\vert x_t))] - \\epsilon<br>\\end{aligned}<br>$$</li>\n<li>求解$\\begin{bmatrix} \\tau \\\\\\ p \\end{bmatrix}^*$：对应的优化问题为：<br>$$<br>\\begin{aligned}<br>\\mathop{\\text{min }}_{\\tau, p} &amp;\\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)}[\\frac{1}{\\lambda} c(x_t, u_t) - \\log \\bar{p}(u_t \\vert x_t) - \\mathcal{H}(p(u_t \\vert x_t))] \\\\<br>\\text{s.t. } &amp;x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.<br>\\end{aligned}<br>$$假如我们设$\\tilde{c}(x_t, u_t) = \\frac{1}{\\lambda} c(x_t, u_t) - \\log \\bar{p}(u_t \\vert x_t)$，则该优化问题为：<br>$$<br>\\begin{aligned}<br>\\mathop{\\text{min }}_{\\tau, p} &amp;\\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)}[\\tilde{c}(x_t, u_t) - \\mathcal{H}(p(u_t \\vert x_t))] \\\\<br>\\text{s.t. } &amp;x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.<br>\\end{aligned}<br>$$而<strong>这个形式的优化问题我们知道其最优解的形式是什么</strong>（回忆Using stochastic controller部分），因此我们能够用<em>iLQR</em>求解$\\begin{bmatrix} \\tau \\\\\\ p \\end{bmatrix}^*$。</li>\n<li>对$\\lambda$做单步gradient ascent，迭代。</li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Introduce-stochastic-policy\"><a href=\"#Introduce-stochastic-policy\" class=\"headerlink\" title=\"Introduce stochastic policy\"></a>Introduce stochastic policy</h2><ul>\n<li>statement<ul>\n<li><strong>这部分由于没有细看论文，所以有些地方我也不是很清楚，只是介绍我自己的理解，希望谅解：）</strong>。</li>\n</ul>\n</li>\n<li>motivation<ul>\n<li>我们想要得到的是一个parametric policy，因此采用跟deterministic policy case一样的思路，添加一个policy约束。</li>\n</ul>\n</li>\n<li>solution<ul>\n<li>optimization problem<br>$$<br>\\begin{aligned}<br>\\mathop{\\text{min }}_{\\tau, p} &amp;\\mathbb{E}_\\tau[\\sum_{t=1}^T c(x_t, u_t)] \\\\<br>\\text{s.t. } &amp;p(u_t \\vert x_t) = \\pi_\\theta(u_t \\vert x_t) \\quad t=1, \\dots, T \\\\<br>&amp;D_{KL}(p(\\tau) \\Vert \\bar{p}(\\tau) ) \\leq \\epsilon \\\\<br>&amp;x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.<br>\\end{aligned}<br>$$</li>\n<li>进行约束条件下的<em>DGD</em>：<ol>\n<li>仅将policy约束和$D_{KL}$约束写进Lagrangian函数：<br>$$<br>\\begin{aligned}<br>\\mathcal{L}(\\tau, p, \\theta, \\lambda, \\eta) &amp;= \\mathbb{E}_\\tau[\\sum_{t=1}^T c(x_t, u_t)] + \\sum_{t=1}^T \\lambda_t [p(u_t \\vert x_t) - \\pi_\\theta(u_t \\vert x_t)] + \\eta (D_{KL}(p(\\tau) \\Vert \\bar{p}(\\tau) ) - \\epsilon) \\\\<br>&amp;// \\sum_{t=1}^T \\lambda_t [p(u_t \\vert x_t) - \\pi_\\theta(u_t \\vert x_t)] \\overset{?}{\\approx} \\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)}[u_t^T\\lambda_t + \\rho_t D_{KL}(p(u_t \\vert x_t) \\Vert \\pi_\\theta(u_t \\vert x_t))]\\\\<br>&amp;\\approx \\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)}[c(x_t, u_t) + u_t^T\\lambda_t + \\rho_t D_{KL}(p(u_t \\vert x_t) \\Vert \\pi_\\theta(u_t \\vert x_t))] + \\eta (D_{KL}(p(\\tau) \\Vert \\bar{p}(\\tau) ) - \\epsilon) \\\\<br>&amp;// \\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)}[D_{KL}(p(u_t \\vert x_t) \\Vert \\pi_\\theta(u_t \\vert x_t))] = \\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)}[- \\log \\pi_\\theta(u_t \\vert x_t) - \\mathcal{H}(p(u_t \\vert x_t))] \\\\<br>&amp;// D_{KL}(p(\\tau) \\Vert \\bar{p}(\\tau) ) = \\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)} [- \\log \\bar{p}(u_t \\vert x_t) - \\mathcal{H}(p(u_t \\vert x_t))]  \\\\<br>&amp;= \\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)}[c(x_t, u_t) + u_t^T\\lambda_t - \\rho_t \\log\\pi_\\theta(u_t \\vert x_t) - \\eta \\log \\bar{p}(u_t \\vert x_t) - ( \\rho_t + \\eta) \\mathcal{H}(p(u_t \\vert x_t))] - \\eta \\epsilon<br>\\end{aligned}<br>$$</li>\n<li>求解$\\begin{bmatrix} \\tau \\\\\\ p \\end{bmatrix}^*$：对应的优化问题为：<br>$$<br>\\begin{aligned}<br>\\mathop{\\text{min }}_{\\tau, p} &amp;\\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)}[c(x_t, u_t) + u_t^T\\lambda_t - \\rho_t \\log\\pi_\\theta(u_t \\vert x_t) - \\eta \\log \\bar{p}(u_t \\vert x_t) - ( \\rho_t + \\eta) \\mathcal{H}(p(u_t \\vert x_t))] \\\\<br>\\text{s.t. } &amp;x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.<br>\\end{aligned}<br>$$设$\\tilde{c}(x_t, u_t) = c(x_t, u_t) + u_t^T\\lambda_t - \\rho_t \\log\\pi_\\theta(u_t \\vert x_t) - \\eta \\log \\bar{p}(u_t \\vert x_t)$，$\\nu_t = \\rho_t + \\eta$，则上述优化问题可以表示为：<br>$$<br>\\begin{aligned}<br>\\mathop{\\text{min }}_{\\tau, p} &amp;\\sum_{t=1}^T \\mathbb{E}_{p(x_t, u_t)}[\\tilde{c}(x_t, u_t) - \\nu_t \\mathcal{H}(p(u_t \\vert x_t))] \\\\<br>\\text{s.t. } &amp;x_t = f(x_{t-1}, u_{t-1}) \\quad t=1, \\dots, T.<br>\\end{aligned}<br>$$而<strong>这个形式的优化问题我们知道最优解</strong>（回忆Using stochastic controller和Constrain controller in trust region部分），因此得到$\\begin{bmatrix} \\tau \\\\\\ p \\end{bmatrix}^*$。</li>\n<li>求解$\\theta^*$：跟deterministic policy case一样，由于约束条件跟待优化变量无关，所以实际上是一个无约束优化问题，不过问题是这里并没有用直接用上面的Lagrangian函数，我猜测问题是出在上面我没搞懂的带问号的约等于号那里，也许上面只是为了求解方便做了近似，因此在求解$\\theta^*$时没有把Lagrangian函数展开到最后的形式，而是用了以下Lagrangian函数：<br>$$<br>\\begin{aligned}<br>\\mathcal{L}(\\tau, p, \\theta, \\lambda, \\eta) &amp;= \\mathbb{E}_\\tau[\\sum_{t=1}^T c(x_t, u_t)] + \\sum_{t=1}^T \\lambda_t [p(u_t \\vert x_t) - \\pi_\\theta(u_t \\vert x_t)] + \\eta (D_{KL}(p(\\tau) \\Vert \\bar{p}(\\tau) ) - \\epsilon) \\\\<br>&amp;// \\sum_{t=1}^T \\lambda_t [p(u_t \\vert x_t) - \\pi_\\theta(u_t \\vert x_t)] \\overset{?}{=} \\sum_{t=1}^T \\mathbb{E}_{p(x_t)}[\\mathbb{E}_{\\pi_\\theta(u_t \\vert x_t)}[u_t]^T\\lambda_t + \\rho_t D_{KL}(p(u_t \\vert x_t) \\Vert \\pi_\\theta(u_t \\vert x_t))]\\\\<br>&amp;= \\mathbb{E}_\\tau[\\sum_{t=1}^T c(x_t, u_t)] + \\sum_{t=1}^T \\mathbb{E}_{p(x_t)}[\\mathbb{E}_{\\pi_\\theta(u_t \\vert x_t)}[u_t]^T\\lambda_t + \\rho_t D_{KL}(p(u_t \\vert x_t) \\Vert \\pi_\\theta(u_t \\vert x_t))] \\\\<br>&amp;+ \\eta (D_{KL}(p(\\tau) \\Vert \\bar{p}(\\tau) ) - \\epsilon) \\\\<br>\\end{aligned}.<br>$$因此，对应的关于$\\theta$的无约束优化问题为：<br>$$<br>\\mathop{\\text{min }}_{\\theta}\\sum_{t=1}^T \\mathbb{E}_{p(x_t)}[\\mathbb{E}_{\\pi_\\theta(u_t \\vert x_t)}[u_t]^T\\lambda_t + \\rho_t D_{KL}(p(u_t \\vert x_t) \\Vert \\pi_\\theta(u_t \\vert x_t))].<br>$$应该可以使用诸如<em>SGD</em>等优化方法进行求解，于是我们得到$\\theta^*$</li>\n<li>对$\\begin{bmatrix} \\lambda \\\\\\ \\eta \\end{bmatrix}$做单步gradient ascent，迭代。</li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h1 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h1><p>至此已经介绍完<em>GPS</em>的流程，这个算法给我印象最深刻的地方就是<strong>化归</strong>的思想，即将新构建的问题转化为之前已经知道解决方法的问题，令人叹为观止。</p>\n<hr>\n<h1 id=\"References\"><a href=\"#References\" class=\"headerlink\" title=\"References\"></a>References</h1><ul>\n<li><a href=\"http://rll.berkeley.edu/deeprlcourse/\">CS294 Fall 2017 lecture 8-10</a></li>\n<li><a href=\"https://people.eecs.berkeley.edu/~pabbeel/cs287-fa15/slides/lecture20-guided-policy-search.pdf\">CS287 Guest Lecture Sergey Levine Slide</a></li>\n<li><a href=\"https://www.youtube.com/watch?v=CW1s6psByxk\">Sergey Levine UCB Talk</a></li>\n<li><a href=\"https://www.youtube.com/watch?v=EtMyH_--vnU&amp;feature=youtu.be\">Sergey Levine UW Talk</a></li>\n<li><a href=\"https://people.eecs.berkeley.edu/~svlevine/papers/mfcgps.pdf\">Learning neural network policies with guided policy search under unknown dynamics</a></li>\n<li><a href=\"http://www.jmlr.org/papers/volume17/15-522/15-522.pdf\">End-to-end training of deep visuomotor policies</a></li>\n</ul>\n"},{"title":"学习总结《强化学习与深度强化学习》","date":"2018-02-03T09:22:34.000Z","description":["关于强化学习与深度强化学习的一些理解与总结"],"_content":"\n## On-Policy vs. Off-Policy\n\n- motivation\n\t+ 假设我们想要一个deterministic的policy，那么按一般的思路，我们就应该用一个deterministic的policy去采样，根据采样结果得到q(s, a)，最后得到$\\pi (s) = \\text{argmax}_a q(s,a)$。\n\t+ 但由于这样的采样过程是greedy的，容易**采样不充分**，陷入局部最优。\n\t+ 因此就想能不能既evaluate一个deterministic的policy，又可以充分采样，由此引出Off-Policy。\n- idea（以sarsa和q-learning为例，阐述On-Policy与Off-Policy的区别）\n\t+ 无论是sarsa还是q-learning，我们真实采取的policy（i.e., 状态变换所依赖的behavior policy）都是对q(s, a)进行$\\epsilon \\text{-greedy}$。sarsa和q-learning的区别在于q(s, a)的含义不同。\n\t+ 假设t时刻到t+1时刻的state, action, reward如下表所示：\n\t$$\n\\begin{array}{c|cc}\n  & t & t+1 \\\\\\ \\hline\nR &   & r'  \\\\\\\nS & s & s'  \\\\\\\nA & a & a'\n\\end{array}\n\t$$当我们要更新q(s, a)时，sarsa与q-learning有相同的$s, a, r', s'$，但他们的$a'$并不相同，也正是$a'$的不同导致了不同的q(s, a)含义：\n\t\t- sarsa通过对q($s'$, $A$)进行$\\epsilon \\text{-greedy}$得到$a'$，因此sarsa的q(s, a)表示$\\epsilon \\text{-greedy}$下的q-value；\n\t\t- q-learning则通过$a'=\\text{argmax}_A q(s', A)$得到$a'$，因此q-learning的q(s, a)表示greedy（deterministic）下的q-value。  \n\t+ 也就是说，在sarsa中，q(s, a)表示的是behavior policy的q-value；而q-learning中，q(s, a)表示的是另外一个policy的q-value。前者这种q(s, a)与behavior policy一致的就称为On-Policy，后者这种不一致的就称为Off-Policy。即划分On-Policy与Off-Policy的依据是**q(s, a)对应的policy是不是behavior policy**。更准确来说，假设更新$Q^{\\pi}(s, a)$时，所用的样本$s, a \\sim \\pi '$，那么划分On-Policy与Off-Policy的依据是$\\pi '$是否为$\\pi$（因此experience replay基本都为Off-Policy，因为q(s, a)对应当前policy，而用到的sample来自experience replay，因此属于以前的policy）。\n- more\n\t+ 上面说的是Off-Policy与On-Policy两者概念上的区分，至于q-learning这种做法能不能保证q(s, a)收敛，q(s, a)收敛的值是不是我们想要的值，则是另外一个问题了。\n\t\n\n## Policy Gradient\n\n- motivation\n\t+ value based的方法难以处理**continuous action space**。因为即使得到了准确的q(s, a)，在给定一个状态s的情况下，仍然不知道该采取哪个action，因此一般的处理方法是discretization，\n\t\t- 但是discretization在某些action space中并不合适（e.g., 表示旋转的四元数），\n\t\t- 即使合适，discretization的程度也比较empirical。\n\t+ value based的方法难以处理**随机策略**（尽管可以根据q(s,a)来生成一个distribution（e.g., softmax distribution），但是并没有什么理论保证这种distribution是合理的）。\n\t+ 有些任务的policy比action value更容易approximate。\n- idea\n\t+ 大多数情况下，我们的目的都是得到policy，value function只是得到policy的一种手段。\n\t+ 实际上我们可以直接对policy建模并求解最优policy。设policy为$\\pi(a \\mid s ; \\boldsymbol\\theta)$（e.g., 高斯分布$a \\sim \\mathcal{N}(\\phi(s)^T \\boldsymbol\\theta, \\sigma ^2)$），则最优policy（i.e., $\\boldsymbol\\theta$）为以下优化问题的解：\n\t$$\n\t\\boldsymbol\\theta = \\mathop{\\text{argmax}}\\limits_{\\boldsymbol\\theta} v_{\\pi_{\\boldsymbol\\theta}}(s_0),\n\t$$此处我们假设每次的初始状态都为$s_0$。\n\t+ 假如知道$\\nabla v_{\\pi_{\\boldsymbol\\theta}}(s_0)$，那么我们就可以使用迭代的方法（e.g., SGD）去求解上述优化问题。\n\t+ 而Policy Gradient Theorem告诉我们\n\t$$\n\t\\nabla v_{\\pi_{\\boldsymbol\\theta}}(s_0)=\\mathbb{E}_{S_t, A_t \\sim \\pi}\\left[\\gamma ^t G_t \\frac{\\nabla _\\boldsymbol\\theta \\pi (A_t \\mid S_t, \\boldsymbol\\theta)}{\\pi(A_t \\mid S_t, \\boldsymbol\\theta)} \\right],\n\t$$因此我们可以通过sample来估计$\\nabla v_{\\pi_{\\boldsymbol\\theta}}(s_0)$从而求解优化问题，得到最优policy。\n- more\n\t+ [不同于Sutton's book的另一种policy gradient推导方式](https://danieltakeshi.github.io/2017/03/28/going-deeper-into-reinforcement-learning-fundamentals-of-policy-gradients/)：\n\t\t- 分析baseline对bias与variance的影响：\n\t\t\t+ 没有增加bias，且baseline越接近v(s)，variance越低；\n\t\t\t+ sample越independent，他的这种分析方法越准确。\n\t\t- 插句题外话，原来不止我一个人觉得rl的公式推导很随意，期望/求导之类的顺序想换就换：）。\n\t\t- 两种形式的policy gradient相差了一个求和符号，但其实是等价的，因为在sutton's book里面的policy gradient用的是discounted state distribution。\n\n## Actor-Critic\n\n- motivation\n\t+ Policy Gradient Theorem中的$G_t=q_{\\pi}(S_t, A_t)$，也就是说在式子中**$G_t$是真实的q(s,a)**，这就限制了Policy Gradient只能用Monte Carlo的方法来采样。\n\t+ 而Monte Carlo方法的variance是比较高的（因为多步取样），甚至在某些情况下Monte Carlo方法并不适用（e.g., non-terminating problem）。\n\t+ 所以要想办法处理$G_t$。\n- idea\n\t+ 一种直观的解决思路是求解一个近似的$G_t$，即找一个$v_{\\boldsymbol w} \\approx G_t$，然后用$v_{\\boldsymbol w}$带入Policy Gradient中的$G_t$。\n\t+ 这个$v_{\\boldsymbol w}$就是所谓的critic，而原来的policy就是所谓的actor。\n\n## High-dimensional Continuous Control Using Generalized Advantage Estimation\n\n- motivation\n\t+ **调控advantage estimation的bias与variance**。\n\t\t+ 由Policy Gradient中的讨论可知添加一个合适的baseline可以在不引入bias的情况下降低variance，而一般情况下都会采用v(s)作为baseline。此时，policy gradient中就带有一项q(s, a)-v(s)，我们将这项定义为advantage。\n\t\t+ 但是policy gradient中的advantage是真实的（但我们并不知道的）advantage，于是我们通过采样来对advantage进行估计，因此估计的质量直接影响Policy Gradient的效果。\n\t\t+ 但效果越逼近于真实值，往往意味着variance会很高，因为真实的return取决于多步决策，而每步决策都有随机因素，因此存在一个bias与variance的tradeoff。\n\t\t+ GAE则给出了如何通过一个参数$\\lambda$来调控这个tradeoff。\n- idea\n\t+ 然后作者将TD(lambda)的思想用到了这里，即加权平均n-step advantage（对advantage的不同估计），得到所谓的GAE（Generalized Advantage Estimation）。\n\t\t- $\\lambda = 1$时：等价于用真实return-v(s)，不引入bias，但variance高。\n\t\t- $\\lambda = 0$时：假如v(s)不等于真实的v(s)，则会引入bias，但variance低。\n- more\n\t+ discounted factor的另一种理解：即假设原来的目标是求undiscounted return，引入discounted factor是为了降低variance。\n\n## Asynchronous Methods for Deep Reinforcement Learning\n\n- motivation\n\t+ **消除sample之间的相关性**的另一种方法（前一种是replay buffer）。\n\t\t- 回顾我们的求解思路\n\t\t\t1. 我们首先得到要优化的目标，通常是个期望值；\n\t\t\t2. 然后基于采样得到的sample估计该目标值（依据是大数定理）；\n\t\t\t3. 接着假装这个估计的值为真的目标，对它进行优化。\n\t\t- 可以看到对目标值估计的准确与否直接决定了效果的好坏，而对目标值估计的准确与否取决于得到的sample是否满足大数定理的条件，即sample是否独立同分布（期望值对应的分布）。\n- idea\n\t+ 不同actor并行地在各自的trajectory中采样。参数更新的框架跟单线程的是一样的：\n\t\t- minibatch：用local的t来模拟（因为对minibatch的求导本来就是sum的形式，因此可以通过累加的形式来模拟）;\n\t\t- target update：用global的T来模拟。\n\n## Deterministic Policy Gradient\n\n- motivation\n\t+ Policy Gradient通过直接求解最优的stochastic policy解决continuous action space的问题，但在某些需要**deterministic policy**的场景下并不适用（e.g., 机器人控制）。\n- idea\n\t+ 仅看推导结果：\n\t\t- determinisitc policy gradient的方向大致为$q(s, \\pi (s))$增大的方向，即$\\mathbb{E}_{s \\sim \\pi}\\left[ \\nabla _ \\theta \\pi(s) \\nabla _a Q^{\\pi}(s, a) \\mid _{a=\\pi(s)} \\right] \\approx \\mathbb{E}_{s \\sim \\pi}\\left[ \\nabla _\\theta Q^{\\pi}(s, \\pi(s))  \\right]$（用约等于号是因为忽略了$\\nabla _\\theta Q^{\\pi}(s,a)$这一项）；\n\t\t- 而policy gradient的方向大致为$q(s, a)\\text{log} \\pi(s)$增大的方向，即$\\mathbb{E}_{s,a \\sim \\pi}\\left[ Q^{\\pi}(s, a) \\nabla _\\theta \\text{log} \\pi(s) \\right] \\approx \\mathbb{E}_{s,a \\sim \\pi}\\left[ \\nabla _\\theta Q^{\\pi}(s, a) \\text{log} \\pi (s) \\right]$（同样忽略了$\\nabla _\\theta Q^{\\pi}(s,a)$这一项）。\n- more\n\t+ 相比Policy Gradient，Determinisitc Policy Gradient还有一个好处就是sampe efficiency更高，毕竟gradient中少了关于action的期望（i.e., 仅仅是$\\mathbb{E}_{s}，而不是\\mathbb{E}_{s,a}$）。但这也会使得exploration不足，所以一般又会采用Off-Policy的方法弥补这个缺陷。\n\t+ 而Off-Policy Actor-Critic的目标居然是$\\mathbb{E}_{s \\sim \\beta}\\left[ V^{\\pi}(s) \\right]$（而不是$\\mathbb{E}_{s \\sim \\pi}\\left[ V^{\\pi}(s) \\right]$），即state的分布由behavior policy决定。我个人认为这个是一个无奈之下的折中做法，因为最理想的情况是$\\nabla _ \\theta \\mathbb{E}_{s \\sim \\pi}\\left[ V^{\\pi}(s) \\right] = \\mathbb{E}_{s, a \\sim \\beta} \\left[ \\sim \\right]$（即可以用behavior policy采取的样本去估计真实的performance的gradient），但这样做的话，最后要显式给出不好求的state分布概率$\\rho ^{\\beta}(s)$，于是退而求其次，换了个好求的目标函数。\n\n## Deep Deterministic Policy Gradient\n\n- motivation\n\t+ 在DPG的基础上引入deep learning，使critic和actor的**表达能力更强**。\n- idea（借鉴DQN）\n\t+ replay buffer：打破数据之间的相关性。值得注意的是，我们原来的目标是要最大化期望，而我们是通过采样来近似这个期望的。仅当我们的采样点是相互独立的，才能更好地近似期望值。于是使用一个replay buffer来把(s, a, r, s')存起来，到更新参数的时候再从中抽取mini batch，这样就可以获得相关性较弱的数据。\n\t+ target network：保证ground truth的一致性。critic实际上是supervised learning，即用一个神经网络去做回归。如果相同的输入对应不同的输出，则无法收敛。于是就将生成ground truth所依赖的$Q(s, a)$和$\\mu(s)$都做了一个备份，来保证相同的输入有相同的输出，从而保证critic能够收敛。得到critic后，actor就跟DPG一样，朝着使得critic增大的方向更新参数就好了。\n\t\t- 这里有个地方比较confusing，因为在DPG中，critic的含义是在当前actor下的return估计（i.e., $V^{\\pi}$）；而使用了target network后，critic的含义更像是在target actor下的return估计（i.e., $V^{\\pi '}$）。那在这种情况下，actor还应该朝着critic增大的方向更新参数吗？我的理解是$\\pi '$是逐步逼近$\\pi$的，所以两者比较相似，差别不大。\n- more\n\t+ DDPG和DPG在本质上的区别是换了一个能力更加强的critic。\n\n## Trust Region Policy Optimization\n\n- motivation\n\t+ policy gradient通过求解performance的gradient，然后使用gradient ascent的方法来提高performance。但\n\t**gradient ascent对step size很敏感**，太小的step size会导致效果提升很慢，太大的step size又不能保证效果的提升。\n\t+ 于是就想能否不用gradient ascent，转而用别的方法来提高performance。\n- idea\n\t+ 通过一系列的定理，找到了新旧policy对应的performance之差的下界\n\t$$\n\t\\eta(\\pi_{\\theta _{\\text{new}}}) - \\eta(\\pi_{\\theta _{\\text{old}}}) \\geq f(\\theta _{\\text{new}}).\n\t$$\n\t+ 通过**最大化下界**来间接提高$\\eta(\\pi_{\\theta _{\\text{new}}})$（这里有个疑惑就是怎么保证rhs>0的？）。\n- detail\n\t+ 本来是一个无约束优化问题，但是求解该无约束优化问题得到的$\\theta _{\\text{new}} - \\theta _{\\text{old}}$很小（这应该是一个经验性的结果，但也很合理，因为目标函数里面有一项负的KL divergence，如果step size大了，该项会很小。但我有个疑问是step size小又有什么问题呢？）。于是把无约束优化问题转换成有约束优化问题。\n\t+ 最后得到的优化问题的目标函数和约束条件都是期望，需要通过采样来进行估计。\n\t+ 为了提高求解优化问题的效率，分别对目标函数和约束条件进行一阶近似和二阶近似，得到一个凸优化问题，因此是一个强对偶问题。于是可以通过求解对偶问题来求解原问题。\n\t\t- 思路是求解对偶问题，但并不完全按照求解对偶问题的过程进行（我觉得是按照标准流程不好解，因为涉及到求解$x^T A x = b$）。\n\t\t- 通过对$\\theta _{\\text{new}}$求导等于$0$得到$\\theta _{\\text{new}}-\\theta _{\\text{old}} = \\frac{1}{\\lambda}F^{-1}g$，其中$F$为KL divergence在$\\theta _{\\text{old}}$的Hessian matrix，$g$为目标函数在$\\theta _{\\text{old}}$的一阶导数，至此知道了$\\theta _{\\text{new}} - \\theta _{\\text{old}}$的方向。\n\t\t- 通过对$\\lambda$求导等于$0$，可得$(\\theta _{\\text{new}}-\\theta _{\\text{old}})^T F (\\theta _{\\text{new}}-\\theta _{\\text{old}})=\\delta$，但这并不好求。回想上一步我们已经知道$\\theta _{\\text{new}} - \\theta _{\\text{old}}$的方向，于是直接在保证满足约束条件下做line search，这也就是scaling步所做的事情。\n\t+ 可以看到整个求解过程最核心的是求解$x=F^{-1}g$，又$F$是一个对称正定矩阵，可以用conjugate gradient来求解该线性方程。而conjugate gradient并不需要显式地使用$F$，仅需要$F$与某个向量$p$的乘积$Fp$。幸运的是，真的有一些方法能够在不使用$F$的情况下求解出$Fp$（仅需要求一阶导，而一阶导又有auto-differentiation工具可用）。所以我们能够在不用显式求出$F$的情况下求解$x=F^{-1}g$。\n- references\n\t+ [TRPO推导过程](http://www.cs.toronto.edu/~tingwuwang/trpo.pdf)\n\t+ [TRPO期望形式到采样形式](https://people.eecs.berkeley.edu/~pabbeel/nips-tutorial-policy-optimization-Schulman-Abbeel.pdf)\n\t+ [practical TRPO（一阶近似目标函数、二阶近似约束条件、Lagrangian求解约束优化问题）](http://rll.berkeley.edu/deeprlcourse/docs/lec5.pdf)\n\t+ [KL divergence简介](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained)\n\t+ [Fisher Information Matrix与KL divergence Hessian的关系](https://math.stackexchange.com/questions/2239040/show-that-fisher-information-matrix-is-the-second-order-gradient-of-kl-divergenc)\n\t+ [Hessian Free Optimization](http://andrew.gibiansky.com/blog/machine-learning/hessian-free-optimization/)\n\t+ [Directional derivative](http://tutorial.math.lamar.edu/Classes/CalcIII/DirectionalDeriv.aspx)\n\t+ [Hessian Free Optimization实例](https://roosephu.github.io/2016/11/19/TRPO/)\n\n## Proximal Policy Optimization Algorithms\n\n- motivation\n\t+ **进化版的TRPO**\n\t\t- 实现更加简单；\n\t\t- 适用于更多网络结构（parameter sharing between critic and actor）。\n- idea\n\t+ TRPO约束条件的含义是在状态s下，新旧两个policy不要相差太远（以KL divergence为度量）。实际上就是担心为了提高$\\frac{\\pi _{\\theta _\\text{new}}(a  \\mid s )}{\\pi _{\\theta _\\text{old}}(a  \\mid s )}\\hat{A}(s,a)$而大幅度改变$\\theta _{\\text{new}}$。具体来说就是当$\\hat{A}(s, a)>0$时，通过大幅提高$\\pi _{\\theta _\\text{new}}(a \\mid s)$来提高目标值；反之，当$\\hat{A}(s, a)<0$时，通过减小$\\pi _{\\theta _\\text{new}}(a \\mid s)$来提高目标值。\n\t+ PPO就是通过取minimize以及clip的方法**改变了目标值的函数图像**，使得大的step size也无法提高目标值，从而间接限制了step size，进而将约束问题转化为无约束优化问题。\n\n<div style=\"width:800px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img ppo_objective.png PPO目标函数图像 %}\n</div>\n\n- more\n\t+ 关于新的目标函数的求导：\n\t\t- 写成根据A>0还是A<0分类讨论的形式；\n\t\t- 直接用auto-differentiation工具。\n\t+ 处理parameter sharing：总的objective中增加value function的objective（i.e., value function的回归），变成多目标优化问题。\n\t+ entropy bonus：鼓励exploration。\n\n\n","source":"_posts/summary-rl-drl.md","raw":"---\ntitle: 学习总结《强化学习与深度强化学习》\ndate: 2018-02-03 17:22:34\ncategories:\n  - 学习总结\ntags:\n  - 强化学习\n  - 深度强化学习\n  - GAE\n  - A3C\n  - DPG\n  - DDPG\n  - TRPO\n  - PPO\ndescription:\n  - 关于强化学习与深度强化学习的一些理解与总结\n---\n\n## On-Policy vs. Off-Policy\n\n- motivation\n\t+ 假设我们想要一个deterministic的policy，那么按一般的思路，我们就应该用一个deterministic的policy去采样，根据采样结果得到q(s, a)，最后得到$\\pi (s) = \\text{argmax}_a q(s,a)$。\n\t+ 但由于这样的采样过程是greedy的，容易**采样不充分**，陷入局部最优。\n\t+ 因此就想能不能既evaluate一个deterministic的policy，又可以充分采样，由此引出Off-Policy。\n- idea（以sarsa和q-learning为例，阐述On-Policy与Off-Policy的区别）\n\t+ 无论是sarsa还是q-learning，我们真实采取的policy（i.e., 状态变换所依赖的behavior policy）都是对q(s, a)进行$\\epsilon \\text{-greedy}$。sarsa和q-learning的区别在于q(s, a)的含义不同。\n\t+ 假设t时刻到t+1时刻的state, action, reward如下表所示：\n\t$$\n\\begin{array}{c|cc}\n  & t & t+1 \\\\\\ \\hline\nR &   & r'  \\\\\\\nS & s & s'  \\\\\\\nA & a & a'\n\\end{array}\n\t$$当我们要更新q(s, a)时，sarsa与q-learning有相同的$s, a, r', s'$，但他们的$a'$并不相同，也正是$a'$的不同导致了不同的q(s, a)含义：\n\t\t- sarsa通过对q($s'$, $A$)进行$\\epsilon \\text{-greedy}$得到$a'$，因此sarsa的q(s, a)表示$\\epsilon \\text{-greedy}$下的q-value；\n\t\t- q-learning则通过$a'=\\text{argmax}_A q(s', A)$得到$a'$，因此q-learning的q(s, a)表示greedy（deterministic）下的q-value。  \n\t+ 也就是说，在sarsa中，q(s, a)表示的是behavior policy的q-value；而q-learning中，q(s, a)表示的是另外一个policy的q-value。前者这种q(s, a)与behavior policy一致的就称为On-Policy，后者这种不一致的就称为Off-Policy。即划分On-Policy与Off-Policy的依据是**q(s, a)对应的policy是不是behavior policy**。更准确来说，假设更新$Q^{\\pi}(s, a)$时，所用的样本$s, a \\sim \\pi '$，那么划分On-Policy与Off-Policy的依据是$\\pi '$是否为$\\pi$（因此experience replay基本都为Off-Policy，因为q(s, a)对应当前policy，而用到的sample来自experience replay，因此属于以前的policy）。\n- more\n\t+ 上面说的是Off-Policy与On-Policy两者概念上的区分，至于q-learning这种做法能不能保证q(s, a)收敛，q(s, a)收敛的值是不是我们想要的值，则是另外一个问题了。\n\t\n\n## Policy Gradient\n\n- motivation\n\t+ value based的方法难以处理**continuous action space**。因为即使得到了准确的q(s, a)，在给定一个状态s的情况下，仍然不知道该采取哪个action，因此一般的处理方法是discretization，\n\t\t- 但是discretization在某些action space中并不合适（e.g., 表示旋转的四元数），\n\t\t- 即使合适，discretization的程度也比较empirical。\n\t+ value based的方法难以处理**随机策略**（尽管可以根据q(s,a)来生成一个distribution（e.g., softmax distribution），但是并没有什么理论保证这种distribution是合理的）。\n\t+ 有些任务的policy比action value更容易approximate。\n- idea\n\t+ 大多数情况下，我们的目的都是得到policy，value function只是得到policy的一种手段。\n\t+ 实际上我们可以直接对policy建模并求解最优policy。设policy为$\\pi(a \\mid s ; \\boldsymbol\\theta)$（e.g., 高斯分布$a \\sim \\mathcal{N}(\\phi(s)^T \\boldsymbol\\theta, \\sigma ^2)$），则最优policy（i.e., $\\boldsymbol\\theta$）为以下优化问题的解：\n\t$$\n\t\\boldsymbol\\theta = \\mathop{\\text{argmax}}\\limits_{\\boldsymbol\\theta} v_{\\pi_{\\boldsymbol\\theta}}(s_0),\n\t$$此处我们假设每次的初始状态都为$s_0$。\n\t+ 假如知道$\\nabla v_{\\pi_{\\boldsymbol\\theta}}(s_0)$，那么我们就可以使用迭代的方法（e.g., SGD）去求解上述优化问题。\n\t+ 而Policy Gradient Theorem告诉我们\n\t$$\n\t\\nabla v_{\\pi_{\\boldsymbol\\theta}}(s_0)=\\mathbb{E}_{S_t, A_t \\sim \\pi}\\left[\\gamma ^t G_t \\frac{\\nabla _\\boldsymbol\\theta \\pi (A_t \\mid S_t, \\boldsymbol\\theta)}{\\pi(A_t \\mid S_t, \\boldsymbol\\theta)} \\right],\n\t$$因此我们可以通过sample来估计$\\nabla v_{\\pi_{\\boldsymbol\\theta}}(s_0)$从而求解优化问题，得到最优policy。\n- more\n\t+ [不同于Sutton's book的另一种policy gradient推导方式](https://danieltakeshi.github.io/2017/03/28/going-deeper-into-reinforcement-learning-fundamentals-of-policy-gradients/)：\n\t\t- 分析baseline对bias与variance的影响：\n\t\t\t+ 没有增加bias，且baseline越接近v(s)，variance越低；\n\t\t\t+ sample越independent，他的这种分析方法越准确。\n\t\t- 插句题外话，原来不止我一个人觉得rl的公式推导很随意，期望/求导之类的顺序想换就换：）。\n\t\t- 两种形式的policy gradient相差了一个求和符号，但其实是等价的，因为在sutton's book里面的policy gradient用的是discounted state distribution。\n\n## Actor-Critic\n\n- motivation\n\t+ Policy Gradient Theorem中的$G_t=q_{\\pi}(S_t, A_t)$，也就是说在式子中**$G_t$是真实的q(s,a)**，这就限制了Policy Gradient只能用Monte Carlo的方法来采样。\n\t+ 而Monte Carlo方法的variance是比较高的（因为多步取样），甚至在某些情况下Monte Carlo方法并不适用（e.g., non-terminating problem）。\n\t+ 所以要想办法处理$G_t$。\n- idea\n\t+ 一种直观的解决思路是求解一个近似的$G_t$，即找一个$v_{\\boldsymbol w} \\approx G_t$，然后用$v_{\\boldsymbol w}$带入Policy Gradient中的$G_t$。\n\t+ 这个$v_{\\boldsymbol w}$就是所谓的critic，而原来的policy就是所谓的actor。\n\n## High-dimensional Continuous Control Using Generalized Advantage Estimation\n\n- motivation\n\t+ **调控advantage estimation的bias与variance**。\n\t\t+ 由Policy Gradient中的讨论可知添加一个合适的baseline可以在不引入bias的情况下降低variance，而一般情况下都会采用v(s)作为baseline。此时，policy gradient中就带有一项q(s, a)-v(s)，我们将这项定义为advantage。\n\t\t+ 但是policy gradient中的advantage是真实的（但我们并不知道的）advantage，于是我们通过采样来对advantage进行估计，因此估计的质量直接影响Policy Gradient的效果。\n\t\t+ 但效果越逼近于真实值，往往意味着variance会很高，因为真实的return取决于多步决策，而每步决策都有随机因素，因此存在一个bias与variance的tradeoff。\n\t\t+ GAE则给出了如何通过一个参数$\\lambda$来调控这个tradeoff。\n- idea\n\t+ 然后作者将TD(lambda)的思想用到了这里，即加权平均n-step advantage（对advantage的不同估计），得到所谓的GAE（Generalized Advantage Estimation）。\n\t\t- $\\lambda = 1$时：等价于用真实return-v(s)，不引入bias，但variance高。\n\t\t- $\\lambda = 0$时：假如v(s)不等于真实的v(s)，则会引入bias，但variance低。\n- more\n\t+ discounted factor的另一种理解：即假设原来的目标是求undiscounted return，引入discounted factor是为了降低variance。\n\n## Asynchronous Methods for Deep Reinforcement Learning\n\n- motivation\n\t+ **消除sample之间的相关性**的另一种方法（前一种是replay buffer）。\n\t\t- 回顾我们的求解思路\n\t\t\t1. 我们首先得到要优化的目标，通常是个期望值；\n\t\t\t2. 然后基于采样得到的sample估计该目标值（依据是大数定理）；\n\t\t\t3. 接着假装这个估计的值为真的目标，对它进行优化。\n\t\t- 可以看到对目标值估计的准确与否直接决定了效果的好坏，而对目标值估计的准确与否取决于得到的sample是否满足大数定理的条件，即sample是否独立同分布（期望值对应的分布）。\n- idea\n\t+ 不同actor并行地在各自的trajectory中采样。参数更新的框架跟单线程的是一样的：\n\t\t- minibatch：用local的t来模拟（因为对minibatch的求导本来就是sum的形式，因此可以通过累加的形式来模拟）;\n\t\t- target update：用global的T来模拟。\n\n## Deterministic Policy Gradient\n\n- motivation\n\t+ Policy Gradient通过直接求解最优的stochastic policy解决continuous action space的问题，但在某些需要**deterministic policy**的场景下并不适用（e.g., 机器人控制）。\n- idea\n\t+ 仅看推导结果：\n\t\t- determinisitc policy gradient的方向大致为$q(s, \\pi (s))$增大的方向，即$\\mathbb{E}_{s \\sim \\pi}\\left[ \\nabla _ \\theta \\pi(s) \\nabla _a Q^{\\pi}(s, a) \\mid _{a=\\pi(s)} \\right] \\approx \\mathbb{E}_{s \\sim \\pi}\\left[ \\nabla _\\theta Q^{\\pi}(s, \\pi(s))  \\right]$（用约等于号是因为忽略了$\\nabla _\\theta Q^{\\pi}(s,a)$这一项）；\n\t\t- 而policy gradient的方向大致为$q(s, a)\\text{log} \\pi(s)$增大的方向，即$\\mathbb{E}_{s,a \\sim \\pi}\\left[ Q^{\\pi}(s, a) \\nabla _\\theta \\text{log} \\pi(s) \\right] \\approx \\mathbb{E}_{s,a \\sim \\pi}\\left[ \\nabla _\\theta Q^{\\pi}(s, a) \\text{log} \\pi (s) \\right]$（同样忽略了$\\nabla _\\theta Q^{\\pi}(s,a)$这一项）。\n- more\n\t+ 相比Policy Gradient，Determinisitc Policy Gradient还有一个好处就是sampe efficiency更高，毕竟gradient中少了关于action的期望（i.e., 仅仅是$\\mathbb{E}_{s}，而不是\\mathbb{E}_{s,a}$）。但这也会使得exploration不足，所以一般又会采用Off-Policy的方法弥补这个缺陷。\n\t+ 而Off-Policy Actor-Critic的目标居然是$\\mathbb{E}_{s \\sim \\beta}\\left[ V^{\\pi}(s) \\right]$（而不是$\\mathbb{E}_{s \\sim \\pi}\\left[ V^{\\pi}(s) \\right]$），即state的分布由behavior policy决定。我个人认为这个是一个无奈之下的折中做法，因为最理想的情况是$\\nabla _ \\theta \\mathbb{E}_{s \\sim \\pi}\\left[ V^{\\pi}(s) \\right] = \\mathbb{E}_{s, a \\sim \\beta} \\left[ \\sim \\right]$（即可以用behavior policy采取的样本去估计真实的performance的gradient），但这样做的话，最后要显式给出不好求的state分布概率$\\rho ^{\\beta}(s)$，于是退而求其次，换了个好求的目标函数。\n\n## Deep Deterministic Policy Gradient\n\n- motivation\n\t+ 在DPG的基础上引入deep learning，使critic和actor的**表达能力更强**。\n- idea（借鉴DQN）\n\t+ replay buffer：打破数据之间的相关性。值得注意的是，我们原来的目标是要最大化期望，而我们是通过采样来近似这个期望的。仅当我们的采样点是相互独立的，才能更好地近似期望值。于是使用一个replay buffer来把(s, a, r, s')存起来，到更新参数的时候再从中抽取mini batch，这样就可以获得相关性较弱的数据。\n\t+ target network：保证ground truth的一致性。critic实际上是supervised learning，即用一个神经网络去做回归。如果相同的输入对应不同的输出，则无法收敛。于是就将生成ground truth所依赖的$Q(s, a)$和$\\mu(s)$都做了一个备份，来保证相同的输入有相同的输出，从而保证critic能够收敛。得到critic后，actor就跟DPG一样，朝着使得critic增大的方向更新参数就好了。\n\t\t- 这里有个地方比较confusing，因为在DPG中，critic的含义是在当前actor下的return估计（i.e., $V^{\\pi}$）；而使用了target network后，critic的含义更像是在target actor下的return估计（i.e., $V^{\\pi '}$）。那在这种情况下，actor还应该朝着critic增大的方向更新参数吗？我的理解是$\\pi '$是逐步逼近$\\pi$的，所以两者比较相似，差别不大。\n- more\n\t+ DDPG和DPG在本质上的区别是换了一个能力更加强的critic。\n\n## Trust Region Policy Optimization\n\n- motivation\n\t+ policy gradient通过求解performance的gradient，然后使用gradient ascent的方法来提高performance。但\n\t**gradient ascent对step size很敏感**，太小的step size会导致效果提升很慢，太大的step size又不能保证效果的提升。\n\t+ 于是就想能否不用gradient ascent，转而用别的方法来提高performance。\n- idea\n\t+ 通过一系列的定理，找到了新旧policy对应的performance之差的下界\n\t$$\n\t\\eta(\\pi_{\\theta _{\\text{new}}}) - \\eta(\\pi_{\\theta _{\\text{old}}}) \\geq f(\\theta _{\\text{new}}).\n\t$$\n\t+ 通过**最大化下界**来间接提高$\\eta(\\pi_{\\theta _{\\text{new}}})$（这里有个疑惑就是怎么保证rhs>0的？）。\n- detail\n\t+ 本来是一个无约束优化问题，但是求解该无约束优化问题得到的$\\theta _{\\text{new}} - \\theta _{\\text{old}}$很小（这应该是一个经验性的结果，但也很合理，因为目标函数里面有一项负的KL divergence，如果step size大了，该项会很小。但我有个疑问是step size小又有什么问题呢？）。于是把无约束优化问题转换成有约束优化问题。\n\t+ 最后得到的优化问题的目标函数和约束条件都是期望，需要通过采样来进行估计。\n\t+ 为了提高求解优化问题的效率，分别对目标函数和约束条件进行一阶近似和二阶近似，得到一个凸优化问题，因此是一个强对偶问题。于是可以通过求解对偶问题来求解原问题。\n\t\t- 思路是求解对偶问题，但并不完全按照求解对偶问题的过程进行（我觉得是按照标准流程不好解，因为涉及到求解$x^T A x = b$）。\n\t\t- 通过对$\\theta _{\\text{new}}$求导等于$0$得到$\\theta _{\\text{new}}-\\theta _{\\text{old}} = \\frac{1}{\\lambda}F^{-1}g$，其中$F$为KL divergence在$\\theta _{\\text{old}}$的Hessian matrix，$g$为目标函数在$\\theta _{\\text{old}}$的一阶导数，至此知道了$\\theta _{\\text{new}} - \\theta _{\\text{old}}$的方向。\n\t\t- 通过对$\\lambda$求导等于$0$，可得$(\\theta _{\\text{new}}-\\theta _{\\text{old}})^T F (\\theta _{\\text{new}}-\\theta _{\\text{old}})=\\delta$，但这并不好求。回想上一步我们已经知道$\\theta _{\\text{new}} - \\theta _{\\text{old}}$的方向，于是直接在保证满足约束条件下做line search，这也就是scaling步所做的事情。\n\t+ 可以看到整个求解过程最核心的是求解$x=F^{-1}g$，又$F$是一个对称正定矩阵，可以用conjugate gradient来求解该线性方程。而conjugate gradient并不需要显式地使用$F$，仅需要$F$与某个向量$p$的乘积$Fp$。幸运的是，真的有一些方法能够在不使用$F$的情况下求解出$Fp$（仅需要求一阶导，而一阶导又有auto-differentiation工具可用）。所以我们能够在不用显式求出$F$的情况下求解$x=F^{-1}g$。\n- references\n\t+ [TRPO推导过程](http://www.cs.toronto.edu/~tingwuwang/trpo.pdf)\n\t+ [TRPO期望形式到采样形式](https://people.eecs.berkeley.edu/~pabbeel/nips-tutorial-policy-optimization-Schulman-Abbeel.pdf)\n\t+ [practical TRPO（一阶近似目标函数、二阶近似约束条件、Lagrangian求解约束优化问题）](http://rll.berkeley.edu/deeprlcourse/docs/lec5.pdf)\n\t+ [KL divergence简介](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained)\n\t+ [Fisher Information Matrix与KL divergence Hessian的关系](https://math.stackexchange.com/questions/2239040/show-that-fisher-information-matrix-is-the-second-order-gradient-of-kl-divergenc)\n\t+ [Hessian Free Optimization](http://andrew.gibiansky.com/blog/machine-learning/hessian-free-optimization/)\n\t+ [Directional derivative](http://tutorial.math.lamar.edu/Classes/CalcIII/DirectionalDeriv.aspx)\n\t+ [Hessian Free Optimization实例](https://roosephu.github.io/2016/11/19/TRPO/)\n\n## Proximal Policy Optimization Algorithms\n\n- motivation\n\t+ **进化版的TRPO**\n\t\t- 实现更加简单；\n\t\t- 适用于更多网络结构（parameter sharing between critic and actor）。\n- idea\n\t+ TRPO约束条件的含义是在状态s下，新旧两个policy不要相差太远（以KL divergence为度量）。实际上就是担心为了提高$\\frac{\\pi _{\\theta _\\text{new}}(a  \\mid s )}{\\pi _{\\theta _\\text{old}}(a  \\mid s )}\\hat{A}(s,a)$而大幅度改变$\\theta _{\\text{new}}$。具体来说就是当$\\hat{A}(s, a)>0$时，通过大幅提高$\\pi _{\\theta _\\text{new}}(a \\mid s)$来提高目标值；反之，当$\\hat{A}(s, a)<0$时，通过减小$\\pi _{\\theta _\\text{new}}(a \\mid s)$来提高目标值。\n\t+ PPO就是通过取minimize以及clip的方法**改变了目标值的函数图像**，使得大的step size也无法提高目标值，从而间接限制了step size，进而将约束问题转化为无约束优化问题。\n\n<div style=\"width:800px; margin-left:auto; margin-right:auto;\" >\n  {% asset_img ppo_objective.png PPO目标函数图像 %}\n</div>\n\n- more\n\t+ 关于新的目标函数的求导：\n\t\t- 写成根据A>0还是A<0分类讨论的形式；\n\t\t- 直接用auto-differentiation工具。\n\t+ 处理parameter sharing：总的objective中增加value function的objective（i.e., value function的回归），变成多目标优化问题。\n\t+ entropy bonus：鼓励exploration。\n\n\n","slug":"summary-rl-drl","published":1,"updated":"2024-08-13T16:03:47.884Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clzvf192k001xeqwom1gfasnd","content":"<h2 id=\"On-Policy-vs-Off-Policy\"><a href=\"#On-Policy-vs-Off-Policy\" class=\"headerlink\" title=\"On-Policy vs. Off-Policy\"></a>On-Policy vs. Off-Policy</h2><ul>\n<li>motivation<ul>\n<li>假设我们想要一个deterministic的policy，那么按一般的思路，我们就应该用一个deterministic的policy去采样，根据采样结果得到q(s, a)，最后得到$\\pi (s) = \\text{argmax}_a q(s,a)$。</li>\n<li>但由于这样的采样过程是greedy的，容易<strong>采样不充分</strong>，陷入局部最优。</li>\n<li>因此就想能不能既evaluate一个deterministic的policy，又可以充分采样，由此引出Off-Policy。</li>\n</ul>\n</li>\n<li>idea（以sarsa和q-learning为例，阐述On-Policy与Off-Policy的区别）<ul>\n<li>无论是sarsa还是q-learning，我们真实采取的policy（i.e., 状态变换所依赖的behavior policy）都是对q(s, a)进行$\\epsilon \\text{-greedy}$。sarsa和q-learning的区别在于q(s, a)的含义不同。</li>\n<li>假设t时刻到t+1时刻的state, action, reward如下表所示：<br>$$<br>\\begin{array}{c|cc}<br>&amp; t &amp; t+1 \\\\ \\hline<br>R &amp;   &amp; r’  \\\\\\<br>S &amp; s &amp; s’  \\\\\\<br>A &amp; a &amp; a’<br>\\end{array}<br>$$当我们要更新q(s, a)时，sarsa与q-learning有相同的$s, a, r’, s’$，但他们的$a’$并不相同，也正是$a’$的不同导致了不同的q(s, a)含义：<ul>\n<li>sarsa通过对q($s’$, $A$)进行$\\epsilon \\text{-greedy}$得到$a’$，因此sarsa的q(s, a)表示$\\epsilon \\text{-greedy}$下的q-value；</li>\n<li>q-learning则通过$a’=\\text{argmax}_A q(s’, A)$得到$a’$，因此q-learning的q(s, a)表示greedy（deterministic）下的q-value。  </li>\n</ul>\n</li>\n<li>也就是说，在sarsa中，q(s, a)表示的是behavior policy的q-value；而q-learning中，q(s, a)表示的是另外一个policy的q-value。前者这种q(s, a)与behavior policy一致的就称为On-Policy，后者这种不一致的就称为Off-Policy。即划分On-Policy与Off-Policy的依据是<strong>q(s, a)对应的policy是不是behavior policy</strong>。更准确来说，假设更新$Q^{\\pi}(s, a)$时，所用的样本$s, a \\sim \\pi ‘$，那么划分On-Policy与Off-Policy的依据是$\\pi ‘$是否为$\\pi$（因此experience replay基本都为Off-Policy，因为q(s, a)对应当前policy，而用到的sample来自experience replay，因此属于以前的policy）。</li>\n</ul>\n</li>\n<li>more<ul>\n<li>上面说的是Off-Policy与On-Policy两者概念上的区分，至于q-learning这种做法能不能保证q(s, a)收敛，q(s, a)收敛的值是不是我们想要的值，则是另外一个问题了。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Policy-Gradient\"><a href=\"#Policy-Gradient\" class=\"headerlink\" title=\"Policy Gradient\"></a>Policy Gradient</h2><ul>\n<li>motivation<ul>\n<li>value based的方法难以处理<strong>continuous action space</strong>。因为即使得到了准确的q(s, a)，在给定一个状态s的情况下，仍然不知道该采取哪个action，因此一般的处理方法是discretization，<ul>\n<li>但是discretization在某些action space中并不合适（e.g., 表示旋转的四元数），</li>\n<li>即使合适，discretization的程度也比较empirical。</li>\n</ul>\n</li>\n<li>value based的方法难以处理<strong>随机策略</strong>（尽管可以根据q(s,a)来生成一个distribution（e.g., softmax distribution），但是并没有什么理论保证这种distribution是合理的）。</li>\n<li>有些任务的policy比action value更容易approximate。</li>\n</ul>\n</li>\n<li>idea<ul>\n<li>大多数情况下，我们的目的都是得到policy，value function只是得到policy的一种手段。</li>\n<li>实际上我们可以直接对policy建模并求解最优policy。设policy为$\\pi(a \\mid s ; \\boldsymbol\\theta)$（e.g., 高斯分布$a \\sim \\mathcal{N}(\\phi(s)^T \\boldsymbol\\theta, \\sigma ^2)$），则最优policy（i.e., $\\boldsymbol\\theta$）为以下优化问题的解：<br>$$<br>\\boldsymbol\\theta = \\mathop{\\text{argmax}}\\limits_{\\boldsymbol\\theta} v_{\\pi_{\\boldsymbol\\theta}}(s_0),<br>$$此处我们假设每次的初始状态都为$s_0$。</li>\n<li>假如知道$\\nabla v_{\\pi_{\\boldsymbol\\theta}}(s_0)$，那么我们就可以使用迭代的方法（e.g., SGD）去求解上述优化问题。</li>\n<li>而Policy Gradient Theorem告诉我们<br>$$<br>\\nabla v_{\\pi_{\\boldsymbol\\theta}}(s_0)=\\mathbb{E}_{S_t, A_t \\sim \\pi}\\left[\\gamma ^t G_t \\frac{\\nabla _\\boldsymbol\\theta \\pi (A_t \\mid S_t, \\boldsymbol\\theta)}{\\pi(A_t \\mid S_t, \\boldsymbol\\theta)} \\right],<br>$$因此我们可以通过sample来估计$\\nabla v_{\\pi_{\\boldsymbol\\theta}}(s_0)$从而求解优化问题，得到最优policy。</li>\n</ul>\n</li>\n<li>more<ul>\n<li><a href=\"https://danieltakeshi.github.io/2017/03/28/going-deeper-into-reinforcement-learning-fundamentals-of-policy-gradients/\" target=\"_blank\" rel=\"external\">不同于Sutton’s book的另一种policy gradient推导方式</a>：<ul>\n<li>分析baseline对bias与variance的影响：<ul>\n<li>没有增加bias，且baseline越接近v(s)，variance越低；</li>\n<li>sample越independent，他的这种分析方法越准确。</li>\n</ul>\n</li>\n<li>插句题外话，原来不止我一个人觉得rl的公式推导很随意，期望/求导之类的顺序想换就换：）。</li>\n<li>两种形式的policy gradient相差了一个求和符号，但其实是等价的，因为在sutton’s book里面的policy gradient用的是discounted state distribution。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Actor-Critic\"><a href=\"#Actor-Critic\" class=\"headerlink\" title=\"Actor-Critic\"></a>Actor-Critic</h2><ul>\n<li>motivation<ul>\n<li>Policy Gradient Theorem中的$G_t=q_{\\pi}(S_t, A_t)$，也就是说在式子中<strong>$G_t$是真实的q(s,a)</strong>，这就限制了Policy Gradient只能用Monte Carlo的方法来采样。</li>\n<li>而Monte Carlo方法的variance是比较高的（因为多步取样），甚至在某些情况下Monte Carlo方法并不适用（e.g., non-terminating problem）。</li>\n<li>所以要想办法处理$G_t$。</li>\n</ul>\n</li>\n<li>idea<ul>\n<li>一种直观的解决思路是求解一个近似的$G_t$，即找一个$v_{\\boldsymbol w} \\approx G_t$，然后用$v_{\\boldsymbol w}$带入Policy Gradient中的$G_t$。</li>\n<li>这个$v_{\\boldsymbol w}$就是所谓的critic，而原来的policy就是所谓的actor。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"High-dimensional-Continuous-Control-Using-Generalized-Advantage-Estimation\"><a href=\"#High-dimensional-Continuous-Control-Using-Generalized-Advantage-Estimation\" class=\"headerlink\" title=\"High-dimensional Continuous Control Using Generalized Advantage Estimation\"></a>High-dimensional Continuous Control Using Generalized Advantage Estimation</h2><ul>\n<li>motivation<ul>\n<li><strong>调控advantage estimation的bias与variance</strong>。<ul>\n<li>由Policy Gradient中的讨论可知添加一个合适的baseline可以在不引入bias的情况下降低variance，而一般情况下都会采用v(s)作为baseline。此时，policy gradient中就带有一项q(s, a)-v(s)，我们将这项定义为advantage。</li>\n<li>但是policy gradient中的advantage是真实的（但我们并不知道的）advantage，于是我们通过采样来对advantage进行估计，因此估计的质量直接影响Policy Gradient的效果。</li>\n<li>但效果越逼近于真实值，往往意味着variance会很高，因为真实的return取决于多步决策，而每步决策都有随机因素，因此存在一个bias与variance的tradeoff。</li>\n<li>GAE则给出了如何通过一个参数$\\lambda$来调控这个tradeoff。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>idea<ul>\n<li>然后作者将TD(lambda)的思想用到了这里，即加权平均n-step advantage（对advantage的不同估计），得到所谓的GAE（Generalized Advantage Estimation）。<ul>\n<li>$\\lambda = 1$时：等价于用真实return-v(s)，不引入bias，但variance高。</li>\n<li>$\\lambda = 0$时：假如v(s)不等于真实的v(s)，则会引入bias，但variance低。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>more<ul>\n<li>discounted factor的另一种理解：即假设原来的目标是求undiscounted return，引入discounted factor是为了降低variance。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Asynchronous-Methods-for-Deep-Reinforcement-Learning\"><a href=\"#Asynchronous-Methods-for-Deep-Reinforcement-Learning\" class=\"headerlink\" title=\"Asynchronous Methods for Deep Reinforcement Learning\"></a>Asynchronous Methods for Deep Reinforcement Learning</h2><ul>\n<li>motivation<ul>\n<li><strong>消除sample之间的相关性</strong>的另一种方法（前一种是replay buffer）。<ul>\n<li>回顾我们的求解思路<ol>\n<li>我们首先得到要优化的目标，通常是个期望值；</li>\n<li>然后基于采样得到的sample估计该目标值（依据是大数定理）；</li>\n<li>接着假装这个估计的值为真的目标，对它进行优化。</li>\n</ol>\n</li>\n<li>可以看到对目标值估计的准确与否直接决定了效果的好坏，而对目标值估计的准确与否取决于得到的sample是否满足大数定理的条件，即sample是否独立同分布（期望值对应的分布）。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>idea<ul>\n<li>不同actor并行地在各自的trajectory中采样。参数更新的框架跟单线程的是一样的：<ul>\n<li>minibatch：用local的t来模拟（因为对minibatch的求导本来就是sum的形式，因此可以通过累加的形式来模拟）;</li>\n<li>target update：用global的T来模拟。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Deterministic-Policy-Gradient\"><a href=\"#Deterministic-Policy-Gradient\" class=\"headerlink\" title=\"Deterministic Policy Gradient\"></a>Deterministic Policy Gradient</h2><ul>\n<li>motivation<ul>\n<li>Policy Gradient通过直接求解最优的stochastic policy解决continuous action space的问题，但在某些需要<strong>deterministic policy</strong>的场景下并不适用（e.g., 机器人控制）。</li>\n</ul>\n</li>\n<li>idea<ul>\n<li>仅看推导结果：<ul>\n<li>determinisitc policy gradient的方向大致为$q(s, \\pi (s))$增大的方向，即$\\mathbb{E}_{s \\sim \\pi}\\left[ \\nabla _ \\theta \\pi(s) \\nabla _a Q^{\\pi}(s, a) \\mid _{a=\\pi(s)} \\right] \\approx \\mathbb{E}_{s \\sim \\pi}\\left[ \\nabla _\\theta Q^{\\pi}(s, \\pi(s))  \\right]$（用约等于号是因为忽略了$\\nabla _\\theta Q^{\\pi}(s,a)$这一项）；</li>\n<li>而policy gradient的方向大致为$q(s, a)\\text{log} \\pi(s)$增大的方向，即$\\mathbb{E}_{s,a \\sim \\pi}\\left[ Q^{\\pi}(s, a) \\nabla _\\theta \\text{log} \\pi(s) \\right] \\approx \\mathbb{E}_{s,a \\sim \\pi}\\left[ \\nabla _\\theta Q^{\\pi}(s, a) \\text{log} \\pi (s) \\right]$（同样忽略了$\\nabla _\\theta Q^{\\pi}(s,a)$这一项）。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>more<ul>\n<li>相比Policy Gradient，Determinisitc Policy Gradient还有一个好处就是sampe efficiency更高，毕竟gradient中少了关于action的期望（i.e., 仅仅是$\\mathbb{E}_{s}，而不是\\mathbb{E}_{s,a}$）。但这也会使得exploration不足，所以一般又会采用Off-Policy的方法弥补这个缺陷。</li>\n<li>而Off-Policy Actor-Critic的目标居然是$\\mathbb{E}_{s \\sim \\beta}\\left[ V^{\\pi}(s) \\right]$（而不是$\\mathbb{E}_{s \\sim \\pi}\\left[ V^{\\pi}(s) \\right]$），即state的分布由behavior policy决定。我个人认为这个是一个无奈之下的折中做法，因为最理想的情况是$\\nabla _ \\theta \\mathbb{E}_{s \\sim \\pi}\\left[ V^{\\pi}(s) \\right] = \\mathbb{E}_{s, a \\sim \\beta} \\left[ \\sim \\right]$（即可以用behavior policy采取的样本去估计真实的performance的gradient），但这样做的话，最后要显式给出不好求的state分布概率$\\rho ^{\\beta}(s)$，于是退而求其次，换了个好求的目标函数。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Deep-Deterministic-Policy-Gradient\"><a href=\"#Deep-Deterministic-Policy-Gradient\" class=\"headerlink\" title=\"Deep Deterministic Policy Gradient\"></a>Deep Deterministic Policy Gradient</h2><ul>\n<li>motivation<ul>\n<li>在DPG的基础上引入deep learning，使critic和actor的<strong>表达能力更强</strong>。</li>\n</ul>\n</li>\n<li>idea（借鉴DQN）<ul>\n<li>replay buffer：打破数据之间的相关性。值得注意的是，我们原来的目标是要最大化期望，而我们是通过采样来近似这个期望的。仅当我们的采样点是相互独立的，才能更好地近似期望值。于是使用一个replay buffer来把(s, a, r, s’)存起来，到更新参数的时候再从中抽取mini batch，这样就可以获得相关性较弱的数据。</li>\n<li>target network：保证ground truth的一致性。critic实际上是supervised learning，即用一个神经网络去做回归。如果相同的输入对应不同的输出，则无法收敛。于是就将生成ground truth所依赖的$Q(s, a)$和$\\mu(s)$都做了一个备份，来保证相同的输入有相同的输出，从而保证critic能够收敛。得到critic后，actor就跟DPG一样，朝着使得critic增大的方向更新参数就好了。<ul>\n<li>这里有个地方比较confusing，因为在DPG中，critic的含义是在当前actor下的return估计（i.e., $V^{\\pi}$）；而使用了target network后，critic的含义更像是在target actor下的return估计（i.e., $V^{\\pi ‘}$）。那在这种情况下，actor还应该朝着critic增大的方向更新参数吗？我的理解是$\\pi ‘$是逐步逼近$\\pi$的，所以两者比较相似，差别不大。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>more<ul>\n<li>DDPG和DPG在本质上的区别是换了一个能力更加强的critic。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Trust-Region-Policy-Optimization\"><a href=\"#Trust-Region-Policy-Optimization\" class=\"headerlink\" title=\"Trust Region Policy Optimization\"></a>Trust Region Policy Optimization</h2><ul>\n<li>motivation<ul>\n<li>policy gradient通过求解performance的gradient，然后使用gradient ascent的方法来提高performance。但<br><strong>gradient ascent对step size很敏感</strong>，太小的step size会导致效果提升很慢，太大的step size又不能保证效果的提升。</li>\n<li>于是就想能否不用gradient ascent，转而用别的方法来提高performance。</li>\n</ul>\n</li>\n<li>idea<ul>\n<li>通过一系列的定理，找到了新旧policy对应的performance之差的下界<br>$$<br>\\eta(\\pi_{\\theta _{\\text{new}}}) - \\eta(\\pi_{\\theta _{\\text{old}}}) \\geq f(\\theta _{\\text{new}}).<br>$$</li>\n<li>通过<strong>最大化下界</strong>来间接提高$\\eta(\\pi_{\\theta _{\\text{new}}})$（这里有个疑惑就是怎么保证rhs&gt;0的？）。</li>\n</ul>\n</li>\n<li>detail<ul>\n<li>本来是一个无约束优化问题，但是求解该无约束优化问题得到的$\\theta _{\\text{new}} - \\theta _{\\text{old}}$很小（这应该是一个经验性的结果，但也很合理，因为目标函数里面有一项负的KL divergence，如果step size大了，该项会很小。但我有个疑问是step size小又有什么问题呢？）。于是把无约束优化问题转换成有约束优化问题。</li>\n<li>最后得到的优化问题的目标函数和约束条件都是期望，需要通过采样来进行估计。</li>\n<li>为了提高求解优化问题的效率，分别对目标函数和约束条件进行一阶近似和二阶近似，得到一个凸优化问题，因此是一个强对偶问题。于是可以通过求解对偶问题来求解原问题。<ul>\n<li>思路是求解对偶问题，但并不完全按照求解对偶问题的过程进行（我觉得是按照标准流程不好解，因为涉及到求解$x^T A x = b$）。</li>\n<li>通过对$\\theta _{\\text{new}}$求导等于$0$得到$\\theta _{\\text{new}}-\\theta _{\\text{old}} = \\frac{1}{\\lambda}F^{-1}g$，其中$F$为KL divergence在$\\theta _{\\text{old}}$的Hessian matrix，$g$为目标函数在$\\theta _{\\text{old}}$的一阶导数，至此知道了$\\theta _{\\text{new}} - \\theta _{\\text{old}}$的方向。</li>\n<li>通过对$\\lambda$求导等于$0$，可得$(\\theta _{\\text{new}}-\\theta _{\\text{old}})^T F (\\theta _{\\text{new}}-\\theta _{\\text{old}})=\\delta$，但这并不好求。回想上一步我们已经知道$\\theta _{\\text{new}} - \\theta _{\\text{old}}$的方向，于是直接在保证满足约束条件下做line search，这也就是scaling步所做的事情。</li>\n</ul>\n</li>\n<li>可以看到整个求解过程最核心的是求解$x=F^{-1}g$，又$F$是一个对称正定矩阵，可以用conjugate gradient来求解该线性方程。而conjugate gradient并不需要显式地使用$F$，仅需要$F$与某个向量$p$的乘积$Fp$。幸运的是，真的有一些方法能够在不使用$F$的情况下求解出$Fp$（仅需要求一阶导，而一阶导又有auto-differentiation工具可用）。所以我们能够在不用显式求出$F$的情况下求解$x=F^{-1}g$。</li>\n</ul>\n</li>\n<li>references<ul>\n<li><a href=\"http://www.cs.toronto.edu/~tingwuwang/trpo.pdf\" target=\"_blank\" rel=\"external\">TRPO推导过程</a></li>\n<li><a href=\"https://people.eecs.berkeley.edu/~pabbeel/nips-tutorial-policy-optimization-Schulman-Abbeel.pdf\" target=\"_blank\" rel=\"external\">TRPO期望形式到采样形式</a></li>\n<li><a href=\"http://rll.berkeley.edu/deeprlcourse/docs/lec5.pdf\" target=\"_blank\" rel=\"external\">practical TRPO（一阶近似目标函数、二阶近似约束条件、Lagrangian求解约束优化问题）</a></li>\n<li><a href=\"https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained\" target=\"_blank\" rel=\"external\">KL divergence简介</a></li>\n<li><a href=\"https://math.stackexchange.com/questions/2239040/show-that-fisher-information-matrix-is-the-second-order-gradient-of-kl-divergenc\" target=\"_blank\" rel=\"external\">Fisher Information Matrix与KL divergence Hessian的关系</a></li>\n<li><a href=\"http://andrew.gibiansky.com/blog/machine-learning/hessian-free-optimization/\" target=\"_blank\" rel=\"external\">Hessian Free Optimization</a></li>\n<li><a href=\"http://tutorial.math.lamar.edu/Classes/CalcIII/DirectionalDeriv.aspx\" target=\"_blank\" rel=\"external\">Directional derivative</a></li>\n<li><a href=\"https://roosephu.github.io/2016/11/19/TRPO/\" target=\"_blank\" rel=\"external\">Hessian Free Optimization实例</a></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Proximal-Policy-Optimization-Algorithms\"><a href=\"#Proximal-Policy-Optimization-Algorithms\" class=\"headerlink\" title=\"Proximal Policy Optimization Algorithms\"></a>Proximal Policy Optimization Algorithms</h2><ul>\n<li>motivation<ul>\n<li><strong>进化版的TRPO</strong><ul>\n<li>实现更加简单；</li>\n<li>适用于更多网络结构（parameter sharing between critic and actor）。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>idea<ul>\n<li>TRPO约束条件的含义是在状态s下，新旧两个policy不要相差太远（以KL divergence为度量）。实际上就是担心为了提高$\\frac{\\pi _{\\theta _\\text{new}}(a  \\mid s )}{\\pi _{\\theta _\\text{old}}(a  \\mid s )}\\hat{A}(s,a)$而大幅度改变$\\theta _{\\text{new}}$。具体来说就是当$\\hat{A}(s, a)&gt;0$时，通过大幅提高$\\pi _{\\theta _\\text{new}}(a \\mid s)$来提高目标值；反之，当$\\hat{A}(s, a)&lt;0$时，通过减小$\\pi _{\\theta _\\text{new}}(a \\mid s)$来提高目标值。</li>\n<li>PPO就是通过取minimize以及clip的方法<strong>改变了目标值的函数图像</strong>，使得大的step size也无法提高目标值，从而间接限制了step size，进而将约束问题转化为无约束优化问题。</li>\n</ul>\n</li>\n</ul>\n<div style=\"width:800px; margin-left:auto; margin-right:auto;\"><br>  <img src=\"/2018/02/03/summary-rl-drl/ppo_objective.png\" alt=\"PPO目标函数图像\" title=\"PPO目标函数图像\"><br></div>\n\n<ul>\n<li>more<ul>\n<li>关于新的目标函数的求导：<ul>\n<li>写成根据A&gt;0还是A&lt;0分类讨论的形式；</li>\n<li>直接用auto-differentiation工具。</li>\n</ul>\n</li>\n<li>处理parameter sharing：总的objective中增加value function的objective（i.e., value function的回归），变成多目标优化问题。</li>\n<li>entropy bonus：鼓励exploration。</li>\n</ul>\n</li>\n</ul>\n","excerpt":"","more":"<h2 id=\"On-Policy-vs-Off-Policy\"><a href=\"#On-Policy-vs-Off-Policy\" class=\"headerlink\" title=\"On-Policy vs. Off-Policy\"></a>On-Policy vs. Off-Policy</h2><ul>\n<li>motivation<ul>\n<li>假设我们想要一个deterministic的policy，那么按一般的思路，我们就应该用一个deterministic的policy去采样，根据采样结果得到q(s, a)，最后得到$\\pi (s) = \\text{argmax}_a q(s,a)$。</li>\n<li>但由于这样的采样过程是greedy的，容易<strong>采样不充分</strong>，陷入局部最优。</li>\n<li>因此就想能不能既evaluate一个deterministic的policy，又可以充分采样，由此引出Off-Policy。</li>\n</ul>\n</li>\n<li>idea（以sarsa和q-learning为例，阐述On-Policy与Off-Policy的区别）<ul>\n<li>无论是sarsa还是q-learning，我们真实采取的policy（i.e., 状态变换所依赖的behavior policy）都是对q(s, a)进行$\\epsilon \\text{-greedy}$。sarsa和q-learning的区别在于q(s, a)的含义不同。</li>\n<li>假设t时刻到t+1时刻的state, action, reward如下表所示：<br>$$<br>\\begin{array}{c|cc}<br>&amp; t &amp; t+1 \\\\ \\hline<br>R &amp;   &amp; r’  \\\\\\<br>S &amp; s &amp; s’  \\\\\\<br>A &amp; a &amp; a’<br>\\end{array}<br>$$当我们要更新q(s, a)时，sarsa与q-learning有相同的$s, a, r’, s’$，但他们的$a’$并不相同，也正是$a’$的不同导致了不同的q(s, a)含义：<ul>\n<li>sarsa通过对q($s’$, $A$)进行$\\epsilon \\text{-greedy}$得到$a’$，因此sarsa的q(s, a)表示$\\epsilon \\text{-greedy}$下的q-value；</li>\n<li>q-learning则通过$a’=\\text{argmax}_A q(s’, A)$得到$a’$，因此q-learning的q(s, a)表示greedy（deterministic）下的q-value。  </li>\n</ul>\n</li>\n<li>也就是说，在sarsa中，q(s, a)表示的是behavior policy的q-value；而q-learning中，q(s, a)表示的是另外一个policy的q-value。前者这种q(s, a)与behavior policy一致的就称为On-Policy，后者这种不一致的就称为Off-Policy。即划分On-Policy与Off-Policy的依据是<strong>q(s, a)对应的policy是不是behavior policy</strong>。更准确来说，假设更新$Q^{\\pi}(s, a)$时，所用的样本$s, a \\sim \\pi ‘$，那么划分On-Policy与Off-Policy的依据是$\\pi ‘$是否为$\\pi$（因此experience replay基本都为Off-Policy，因为q(s, a)对应当前policy，而用到的sample来自experience replay，因此属于以前的policy）。</li>\n</ul>\n</li>\n<li>more<ul>\n<li>上面说的是Off-Policy与On-Policy两者概念上的区分，至于q-learning这种做法能不能保证q(s, a)收敛，q(s, a)收敛的值是不是我们想要的值，则是另外一个问题了。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Policy-Gradient\"><a href=\"#Policy-Gradient\" class=\"headerlink\" title=\"Policy Gradient\"></a>Policy Gradient</h2><ul>\n<li>motivation<ul>\n<li>value based的方法难以处理<strong>continuous action space</strong>。因为即使得到了准确的q(s, a)，在给定一个状态s的情况下，仍然不知道该采取哪个action，因此一般的处理方法是discretization，<ul>\n<li>但是discretization在某些action space中并不合适（e.g., 表示旋转的四元数），</li>\n<li>即使合适，discretization的程度也比较empirical。</li>\n</ul>\n</li>\n<li>value based的方法难以处理<strong>随机策略</strong>（尽管可以根据q(s,a)来生成一个distribution（e.g., softmax distribution），但是并没有什么理论保证这种distribution是合理的）。</li>\n<li>有些任务的policy比action value更容易approximate。</li>\n</ul>\n</li>\n<li>idea<ul>\n<li>大多数情况下，我们的目的都是得到policy，value function只是得到policy的一种手段。</li>\n<li>实际上我们可以直接对policy建模并求解最优policy。设policy为$\\pi(a \\mid s ; \\boldsymbol\\theta)$（e.g., 高斯分布$a \\sim \\mathcal{N}(\\phi(s)^T \\boldsymbol\\theta, \\sigma ^2)$），则最优policy（i.e., $\\boldsymbol\\theta$）为以下优化问题的解：<br>$$<br>\\boldsymbol\\theta = \\mathop{\\text{argmax}}\\limits_{\\boldsymbol\\theta} v_{\\pi_{\\boldsymbol\\theta}}(s_0),<br>$$此处我们假设每次的初始状态都为$s_0$。</li>\n<li>假如知道$\\nabla v_{\\pi_{\\boldsymbol\\theta}}(s_0)$，那么我们就可以使用迭代的方法（e.g., SGD）去求解上述优化问题。</li>\n<li>而Policy Gradient Theorem告诉我们<br>$$<br>\\nabla v_{\\pi_{\\boldsymbol\\theta}}(s_0)=\\mathbb{E}_{S_t, A_t \\sim \\pi}\\left[\\gamma ^t G_t \\frac{\\nabla _\\boldsymbol\\theta \\pi (A_t \\mid S_t, \\boldsymbol\\theta)}{\\pi(A_t \\mid S_t, \\boldsymbol\\theta)} \\right],<br>$$因此我们可以通过sample来估计$\\nabla v_{\\pi_{\\boldsymbol\\theta}}(s_0)$从而求解优化问题，得到最优policy。</li>\n</ul>\n</li>\n<li>more<ul>\n<li><a href=\"https://danieltakeshi.github.io/2017/03/28/going-deeper-into-reinforcement-learning-fundamentals-of-policy-gradients/\">不同于Sutton’s book的另一种policy gradient推导方式</a>：<ul>\n<li>分析baseline对bias与variance的影响：<ul>\n<li>没有增加bias，且baseline越接近v(s)，variance越低；</li>\n<li>sample越independent，他的这种分析方法越准确。</li>\n</ul>\n</li>\n<li>插句题外话，原来不止我一个人觉得rl的公式推导很随意，期望/求导之类的顺序想换就换：）。</li>\n<li>两种形式的policy gradient相差了一个求和符号，但其实是等价的，因为在sutton’s book里面的policy gradient用的是discounted state distribution。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Actor-Critic\"><a href=\"#Actor-Critic\" class=\"headerlink\" title=\"Actor-Critic\"></a>Actor-Critic</h2><ul>\n<li>motivation<ul>\n<li>Policy Gradient Theorem中的$G_t=q_{\\pi}(S_t, A_t)$，也就是说在式子中<strong>$G_t$是真实的q(s,a)</strong>，这就限制了Policy Gradient只能用Monte Carlo的方法来采样。</li>\n<li>而Monte Carlo方法的variance是比较高的（因为多步取样），甚至在某些情况下Monte Carlo方法并不适用（e.g., non-terminating problem）。</li>\n<li>所以要想办法处理$G_t$。</li>\n</ul>\n</li>\n<li>idea<ul>\n<li>一种直观的解决思路是求解一个近似的$G_t$，即找一个$v_{\\boldsymbol w} \\approx G_t$，然后用$v_{\\boldsymbol w}$带入Policy Gradient中的$G_t$。</li>\n<li>这个$v_{\\boldsymbol w}$就是所谓的critic，而原来的policy就是所谓的actor。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"High-dimensional-Continuous-Control-Using-Generalized-Advantage-Estimation\"><a href=\"#High-dimensional-Continuous-Control-Using-Generalized-Advantage-Estimation\" class=\"headerlink\" title=\"High-dimensional Continuous Control Using Generalized Advantage Estimation\"></a>High-dimensional Continuous Control Using Generalized Advantage Estimation</h2><ul>\n<li>motivation<ul>\n<li><strong>调控advantage estimation的bias与variance</strong>。<ul>\n<li>由Policy Gradient中的讨论可知添加一个合适的baseline可以在不引入bias的情况下降低variance，而一般情况下都会采用v(s)作为baseline。此时，policy gradient中就带有一项q(s, a)-v(s)，我们将这项定义为advantage。</li>\n<li>但是policy gradient中的advantage是真实的（但我们并不知道的）advantage，于是我们通过采样来对advantage进行估计，因此估计的质量直接影响Policy Gradient的效果。</li>\n<li>但效果越逼近于真实值，往往意味着variance会很高，因为真实的return取决于多步决策，而每步决策都有随机因素，因此存在一个bias与variance的tradeoff。</li>\n<li>GAE则给出了如何通过一个参数$\\lambda$来调控这个tradeoff。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>idea<ul>\n<li>然后作者将TD(lambda)的思想用到了这里，即加权平均n-step advantage（对advantage的不同估计），得到所谓的GAE（Generalized Advantage Estimation）。<ul>\n<li>$\\lambda = 1$时：等价于用真实return-v(s)，不引入bias，但variance高。</li>\n<li>$\\lambda = 0$时：假如v(s)不等于真实的v(s)，则会引入bias，但variance低。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>more<ul>\n<li>discounted factor的另一种理解：即假设原来的目标是求undiscounted return，引入discounted factor是为了降低variance。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Asynchronous-Methods-for-Deep-Reinforcement-Learning\"><a href=\"#Asynchronous-Methods-for-Deep-Reinforcement-Learning\" class=\"headerlink\" title=\"Asynchronous Methods for Deep Reinforcement Learning\"></a>Asynchronous Methods for Deep Reinforcement Learning</h2><ul>\n<li>motivation<ul>\n<li><strong>消除sample之间的相关性</strong>的另一种方法（前一种是replay buffer）。<ul>\n<li>回顾我们的求解思路<ol>\n<li>我们首先得到要优化的目标，通常是个期望值；</li>\n<li>然后基于采样得到的sample估计该目标值（依据是大数定理）；</li>\n<li>接着假装这个估计的值为真的目标，对它进行优化。</li>\n</ol>\n</li>\n<li>可以看到对目标值估计的准确与否直接决定了效果的好坏，而对目标值估计的准确与否取决于得到的sample是否满足大数定理的条件，即sample是否独立同分布（期望值对应的分布）。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>idea<ul>\n<li>不同actor并行地在各自的trajectory中采样。参数更新的框架跟单线程的是一样的：<ul>\n<li>minibatch：用local的t来模拟（因为对minibatch的求导本来就是sum的形式，因此可以通过累加的形式来模拟）;</li>\n<li>target update：用global的T来模拟。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Deterministic-Policy-Gradient\"><a href=\"#Deterministic-Policy-Gradient\" class=\"headerlink\" title=\"Deterministic Policy Gradient\"></a>Deterministic Policy Gradient</h2><ul>\n<li>motivation<ul>\n<li>Policy Gradient通过直接求解最优的stochastic policy解决continuous action space的问题，但在某些需要<strong>deterministic policy</strong>的场景下并不适用（e.g., 机器人控制）。</li>\n</ul>\n</li>\n<li>idea<ul>\n<li>仅看推导结果：<ul>\n<li>determinisitc policy gradient的方向大致为$q(s, \\pi (s))$增大的方向，即$\\mathbb{E}_{s \\sim \\pi}\\left[ \\nabla _ \\theta \\pi(s) \\nabla _a Q^{\\pi}(s, a) \\mid _{a=\\pi(s)} \\right] \\approx \\mathbb{E}_{s \\sim \\pi}\\left[ \\nabla _\\theta Q^{\\pi}(s, \\pi(s))  \\right]$（用约等于号是因为忽略了$\\nabla _\\theta Q^{\\pi}(s,a)$这一项）；</li>\n<li>而policy gradient的方向大致为$q(s, a)\\text{log} \\pi(s)$增大的方向，即$\\mathbb{E}_{s,a \\sim \\pi}\\left[ Q^{\\pi}(s, a) \\nabla _\\theta \\text{log} \\pi(s) \\right] \\approx \\mathbb{E}_{s,a \\sim \\pi}\\left[ \\nabla _\\theta Q^{\\pi}(s, a) \\text{log} \\pi (s) \\right]$（同样忽略了$\\nabla _\\theta Q^{\\pi}(s,a)$这一项）。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>more<ul>\n<li>相比Policy Gradient，Determinisitc Policy Gradient还有一个好处就是sampe efficiency更高，毕竟gradient中少了关于action的期望（i.e., 仅仅是$\\mathbb{E}_{s}，而不是\\mathbb{E}_{s,a}$）。但这也会使得exploration不足，所以一般又会采用Off-Policy的方法弥补这个缺陷。</li>\n<li>而Off-Policy Actor-Critic的目标居然是$\\mathbb{E}_{s \\sim \\beta}\\left[ V^{\\pi}(s) \\right]$（而不是$\\mathbb{E}_{s \\sim \\pi}\\left[ V^{\\pi}(s) \\right]$），即state的分布由behavior policy决定。我个人认为这个是一个无奈之下的折中做法，因为最理想的情况是$\\nabla _ \\theta \\mathbb{E}_{s \\sim \\pi}\\left[ V^{\\pi}(s) \\right] = \\mathbb{E}_{s, a \\sim \\beta} \\left[ \\sim \\right]$（即可以用behavior policy采取的样本去估计真实的performance的gradient），但这样做的话，最后要显式给出不好求的state分布概率$\\rho ^{\\beta}(s)$，于是退而求其次，换了个好求的目标函数。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Deep-Deterministic-Policy-Gradient\"><a href=\"#Deep-Deterministic-Policy-Gradient\" class=\"headerlink\" title=\"Deep Deterministic Policy Gradient\"></a>Deep Deterministic Policy Gradient</h2><ul>\n<li>motivation<ul>\n<li>在DPG的基础上引入deep learning，使critic和actor的<strong>表达能力更强</strong>。</li>\n</ul>\n</li>\n<li>idea（借鉴DQN）<ul>\n<li>replay buffer：打破数据之间的相关性。值得注意的是，我们原来的目标是要最大化期望，而我们是通过采样来近似这个期望的。仅当我们的采样点是相互独立的，才能更好地近似期望值。于是使用一个replay buffer来把(s, a, r, s’)存起来，到更新参数的时候再从中抽取mini batch，这样就可以获得相关性较弱的数据。</li>\n<li>target network：保证ground truth的一致性。critic实际上是supervised learning，即用一个神经网络去做回归。如果相同的输入对应不同的输出，则无法收敛。于是就将生成ground truth所依赖的$Q(s, a)$和$\\mu(s)$都做了一个备份，来保证相同的输入有相同的输出，从而保证critic能够收敛。得到critic后，actor就跟DPG一样，朝着使得critic增大的方向更新参数就好了。<ul>\n<li>这里有个地方比较confusing，因为在DPG中，critic的含义是在当前actor下的return估计（i.e., $V^{\\pi}$）；而使用了target network后，critic的含义更像是在target actor下的return估计（i.e., $V^{\\pi ‘}$）。那在这种情况下，actor还应该朝着critic增大的方向更新参数吗？我的理解是$\\pi ‘$是逐步逼近$\\pi$的，所以两者比较相似，差别不大。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>more<ul>\n<li>DDPG和DPG在本质上的区别是换了一个能力更加强的critic。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Trust-Region-Policy-Optimization\"><a href=\"#Trust-Region-Policy-Optimization\" class=\"headerlink\" title=\"Trust Region Policy Optimization\"></a>Trust Region Policy Optimization</h2><ul>\n<li>motivation<ul>\n<li>policy gradient通过求解performance的gradient，然后使用gradient ascent的方法来提高performance。但<br><strong>gradient ascent对step size很敏感</strong>，太小的step size会导致效果提升很慢，太大的step size又不能保证效果的提升。</li>\n<li>于是就想能否不用gradient ascent，转而用别的方法来提高performance。</li>\n</ul>\n</li>\n<li>idea<ul>\n<li>通过一系列的定理，找到了新旧policy对应的performance之差的下界<br>$$<br>\\eta(\\pi_{\\theta _{\\text{new}}}) - \\eta(\\pi_{\\theta _{\\text{old}}}) \\geq f(\\theta _{\\text{new}}).<br>$$</li>\n<li>通过<strong>最大化下界</strong>来间接提高$\\eta(\\pi_{\\theta _{\\text{new}}})$（这里有个疑惑就是怎么保证rhs&gt;0的？）。</li>\n</ul>\n</li>\n<li>detail<ul>\n<li>本来是一个无约束优化问题，但是求解该无约束优化问题得到的$\\theta _{\\text{new}} - \\theta _{\\text{old}}$很小（这应该是一个经验性的结果，但也很合理，因为目标函数里面有一项负的KL divergence，如果step size大了，该项会很小。但我有个疑问是step size小又有什么问题呢？）。于是把无约束优化问题转换成有约束优化问题。</li>\n<li>最后得到的优化问题的目标函数和约束条件都是期望，需要通过采样来进行估计。</li>\n<li>为了提高求解优化问题的效率，分别对目标函数和约束条件进行一阶近似和二阶近似，得到一个凸优化问题，因此是一个强对偶问题。于是可以通过求解对偶问题来求解原问题。<ul>\n<li>思路是求解对偶问题，但并不完全按照求解对偶问题的过程进行（我觉得是按照标准流程不好解，因为涉及到求解$x^T A x = b$）。</li>\n<li>通过对$\\theta _{\\text{new}}$求导等于$0$得到$\\theta _{\\text{new}}-\\theta _{\\text{old}} = \\frac{1}{\\lambda}F^{-1}g$，其中$F$为KL divergence在$\\theta _{\\text{old}}$的Hessian matrix，$g$为目标函数在$\\theta _{\\text{old}}$的一阶导数，至此知道了$\\theta _{\\text{new}} - \\theta _{\\text{old}}$的方向。</li>\n<li>通过对$\\lambda$求导等于$0$，可得$(\\theta _{\\text{new}}-\\theta _{\\text{old}})^T F (\\theta _{\\text{new}}-\\theta _{\\text{old}})=\\delta$，但这并不好求。回想上一步我们已经知道$\\theta _{\\text{new}} - \\theta _{\\text{old}}$的方向，于是直接在保证满足约束条件下做line search，这也就是scaling步所做的事情。</li>\n</ul>\n</li>\n<li>可以看到整个求解过程最核心的是求解$x=F^{-1}g$，又$F$是一个对称正定矩阵，可以用conjugate gradient来求解该线性方程。而conjugate gradient并不需要显式地使用$F$，仅需要$F$与某个向量$p$的乘积$Fp$。幸运的是，真的有一些方法能够在不使用$F$的情况下求解出$Fp$（仅需要求一阶导，而一阶导又有auto-differentiation工具可用）。所以我们能够在不用显式求出$F$的情况下求解$x=F^{-1}g$。</li>\n</ul>\n</li>\n<li>references<ul>\n<li><a href=\"http://www.cs.toronto.edu/~tingwuwang/trpo.pdf\">TRPO推导过程</a></li>\n<li><a href=\"https://people.eecs.berkeley.edu/~pabbeel/nips-tutorial-policy-optimization-Schulman-Abbeel.pdf\">TRPO期望形式到采样形式</a></li>\n<li><a href=\"http://rll.berkeley.edu/deeprlcourse/docs/lec5.pdf\">practical TRPO（一阶近似目标函数、二阶近似约束条件、Lagrangian求解约束优化问题）</a></li>\n<li><a href=\"https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained\">KL divergence简介</a></li>\n<li><a href=\"https://math.stackexchange.com/questions/2239040/show-that-fisher-information-matrix-is-the-second-order-gradient-of-kl-divergenc\">Fisher Information Matrix与KL divergence Hessian的关系</a></li>\n<li><a href=\"http://andrew.gibiansky.com/blog/machine-learning/hessian-free-optimization/\">Hessian Free Optimization</a></li>\n<li><a href=\"http://tutorial.math.lamar.edu/Classes/CalcIII/DirectionalDeriv.aspx\">Directional derivative</a></li>\n<li><a href=\"https://roosephu.github.io/2016/11/19/TRPO/\">Hessian Free Optimization实例</a></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Proximal-Policy-Optimization-Algorithms\"><a href=\"#Proximal-Policy-Optimization-Algorithms\" class=\"headerlink\" title=\"Proximal Policy Optimization Algorithms\"></a>Proximal Policy Optimization Algorithms</h2><ul>\n<li>motivation<ul>\n<li><strong>进化版的TRPO</strong><ul>\n<li>实现更加简单；</li>\n<li>适用于更多网络结构（parameter sharing between critic and actor）。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>idea<ul>\n<li>TRPO约束条件的含义是在状态s下，新旧两个policy不要相差太远（以KL divergence为度量）。实际上就是担心为了提高$\\frac{\\pi _{\\theta _\\text{new}}(a  \\mid s )}{\\pi _{\\theta _\\text{old}}(a  \\mid s )}\\hat{A}(s,a)$而大幅度改变$\\theta _{\\text{new}}$。具体来说就是当$\\hat{A}(s, a)&gt;0$时，通过大幅提高$\\pi _{\\theta _\\text{new}}(a \\mid s)$来提高目标值；反之，当$\\hat{A}(s, a)&lt;0$时，通过减小$\\pi _{\\theta _\\text{new}}(a \\mid s)$来提高目标值。</li>\n<li>PPO就是通过取minimize以及clip的方法<strong>改变了目标值的函数图像</strong>，使得大的step size也无法提高目标值，从而间接限制了step size，进而将约束问题转化为无约束优化问题。</li>\n</ul>\n</li>\n</ul>\n<div style=\"width:800px; margin-left:auto; margin-right:auto;\" ><br>  <img src=\"/2018/02/03/summary-rl-drl/ppo_objective.png\" alt=\"PPO目标函数图像\" title=\"PPO目标函数图像\"><br></div>\n\n<ul>\n<li>more<ul>\n<li>关于新的目标函数的求导：<ul>\n<li>写成根据A&gt;0还是A&lt;0分类讨论的形式；</li>\n<li>直接用auto-differentiation工具。</li>\n</ul>\n</li>\n<li>处理parameter sharing：总的objective中增加value function的objective（i.e., value function的回归），变成多目标优化问题。</li>\n<li>entropy bonus：鼓励exploration。</li>\n</ul>\n</li>\n</ul>\n"},{"title":"技术总结《OpenAI Gym》","date":"2018-03-26T04:01:12.000Z","description":["关于OpenAI Gym的一些技术总结"],"_content":"\n本文首先介绍Gym的**核心函数调用链**，然后介绍如何**创建自定义的Gym环境**，最后给出一些使用Gym过程中碰到的**问题及其解决方案**。\n\n## Gym核心函数调用链\n\n一般来说，使用Gym的代码如下：\n\n```python\n# main.py\n\nimport gym\n\ndef choose_action(o):\n\t...\n\nenv = gym.make('CartPole-v0')\no = env.reset()\nwhile True:\n\ta = choose_action(o)\n\to_, r, done, info = env.step(a)\n\to = o_\n\tif done:\n\t\tbreak\n```\n\n可见，关键的函数有：\n\n- `env = gym.make('CartPole-v0')`\n- `env.reset()`\n- `env.step(a)`\n\n\n---\n\n我们先关注`env.reset()`和`env.step(a)`。这两个函数是超类`Env`的成员函数，`Env`的相关代码如下：\n\n```python\n# gym/core.py\n\nclass Env(object):\n\t...\n\n    # Override in ALL subclasses\n    def _step(self, action): raise NotImplementedError\n    def _reset(self): raise NotImplementedError\n\n    ...\n\n    def step(self, action):\n        return self._step(action)\n\n    def reset(self):\n        return self._reset()\n\n    ...\n```\n\n可以看到这两个函数依赖于子类的`_reset(self)`和`_step(self, action)`实现，子类`CartPoleEnv`的相关代码如下：\n\n```python\n# gym/envs/classic_control/CartPole.py\n\nclass CartPoleEnv(gym.Env):\n\t...\n\n    def _step(self, action):\n        ...\n\n    def _reset(self):\n        ...\n\n    ...\n```\n\n综上，`env.reset()`和`env.step(a)`实际上是调用子类的`_reset(self)`和`_step(self, action)`。\n\n---\n\n下面我们关注`gym.make('CartPole-v0')`，它的实现如下：\n\n\n```python\n# gym/envs/registration.py\n\n# Have a global registry\nregistry = EnvRegistry()\n\n...\n\ndef make(id):\n    return registry.make(id)\n```\n\n可以看到`gym.make`依赖于类`EnvRegistry`的成员函数`make`，`EnvRegistry`的相关代码如下：\n\n```python\n# gym/envs/registration.py\n\nclass EnvRegistry(object):\n    def __init__(self):\n    \t# 注册表\n    \t# key:\t环境名称（e.g., 'CartPole-v0'）\n    \t# value:类型为EnvSpec，可以暂时理解为环境\n        self.env_specs = {}\n\n    def make(self, id):\n        ...\n\n        # 根据环境名称，通过成员函数找到对应的环境\n        spec = self.spec(id)\n        # 实例化环境\n        env = spec.make()\n\n        ...\n\n        return env\n\n    ...\n\n    def spec(self, id):\n        ...\n\n    ...\n```\n\n可见类`EnvRegistry`的成员函数`make`依赖于类`EnvSpec`的成员函数`make`，`EnvSpec`的相关代码如下：\n\n```python\n# gym/envs/registration.py\n\ndef load(name):\n    ...\n\n# EnvSpec与Env之间的关系类似于说明商品规格的订单与商品之间的关系，\n# 下面用一个例子来说明：\n# 假设你网购看中了一款衣服，那么你会挑选该款衣服的颜色、码数，然后再下单。\n# 在这个例子里面，那款衣服就是Env，而说明该款衣服颜色、码数的订单就是EnvSpec。\n# 这就是为什么EnvRegistry.make(self, id)中，在得到spec之后还要再spec.make()，\n# 因为EnvSpec并不是Env，正如订单不是衣服。\nclass EnvSpec(object):\n    def __init__(self, id, entry_point=None, ...):\n    \tself.id = id\n        ...\n        self._entry_point = entry_point\n        ...\n\n    def make(self):\n        ...\n\n        # 动态加载环境类\n        # 相当于以下代码\n        # from self._entry_point import classA\n        # cls = classA\n        cls = load(self._entry_point)\n        # 实例化环境\n        env = cls(**self._kwargs)\n\n        ...\n\n        return env\n\n    ...\n```\n\n至此，我们对Gym的核心函数调用链有了一个基本的了解：\n\n- `gym.make(id)`：通过`EnvRegistry`中的注册表找到对应的`EnvSpec`，`EnvSpec`根据`entry_point`动态`import`对应的`Env`，并将其实例化；\n- `env.reset()`和`env.step(a)`：子类的`_reset(self)`和`_step(self, action)`。\n\n## 创建自定义环境\n\n对Gym的核心函数调用链有了基本了解后，我们知道创建自定义环境的关键有两个：\n\n- 第一个是搭建自己的`Env`子类`FooEnv`；\n- 第二个是注册`FooEnv`（i.e., 将`FooEnv`添加到`registry.env_specs`中），使得`gym.make(id)`可以找到`FooEnv`。\n\n[官方文档](https://github.com/openai/gym/tree/master/gym/envs)推荐的自定义环境目录结构如下：\n\n```shell\ngym-foo/\n  README.md\n  setup.py \t\t\t#将gym_foo这个package加到系统环境变量中\n  gym_foo/ \t\t\t#核心部分\n    __init__.py \t#注册FooEnv\n    envs/\n      __init__.py\n      foo_env.py \t#实现FooEnv\n```\n\n实现`FooEnv`没什么特别的，就是根据自己的需求，实现`_step(self, action)`、`_reset(self)`等函数。\n\n值得一提的是注册`FooEnv`，我们**无需自己实现**注册环境的代码，因为Gym已经有**现成的注册环境API**，我们只需要调用该API即可。在我们的自定义环境中，负责注册FooEnv的文件为`gym-foo/gym_foo/__init__.py`，它的内容如下：\n\n\n```python\n# gym-foo/gym_foo/__init__.py\n\nfrom gym.envs.registration import register\n\nregister(\n    id='foo-v0', \t# 环境名\n    entry_point='gym_foo.envs:FooEnv', \t# 环境类，之后就根据这个路径动态import环境\n)\n```\n\n可见，注册的关键是`register`函数，而`register`函数的实现如下：\n\n```python\n# gym/envs/registration.py\n\n# Have a global registry\nregistry = EnvRegistry()\n\n# Gym的注册环境API\ndef register(id, **kwargs):\n    return registry.register(id, **kwargs)\n\ndef make(id):\n    return registry.make(id)\n```\n\n可以看到`register`的实现依赖于类`EnvRegistry`的成员函数`register`，其相关代码如下：\n\n```python\n# gym/envs/registration.py\n\nclass EnvRegistry(object):\n\t...\n\n    def register(self, id, **kwargs):\n        ...\n        # 将FooEnv对应的“订单”写到“注册表”上\n        self.env_specs[id] = EnvSpec(id, **kwargs)\n\n```\n\n综上，我们可以通过API函数`register`注册自定义的环境`FooEnv`。\n\n## 注意事项\n\n### server render\n\n假如你通过ssh连接server，在server上运行（i.e., `python main.py`）以下代码（关键点在使用`env.render()`保存录像）：\n```python\n# main.py\n\nimport gym\nfrom gym import wrappers\n\nenv = gym.make('CartPole-v0')\nenv = wrappers.Monitor(env, 'video')\nfor i_episode in range(20):\n    observation = env.reset()\n    for t in range(100):\n        env.render()\n        action = env.action_space.sample()\n        observation, reward, done, info = env.step(action)\n        if done:\n            break\n```\n那么你会得到一个报错，报错的信息大概是`pyglet.canvas.xlib.NoSuchDisplayException: Cannot connect to \"None\"`。\n\n原因大概是`env.render()`**需要图形界面**（就是弹出来的那个框框），而当你使用ssh连接server时是没有图形界面的。因此我们需要一个**虚拟的图形界面**，而`xvfb-run`就是一个提供虚拟图形界面的工具。\n\n所以我们需要使用`xvfb-run -a -s \"-screen 0 1400x900x24 +extension RANDR\" -- python main.py`来运行我们的代码。\n\n一般来说，运行上述指令是会报错的，报错的信息大概是`pyglet requires an X server with GLX`，主要原因在于**显卡驱动以及cuda的安装有问题**，没有加`--no-opengl`的flag。解决方案可以参考[这里](https://gist.github.com/8enmann/931ec2a9dc45fde871d2139a7d1f2d78)和[这里](https://davidsanwald.github.io/2016/11/13/building-tensorflow-with-gpu-support.html )\n\n### 保存每一段episode的录像\n\n`wrappers.Monitor`默认不会保存所有episode的录像，但我们可以通过以下代码来设置保存所有episode的录像：\n\n```python\nenv = wrappers.Monitor(env, 'video', video_callable=lambda episode_id: True)\n```\n\n### 动态修改episode的最大step\n\n`env._max_episode_steps = xxx`。注意，这仅当env的类型为`TimeLimit`时可用。\n\n### 关于wrapper\n\n- 相同的两个wrapper不能叠加（e.g., `Monitor`不可以和`Monitor`叠加，但是`Monitor`可以和`TimeLimit`叠加），否则会报double wrapper的错。\n- 在注册`FooEnv`时，加不加`max_episode_steps=xxx`会影响返回的`Env`的类型。假如加了，返回的是`TimeLimit`类型的wrapper；假如不加，返回的就是裸的`FooEnv`。\n- `Monitor`里面有两个`recorder`，一个是`stat_recorder`，用于保存数据（reward之类的）；另一个是`video_recorder`，用于录像。`Monitor`会在每一次调用`env.reset`和`env.step`之后调用`render`\n\n### 屏蔽log信息\n\n```python\n# main.py\n\nimport logging\n\n# suppress INFO level logging 'Making new env: ...'\nlogging.getLogger('gym.envs.registration').setLevel(logging.WARNING)\n# suppress INFO level logging 'Starting new video recorder writing to ...'\nlogging.getLogger('gym.monitoring.video_recorder').setLevel(logging.WARNING)\n# suppress INFO level logging 'Creating monitor directory ...'\nlogging.getLogger('gym.wrappers.monitoring').setLevel(logging.WARNING)\n\n```","source":"_posts/tech-gym.md","raw":"---\ntitle: 技术总结《OpenAI Gym》\ndate: 2018-03-26 12:01:12\ntags:\n\t- Gym\ncategories:\n\t- 技术总结\ndescription:\n\t- 关于OpenAI Gym的一些技术总结\n---\n\n本文首先介绍Gym的**核心函数调用链**，然后介绍如何**创建自定义的Gym环境**，最后给出一些使用Gym过程中碰到的**问题及其解决方案**。\n\n## Gym核心函数调用链\n\n一般来说，使用Gym的代码如下：\n\n```python\n# main.py\n\nimport gym\n\ndef choose_action(o):\n\t...\n\nenv = gym.make('CartPole-v0')\no = env.reset()\nwhile True:\n\ta = choose_action(o)\n\to_, r, done, info = env.step(a)\n\to = o_\n\tif done:\n\t\tbreak\n```\n\n可见，关键的函数有：\n\n- `env = gym.make('CartPole-v0')`\n- `env.reset()`\n- `env.step(a)`\n\n\n---\n\n我们先关注`env.reset()`和`env.step(a)`。这两个函数是超类`Env`的成员函数，`Env`的相关代码如下：\n\n```python\n# gym/core.py\n\nclass Env(object):\n\t...\n\n    # Override in ALL subclasses\n    def _step(self, action): raise NotImplementedError\n    def _reset(self): raise NotImplementedError\n\n    ...\n\n    def step(self, action):\n        return self._step(action)\n\n    def reset(self):\n        return self._reset()\n\n    ...\n```\n\n可以看到这两个函数依赖于子类的`_reset(self)`和`_step(self, action)`实现，子类`CartPoleEnv`的相关代码如下：\n\n```python\n# gym/envs/classic_control/CartPole.py\n\nclass CartPoleEnv(gym.Env):\n\t...\n\n    def _step(self, action):\n        ...\n\n    def _reset(self):\n        ...\n\n    ...\n```\n\n综上，`env.reset()`和`env.step(a)`实际上是调用子类的`_reset(self)`和`_step(self, action)`。\n\n---\n\n下面我们关注`gym.make('CartPole-v0')`，它的实现如下：\n\n\n```python\n# gym/envs/registration.py\n\n# Have a global registry\nregistry = EnvRegistry()\n\n...\n\ndef make(id):\n    return registry.make(id)\n```\n\n可以看到`gym.make`依赖于类`EnvRegistry`的成员函数`make`，`EnvRegistry`的相关代码如下：\n\n```python\n# gym/envs/registration.py\n\nclass EnvRegistry(object):\n    def __init__(self):\n    \t# 注册表\n    \t# key:\t环境名称（e.g., 'CartPole-v0'）\n    \t# value:类型为EnvSpec，可以暂时理解为环境\n        self.env_specs = {}\n\n    def make(self, id):\n        ...\n\n        # 根据环境名称，通过成员函数找到对应的环境\n        spec = self.spec(id)\n        # 实例化环境\n        env = spec.make()\n\n        ...\n\n        return env\n\n    ...\n\n    def spec(self, id):\n        ...\n\n    ...\n```\n\n可见类`EnvRegistry`的成员函数`make`依赖于类`EnvSpec`的成员函数`make`，`EnvSpec`的相关代码如下：\n\n```python\n# gym/envs/registration.py\n\ndef load(name):\n    ...\n\n# EnvSpec与Env之间的关系类似于说明商品规格的订单与商品之间的关系，\n# 下面用一个例子来说明：\n# 假设你网购看中了一款衣服，那么你会挑选该款衣服的颜色、码数，然后再下单。\n# 在这个例子里面，那款衣服就是Env，而说明该款衣服颜色、码数的订单就是EnvSpec。\n# 这就是为什么EnvRegistry.make(self, id)中，在得到spec之后还要再spec.make()，\n# 因为EnvSpec并不是Env，正如订单不是衣服。\nclass EnvSpec(object):\n    def __init__(self, id, entry_point=None, ...):\n    \tself.id = id\n        ...\n        self._entry_point = entry_point\n        ...\n\n    def make(self):\n        ...\n\n        # 动态加载环境类\n        # 相当于以下代码\n        # from self._entry_point import classA\n        # cls = classA\n        cls = load(self._entry_point)\n        # 实例化环境\n        env = cls(**self._kwargs)\n\n        ...\n\n        return env\n\n    ...\n```\n\n至此，我们对Gym的核心函数调用链有了一个基本的了解：\n\n- `gym.make(id)`：通过`EnvRegistry`中的注册表找到对应的`EnvSpec`，`EnvSpec`根据`entry_point`动态`import`对应的`Env`，并将其实例化；\n- `env.reset()`和`env.step(a)`：子类的`_reset(self)`和`_step(self, action)`。\n\n## 创建自定义环境\n\n对Gym的核心函数调用链有了基本了解后，我们知道创建自定义环境的关键有两个：\n\n- 第一个是搭建自己的`Env`子类`FooEnv`；\n- 第二个是注册`FooEnv`（i.e., 将`FooEnv`添加到`registry.env_specs`中），使得`gym.make(id)`可以找到`FooEnv`。\n\n[官方文档](https://github.com/openai/gym/tree/master/gym/envs)推荐的自定义环境目录结构如下：\n\n```shell\ngym-foo/\n  README.md\n  setup.py \t\t\t#将gym_foo这个package加到系统环境变量中\n  gym_foo/ \t\t\t#核心部分\n    __init__.py \t#注册FooEnv\n    envs/\n      __init__.py\n      foo_env.py \t#实现FooEnv\n```\n\n实现`FooEnv`没什么特别的，就是根据自己的需求，实现`_step(self, action)`、`_reset(self)`等函数。\n\n值得一提的是注册`FooEnv`，我们**无需自己实现**注册环境的代码，因为Gym已经有**现成的注册环境API**，我们只需要调用该API即可。在我们的自定义环境中，负责注册FooEnv的文件为`gym-foo/gym_foo/__init__.py`，它的内容如下：\n\n\n```python\n# gym-foo/gym_foo/__init__.py\n\nfrom gym.envs.registration import register\n\nregister(\n    id='foo-v0', \t# 环境名\n    entry_point='gym_foo.envs:FooEnv', \t# 环境类，之后就根据这个路径动态import环境\n)\n```\n\n可见，注册的关键是`register`函数，而`register`函数的实现如下：\n\n```python\n# gym/envs/registration.py\n\n# Have a global registry\nregistry = EnvRegistry()\n\n# Gym的注册环境API\ndef register(id, **kwargs):\n    return registry.register(id, **kwargs)\n\ndef make(id):\n    return registry.make(id)\n```\n\n可以看到`register`的实现依赖于类`EnvRegistry`的成员函数`register`，其相关代码如下：\n\n```python\n# gym/envs/registration.py\n\nclass EnvRegistry(object):\n\t...\n\n    def register(self, id, **kwargs):\n        ...\n        # 将FooEnv对应的“订单”写到“注册表”上\n        self.env_specs[id] = EnvSpec(id, **kwargs)\n\n```\n\n综上，我们可以通过API函数`register`注册自定义的环境`FooEnv`。\n\n## 注意事项\n\n### server render\n\n假如你通过ssh连接server，在server上运行（i.e., `python main.py`）以下代码（关键点在使用`env.render()`保存录像）：\n```python\n# main.py\n\nimport gym\nfrom gym import wrappers\n\nenv = gym.make('CartPole-v0')\nenv = wrappers.Monitor(env, 'video')\nfor i_episode in range(20):\n    observation = env.reset()\n    for t in range(100):\n        env.render()\n        action = env.action_space.sample()\n        observation, reward, done, info = env.step(action)\n        if done:\n            break\n```\n那么你会得到一个报错，报错的信息大概是`pyglet.canvas.xlib.NoSuchDisplayException: Cannot connect to \"None\"`。\n\n原因大概是`env.render()`**需要图形界面**（就是弹出来的那个框框），而当你使用ssh连接server时是没有图形界面的。因此我们需要一个**虚拟的图形界面**，而`xvfb-run`就是一个提供虚拟图形界面的工具。\n\n所以我们需要使用`xvfb-run -a -s \"-screen 0 1400x900x24 +extension RANDR\" -- python main.py`来运行我们的代码。\n\n一般来说，运行上述指令是会报错的，报错的信息大概是`pyglet requires an X server with GLX`，主要原因在于**显卡驱动以及cuda的安装有问题**，没有加`--no-opengl`的flag。解决方案可以参考[这里](https://gist.github.com/8enmann/931ec2a9dc45fde871d2139a7d1f2d78)和[这里](https://davidsanwald.github.io/2016/11/13/building-tensorflow-with-gpu-support.html )\n\n### 保存每一段episode的录像\n\n`wrappers.Monitor`默认不会保存所有episode的录像，但我们可以通过以下代码来设置保存所有episode的录像：\n\n```python\nenv = wrappers.Monitor(env, 'video', video_callable=lambda episode_id: True)\n```\n\n### 动态修改episode的最大step\n\n`env._max_episode_steps = xxx`。注意，这仅当env的类型为`TimeLimit`时可用。\n\n### 关于wrapper\n\n- 相同的两个wrapper不能叠加（e.g., `Monitor`不可以和`Monitor`叠加，但是`Monitor`可以和`TimeLimit`叠加），否则会报double wrapper的错。\n- 在注册`FooEnv`时，加不加`max_episode_steps=xxx`会影响返回的`Env`的类型。假如加了，返回的是`TimeLimit`类型的wrapper；假如不加，返回的就是裸的`FooEnv`。\n- `Monitor`里面有两个`recorder`，一个是`stat_recorder`，用于保存数据（reward之类的）；另一个是`video_recorder`，用于录像。`Monitor`会在每一次调用`env.reset`和`env.step`之后调用`render`\n\n### 屏蔽log信息\n\n```python\n# main.py\n\nimport logging\n\n# suppress INFO level logging 'Making new env: ...'\nlogging.getLogger('gym.envs.registration').setLevel(logging.WARNING)\n# suppress INFO level logging 'Starting new video recorder writing to ...'\nlogging.getLogger('gym.monitoring.video_recorder').setLevel(logging.WARNING)\n# suppress INFO level logging 'Creating monitor directory ...'\nlogging.getLogger('gym.wrappers.monitoring').setLevel(logging.WARNING)\n\n```","slug":"tech-gym","published":1,"updated":"2024-08-13T16:03:47.884Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clzvf192m0020eqwoj3zjysjt","content":"<p>本文首先介绍Gym的<strong>核心函数调用链</strong>，然后介绍如何<strong>创建自定义的Gym环境</strong>，最后给出一些使用Gym过程中碰到的<strong>问题及其解决方案</strong>。</p>\n<h2 id=\"Gym核心函数调用链\"><a href=\"#Gym核心函数调用链\" class=\"headerlink\" title=\"Gym核心函数调用链\"></a>Gym核心函数调用链</h2><p>一般来说，使用Gym的代码如下：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># main.py</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">import</span> gym</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">choose_action</span><span class=\"params\">(o)</span>:</span></div><div class=\"line\">\t...</div><div class=\"line\"></div><div class=\"line\">env = gym.make(<span class=\"string\">'CartPole-v0'</span>)</div><div class=\"line\">o = env.reset()</div><div class=\"line\"><span class=\"keyword\">while</span> <span class=\"keyword\">True</span>:</div><div class=\"line\">\ta = choose_action(o)</div><div class=\"line\">\to_, r, done, info = env.step(a)</div><div class=\"line\">\to = o_</div><div class=\"line\">\t<span class=\"keyword\">if</span> done:</div><div class=\"line\">\t\t<span class=\"keyword\">break</span></div></pre></td></tr></table></figure>\n<p>可见，关键的函数有：</p>\n<ul>\n<li><code>env = gym.make(&#39;CartPole-v0&#39;)</code></li>\n<li><code>env.reset()</code></li>\n<li><code>env.step(a)</code></li>\n</ul>\n<hr>\n<p>我们先关注<code>env.reset()</code>和<code>env.step(a)</code>。这两个函数是超类<code>Env</code>的成员函数，<code>Env</code>的相关代码如下：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># gym/core.py</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Env</span><span class=\"params\">(object)</span>:</span></div><div class=\"line\">\t...</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\"># Override in ALL subclasses</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_step</span><span class=\"params\">(self, action)</span>:</span> <span class=\"keyword\">raise</span> NotImplementedError</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_reset</span><span class=\"params\">(self)</span>:</span> <span class=\"keyword\">raise</span> NotImplementedError</div><div class=\"line\"></div><div class=\"line\">    ...</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">step</span><span class=\"params\">(self, action)</span>:</span></div><div class=\"line\">        <span class=\"keyword\">return</span> self._step(action)</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">reset</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        <span class=\"keyword\">return</span> self._reset()</div><div class=\"line\"></div><div class=\"line\">    ...</div></pre></td></tr></table></figure>\n<p>可以看到这两个函数依赖于子类的<code>_reset(self)</code>和<code>_step(self, action)</code>实现，子类<code>CartPoleEnv</code>的相关代码如下：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># gym/envs/classic_control/CartPole.py</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">CartPoleEnv</span><span class=\"params\">(gym.Env)</span>:</span></div><div class=\"line\">\t...</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_step</span><span class=\"params\">(self, action)</span>:</span></div><div class=\"line\">        ...</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_reset</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        ...</div><div class=\"line\"></div><div class=\"line\">    ...</div></pre></td></tr></table></figure>\n<p>综上，<code>env.reset()</code>和<code>env.step(a)</code>实际上是调用子类的<code>_reset(self)</code>和<code>_step(self, action)</code>。</p>\n<hr>\n<p>下面我们关注<code>gym.make(&#39;CartPole-v0&#39;)</code>，它的实现如下：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># gym/envs/registration.py</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># Have a global registry</span></div><div class=\"line\">registry = EnvRegistry()</div><div class=\"line\"></div><div class=\"line\">...</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">make</span><span class=\"params\">(id)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">return</span> registry.make(id)</div></pre></td></tr></table></figure>\n<p>可以看到<code>gym.make</code>依赖于类<code>EnvRegistry</code>的成员函数<code>make</code>，<code>EnvRegistry</code>的相关代码如下：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># gym/envs/registration.py</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">EnvRegistry</span><span class=\"params\">(object)</span>:</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">    \t<span class=\"comment\"># 注册表</span></div><div class=\"line\">    \t<span class=\"comment\"># key:\t环境名称（e.g., 'CartPole-v0'）</span></div><div class=\"line\">    \t<span class=\"comment\"># value:类型为EnvSpec，可以暂时理解为环境</span></div><div class=\"line\">        self.env_specs = &#123;&#125;</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">make</span><span class=\"params\">(self, id)</span>:</span></div><div class=\"line\">        ...</div><div class=\"line\"></div><div class=\"line\">        <span class=\"comment\"># 根据环境名称，通过成员函数找到对应的环境</span></div><div class=\"line\">        spec = self.spec(id)</div><div class=\"line\">        <span class=\"comment\"># 实例化环境</span></div><div class=\"line\">        env = spec.make()</div><div class=\"line\"></div><div class=\"line\">        ...</div><div class=\"line\"></div><div class=\"line\">        <span class=\"keyword\">return</span> env</div><div class=\"line\"></div><div class=\"line\">    ...</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">spec</span><span class=\"params\">(self, id)</span>:</span></div><div class=\"line\">        ...</div><div class=\"line\"></div><div class=\"line\">    ...</div></pre></td></tr></table></figure>\n<p>可见类<code>EnvRegistry</code>的成员函数<code>make</code>依赖于类<code>EnvSpec</code>的成员函数<code>make</code>，<code>EnvSpec</code>的相关代码如下：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># gym/envs/registration.py</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">load</span><span class=\"params\">(name)</span>:</span></div><div class=\"line\">    ...</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># EnvSpec与Env之间的关系类似于说明商品规格的订单与商品之间的关系，</span></div><div class=\"line\"><span class=\"comment\"># 下面用一个例子来说明：</span></div><div class=\"line\"><span class=\"comment\"># 假设你网购看中了一款衣服，那么你会挑选该款衣服的颜色、码数，然后再下单。</span></div><div class=\"line\"><span class=\"comment\"># 在这个例子里面，那款衣服就是Env，而说明该款衣服颜色、码数的订单就是EnvSpec。</span></div><div class=\"line\"><span class=\"comment\"># 这就是为什么EnvRegistry.make(self, id)中，在得到spec之后还要再spec.make()，</span></div><div class=\"line\"><span class=\"comment\"># 因为EnvSpec并不是Env，正如订单不是衣服。</span></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">EnvSpec</span><span class=\"params\">(object)</span>:</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, id, entry_point=None, ...)</span>:</span></div><div class=\"line\">    \tself.id = id</div><div class=\"line\">        ...</div><div class=\"line\">        self._entry_point = entry_point</div><div class=\"line\">        ...</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">make</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        ...</div><div class=\"line\"></div><div class=\"line\">        <span class=\"comment\"># 动态加载环境类</span></div><div class=\"line\">        <span class=\"comment\"># 相当于以下代码</span></div><div class=\"line\">        <span class=\"comment\"># from self._entry_point import classA</span></div><div class=\"line\">        <span class=\"comment\"># cls = classA</span></div><div class=\"line\">        cls = load(self._entry_point)</div><div class=\"line\">        <span class=\"comment\"># 实例化环境</span></div><div class=\"line\">        env = cls(**self._kwargs)</div><div class=\"line\"></div><div class=\"line\">        ...</div><div class=\"line\"></div><div class=\"line\">        <span class=\"keyword\">return</span> env</div><div class=\"line\"></div><div class=\"line\">    ...</div></pre></td></tr></table></figure>\n<p>至此，我们对Gym的核心函数调用链有了一个基本的了解：</p>\n<ul>\n<li><code>gym.make(id)</code>：通过<code>EnvRegistry</code>中的注册表找到对应的<code>EnvSpec</code>，<code>EnvSpec</code>根据<code>entry_point</code>动态<code>import</code>对应的<code>Env</code>，并将其实例化；</li>\n<li><code>env.reset()</code>和<code>env.step(a)</code>：子类的<code>_reset(self)</code>和<code>_step(self, action)</code>。</li>\n</ul>\n<h2 id=\"创建自定义环境\"><a href=\"#创建自定义环境\" class=\"headerlink\" title=\"创建自定义环境\"></a>创建自定义环境</h2><p>对Gym的核心函数调用链有了基本了解后，我们知道创建自定义环境的关键有两个：</p>\n<ul>\n<li>第一个是搭建自己的<code>Env</code>子类<code>FooEnv</code>；</li>\n<li>第二个是注册<code>FooEnv</code>（i.e., 将<code>FooEnv</code>添加到<code>registry.env_specs</code>中），使得<code>gym.make(id)</code>可以找到<code>FooEnv</code>。</li>\n</ul>\n<p><a href=\"https://github.com/openai/gym/tree/master/gym/envs\" target=\"_blank\" rel=\"external\">官方文档</a>推荐的自定义环境目录结构如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">gym-foo/</div><div class=\"line\">  README.md</div><div class=\"line\">  setup.py \t\t\t#将gym_foo这个package加到系统环境变量中</div><div class=\"line\">  gym_foo/ \t\t\t#核心部分</div><div class=\"line\">    __init__.py \t#注册FooEnv</div><div class=\"line\">    envs/</div><div class=\"line\">      __init__.py</div><div class=\"line\">      foo_env.py \t#实现FooEnv</div></pre></td></tr></table></figure>\n<p>实现<code>FooEnv</code>没什么特别的，就是根据自己的需求，实现<code>_step(self, action)</code>、<code>_reset(self)</code>等函数。</p>\n<p>值得一提的是注册<code>FooEnv</code>，我们<strong>无需自己实现</strong>注册环境的代码，因为Gym已经有<strong>现成的注册环境API</strong>，我们只需要调用该API即可。在我们的自定义环境中，负责注册FooEnv的文件为<code>gym-foo/gym_foo/__init__.py</code>，它的内容如下：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># gym-foo/gym_foo/__init__.py</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">from</span> gym.envs.registration <span class=\"keyword\">import</span> register</div><div class=\"line\"></div><div class=\"line\">register(</div><div class=\"line\">    id=<span class=\"string\">'foo-v0'</span>, \t<span class=\"comment\"># 环境名</span></div><div class=\"line\">    entry_point=<span class=\"string\">'gym_foo.envs:FooEnv'</span>, \t<span class=\"comment\"># 环境类，之后就根据这个路径动态import环境</span></div><div class=\"line\">)</div></pre></td></tr></table></figure>\n<p>可见，注册的关键是<code>register</code>函数，而<code>register</code>函数的实现如下：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># gym/envs/registration.py</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># Have a global registry</span></div><div class=\"line\">registry = EnvRegistry()</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># Gym的注册环境API</span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">register</span><span class=\"params\">(id, **kwargs)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">return</span> registry.register(id, **kwargs)</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">make</span><span class=\"params\">(id)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">return</span> registry.make(id)</div></pre></td></tr></table></figure>\n<p>可以看到<code>register</code>的实现依赖于类<code>EnvRegistry</code>的成员函数<code>register</code>，其相关代码如下：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># gym/envs/registration.py</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">EnvRegistry</span><span class=\"params\">(object)</span>:</span></div><div class=\"line\">\t...</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">register</span><span class=\"params\">(self, id, **kwargs)</span>:</span></div><div class=\"line\">        ...</div><div class=\"line\">        <span class=\"comment\"># 将FooEnv对应的“订单”写到“注册表”上</span></div><div class=\"line\">        self.env_specs[id] = EnvSpec(id, **kwargs)</div></pre></td></tr></table></figure>\n<p>综上，我们可以通过API函数<code>register</code>注册自定义的环境<code>FooEnv</code>。</p>\n<h2 id=\"注意事项\"><a href=\"#注意事项\" class=\"headerlink\" title=\"注意事项\"></a>注意事项</h2><h3 id=\"server-render\"><a href=\"#server-render\" class=\"headerlink\" title=\"server render\"></a>server render</h3><p>假如你通过ssh连接server，在server上运行（i.e., <code>python main.py</code>）以下代码（关键点在使用<code>env.render()</code>保存录像）：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># main.py</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">import</span> gym</div><div class=\"line\"><span class=\"keyword\">from</span> gym <span class=\"keyword\">import</span> wrappers</div><div class=\"line\"></div><div class=\"line\">env = gym.make(<span class=\"string\">'CartPole-v0'</span>)</div><div class=\"line\">env = wrappers.Monitor(env, <span class=\"string\">'video'</span>)</div><div class=\"line\"><span class=\"keyword\">for</span> i_episode <span class=\"keyword\">in</span> range(<span class=\"number\">20</span>):</div><div class=\"line\">    observation = env.reset()</div><div class=\"line\">    <span class=\"keyword\">for</span> t <span class=\"keyword\">in</span> range(<span class=\"number\">100</span>):</div><div class=\"line\">        env.render()</div><div class=\"line\">        action = env.action_space.sample()</div><div class=\"line\">        observation, reward, done, info = env.step(action)</div><div class=\"line\">        <span class=\"keyword\">if</span> done:</div><div class=\"line\">            <span class=\"keyword\">break</span></div></pre></td></tr></table></figure></p>\n<p>那么你会得到一个报错，报错的信息大概是<code>pyglet.canvas.xlib.NoSuchDisplayException: Cannot connect to &quot;None&quot;</code>。</p>\n<p>原因大概是<code>env.render()</code><strong>需要图形界面</strong>（就是弹出来的那个框框），而当你使用ssh连接server时是没有图形界面的。因此我们需要一个<strong>虚拟的图形界面</strong>，而<code>xvfb-run</code>就是一个提供虚拟图形界面的工具。</p>\n<p>所以我们需要使用<code>xvfb-run -a -s &quot;-screen 0 1400x900x24 +extension RANDR&quot; -- python main.py</code>来运行我们的代码。</p>\n<p>一般来说，运行上述指令是会报错的，报错的信息大概是<code>pyglet requires an X server with GLX</code>，主要原因在于<strong>显卡驱动以及cuda的安装有问题</strong>，没有加<code>--no-opengl</code>的flag。解决方案可以参考<a href=\"https://gist.github.com/8enmann/931ec2a9dc45fde871d2139a7d1f2d78\" target=\"_blank\" rel=\"external\">这里</a>和<a href=\"https://davidsanwald.github.io/2016/11/13/building-tensorflow-with-gpu-support.html\" target=\"_blank\" rel=\"external\">这里</a></p>\n<h3 id=\"保存每一段episode的录像\"><a href=\"#保存每一段episode的录像\" class=\"headerlink\" title=\"保存每一段episode的录像\"></a>保存每一段episode的录像</h3><p><code>wrappers.Monitor</code>默认不会保存所有episode的录像，但我们可以通过以下代码来设置保存所有episode的录像：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">env = wrappers.Monitor(env, <span class=\"string\">'video'</span>, video_callable=<span class=\"keyword\">lambda</span> episode_id: <span class=\"keyword\">True</span>)</div></pre></td></tr></table></figure>\n<h3 id=\"动态修改episode的最大step\"><a href=\"#动态修改episode的最大step\" class=\"headerlink\" title=\"动态修改episode的最大step\"></a>动态修改episode的最大step</h3><p><code>env._max_episode_steps = xxx</code>。注意，这仅当env的类型为<code>TimeLimit</code>时可用。</p>\n<h3 id=\"关于wrapper\"><a href=\"#关于wrapper\" class=\"headerlink\" title=\"关于wrapper\"></a>关于wrapper</h3><ul>\n<li>相同的两个wrapper不能叠加（e.g., <code>Monitor</code>不可以和<code>Monitor</code>叠加，但是<code>Monitor</code>可以和<code>TimeLimit</code>叠加），否则会报double wrapper的错。</li>\n<li>在注册<code>FooEnv</code>时，加不加<code>max_episode_steps=xxx</code>会影响返回的<code>Env</code>的类型。假如加了，返回的是<code>TimeLimit</code>类型的wrapper；假如不加，返回的就是裸的<code>FooEnv</code>。</li>\n<li><code>Monitor</code>里面有两个<code>recorder</code>，一个是<code>stat_recorder</code>，用于保存数据（reward之类的）；另一个是<code>video_recorder</code>，用于录像。<code>Monitor</code>会在每一次调用<code>env.reset</code>和<code>env.step</code>之后调用<code>render</code></li>\n</ul>\n<h3 id=\"屏蔽log信息\"><a href=\"#屏蔽log信息\" class=\"headerlink\" title=\"屏蔽log信息\"></a>屏蔽log信息</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># main.py</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">import</span> logging</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># suppress INFO level logging 'Making new env: ...'</span></div><div class=\"line\">logging.getLogger(<span class=\"string\">'gym.envs.registration'</span>).setLevel(logging.WARNING)</div><div class=\"line\"><span class=\"comment\"># suppress INFO level logging 'Starting new video recorder writing to ...'</span></div><div class=\"line\">logging.getLogger(<span class=\"string\">'gym.monitoring.video_recorder'</span>).setLevel(logging.WARNING)</div><div class=\"line\"><span class=\"comment\"># suppress INFO level logging 'Creating monitor directory ...'</span></div><div class=\"line\">logging.getLogger(<span class=\"string\">'gym.wrappers.monitoring'</span>).setLevel(logging.WARNING)</div></pre></td></tr></table></figure>","excerpt":"","more":"<p>本文首先介绍Gym的<strong>核心函数调用链</strong>，然后介绍如何<strong>创建自定义的Gym环境</strong>，最后给出一些使用Gym过程中碰到的<strong>问题及其解决方案</strong>。</p>\n<h2 id=\"Gym核心函数调用链\"><a href=\"#Gym核心函数调用链\" class=\"headerlink\" title=\"Gym核心函数调用链\"></a>Gym核心函数调用链</h2><p>一般来说，使用Gym的代码如下：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># main.py</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">import</span> gym</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">choose_action</span><span class=\"params\">(o)</span>:</span></div><div class=\"line\">\t...</div><div class=\"line\"></div><div class=\"line\">env = gym.make(<span class=\"string\">'CartPole-v0'</span>)</div><div class=\"line\">o = env.reset()</div><div class=\"line\"><span class=\"keyword\">while</span> <span class=\"keyword\">True</span>:</div><div class=\"line\">\ta = choose_action(o)</div><div class=\"line\">\to_, r, done, info = env.step(a)</div><div class=\"line\">\to = o_</div><div class=\"line\">\t<span class=\"keyword\">if</span> done:</div><div class=\"line\">\t\t<span class=\"keyword\">break</span></div></pre></td></tr></table></figure>\n<p>可见，关键的函数有：</p>\n<ul>\n<li><code>env = gym.make(&#39;CartPole-v0&#39;)</code></li>\n<li><code>env.reset()</code></li>\n<li><code>env.step(a)</code></li>\n</ul>\n<hr>\n<p>我们先关注<code>env.reset()</code>和<code>env.step(a)</code>。这两个函数是超类<code>Env</code>的成员函数，<code>Env</code>的相关代码如下：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># gym/core.py</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Env</span><span class=\"params\">(object)</span>:</span></div><div class=\"line\">\t...</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\"># Override in ALL subclasses</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_step</span><span class=\"params\">(self, action)</span>:</span> <span class=\"keyword\">raise</span> NotImplementedError</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_reset</span><span class=\"params\">(self)</span>:</span> <span class=\"keyword\">raise</span> NotImplementedError</div><div class=\"line\"></div><div class=\"line\">    ...</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">step</span><span class=\"params\">(self, action)</span>:</span></div><div class=\"line\">        <span class=\"keyword\">return</span> self._step(action)</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">reset</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        <span class=\"keyword\">return</span> self._reset()</div><div class=\"line\"></div><div class=\"line\">    ...</div></pre></td></tr></table></figure>\n<p>可以看到这两个函数依赖于子类的<code>_reset(self)</code>和<code>_step(self, action)</code>实现，子类<code>CartPoleEnv</code>的相关代码如下：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># gym/envs/classic_control/CartPole.py</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">CartPoleEnv</span><span class=\"params\">(gym.Env)</span>:</span></div><div class=\"line\">\t...</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_step</span><span class=\"params\">(self, action)</span>:</span></div><div class=\"line\">        ...</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_reset</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        ...</div><div class=\"line\"></div><div class=\"line\">    ...</div></pre></td></tr></table></figure>\n<p>综上，<code>env.reset()</code>和<code>env.step(a)</code>实际上是调用子类的<code>_reset(self)</code>和<code>_step(self, action)</code>。</p>\n<hr>\n<p>下面我们关注<code>gym.make(&#39;CartPole-v0&#39;)</code>，它的实现如下：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># gym/envs/registration.py</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># Have a global registry</span></div><div class=\"line\">registry = EnvRegistry()</div><div class=\"line\"></div><div class=\"line\">...</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">make</span><span class=\"params\">(id)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">return</span> registry.make(id)</div></pre></td></tr></table></figure>\n<p>可以看到<code>gym.make</code>依赖于类<code>EnvRegistry</code>的成员函数<code>make</code>，<code>EnvRegistry</code>的相关代码如下：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># gym/envs/registration.py</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">EnvRegistry</span><span class=\"params\">(object)</span>:</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">    \t<span class=\"comment\"># 注册表</span></div><div class=\"line\">    \t<span class=\"comment\"># key:\t环境名称（e.g., 'CartPole-v0'）</span></div><div class=\"line\">    \t<span class=\"comment\"># value:类型为EnvSpec，可以暂时理解为环境</span></div><div class=\"line\">        self.env_specs = &#123;&#125;</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">make</span><span class=\"params\">(self, id)</span>:</span></div><div class=\"line\">        ...</div><div class=\"line\"></div><div class=\"line\">        <span class=\"comment\"># 根据环境名称，通过成员函数找到对应的环境</span></div><div class=\"line\">        spec = self.spec(id)</div><div class=\"line\">        <span class=\"comment\"># 实例化环境</span></div><div class=\"line\">        env = spec.make()</div><div class=\"line\"></div><div class=\"line\">        ...</div><div class=\"line\"></div><div class=\"line\">        <span class=\"keyword\">return</span> env</div><div class=\"line\"></div><div class=\"line\">    ...</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">spec</span><span class=\"params\">(self, id)</span>:</span></div><div class=\"line\">        ...</div><div class=\"line\"></div><div class=\"line\">    ...</div></pre></td></tr></table></figure>\n<p>可见类<code>EnvRegistry</code>的成员函数<code>make</code>依赖于类<code>EnvSpec</code>的成员函数<code>make</code>，<code>EnvSpec</code>的相关代码如下：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># gym/envs/registration.py</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">load</span><span class=\"params\">(name)</span>:</span></div><div class=\"line\">    ...</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># EnvSpec与Env之间的关系类似于说明商品规格的订单与商品之间的关系，</span></div><div class=\"line\"><span class=\"comment\"># 下面用一个例子来说明：</span></div><div class=\"line\"><span class=\"comment\"># 假设你网购看中了一款衣服，那么你会挑选该款衣服的颜色、码数，然后再下单。</span></div><div class=\"line\"><span class=\"comment\"># 在这个例子里面，那款衣服就是Env，而说明该款衣服颜色、码数的订单就是EnvSpec。</span></div><div class=\"line\"><span class=\"comment\"># 这就是为什么EnvRegistry.make(self, id)中，在得到spec之后还要再spec.make()，</span></div><div class=\"line\"><span class=\"comment\"># 因为EnvSpec并不是Env，正如订单不是衣服。</span></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">EnvSpec</span><span class=\"params\">(object)</span>:</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, id, entry_point=None, ...)</span>:</span></div><div class=\"line\">    \tself.id = id</div><div class=\"line\">        ...</div><div class=\"line\">        self._entry_point = entry_point</div><div class=\"line\">        ...</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">make</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        ...</div><div class=\"line\"></div><div class=\"line\">        <span class=\"comment\"># 动态加载环境类</span></div><div class=\"line\">        <span class=\"comment\"># 相当于以下代码</span></div><div class=\"line\">        <span class=\"comment\"># from self._entry_point import classA</span></div><div class=\"line\">        <span class=\"comment\"># cls = classA</span></div><div class=\"line\">        cls = load(self._entry_point)</div><div class=\"line\">        <span class=\"comment\"># 实例化环境</span></div><div class=\"line\">        env = cls(**self._kwargs)</div><div class=\"line\"></div><div class=\"line\">        ...</div><div class=\"line\"></div><div class=\"line\">        <span class=\"keyword\">return</span> env</div><div class=\"line\"></div><div class=\"line\">    ...</div></pre></td></tr></table></figure>\n<p>至此，我们对Gym的核心函数调用链有了一个基本的了解：</p>\n<ul>\n<li><code>gym.make(id)</code>：通过<code>EnvRegistry</code>中的注册表找到对应的<code>EnvSpec</code>，<code>EnvSpec</code>根据<code>entry_point</code>动态<code>import</code>对应的<code>Env</code>，并将其实例化；</li>\n<li><code>env.reset()</code>和<code>env.step(a)</code>：子类的<code>_reset(self)</code>和<code>_step(self, action)</code>。</li>\n</ul>\n<h2 id=\"创建自定义环境\"><a href=\"#创建自定义环境\" class=\"headerlink\" title=\"创建自定义环境\"></a>创建自定义环境</h2><p>对Gym的核心函数调用链有了基本了解后，我们知道创建自定义环境的关键有两个：</p>\n<ul>\n<li>第一个是搭建自己的<code>Env</code>子类<code>FooEnv</code>；</li>\n<li>第二个是注册<code>FooEnv</code>（i.e., 将<code>FooEnv</code>添加到<code>registry.env_specs</code>中），使得<code>gym.make(id)</code>可以找到<code>FooEnv</code>。</li>\n</ul>\n<p><a href=\"https://github.com/openai/gym/tree/master/gym/envs\">官方文档</a>推荐的自定义环境目录结构如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">gym-foo/</div><div class=\"line\">  README.md</div><div class=\"line\">  setup.py \t\t\t#将gym_foo这个package加到系统环境变量中</div><div class=\"line\">  gym_foo/ \t\t\t#核心部分</div><div class=\"line\">    __init__.py \t#注册FooEnv</div><div class=\"line\">    envs/</div><div class=\"line\">      __init__.py</div><div class=\"line\">      foo_env.py \t#实现FooEnv</div></pre></td></tr></table></figure>\n<p>实现<code>FooEnv</code>没什么特别的，就是根据自己的需求，实现<code>_step(self, action)</code>、<code>_reset(self)</code>等函数。</p>\n<p>值得一提的是注册<code>FooEnv</code>，我们<strong>无需自己实现</strong>注册环境的代码，因为Gym已经有<strong>现成的注册环境API</strong>，我们只需要调用该API即可。在我们的自定义环境中，负责注册FooEnv的文件为<code>gym-foo/gym_foo/__init__.py</code>，它的内容如下：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># gym-foo/gym_foo/__init__.py</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">from</span> gym.envs.registration <span class=\"keyword\">import</span> register</div><div class=\"line\"></div><div class=\"line\">register(</div><div class=\"line\">    id=<span class=\"string\">'foo-v0'</span>, \t<span class=\"comment\"># 环境名</span></div><div class=\"line\">    entry_point=<span class=\"string\">'gym_foo.envs:FooEnv'</span>, \t<span class=\"comment\"># 环境类，之后就根据这个路径动态import环境</span></div><div class=\"line\">)</div></pre></td></tr></table></figure>\n<p>可见，注册的关键是<code>register</code>函数，而<code>register</code>函数的实现如下：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># gym/envs/registration.py</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># Have a global registry</span></div><div class=\"line\">registry = EnvRegistry()</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># Gym的注册环境API</span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">register</span><span class=\"params\">(id, **kwargs)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">return</span> registry.register(id, **kwargs)</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">make</span><span class=\"params\">(id)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">return</span> registry.make(id)</div></pre></td></tr></table></figure>\n<p>可以看到<code>register</code>的实现依赖于类<code>EnvRegistry</code>的成员函数<code>register</code>，其相关代码如下：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># gym/envs/registration.py</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">EnvRegistry</span><span class=\"params\">(object)</span>:</span></div><div class=\"line\">\t...</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">register</span><span class=\"params\">(self, id, **kwargs)</span>:</span></div><div class=\"line\">        ...</div><div class=\"line\">        <span class=\"comment\"># 将FooEnv对应的“订单”写到“注册表”上</span></div><div class=\"line\">        self.env_specs[id] = EnvSpec(id, **kwargs)</div></pre></td></tr></table></figure>\n<p>综上，我们可以通过API函数<code>register</code>注册自定义的环境<code>FooEnv</code>。</p>\n<h2 id=\"注意事项\"><a href=\"#注意事项\" class=\"headerlink\" title=\"注意事项\"></a>注意事项</h2><h3 id=\"server-render\"><a href=\"#server-render\" class=\"headerlink\" title=\"server render\"></a>server render</h3><p>假如你通过ssh连接server，在server上运行（i.e., <code>python main.py</code>）以下代码（关键点在使用<code>env.render()</code>保存录像）：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># main.py</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">import</span> gym</div><div class=\"line\"><span class=\"keyword\">from</span> gym <span class=\"keyword\">import</span> wrappers</div><div class=\"line\"></div><div class=\"line\">env = gym.make(<span class=\"string\">'CartPole-v0'</span>)</div><div class=\"line\">env = wrappers.Monitor(env, <span class=\"string\">'video'</span>)</div><div class=\"line\"><span class=\"keyword\">for</span> i_episode <span class=\"keyword\">in</span> range(<span class=\"number\">20</span>):</div><div class=\"line\">    observation = env.reset()</div><div class=\"line\">    <span class=\"keyword\">for</span> t <span class=\"keyword\">in</span> range(<span class=\"number\">100</span>):</div><div class=\"line\">        env.render()</div><div class=\"line\">        action = env.action_space.sample()</div><div class=\"line\">        observation, reward, done, info = env.step(action)</div><div class=\"line\">        <span class=\"keyword\">if</span> done:</div><div class=\"line\">            <span class=\"keyword\">break</span></div></pre></td></tr></table></figure></p>\n<p>那么你会得到一个报错，报错的信息大概是<code>pyglet.canvas.xlib.NoSuchDisplayException: Cannot connect to &quot;None&quot;</code>。</p>\n<p>原因大概是<code>env.render()</code><strong>需要图形界面</strong>（就是弹出来的那个框框），而当你使用ssh连接server时是没有图形界面的。因此我们需要一个<strong>虚拟的图形界面</strong>，而<code>xvfb-run</code>就是一个提供虚拟图形界面的工具。</p>\n<p>所以我们需要使用<code>xvfb-run -a -s &quot;-screen 0 1400x900x24 +extension RANDR&quot; -- python main.py</code>来运行我们的代码。</p>\n<p>一般来说，运行上述指令是会报错的，报错的信息大概是<code>pyglet requires an X server with GLX</code>，主要原因在于<strong>显卡驱动以及cuda的安装有问题</strong>，没有加<code>--no-opengl</code>的flag。解决方案可以参考<a href=\"https://gist.github.com/8enmann/931ec2a9dc45fde871d2139a7d1f2d78\">这里</a>和<a href=\"https://davidsanwald.github.io/2016/11/13/building-tensorflow-with-gpu-support.html\">这里</a></p>\n<h3 id=\"保存每一段episode的录像\"><a href=\"#保存每一段episode的录像\" class=\"headerlink\" title=\"保存每一段episode的录像\"></a>保存每一段episode的录像</h3><p><code>wrappers.Monitor</code>默认不会保存所有episode的录像，但我们可以通过以下代码来设置保存所有episode的录像：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">env = wrappers.Monitor(env, <span class=\"string\">'video'</span>, video_callable=<span class=\"keyword\">lambda</span> episode_id: <span class=\"keyword\">True</span>)</div></pre></td></tr></table></figure>\n<h3 id=\"动态修改episode的最大step\"><a href=\"#动态修改episode的最大step\" class=\"headerlink\" title=\"动态修改episode的最大step\"></a>动态修改episode的最大step</h3><p><code>env._max_episode_steps = xxx</code>。注意，这仅当env的类型为<code>TimeLimit</code>时可用。</p>\n<h3 id=\"关于wrapper\"><a href=\"#关于wrapper\" class=\"headerlink\" title=\"关于wrapper\"></a>关于wrapper</h3><ul>\n<li>相同的两个wrapper不能叠加（e.g., <code>Monitor</code>不可以和<code>Monitor</code>叠加，但是<code>Monitor</code>可以和<code>TimeLimit</code>叠加），否则会报double wrapper的错。</li>\n<li>在注册<code>FooEnv</code>时，加不加<code>max_episode_steps=xxx</code>会影响返回的<code>Env</code>的类型。假如加了，返回的是<code>TimeLimit</code>类型的wrapper；假如不加，返回的就是裸的<code>FooEnv</code>。</li>\n<li><code>Monitor</code>里面有两个<code>recorder</code>，一个是<code>stat_recorder</code>，用于保存数据（reward之类的）；另一个是<code>video_recorder</code>，用于录像。<code>Monitor</code>会在每一次调用<code>env.reset</code>和<code>env.step</code>之后调用<code>render</code></li>\n</ul>\n<h3 id=\"屏蔽log信息\"><a href=\"#屏蔽log信息\" class=\"headerlink\" title=\"屏蔽log信息\"></a>屏蔽log信息</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># main.py</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">import</span> logging</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># suppress INFO level logging 'Making new env: ...'</span></div><div class=\"line\">logging.getLogger(<span class=\"string\">'gym.envs.registration'</span>).setLevel(logging.WARNING)</div><div class=\"line\"><span class=\"comment\"># suppress INFO level logging 'Starting new video recorder writing to ...'</span></div><div class=\"line\">logging.getLogger(<span class=\"string\">'gym.monitoring.video_recorder'</span>).setLevel(logging.WARNING)</div><div class=\"line\"><span class=\"comment\"># suppress INFO level logging 'Creating monitor directory ...'</span></div><div class=\"line\">logging.getLogger(<span class=\"string\">'gym.wrappers.monitoring'</span>).setLevel(logging.WARNING)</div></pre></td></tr></table></figure>"},{"title":"技术总结《在Ubuntu中使用USB蓝牙适配器》","date":"2021-12-29T14:08:35.000Z","description":["不再担心客服说USB蓝牙适配器不支持Linux系统"],"_content":"\n最近买了个蓝牙键盘，但是PC不带蓝牙，于是就想着外接个USB蓝牙适配器。在京东上找了一圈，发现就没有一个USB蓝牙适配器是支持Linux的。\n\n抱着死马当活马医的想法，还是买了一款USB蓝牙适配器回来试，发现确实没法像在Windows一样即插即用。所幸的是捣鼓一翻之后，最终还是能够正常使用。\n\n接下来就介绍一下我碰到的问题以及对应的解决方案，主要包含以下内容：\n\n1. 识别碰到的问题\n2. 处理`rtl_bt/rtl8761b_fw.bin not found`的问题\n3. 处理把`rtl8761b`识别成`rtl8761a`的问题\n\n这里补充一句，**建议购买支持蓝牙5.0的USB蓝牙适配器**，一个原因是这篇文章用的是蓝牙5.0的适配器，另一个原因是有些设备确实需要蓝牙5.0。\n\n## 识别碰到的问题\n\n将USB蓝牙适配器插入PC，然后看一下你的设备能不能连上PC，我相信肯定是不行的，不然你也不会搜到这篇文章。\n\n然后通过`dmesg | grep -i bluetooth`查看报错信息，我这边在不同版本的Ubuntu里面碰到了不同的问题，分别是：\n\n- Ubuntu 20: `rtl_bt/rtl8761b_fw.bin not found`\n- Ubuntu 18: 把`rtl8761b`识别成了`rtl8761a`\n\n假如你碰到的也是这两个问题，那么恭喜你，很有可能这篇文章就能帮你解决问题。假如不是这两个问题的话，那good luck。\n\n接下来就分别介绍这两个问题的解决方案。\n\n## 处理`rtl_bt/rtl8761b_fw.bin not found`的问题\n\n这个问题相对好处理，只是没有安装固件，把固件安装上即可：\n\n1. 到[这个网站](https://github.com/Realtek-OpenSource/android_hardware_realtek/tree/rtk1395/bt/rtkbt/Firmware/BT)下载`rtl8761b_fw`和`rtl8761b_config`这两个文件\n2. 将上述两个文件复制粘贴到`/usr/lib/firmware/rtl_bt/`这个目录下\n3. 重新拔插USB蓝牙适配器\n\n## 处理把`rtl8761b`识别成`rtl8761a`的问题\n\n**这里有个前提是要知道真实的固件是什么，你可以通过查官网来获得这个信息。我这里是因为我在Ubuntu 20下用`rtl8761b`是work的，所以确定该USB蓝牙适配器的固件是`rtl8761b`。**\n\n这个问题相对麻烦，是由于系统蓝牙模块的驱动有问题，因此需要重新编译、安装系统蓝牙模块的驱动：\n\n1. 查看当前系统的内核版本：`uname -r`\n2. 下载对应版本的内核源码：到[这个网站](https://github.com/torvalds/linux/tree/master)通过切换`tag`来下载对应版本的内核源码\n3. 按照[这个网站](https://discourse.coreelec.org/t/rtl8761b-bluetooth-driver-fix/15286)去修改蓝牙模块的驱动代码\n4. 按照[这个网站](https://gist.github.com/rometsch/dfd24fb09c85c1ad2f25223dc1481aaa#patch-the-bluetooth-kernel-module)去编译、安装新的蓝牙模块驱动\n5. 重启电脑\n\n## References\n\n- https://linuxreviews.org/Realtek_RTL8761B\n- https://blog.csdn.net/avatar1912/article/details/120851889","source":"_posts/tech-ubuntu-bluetooth.md","raw":"---\ntitle: 技术总结《在Ubuntu中使用USB蓝牙适配器》\ndate: 2021-12-29 22:08:35\ntags:\n\t- Ubuntu USB蓝牙适配器\ncategories:\n\t- 技术总结\ndescription:\n\t- 不再担心客服说USB蓝牙适配器不支持Linux系统\n---\n\n最近买了个蓝牙键盘，但是PC不带蓝牙，于是就想着外接个USB蓝牙适配器。在京东上找了一圈，发现就没有一个USB蓝牙适配器是支持Linux的。\n\n抱着死马当活马医的想法，还是买了一款USB蓝牙适配器回来试，发现确实没法像在Windows一样即插即用。所幸的是捣鼓一翻之后，最终还是能够正常使用。\n\n接下来就介绍一下我碰到的问题以及对应的解决方案，主要包含以下内容：\n\n1. 识别碰到的问题\n2. 处理`rtl_bt/rtl8761b_fw.bin not found`的问题\n3. 处理把`rtl8761b`识别成`rtl8761a`的问题\n\n这里补充一句，**建议购买支持蓝牙5.0的USB蓝牙适配器**，一个原因是这篇文章用的是蓝牙5.0的适配器，另一个原因是有些设备确实需要蓝牙5.0。\n\n## 识别碰到的问题\n\n将USB蓝牙适配器插入PC，然后看一下你的设备能不能连上PC，我相信肯定是不行的，不然你也不会搜到这篇文章。\n\n然后通过`dmesg | grep -i bluetooth`查看报错信息，我这边在不同版本的Ubuntu里面碰到了不同的问题，分别是：\n\n- Ubuntu 20: `rtl_bt/rtl8761b_fw.bin not found`\n- Ubuntu 18: 把`rtl8761b`识别成了`rtl8761a`\n\n假如你碰到的也是这两个问题，那么恭喜你，很有可能这篇文章就能帮你解决问题。假如不是这两个问题的话，那good luck。\n\n接下来就分别介绍这两个问题的解决方案。\n\n## 处理`rtl_bt/rtl8761b_fw.bin not found`的问题\n\n这个问题相对好处理，只是没有安装固件，把固件安装上即可：\n\n1. 到[这个网站](https://github.com/Realtek-OpenSource/android_hardware_realtek/tree/rtk1395/bt/rtkbt/Firmware/BT)下载`rtl8761b_fw`和`rtl8761b_config`这两个文件\n2. 将上述两个文件复制粘贴到`/usr/lib/firmware/rtl_bt/`这个目录下\n3. 重新拔插USB蓝牙适配器\n\n## 处理把`rtl8761b`识别成`rtl8761a`的问题\n\n**这里有个前提是要知道真实的固件是什么，你可以通过查官网来获得这个信息。我这里是因为我在Ubuntu 20下用`rtl8761b`是work的，所以确定该USB蓝牙适配器的固件是`rtl8761b`。**\n\n这个问题相对麻烦，是由于系统蓝牙模块的驱动有问题，因此需要重新编译、安装系统蓝牙模块的驱动：\n\n1. 查看当前系统的内核版本：`uname -r`\n2. 下载对应版本的内核源码：到[这个网站](https://github.com/torvalds/linux/tree/master)通过切换`tag`来下载对应版本的内核源码\n3. 按照[这个网站](https://discourse.coreelec.org/t/rtl8761b-bluetooth-driver-fix/15286)去修改蓝牙模块的驱动代码\n4. 按照[这个网站](https://gist.github.com/rometsch/dfd24fb09c85c1ad2f25223dc1481aaa#patch-the-bluetooth-kernel-module)去编译、安装新的蓝牙模块驱动\n5. 重启电脑\n\n## References\n\n- https://linuxreviews.org/Realtek_RTL8761B\n- https://blog.csdn.net/avatar1912/article/details/120851889","slug":"tech-ubuntu-bluetooth","published":1,"updated":"2024-08-13T16:03:47.884Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clzvf192o0024eqwoyxd6pbvq","content":"<p>最近买了个蓝牙键盘，但是PC不带蓝牙，于是就想着外接个USB蓝牙适配器。在京东上找了一圈，发现就没有一个USB蓝牙适配器是支持Linux的。</p>\n<p>抱着死马当活马医的想法，还是买了一款USB蓝牙适配器回来试，发现确实没法像在Windows一样即插即用。所幸的是捣鼓一翻之后，最终还是能够正常使用。</p>\n<p>接下来就介绍一下我碰到的问题以及对应的解决方案，主要包含以下内容：</p>\n<ol>\n<li>识别碰到的问题</li>\n<li>处理<code>rtl_bt/rtl8761b_fw.bin not found</code>的问题</li>\n<li>处理把<code>rtl8761b</code>识别成<code>rtl8761a</code>的问题</li>\n</ol>\n<p>这里补充一句，<strong>建议购买支持蓝牙5.0的USB蓝牙适配器</strong>，一个原因是这篇文章用的是蓝牙5.0的适配器，另一个原因是有些设备确实需要蓝牙5.0。</p>\n<h2 id=\"识别碰到的问题\"><a href=\"#识别碰到的问题\" class=\"headerlink\" title=\"识别碰到的问题\"></a>识别碰到的问题</h2><p>将USB蓝牙适配器插入PC，然后看一下你的设备能不能连上PC，我相信肯定是不行的，不然你也不会搜到这篇文章。</p>\n<p>然后通过<code>dmesg | grep -i bluetooth</code>查看报错信息，我这边在不同版本的Ubuntu里面碰到了不同的问题，分别是：</p>\n<ul>\n<li>Ubuntu 20: <code>rtl_bt/rtl8761b_fw.bin not found</code></li>\n<li>Ubuntu 18: 把<code>rtl8761b</code>识别成了<code>rtl8761a</code></li>\n</ul>\n<p>假如你碰到的也是这两个问题，那么恭喜你，很有可能这篇文章就能帮你解决问题。假如不是这两个问题的话，那good luck。</p>\n<p>接下来就分别介绍这两个问题的解决方案。</p>\n<h2 id=\"处理rtl-bt-rtl8761b-fw-bin-not-found的问题\"><a href=\"#处理rtl-bt-rtl8761b-fw-bin-not-found的问题\" class=\"headerlink\" title=\"处理rtl_bt/rtl8761b_fw.bin not found的问题\"></a>处理<code>rtl_bt/rtl8761b_fw.bin not found</code>的问题</h2><p>这个问题相对好处理，只是没有安装固件，把固件安装上即可：</p>\n<ol>\n<li>到<a href=\"https://github.com/Realtek-OpenSource/android_hardware_realtek/tree/rtk1395/bt/rtkbt/Firmware/BT\" target=\"_blank\" rel=\"external\">这个网站</a>下载<code>rtl8761b_fw</code>和<code>rtl8761b_config</code>这两个文件</li>\n<li>将上述两个文件复制粘贴到<code>/usr/lib/firmware/rtl_bt/</code>这个目录下</li>\n<li>重新拔插USB蓝牙适配器</li>\n</ol>\n<h2 id=\"处理把rtl8761b识别成rtl8761a的问题\"><a href=\"#处理把rtl8761b识别成rtl8761a的问题\" class=\"headerlink\" title=\"处理把rtl8761b识别成rtl8761a的问题\"></a>处理把<code>rtl8761b</code>识别成<code>rtl8761a</code>的问题</h2><p><strong>这里有个前提是要知道真实的固件是什么，你可以通过查官网来获得这个信息。我这里是因为我在Ubuntu 20下用<code>rtl8761b</code>是work的，所以确定该USB蓝牙适配器的固件是<code>rtl8761b</code>。</strong></p>\n<p>这个问题相对麻烦，是由于系统蓝牙模块的驱动有问题，因此需要重新编译、安装系统蓝牙模块的驱动：</p>\n<ol>\n<li>查看当前系统的内核版本：<code>uname -r</code></li>\n<li>下载对应版本的内核源码：到<a href=\"https://github.com/torvalds/linux/tree/master\" target=\"_blank\" rel=\"external\">这个网站</a>通过切换<code>tag</code>来下载对应版本的内核源码</li>\n<li>按照<a href=\"https://discourse.coreelec.org/t/rtl8761b-bluetooth-driver-fix/15286\" target=\"_blank\" rel=\"external\">这个网站</a>去修改蓝牙模块的驱动代码</li>\n<li>按照<a href=\"https://gist.github.com/rometsch/dfd24fb09c85c1ad2f25223dc1481aaa#patch-the-bluetooth-kernel-module\" target=\"_blank\" rel=\"external\">这个网站</a>去编译、安装新的蓝牙模块驱动</li>\n<li>重启电脑</li>\n</ol>\n<h2 id=\"References\"><a href=\"#References\" class=\"headerlink\" title=\"References\"></a>References</h2><ul>\n<li><a href=\"https://linuxreviews.org/Realtek_RTL8761B\" target=\"_blank\" rel=\"external\">https://linuxreviews.org/Realtek_RTL8761B</a></li>\n<li><a href=\"https://blog.csdn.net/avatar1912/article/details/120851889\" target=\"_blank\" rel=\"external\">https://blog.csdn.net/avatar1912/article/details/120851889</a></li>\n</ul>\n","excerpt":"","more":"<p>最近买了个蓝牙键盘，但是PC不带蓝牙，于是就想着外接个USB蓝牙适配器。在京东上找了一圈，发现就没有一个USB蓝牙适配器是支持Linux的。</p>\n<p>抱着死马当活马医的想法，还是买了一款USB蓝牙适配器回来试，发现确实没法像在Windows一样即插即用。所幸的是捣鼓一翻之后，最终还是能够正常使用。</p>\n<p>接下来就介绍一下我碰到的问题以及对应的解决方案，主要包含以下内容：</p>\n<ol>\n<li>识别碰到的问题</li>\n<li>处理<code>rtl_bt/rtl8761b_fw.bin not found</code>的问题</li>\n<li>处理把<code>rtl8761b</code>识别成<code>rtl8761a</code>的问题</li>\n</ol>\n<p>这里补充一句，<strong>建议购买支持蓝牙5.0的USB蓝牙适配器</strong>，一个原因是这篇文章用的是蓝牙5.0的适配器，另一个原因是有些设备确实需要蓝牙5.0。</p>\n<h2 id=\"识别碰到的问题\"><a href=\"#识别碰到的问题\" class=\"headerlink\" title=\"识别碰到的问题\"></a>识别碰到的问题</h2><p>将USB蓝牙适配器插入PC，然后看一下你的设备能不能连上PC，我相信肯定是不行的，不然你也不会搜到这篇文章。</p>\n<p>然后通过<code>dmesg | grep -i bluetooth</code>查看报错信息，我这边在不同版本的Ubuntu里面碰到了不同的问题，分别是：</p>\n<ul>\n<li>Ubuntu 20: <code>rtl_bt/rtl8761b_fw.bin not found</code></li>\n<li>Ubuntu 18: 把<code>rtl8761b</code>识别成了<code>rtl8761a</code></li>\n</ul>\n<p>假如你碰到的也是这两个问题，那么恭喜你，很有可能这篇文章就能帮你解决问题。假如不是这两个问题的话，那good luck。</p>\n<p>接下来就分别介绍这两个问题的解决方案。</p>\n<h2 id=\"处理rtl-bt-rtl8761b-fw-bin-not-found的问题\"><a href=\"#处理rtl-bt-rtl8761b-fw-bin-not-found的问题\" class=\"headerlink\" title=\"处理rtl_bt/rtl8761b_fw.bin not found的问题\"></a>处理<code>rtl_bt/rtl8761b_fw.bin not found</code>的问题</h2><p>这个问题相对好处理，只是没有安装固件，把固件安装上即可：</p>\n<ol>\n<li>到<a href=\"https://github.com/Realtek-OpenSource/android_hardware_realtek/tree/rtk1395/bt/rtkbt/Firmware/BT\">这个网站</a>下载<code>rtl8761b_fw</code>和<code>rtl8761b_config</code>这两个文件</li>\n<li>将上述两个文件复制粘贴到<code>/usr/lib/firmware/rtl_bt/</code>这个目录下</li>\n<li>重新拔插USB蓝牙适配器</li>\n</ol>\n<h2 id=\"处理把rtl8761b识别成rtl8761a的问题\"><a href=\"#处理把rtl8761b识别成rtl8761a的问题\" class=\"headerlink\" title=\"处理把rtl8761b识别成rtl8761a的问题\"></a>处理把<code>rtl8761b</code>识别成<code>rtl8761a</code>的问题</h2><p><strong>这里有个前提是要知道真实的固件是什么，你可以通过查官网来获得这个信息。我这里是因为我在Ubuntu 20下用<code>rtl8761b</code>是work的，所以确定该USB蓝牙适配器的固件是<code>rtl8761b</code>。</strong></p>\n<p>这个问题相对麻烦，是由于系统蓝牙模块的驱动有问题，因此需要重新编译、安装系统蓝牙模块的驱动：</p>\n<ol>\n<li>查看当前系统的内核版本：<code>uname -r</code></li>\n<li>下载对应版本的内核源码：到<a href=\"https://github.com/torvalds/linux/tree/master\">这个网站</a>通过切换<code>tag</code>来下载对应版本的内核源码</li>\n<li>按照<a href=\"https://discourse.coreelec.org/t/rtl8761b-bluetooth-driver-fix/15286\">这个网站</a>去修改蓝牙模块的驱动代码</li>\n<li>按照<a href=\"https://gist.github.com/rometsch/dfd24fb09c85c1ad2f25223dc1481aaa#patch-the-bluetooth-kernel-module\">这个网站</a>去编译、安装新的蓝牙模块驱动</li>\n<li>重启电脑</li>\n</ol>\n<h2 id=\"References\"><a href=\"#References\" class=\"headerlink\" title=\"References\"></a>References</h2><ul>\n<li><a href=\"https://linuxreviews.org/Realtek_RTL8761B\">https://linuxreviews.org/Realtek_RTL8761B</a></li>\n<li><a href=\"https://blog.csdn.net/avatar1912/article/details/120851889\">https://blog.csdn.net/avatar1912/article/details/120851889</a></li>\n</ul>\n"},{"title":"技术总结《Ubuntu to Go》","date":"2021-12-11T02:11:00.000Z","description":["将Ubuntu安装到U盘中，到哪都可以使用自己的电脑"],"_content":"\n带自己的笔记本电脑太麻烦，用别人的电脑不顺手。如果你也有这种困扰的话，可以尝试一下*Ubuntu to Go*。\n\n*Ubuntu to Go*是仿照*Windows to Go*起的名字，干的事情就是将操作系统安装到U盘中。这样一来，你只需要携带一个U盘，就可以在不同的电脑上运行你自己的操作系统了。\n\n本文不会详细罗列所有的步骤，只会介绍区别于常规安装*Ubuntu*的地方，换句话说就是假设你已经知道常规安装*Ubuntu*的方法。\n\n接下来会：\n\n1. 首先介绍安装*Ubuntu to Go*和安装普通的*Ubuntu*区别在哪\n2. 然后介绍具体操作\n\n## 区别在哪\n\n直觉上来讲，将*Ubuntu*安装到U盘中是很简单的事情，只需要在安装的时候将Boot Loader的安装路径设置为U盘就可以了。\n\n问题就出在了*Ubuntu*的安装程序有Bug（也不知道是不是个Feature），不管你怎么设置安装路径，它一定会将Boot Loader安装在第一个EFI分区里面。往往第一个EFI分区都在我们原来的硬盘，而不在我们的U盘（而且一般来说，U盘中也不包含EFI分区）。Boot Loader不在U盘就意味着没办法通过U盘启动*Ubuntu*，就达不成我们的目标。\n\n因此，相比于一般的安装流程，我们还需要额外做两件事情：\n\n1. 安装时为U盘创建EFI分区\n2. 安装后将Boot Loader安装到所创建的EFI分区中\n\n## 为U盘创建EFI分区\n\n在设置*Ubuntu*分区的时候，多加一个格式为FAT32、大小为100MB的分区，并且将这个分区设置为EFI。\n\n## 将Boot Loader安装到所创建的EFI分区中\n\n按照Installer提示，完成常规的安装之后，打开一个终端，去完成以下操作：\n\n1. 查看第一个EFI分区以及U盘中的EFI分区在哪，在这里是`/dev/sda2`和`/dev/sdb1`\n```sh\nsudo fdisk -l\n\nDevice         Start       End   Sectors   Size Type\n/dev/sda1       2048    923647    921600   450M Windows recovery environment\n/dev/sda2     923648   1126399    202752    99M EFI System\n/dev/sda3    1126400   1159167     32768    16M Microsoft reserved\n/dev/sda4    1159168 248347899 247188732 117.9G Microsoft basic data\n/dev/sda5  248348672 250066943   1718272   839M Windows recovery environment\n\n...\n\nDevice       Start        End    Sectors   Size Type\n/dev/sdb1     2048     194559     192512    94M EFI System\n/dev/sdb2   194560    8194047    7999488   3.8G Linux swap\n/dev/sdb3  8194048 1953457719 1945263672 927.6G Linux filesystem\n\n```\n2. 将Boot Loader安装到U盘中的EFI\n```sh\n# 挂载EFI\nmkdir windows_epi ubuntu_epi\nsudo mount /dev/sda2 windows_epi\nsudo mount /dev/sdb1 ubuntu_epi\n# 安装\nmkdir ubuntu_epi/EFI\ncp -r windows_epi/EFI/Boot ubuntu_epi/EFI\nmv windows_epi/EFI/ubuntu ubuntu_epi/EFI\nsudo sync; umount windows_epi; umount ubuntu_epi; sync\n```\n\n## 收尾\n\n至此应该已经将*Ubuntu*安装到U盘中了，接下来只需要重启，然后在UEFI中选择一下Boot的优先级就可以从U盘中启动*Ubuntu*了。\n\n## References\n\n- [1] [Legacy / UEFI / MBR / GPT的关系](https://zhuanlan.zhihu.com/p/262069479)\n- [2] [EFI / Boot Loader / GRUB的关系](https://blog.csdn.net/u011433762/article/details/49934253)\n- [3] [迁移Boot Loader到U盘](https://meaningofstuff.blogspot.com/2019/09/linux-ubuntu-1904-full-install-on-usb.html)\n- [4] [删除Windows中的Grub](https://askubuntu.com/questions/429610/uninstall-grub-and-use-windows-bootloader/869888#869888)\n","source":"_posts/tech-ubuntu-to-go.md","raw":"---\ntitle: 技术总结《Ubuntu to Go》\ndate: 2021-12-11 10:11:00\ntags:\n\t- Ubuntu to Go\ncategories:\n\t- 技术总结\ndescription:\n\t- 将Ubuntu安装到U盘中，到哪都可以使用自己的电脑\n---\n\n带自己的笔记本电脑太麻烦，用别人的电脑不顺手。如果你也有这种困扰的话，可以尝试一下*Ubuntu to Go*。\n\n*Ubuntu to Go*是仿照*Windows to Go*起的名字，干的事情就是将操作系统安装到U盘中。这样一来，你只需要携带一个U盘，就可以在不同的电脑上运行你自己的操作系统了。\n\n本文不会详细罗列所有的步骤，只会介绍区别于常规安装*Ubuntu*的地方，换句话说就是假设你已经知道常规安装*Ubuntu*的方法。\n\n接下来会：\n\n1. 首先介绍安装*Ubuntu to Go*和安装普通的*Ubuntu*区别在哪\n2. 然后介绍具体操作\n\n## 区别在哪\n\n直觉上来讲，将*Ubuntu*安装到U盘中是很简单的事情，只需要在安装的时候将Boot Loader的安装路径设置为U盘就可以了。\n\n问题就出在了*Ubuntu*的安装程序有Bug（也不知道是不是个Feature），不管你怎么设置安装路径，它一定会将Boot Loader安装在第一个EFI分区里面。往往第一个EFI分区都在我们原来的硬盘，而不在我们的U盘（而且一般来说，U盘中也不包含EFI分区）。Boot Loader不在U盘就意味着没办法通过U盘启动*Ubuntu*，就达不成我们的目标。\n\n因此，相比于一般的安装流程，我们还需要额外做两件事情：\n\n1. 安装时为U盘创建EFI分区\n2. 安装后将Boot Loader安装到所创建的EFI分区中\n\n## 为U盘创建EFI分区\n\n在设置*Ubuntu*分区的时候，多加一个格式为FAT32、大小为100MB的分区，并且将这个分区设置为EFI。\n\n## 将Boot Loader安装到所创建的EFI分区中\n\n按照Installer提示，完成常规的安装之后，打开一个终端，去完成以下操作：\n\n1. 查看第一个EFI分区以及U盘中的EFI分区在哪，在这里是`/dev/sda2`和`/dev/sdb1`\n```sh\nsudo fdisk -l\n\nDevice         Start       End   Sectors   Size Type\n/dev/sda1       2048    923647    921600   450M Windows recovery environment\n/dev/sda2     923648   1126399    202752    99M EFI System\n/dev/sda3    1126400   1159167     32768    16M Microsoft reserved\n/dev/sda4    1159168 248347899 247188732 117.9G Microsoft basic data\n/dev/sda5  248348672 250066943   1718272   839M Windows recovery environment\n\n...\n\nDevice       Start        End    Sectors   Size Type\n/dev/sdb1     2048     194559     192512    94M EFI System\n/dev/sdb2   194560    8194047    7999488   3.8G Linux swap\n/dev/sdb3  8194048 1953457719 1945263672 927.6G Linux filesystem\n\n```\n2. 将Boot Loader安装到U盘中的EFI\n```sh\n# 挂载EFI\nmkdir windows_epi ubuntu_epi\nsudo mount /dev/sda2 windows_epi\nsudo mount /dev/sdb1 ubuntu_epi\n# 安装\nmkdir ubuntu_epi/EFI\ncp -r windows_epi/EFI/Boot ubuntu_epi/EFI\nmv windows_epi/EFI/ubuntu ubuntu_epi/EFI\nsudo sync; umount windows_epi; umount ubuntu_epi; sync\n```\n\n## 收尾\n\n至此应该已经将*Ubuntu*安装到U盘中了，接下来只需要重启，然后在UEFI中选择一下Boot的优先级就可以从U盘中启动*Ubuntu*了。\n\n## References\n\n- [1] [Legacy / UEFI / MBR / GPT的关系](https://zhuanlan.zhihu.com/p/262069479)\n- [2] [EFI / Boot Loader / GRUB的关系](https://blog.csdn.net/u011433762/article/details/49934253)\n- [3] [迁移Boot Loader到U盘](https://meaningofstuff.blogspot.com/2019/09/linux-ubuntu-1904-full-install-on-usb.html)\n- [4] [删除Windows中的Grub](https://askubuntu.com/questions/429610/uninstall-grub-and-use-windows-bootloader/869888#869888)\n","slug":"tech-ubuntu-to-go","published":1,"updated":"2024-08-13T16:03:47.884Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clzvf192p0026eqwoc9y7tmqf","content":"<p>带自己的笔记本电脑太麻烦，用别人的电脑不顺手。如果你也有这种困扰的话，可以尝试一下<em>Ubuntu to Go</em>。</p>\n<p><em>Ubuntu to Go</em>是仿照<em>Windows to Go</em>起的名字，干的事情就是将操作系统安装到U盘中。这样一来，你只需要携带一个U盘，就可以在不同的电脑上运行你自己的操作系统了。</p>\n<p>本文不会详细罗列所有的步骤，只会介绍区别于常规安装<em>Ubuntu</em>的地方，换句话说就是假设你已经知道常规安装<em>Ubuntu</em>的方法。</p>\n<p>接下来会：</p>\n<ol>\n<li>首先介绍安装<em>Ubuntu to Go</em>和安装普通的<em>Ubuntu</em>区别在哪</li>\n<li>然后介绍具体操作</li>\n</ol>\n<h2 id=\"区别在哪\"><a href=\"#区别在哪\" class=\"headerlink\" title=\"区别在哪\"></a>区别在哪</h2><p>直觉上来讲，将<em>Ubuntu</em>安装到U盘中是很简单的事情，只需要在安装的时候将Boot Loader的安装路径设置为U盘就可以了。</p>\n<p>问题就出在了<em>Ubuntu</em>的安装程序有Bug（也不知道是不是个Feature），不管你怎么设置安装路径，它一定会将Boot Loader安装在第一个EFI分区里面。往往第一个EFI分区都在我们原来的硬盘，而不在我们的U盘（而且一般来说，U盘中也不包含EFI分区）。Boot Loader不在U盘就意味着没办法通过U盘启动<em>Ubuntu</em>，就达不成我们的目标。</p>\n<p>因此，相比于一般的安装流程，我们还需要额外做两件事情：</p>\n<ol>\n<li>安装时为U盘创建EFI分区</li>\n<li>安装后将Boot Loader安装到所创建的EFI分区中</li>\n</ol>\n<h2 id=\"为U盘创建EFI分区\"><a href=\"#为U盘创建EFI分区\" class=\"headerlink\" title=\"为U盘创建EFI分区\"></a>为U盘创建EFI分区</h2><p>在设置<em>Ubuntu</em>分区的时候，多加一个格式为FAT32、大小为100MB的分区，并且将这个分区设置为EFI。</p>\n<h2 id=\"将Boot-Loader安装到所创建的EFI分区中\"><a href=\"#将Boot-Loader安装到所创建的EFI分区中\" class=\"headerlink\" title=\"将Boot Loader安装到所创建的EFI分区中\"></a>将Boot Loader安装到所创建的EFI分区中</h2><p>按照Installer提示，完成常规的安装之后，打开一个终端，去完成以下操作：</p>\n<ol>\n<li><p>查看第一个EFI分区以及U盘中的EFI分区在哪，在这里是<code>/dev/sda2</code>和<code>/dev/sdb1</code></p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo fdisk <span class=\"_\">-l</span></div><div class=\"line\"></div><div class=\"line\">Device         Start       End   Sectors   Size Type</div><div class=\"line\">/dev/sda1       2048    923647    921600   450M Windows recovery environment</div><div class=\"line\">/dev/sda2     923648   1126399    202752    99M EFI System</div><div class=\"line\">/dev/sda3    1126400   1159167     32768    16M Microsoft reserved</div><div class=\"line\">/dev/sda4    1159168 248347899 247188732 117.9G Microsoft basic data</div><div class=\"line\">/dev/sda5  248348672 250066943   1718272   839M Windows recovery environment</div><div class=\"line\"></div><div class=\"line\">...</div><div class=\"line\"></div><div class=\"line\">Device       Start        End    Sectors   Size Type</div><div class=\"line\">/dev/sdb1     2048     194559     192512    94M EFI System</div><div class=\"line\">/dev/sdb2   194560    8194047    7999488   3.8G Linux swap</div><div class=\"line\">/dev/sdb3  8194048 1953457719 1945263672 927.6G Linux filesystem</div></pre></td></tr></table></figure>\n</li>\n<li><p>将Boot Loader安装到U盘中的EFI</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># 挂载EFI</span></div><div class=\"line\">mkdir windows_epi ubuntu_epi</div><div class=\"line\">sudo mount /dev/sda2 windows_epi</div><div class=\"line\">sudo mount /dev/sdb1 ubuntu_epi</div><div class=\"line\"><span class=\"comment\"># 安装</span></div><div class=\"line\">mkdir ubuntu_epi/EFI</div><div class=\"line\">cp -r windows_epi/EFI/Boot ubuntu_epi/EFI</div><div class=\"line\">mv windows_epi/EFI/ubuntu ubuntu_epi/EFI</div><div class=\"line\">sudo sync; umount windows_epi; umount ubuntu_epi; sync</div></pre></td></tr></table></figure>\n</li>\n</ol>\n<h2 id=\"收尾\"><a href=\"#收尾\" class=\"headerlink\" title=\"收尾\"></a>收尾</h2><p>至此应该已经将<em>Ubuntu</em>安装到U盘中了，接下来只需要重启，然后在UEFI中选择一下Boot的优先级就可以从U盘中启动<em>Ubuntu</em>了。</p>\n<h2 id=\"References\"><a href=\"#References\" class=\"headerlink\" title=\"References\"></a>References</h2><ul>\n<li>[1] <a href=\"https://zhuanlan.zhihu.com/p/262069479\" target=\"_blank\" rel=\"external\">Legacy / UEFI / MBR / GPT的关系</a></li>\n<li>[2] <a href=\"https://blog.csdn.net/u011433762/article/details/49934253\" target=\"_blank\" rel=\"external\">EFI / Boot Loader / GRUB的关系</a></li>\n<li>[3] <a href=\"https://meaningofstuff.blogspot.com/2019/09/linux-ubuntu-1904-full-install-on-usb.html\" target=\"_blank\" rel=\"external\">迁移Boot Loader到U盘</a></li>\n<li>[4] <a href=\"https://askubuntu.com/questions/429610/uninstall-grub-and-use-windows-bootloader/869888#869888\" target=\"_blank\" rel=\"external\">删除Windows中的Grub</a></li>\n</ul>\n","excerpt":"","more":"<p>带自己的笔记本电脑太麻烦，用别人的电脑不顺手。如果你也有这种困扰的话，可以尝试一下<em>Ubuntu to Go</em>。</p>\n<p><em>Ubuntu to Go</em>是仿照<em>Windows to Go</em>起的名字，干的事情就是将操作系统安装到U盘中。这样一来，你只需要携带一个U盘，就可以在不同的电脑上运行你自己的操作系统了。</p>\n<p>本文不会详细罗列所有的步骤，只会介绍区别于常规安装<em>Ubuntu</em>的地方，换句话说就是假设你已经知道常规安装<em>Ubuntu</em>的方法。</p>\n<p>接下来会：</p>\n<ol>\n<li>首先介绍安装<em>Ubuntu to Go</em>和安装普通的<em>Ubuntu</em>区别在哪</li>\n<li>然后介绍具体操作</li>\n</ol>\n<h2 id=\"区别在哪\"><a href=\"#区别在哪\" class=\"headerlink\" title=\"区别在哪\"></a>区别在哪</h2><p>直觉上来讲，将<em>Ubuntu</em>安装到U盘中是很简单的事情，只需要在安装的时候将Boot Loader的安装路径设置为U盘就可以了。</p>\n<p>问题就出在了<em>Ubuntu</em>的安装程序有Bug（也不知道是不是个Feature），不管你怎么设置安装路径，它一定会将Boot Loader安装在第一个EFI分区里面。往往第一个EFI分区都在我们原来的硬盘，而不在我们的U盘（而且一般来说，U盘中也不包含EFI分区）。Boot Loader不在U盘就意味着没办法通过U盘启动<em>Ubuntu</em>，就达不成我们的目标。</p>\n<p>因此，相比于一般的安装流程，我们还需要额外做两件事情：</p>\n<ol>\n<li>安装时为U盘创建EFI分区</li>\n<li>安装后将Boot Loader安装到所创建的EFI分区中</li>\n</ol>\n<h2 id=\"为U盘创建EFI分区\"><a href=\"#为U盘创建EFI分区\" class=\"headerlink\" title=\"为U盘创建EFI分区\"></a>为U盘创建EFI分区</h2><p>在设置<em>Ubuntu</em>分区的时候，多加一个格式为FAT32、大小为100MB的分区，并且将这个分区设置为EFI。</p>\n<h2 id=\"将Boot-Loader安装到所创建的EFI分区中\"><a href=\"#将Boot-Loader安装到所创建的EFI分区中\" class=\"headerlink\" title=\"将Boot Loader安装到所创建的EFI分区中\"></a>将Boot Loader安装到所创建的EFI分区中</h2><p>按照Installer提示，完成常规的安装之后，打开一个终端，去完成以下操作：</p>\n<ol>\n<li><p>查看第一个EFI分区以及U盘中的EFI分区在哪，在这里是<code>/dev/sda2</code>和<code>/dev/sdb1</code></p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo fdisk <span class=\"_\">-l</span></div><div class=\"line\"></div><div class=\"line\">Device         Start       End   Sectors   Size Type</div><div class=\"line\">/dev/sda1       2048    923647    921600   450M Windows recovery environment</div><div class=\"line\">/dev/sda2     923648   1126399    202752    99M EFI System</div><div class=\"line\">/dev/sda3    1126400   1159167     32768    16M Microsoft reserved</div><div class=\"line\">/dev/sda4    1159168 248347899 247188732 117.9G Microsoft basic data</div><div class=\"line\">/dev/sda5  248348672 250066943   1718272   839M Windows recovery environment</div><div class=\"line\"></div><div class=\"line\">...</div><div class=\"line\"></div><div class=\"line\">Device       Start        End    Sectors   Size Type</div><div class=\"line\">/dev/sdb1     2048     194559     192512    94M EFI System</div><div class=\"line\">/dev/sdb2   194560    8194047    7999488   3.8G Linux swap</div><div class=\"line\">/dev/sdb3  8194048 1953457719 1945263672 927.6G Linux filesystem</div></pre></td></tr></table></figure>\n</li>\n<li><p>将Boot Loader安装到U盘中的EFI</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># 挂载EFI</span></div><div class=\"line\">mkdir windows_epi ubuntu_epi</div><div class=\"line\">sudo mount /dev/sda2 windows_epi</div><div class=\"line\">sudo mount /dev/sdb1 ubuntu_epi</div><div class=\"line\"><span class=\"comment\"># 安装</span></div><div class=\"line\">mkdir ubuntu_epi/EFI</div><div class=\"line\">cp -r windows_epi/EFI/Boot ubuntu_epi/EFI</div><div class=\"line\">mv windows_epi/EFI/ubuntu ubuntu_epi/EFI</div><div class=\"line\">sudo sync; umount windows_epi; umount ubuntu_epi; sync</div></pre></td></tr></table></figure>\n</li>\n</ol>\n<h2 id=\"收尾\"><a href=\"#收尾\" class=\"headerlink\" title=\"收尾\"></a>收尾</h2><p>至此应该已经将<em>Ubuntu</em>安装到U盘中了，接下来只需要重启，然后在UEFI中选择一下Boot的优先级就可以从U盘中启动<em>Ubuntu</em>了。</p>\n<h2 id=\"References\"><a href=\"#References\" class=\"headerlink\" title=\"References\"></a>References</h2><ul>\n<li>[1] <a href=\"https://zhuanlan.zhihu.com/p/262069479\">Legacy / UEFI / MBR / GPT的关系</a></li>\n<li>[2] <a href=\"https://blog.csdn.net/u011433762/article/details/49934253\">EFI / Boot Loader / GRUB的关系</a></li>\n<li>[3] <a href=\"https://meaningofstuff.blogspot.com/2019/09/linux-ubuntu-1904-full-install-on-usb.html\">迁移Boot Loader到U盘</a></li>\n<li>[4] <a href=\"https://askubuntu.com/questions/429610/uninstall-grub-and-use-windows-bootloader/869888#869888\">删除Windows中的Grub</a></li>\n</ul>\n"},{"title":"技术总结《配置Vim》","date":"2018-09-27T03:15:27.000Z","description":["关于配置Vim的一些技术总结"],"_content":"\n本文主要介绍我自己的Vim配置（Ubuntu 16.04，主要用于写Python和C++）以及管理方案（如何将Vim配置快速部署到新机子上）。接下来首先介绍一款**强大的Vim配置**，然后介绍如何在该Vim配置的基础上**添加更多插件**，最后给出一个Vim配置**管理方案**。\n\n## The ultimate Vim configuration\n\n### 核心框架\n\n[The ultimate Vim configuration](https://github.com/amix/vimrc)是一份强大的Vim配置，它使用了Pathogen作为插件管理器（关于Vim插件管理器的发展可以看[这里](https://www.zhihu.com/question/24294358)），安装插件只需要**把插件放到对应目录**就好了（一般来说就是`git clone`）。按照[指引](https://github.com/amix/vimrc#install-for-your-own-user-only)安装完后，这份Vim配置的**核心目录结构**如下：\n\n```sh\n.vim_runtime\n│\n# default plugins & configurations\n├── sources_forked\n├── sources_non_forked\n├── vimrcs\n│   ├── basic.vim # general configurations\n│   └── plugins_config.vim # plugin configurations\n│\n# custom plugins & configurations\n├── my_plugins\n├── my_configs.vim # may not exist\n│\n# installer\n├── install_awesome_vimrc.sh\n```\n\n从以上目录结构可见，**核心框架**包含以下**三部分**：\n\n- 自带插件\n\t- `sources_forked`和`sources_non_forked`中包含了自带的插件；\n\t- `vimrcs`中的\n\t\t- `basic.vim`包含插件无关的通用配置（e.g., 一个tab等于4个空格）；\n\t\t- `plugins_config.vim`中包含了针对自带插件的配置。\n- 自定义插件\n\t- `my_plugins`是安装自定义插件的地方；\n\t- `my_configs.vim`则用于编写针对自定义插件的配置和插件无关的通用配置（值得注意的是，因为`my_configs.vim`在最后的`~/.vimrc`中是最后一个被引用的，因此假如它的配置与其他`.vim`有冲突的话，以`my_configs.vim`中的配置为准）。\n- 安装脚本\n\t- `install_awesome_vimrc.sh`包含修改`~/.vimrc`的代码。\n\n### 使用方法\n\n本节主要介绍**自带插件的使用方法**。\n\n- 打开/关闭文件\n\t- `,nn`：在Vim中打开目录树；\n\t- `,f`：查看最近使用过的文件；\n\t- `:W`：以sudo权限保存文件；\n\t- `gf`：当光标在一个路径上时，打开该文件。\n- 编辑\n\t- `gcc`：注释选中的行；\n\t- `$123 / $q / $e`：为选中的内容添加不同的括号/引号；\n\t- `Ctrl+s / Ctrl+x / Ctrl+p`：多光标（同时选中多个相同的内容，重构的时候很有用）；\n\t\t- 要实现这个功能，需要进行一些修改，参考[这里](https://github.com/amix/vimrc/issues/340)。简单来说就是要在`~/.bashrc`中加上`stty -ixon`。\n\t- `+ / _`：在逻辑意义上扩展/收缩选中的内容（e.g., 变量，函数，类）；\n\t\t- 要实现这个功能，需要再安装一些插件来告诉Vim怎么在逻辑意义上划分内容。以Python为例（参考[这里](https://github.com/terryma/vim-expand-region/issues/15)），大概分为以下两步：\n\t\t\t1. 将[vim-textobj-user](https://github.com/kana/vim-textobj-user)和[vim-textobj-python](https://github.com/bps/vim-textobj-python)下载到`my_plugins`；\n\t\t\t2. 在`my_configs.vim`中加上以下代码。\n\n```vim\ncall expand_region#custom_text_objects('python', {\n      \\ 'af' :1,\n      \\ 'if' :1,\n      \\ 'ac' :1,\n      \\ 'ic' :1,\n      \\ })\n```\n\n## 更多插件\n\n本节介绍如何在[The ultimate Vim configuration](https://github.com/amix/vimrc)的基础上，安装更多的插件，使Vim用起来更顺手。\n\n\n- [SimpylFold](https://github.com/tmhedberg/SimpylFold)\n\t- 功能：代码折叠插件，方便以不同层级去阅读代码；\n\t- 安装：下载到`my_plugins`文件夹中；\n\t- 使用：`za / zm / zr`。\n- [YouCompleteMe](https://github.com/Valloric/YouCompleteMe)\n\t- 功能：代码补全插件，同时还提供跳转功能（变量/函数的定义），能够大幅提高阅读代码的速度。\n\t- 安装：跟[指引](https://github.com/Valloric/YouCompleteMe#linux-64-bit)，用`install.py`来装；\n\t- 使用（下面仅针对Python，C++还要进一步配置来告诉这个插件编译的flag是什么，参考[这里](https://github.com/Valloric/YouCompleteMe#c-family-semantic-completion)）\n\t\t- 自动补全装好就能用；\n\t\t- 代码跳转需要设置一下快捷键，参考[这里](https://github.com/Valloric/YouCompleteMe#ycmcompleter-subcommands)。简单来说，就是将`nnoremap <leader>jd :YcmCompleter GoTo<CR>`加到`my_configs.vim`中，之后就可以通过`,jd`进行跳转了（跳转后可以用`Ctrl+o`返回）。\n\n## 管理方案\n\n用Vim的一个很大的motivation是通用性，也就是说在不同的机子上都能够用同一套顺手的IDE，这就对快速部署提出了要求。\n\n下面介绍我自己的方案，大体来说分为以下步骤：\n\n1. 将[The ultimate Vim configuration](https://github.com/amix/vimrc)`fork`到自己的Github上；\n2. 通过`git submodule add xxx`来安装插件；\n\t- 之所以不用`git clone`是预防嵌套Git repository无法`git push`的问题。\n3. 每次更新完插件/配置后`git push`到自己的Github；\n4. 在一台新的机子上，用`git clone --recursive`从自己的Github上下载配置文件\n\t- `--recursive`表明要把submodule都下载下来\n5. 运行`install_awesome_vimrc.sh`安装Vim配置\n\n## References\n\n- [Vim配置文件语法cheatsheet](https://devhints.io/vimscript)\n- [可用的Vim快捷键](https://vi.stackexchange.com/questions/8856/mapping-ctrl-with-equal-sign)\n- [Vim中编译、运行C++代码](https://www.quora.com/How-can-I-compile-and-execute-a-c++-program-directly-from-Vim-in-Ubuntu)\n- [Git submodule](https://blog.github.com/2016-02-01-working-with-submodules/)","source":"_posts/tech-vimrc.md","raw":"---\ntitle: 技术总结《配置Vim》\ndate: 2018-09-27 11:15:27\ntags:\n\t- Vim\ncategories:\n\t- 技术总结\ndescription:\n\t- 关于配置Vim的一些技术总结\n---\n\n本文主要介绍我自己的Vim配置（Ubuntu 16.04，主要用于写Python和C++）以及管理方案（如何将Vim配置快速部署到新机子上）。接下来首先介绍一款**强大的Vim配置**，然后介绍如何在该Vim配置的基础上**添加更多插件**，最后给出一个Vim配置**管理方案**。\n\n## The ultimate Vim configuration\n\n### 核心框架\n\n[The ultimate Vim configuration](https://github.com/amix/vimrc)是一份强大的Vim配置，它使用了Pathogen作为插件管理器（关于Vim插件管理器的发展可以看[这里](https://www.zhihu.com/question/24294358)），安装插件只需要**把插件放到对应目录**就好了（一般来说就是`git clone`）。按照[指引](https://github.com/amix/vimrc#install-for-your-own-user-only)安装完后，这份Vim配置的**核心目录结构**如下：\n\n```sh\n.vim_runtime\n│\n# default plugins & configurations\n├── sources_forked\n├── sources_non_forked\n├── vimrcs\n│   ├── basic.vim # general configurations\n│   └── plugins_config.vim # plugin configurations\n│\n# custom plugins & configurations\n├── my_plugins\n├── my_configs.vim # may not exist\n│\n# installer\n├── install_awesome_vimrc.sh\n```\n\n从以上目录结构可见，**核心框架**包含以下**三部分**：\n\n- 自带插件\n\t- `sources_forked`和`sources_non_forked`中包含了自带的插件；\n\t- `vimrcs`中的\n\t\t- `basic.vim`包含插件无关的通用配置（e.g., 一个tab等于4个空格）；\n\t\t- `plugins_config.vim`中包含了针对自带插件的配置。\n- 自定义插件\n\t- `my_plugins`是安装自定义插件的地方；\n\t- `my_configs.vim`则用于编写针对自定义插件的配置和插件无关的通用配置（值得注意的是，因为`my_configs.vim`在最后的`~/.vimrc`中是最后一个被引用的，因此假如它的配置与其他`.vim`有冲突的话，以`my_configs.vim`中的配置为准）。\n- 安装脚本\n\t- `install_awesome_vimrc.sh`包含修改`~/.vimrc`的代码。\n\n### 使用方法\n\n本节主要介绍**自带插件的使用方法**。\n\n- 打开/关闭文件\n\t- `,nn`：在Vim中打开目录树；\n\t- `,f`：查看最近使用过的文件；\n\t- `:W`：以sudo权限保存文件；\n\t- `gf`：当光标在一个路径上时，打开该文件。\n- 编辑\n\t- `gcc`：注释选中的行；\n\t- `$123 / $q / $e`：为选中的内容添加不同的括号/引号；\n\t- `Ctrl+s / Ctrl+x / Ctrl+p`：多光标（同时选中多个相同的内容，重构的时候很有用）；\n\t\t- 要实现这个功能，需要进行一些修改，参考[这里](https://github.com/amix/vimrc/issues/340)。简单来说就是要在`~/.bashrc`中加上`stty -ixon`。\n\t- `+ / _`：在逻辑意义上扩展/收缩选中的内容（e.g., 变量，函数，类）；\n\t\t- 要实现这个功能，需要再安装一些插件来告诉Vim怎么在逻辑意义上划分内容。以Python为例（参考[这里](https://github.com/terryma/vim-expand-region/issues/15)），大概分为以下两步：\n\t\t\t1. 将[vim-textobj-user](https://github.com/kana/vim-textobj-user)和[vim-textobj-python](https://github.com/bps/vim-textobj-python)下载到`my_plugins`；\n\t\t\t2. 在`my_configs.vim`中加上以下代码。\n\n```vim\ncall expand_region#custom_text_objects('python', {\n      \\ 'af' :1,\n      \\ 'if' :1,\n      \\ 'ac' :1,\n      \\ 'ic' :1,\n      \\ })\n```\n\n## 更多插件\n\n本节介绍如何在[The ultimate Vim configuration](https://github.com/amix/vimrc)的基础上，安装更多的插件，使Vim用起来更顺手。\n\n\n- [SimpylFold](https://github.com/tmhedberg/SimpylFold)\n\t- 功能：代码折叠插件，方便以不同层级去阅读代码；\n\t- 安装：下载到`my_plugins`文件夹中；\n\t- 使用：`za / zm / zr`。\n- [YouCompleteMe](https://github.com/Valloric/YouCompleteMe)\n\t- 功能：代码补全插件，同时还提供跳转功能（变量/函数的定义），能够大幅提高阅读代码的速度。\n\t- 安装：跟[指引](https://github.com/Valloric/YouCompleteMe#linux-64-bit)，用`install.py`来装；\n\t- 使用（下面仅针对Python，C++还要进一步配置来告诉这个插件编译的flag是什么，参考[这里](https://github.com/Valloric/YouCompleteMe#c-family-semantic-completion)）\n\t\t- 自动补全装好就能用；\n\t\t- 代码跳转需要设置一下快捷键，参考[这里](https://github.com/Valloric/YouCompleteMe#ycmcompleter-subcommands)。简单来说，就是将`nnoremap <leader>jd :YcmCompleter GoTo<CR>`加到`my_configs.vim`中，之后就可以通过`,jd`进行跳转了（跳转后可以用`Ctrl+o`返回）。\n\n## 管理方案\n\n用Vim的一个很大的motivation是通用性，也就是说在不同的机子上都能够用同一套顺手的IDE，这就对快速部署提出了要求。\n\n下面介绍我自己的方案，大体来说分为以下步骤：\n\n1. 将[The ultimate Vim configuration](https://github.com/amix/vimrc)`fork`到自己的Github上；\n2. 通过`git submodule add xxx`来安装插件；\n\t- 之所以不用`git clone`是预防嵌套Git repository无法`git push`的问题。\n3. 每次更新完插件/配置后`git push`到自己的Github；\n4. 在一台新的机子上，用`git clone --recursive`从自己的Github上下载配置文件\n\t- `--recursive`表明要把submodule都下载下来\n5. 运行`install_awesome_vimrc.sh`安装Vim配置\n\n## References\n\n- [Vim配置文件语法cheatsheet](https://devhints.io/vimscript)\n- [可用的Vim快捷键](https://vi.stackexchange.com/questions/8856/mapping-ctrl-with-equal-sign)\n- [Vim中编译、运行C++代码](https://www.quora.com/How-can-I-compile-and-execute-a-c++-program-directly-from-Vim-in-Ubuntu)\n- [Git submodule](https://blog.github.com/2016-02-01-working-with-submodules/)","slug":"tech-vimrc","published":1,"updated":"2024-08-13T16:03:47.884Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clzvf192r002aeqwoyvqy18hr","content":"<p>本文主要介绍我自己的Vim配置（Ubuntu 16.04，主要用于写Python和C++）以及管理方案（如何将Vim配置快速部署到新机子上）。接下来首先介绍一款<strong>强大的Vim配置</strong>，然后介绍如何在该Vim配置的基础上<strong>添加更多插件</strong>，最后给出一个Vim配置<strong>管理方案</strong>。</p>\n<h2 id=\"The-ultimate-Vim-configuration\"><a href=\"#The-ultimate-Vim-configuration\" class=\"headerlink\" title=\"The ultimate Vim configuration\"></a>The ultimate Vim configuration</h2><h3 id=\"核心框架\"><a href=\"#核心框架\" class=\"headerlink\" title=\"核心框架\"></a>核心框架</h3><p><a href=\"https://github.com/amix/vimrc\" target=\"_blank\" rel=\"external\">The ultimate Vim configuration</a>是一份强大的Vim配置，它使用了Pathogen作为插件管理器（关于Vim插件管理器的发展可以看<a href=\"https://www.zhihu.com/question/24294358\" target=\"_blank\" rel=\"external\">这里</a>），安装插件只需要<strong>把插件放到对应目录</strong>就好了（一般来说就是<code>git clone</code>）。按照<a href=\"https://github.com/amix/vimrc#install-for-your-own-user-only\" target=\"_blank\" rel=\"external\">指引</a>安装完后，这份Vim配置的<strong>核心目录结构</strong>如下：</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\">.vim_runtime</div><div class=\"line\">│</div><div class=\"line\"><span class=\"comment\"># default plugins &amp; configurations</span></div><div class=\"line\">├── sources_forked</div><div class=\"line\">├── sources_non_forked</div><div class=\"line\">├── vimrcs</div><div class=\"line\">│   ├── basic.vim <span class=\"comment\"># general configurations</span></div><div class=\"line\">│   └── plugins_config.vim <span class=\"comment\"># plugin configurations</span></div><div class=\"line\">│</div><div class=\"line\"><span class=\"comment\"># custom plugins &amp; configurations</span></div><div class=\"line\">├── my_plugins</div><div class=\"line\">├── my_configs.vim <span class=\"comment\"># may not exist</span></div><div class=\"line\">│</div><div class=\"line\"><span class=\"comment\"># installer</span></div><div class=\"line\">├── install_awesome_vimrc.sh</div></pre></td></tr></table></figure>\n<p>从以上目录结构可见，<strong>核心框架</strong>包含以下<strong>三部分</strong>：</p>\n<ul>\n<li>自带插件<ul>\n<li><code>sources_forked</code>和<code>sources_non_forked</code>中包含了自带的插件；</li>\n<li><code>vimrcs</code>中的<ul>\n<li><code>basic.vim</code>包含插件无关的通用配置（e.g., 一个tab等于4个空格）；</li>\n<li><code>plugins_config.vim</code>中包含了针对自带插件的配置。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>自定义插件<ul>\n<li><code>my_plugins</code>是安装自定义插件的地方；</li>\n<li><code>my_configs.vim</code>则用于编写针对自定义插件的配置和插件无关的通用配置（值得注意的是，因为<code>my_configs.vim</code>在最后的<code>~/.vimrc</code>中是最后一个被引用的，因此假如它的配置与其他<code>.vim</code>有冲突的话，以<code>my_configs.vim</code>中的配置为准）。</li>\n</ul>\n</li>\n<li>安装脚本<ul>\n<li><code>install_awesome_vimrc.sh</code>包含修改<code>~/.vimrc</code>的代码。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"使用方法\"><a href=\"#使用方法\" class=\"headerlink\" title=\"使用方法\"></a>使用方法</h3><p>本节主要介绍<strong>自带插件的使用方法</strong>。</p>\n<ul>\n<li>打开/关闭文件<ul>\n<li><code>,nn</code>：在Vim中打开目录树；</li>\n<li><code>,f</code>：查看最近使用过的文件；</li>\n<li><code>:W</code>：以sudo权限保存文件；</li>\n<li><code>gf</code>：当光标在一个路径上时，打开该文件。</li>\n</ul>\n</li>\n<li>编辑<ul>\n<li><code>gcc</code>：注释选中的行；</li>\n<li><code>$123 / $q / $e</code>：为选中的内容添加不同的括号/引号；</li>\n<li><code>Ctrl+s / Ctrl+x / Ctrl+p</code>：多光标（同时选中多个相同的内容，重构的时候很有用）；<ul>\n<li>要实现这个功能，需要进行一些修改，参考<a href=\"https://github.com/amix/vimrc/issues/340\" target=\"_blank\" rel=\"external\">这里</a>。简单来说就是要在<code>~/.bashrc</code>中加上<code>stty -ixon</code>。</li>\n</ul>\n</li>\n<li><code>+ / _</code>：在逻辑意义上扩展/收缩选中的内容（e.g., 变量，函数，类）；<ul>\n<li>要实现这个功能，需要再安装一些插件来告诉Vim怎么在逻辑意义上划分内容。以Python为例（参考<a href=\"https://github.com/terryma/vim-expand-region/issues/15\" target=\"_blank\" rel=\"external\">这里</a>），大概分为以下两步：<ol>\n<li>将<a href=\"https://github.com/kana/vim-textobj-user\" target=\"_blank\" rel=\"external\">vim-textobj-user</a>和<a href=\"https://github.com/bps/vim-textobj-python\" target=\"_blank\" rel=\"external\">vim-textobj-python</a>下载到<code>my_plugins</code>；</li>\n<li>在<code>my_configs.vim</code>中加上以下代码。</li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight vim\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">call</span> expand_region#custom_text_objects(<span class=\"string\">'python'</span>, &#123;</div><div class=\"line\">      \\ <span class=\"string\">'af'</span> :<span class=\"number\">1</span>,</div><div class=\"line\">      \\ <span class=\"string\">'if'</span> :<span class=\"number\">1</span>,</div><div class=\"line\">      \\ <span class=\"string\">'ac'</span> :<span class=\"number\">1</span>,</div><div class=\"line\">      \\ <span class=\"string\">'ic'</span> :<span class=\"number\">1</span>,</div><div class=\"line\">      \\ &#125;)</div></pre></td></tr></table></figure>\n<h2 id=\"更多插件\"><a href=\"#更多插件\" class=\"headerlink\" title=\"更多插件\"></a>更多插件</h2><p>本节介绍如何在<a href=\"https://github.com/amix/vimrc\" target=\"_blank\" rel=\"external\">The ultimate Vim configuration</a>的基础上，安装更多的插件，使Vim用起来更顺手。</p>\n<ul>\n<li><a href=\"https://github.com/tmhedberg/SimpylFold\" target=\"_blank\" rel=\"external\">SimpylFold</a><ul>\n<li>功能：代码折叠插件，方便以不同层级去阅读代码；</li>\n<li>安装：下载到<code>my_plugins</code>文件夹中；</li>\n<li>使用：<code>za / zm / zr</code>。</li>\n</ul>\n</li>\n<li><a href=\"https://github.com/Valloric/YouCompleteMe\" target=\"_blank\" rel=\"external\">YouCompleteMe</a><ul>\n<li>功能：代码补全插件，同时还提供跳转功能（变量/函数的定义），能够大幅提高阅读代码的速度。</li>\n<li>安装：跟<a href=\"https://github.com/Valloric/YouCompleteMe#linux-64-bit\" target=\"_blank\" rel=\"external\">指引</a>，用<code>install.py</code>来装；</li>\n<li>使用（下面仅针对Python，C++还要进一步配置来告诉这个插件编译的flag是什么，参考<a href=\"https://github.com/Valloric/YouCompleteMe#c-family-semantic-completion\" target=\"_blank\" rel=\"external\">这里</a>）<ul>\n<li>自动补全装好就能用；</li>\n<li>代码跳转需要设置一下快捷键，参考<a href=\"https://github.com/Valloric/YouCompleteMe#ycmcompleter-subcommands\" target=\"_blank\" rel=\"external\">这里</a>。简单来说，就是将<code>nnoremap &lt;leader&gt;jd :YcmCompleter GoTo&lt;CR&gt;</code>加到<code>my_configs.vim</code>中，之后就可以通过<code>,jd</code>进行跳转了（跳转后可以用<code>Ctrl+o</code>返回）。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"管理方案\"><a href=\"#管理方案\" class=\"headerlink\" title=\"管理方案\"></a>管理方案</h2><p>用Vim的一个很大的motivation是通用性，也就是说在不同的机子上都能够用同一套顺手的IDE，这就对快速部署提出了要求。</p>\n<p>下面介绍我自己的方案，大体来说分为以下步骤：</p>\n<ol>\n<li>将<a href=\"https://github.com/amix/vimrc\" target=\"_blank\" rel=\"external\">The ultimate Vim configuration</a><code>fork</code>到自己的Github上；</li>\n<li>通过<code>git submodule add xxx</code>来安装插件；<ul>\n<li>之所以不用<code>git clone</code>是预防嵌套Git repository无法<code>git push</code>的问题。</li>\n</ul>\n</li>\n<li>每次更新完插件/配置后<code>git push</code>到自己的Github；</li>\n<li>在一台新的机子上，用<code>git clone --recursive</code>从自己的Github上下载配置文件<ul>\n<li><code>--recursive</code>表明要把submodule都下载下来</li>\n</ul>\n</li>\n<li>运行<code>install_awesome_vimrc.sh</code>安装Vim配置</li>\n</ol>\n<h2 id=\"References\"><a href=\"#References\" class=\"headerlink\" title=\"References\"></a>References</h2><ul>\n<li><a href=\"https://devhints.io/vimscript\" target=\"_blank\" rel=\"external\">Vim配置文件语法cheatsheet</a></li>\n<li><a href=\"https://vi.stackexchange.com/questions/8856/mapping-ctrl-with-equal-sign\" target=\"_blank\" rel=\"external\">可用的Vim快捷键</a></li>\n<li><a href=\"https://www.quora.com/How-can-I-compile-and-execute-a-c++-program-directly-from-Vim-in-Ubuntu\" target=\"_blank\" rel=\"external\">Vim中编译、运行C++代码</a></li>\n<li><a href=\"https://blog.github.com/2016-02-01-working-with-submodules/\" target=\"_blank\" rel=\"external\">Git submodule</a></li>\n</ul>\n","excerpt":"","more":"<p>本文主要介绍我自己的Vim配置（Ubuntu 16.04，主要用于写Python和C++）以及管理方案（如何将Vim配置快速部署到新机子上）。接下来首先介绍一款<strong>强大的Vim配置</strong>，然后介绍如何在该Vim配置的基础上<strong>添加更多插件</strong>，最后给出一个Vim配置<strong>管理方案</strong>。</p>\n<h2 id=\"The-ultimate-Vim-configuration\"><a href=\"#The-ultimate-Vim-configuration\" class=\"headerlink\" title=\"The ultimate Vim configuration\"></a>The ultimate Vim configuration</h2><h3 id=\"核心框架\"><a href=\"#核心框架\" class=\"headerlink\" title=\"核心框架\"></a>核心框架</h3><p><a href=\"https://github.com/amix/vimrc\">The ultimate Vim configuration</a>是一份强大的Vim配置，它使用了Pathogen作为插件管理器（关于Vim插件管理器的发展可以看<a href=\"https://www.zhihu.com/question/24294358\">这里</a>），安装插件只需要<strong>把插件放到对应目录</strong>就好了（一般来说就是<code>git clone</code>）。按照<a href=\"https://github.com/amix/vimrc#install-for-your-own-user-only\">指引</a>安装完后，这份Vim配置的<strong>核心目录结构</strong>如下：</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\">.vim_runtime</div><div class=\"line\">│</div><div class=\"line\"><span class=\"comment\"># default plugins &amp; configurations</span></div><div class=\"line\">├── sources_forked</div><div class=\"line\">├── sources_non_forked</div><div class=\"line\">├── vimrcs</div><div class=\"line\">│   ├── basic.vim <span class=\"comment\"># general configurations</span></div><div class=\"line\">│   └── plugins_config.vim <span class=\"comment\"># plugin configurations</span></div><div class=\"line\">│</div><div class=\"line\"><span class=\"comment\"># custom plugins &amp; configurations</span></div><div class=\"line\">├── my_plugins</div><div class=\"line\">├── my_configs.vim <span class=\"comment\"># may not exist</span></div><div class=\"line\">│</div><div class=\"line\"><span class=\"comment\"># installer</span></div><div class=\"line\">├── install_awesome_vimrc.sh</div></pre></td></tr></table></figure>\n<p>从以上目录结构可见，<strong>核心框架</strong>包含以下<strong>三部分</strong>：</p>\n<ul>\n<li>自带插件<ul>\n<li><code>sources_forked</code>和<code>sources_non_forked</code>中包含了自带的插件；</li>\n<li><code>vimrcs</code>中的<ul>\n<li><code>basic.vim</code>包含插件无关的通用配置（e.g., 一个tab等于4个空格）；</li>\n<li><code>plugins_config.vim</code>中包含了针对自带插件的配置。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>自定义插件<ul>\n<li><code>my_plugins</code>是安装自定义插件的地方；</li>\n<li><code>my_configs.vim</code>则用于编写针对自定义插件的配置和插件无关的通用配置（值得注意的是，因为<code>my_configs.vim</code>在最后的<code>~/.vimrc</code>中是最后一个被引用的，因此假如它的配置与其他<code>.vim</code>有冲突的话，以<code>my_configs.vim</code>中的配置为准）。</li>\n</ul>\n</li>\n<li>安装脚本<ul>\n<li><code>install_awesome_vimrc.sh</code>包含修改<code>~/.vimrc</code>的代码。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"使用方法\"><a href=\"#使用方法\" class=\"headerlink\" title=\"使用方法\"></a>使用方法</h3><p>本节主要介绍<strong>自带插件的使用方法</strong>。</p>\n<ul>\n<li>打开/关闭文件<ul>\n<li><code>,nn</code>：在Vim中打开目录树；</li>\n<li><code>,f</code>：查看最近使用过的文件；</li>\n<li><code>:W</code>：以sudo权限保存文件；</li>\n<li><code>gf</code>：当光标在一个路径上时，打开该文件。</li>\n</ul>\n</li>\n<li>编辑<ul>\n<li><code>gcc</code>：注释选中的行；</li>\n<li><code>$123 / $q / $e</code>：为选中的内容添加不同的括号/引号；</li>\n<li><code>Ctrl+s / Ctrl+x / Ctrl+p</code>：多光标（同时选中多个相同的内容，重构的时候很有用）；<ul>\n<li>要实现这个功能，需要进行一些修改，参考<a href=\"https://github.com/amix/vimrc/issues/340\">这里</a>。简单来说就是要在<code>~/.bashrc</code>中加上<code>stty -ixon</code>。</li>\n</ul>\n</li>\n<li><code>+ / _</code>：在逻辑意义上扩展/收缩选中的内容（e.g., 变量，函数，类）；<ul>\n<li>要实现这个功能，需要再安装一些插件来告诉Vim怎么在逻辑意义上划分内容。以Python为例（参考<a href=\"https://github.com/terryma/vim-expand-region/issues/15\">这里</a>），大概分为以下两步：<ol>\n<li>将<a href=\"https://github.com/kana/vim-textobj-user\">vim-textobj-user</a>和<a href=\"https://github.com/bps/vim-textobj-python\">vim-textobj-python</a>下载到<code>my_plugins</code>；</li>\n<li>在<code>my_configs.vim</code>中加上以下代码。</li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight vim\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">call</span> expand_region#custom_text_objects(<span class=\"string\">'python'</span>, &#123;</div><div class=\"line\">      \\ <span class=\"string\">'af'</span> :<span class=\"number\">1</span>,</div><div class=\"line\">      \\ <span class=\"string\">'if'</span> :<span class=\"number\">1</span>,</div><div class=\"line\">      \\ <span class=\"string\">'ac'</span> :<span class=\"number\">1</span>,</div><div class=\"line\">      \\ <span class=\"string\">'ic'</span> :<span class=\"number\">1</span>,</div><div class=\"line\">      \\ &#125;)</div></pre></td></tr></table></figure>\n<h2 id=\"更多插件\"><a href=\"#更多插件\" class=\"headerlink\" title=\"更多插件\"></a>更多插件</h2><p>本节介绍如何在<a href=\"https://github.com/amix/vimrc\">The ultimate Vim configuration</a>的基础上，安装更多的插件，使Vim用起来更顺手。</p>\n<ul>\n<li><a href=\"https://github.com/tmhedberg/SimpylFold\">SimpylFold</a><ul>\n<li>功能：代码折叠插件，方便以不同层级去阅读代码；</li>\n<li>安装：下载到<code>my_plugins</code>文件夹中；</li>\n<li>使用：<code>za / zm / zr</code>。</li>\n</ul>\n</li>\n<li><a href=\"https://github.com/Valloric/YouCompleteMe\">YouCompleteMe</a><ul>\n<li>功能：代码补全插件，同时还提供跳转功能（变量/函数的定义），能够大幅提高阅读代码的速度。</li>\n<li>安装：跟<a href=\"https://github.com/Valloric/YouCompleteMe#linux-64-bit\">指引</a>，用<code>install.py</code>来装；</li>\n<li>使用（下面仅针对Python，C++还要进一步配置来告诉这个插件编译的flag是什么，参考<a href=\"https://github.com/Valloric/YouCompleteMe#c-family-semantic-completion\">这里</a>）<ul>\n<li>自动补全装好就能用；</li>\n<li>代码跳转需要设置一下快捷键，参考<a href=\"https://github.com/Valloric/YouCompleteMe#ycmcompleter-subcommands\">这里</a>。简单来说，就是将<code>nnoremap &lt;leader&gt;jd :YcmCompleter GoTo&lt;CR&gt;</code>加到<code>my_configs.vim</code>中，之后就可以通过<code>,jd</code>进行跳转了（跳转后可以用<code>Ctrl+o</code>返回）。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"管理方案\"><a href=\"#管理方案\" class=\"headerlink\" title=\"管理方案\"></a>管理方案</h2><p>用Vim的一个很大的motivation是通用性，也就是说在不同的机子上都能够用同一套顺手的IDE，这就对快速部署提出了要求。</p>\n<p>下面介绍我自己的方案，大体来说分为以下步骤：</p>\n<ol>\n<li>将<a href=\"https://github.com/amix/vimrc\">The ultimate Vim configuration</a><code>fork</code>到自己的Github上；</li>\n<li>通过<code>git submodule add xxx</code>来安装插件；<ul>\n<li>之所以不用<code>git clone</code>是预防嵌套Git repository无法<code>git push</code>的问题。</li>\n</ul>\n</li>\n<li>每次更新完插件/配置后<code>git push</code>到自己的Github；</li>\n<li>在一台新的机子上，用<code>git clone --recursive</code>从自己的Github上下载配置文件<ul>\n<li><code>--recursive</code>表明要把submodule都下载下来</li>\n</ul>\n</li>\n<li>运行<code>install_awesome_vimrc.sh</code>安装Vim配置</li>\n</ol>\n<h2 id=\"References\"><a href=\"#References\" class=\"headerlink\" title=\"References\"></a>References</h2><ul>\n<li><a href=\"https://devhints.io/vimscript\">Vim配置文件语法cheatsheet</a></li>\n<li><a href=\"https://vi.stackexchange.com/questions/8856/mapping-ctrl-with-equal-sign\">可用的Vim快捷键</a></li>\n<li><a href=\"https://www.quora.com/How-can-I-compile-and-execute-a-c++-program-directly-from-Vim-in-Ubuntu\">Vim中编译、运行C++代码</a></li>\n<li><a href=\"https://blog.github.com/2016-02-01-working-with-submodules/\">Git submodule</a></li>\n</ul>\n"},{"title":"技术总结《在Win11上构建UE5版本的Carla》","date":"2024-08-04T15:47:02.000Z","description":["记录在Win11上构建CarlaUE5所踩的坑"],"_content":"\nCarla是一个开源的自动驾驶仿真平台，其[最新版本](https://github.com/carla-simulator/carla/tree/ue5-dev)基于UE5开发，画面十分的逼真。\n\n本文主要记录在Win11上通过源码构建CarlaUE5时所碰到的问题以及解决方案，整理流程参考[官方教程](https://carla.readthedocs.io/en/latest/build_windows_ue5/)。\n\n在构建的过程中，主要碰到了以下问题：\n  \n- 本机已有的VS2022专业版，如何跳过默认的VS2022社区版安装流程，并把依赖安装到原有的VS2022专业版上；\n- 构建过程中报了一个跟编码格式相关的错；\n- 构建过程中报了一个跟路径长度相关的错。\n\n接下来分别介绍各个问题以及对应的解决方案。\n\n---\n\n# 使用已有的VS2022专业版\n\n## 修改`C:\\Carla\\CarlaUE5\\Setup.bat`\n\n- 注释掉安装VS2022社区版相关的代码\n- 将类似`C:\\Program Files\\Microsoft Visual Studio\\2022\\Community`的字段换成已有的VS2022专业版路径\n\n## 安装依赖\n\n如下所示，`C:\\Carla\\CarlaUE5\\Setup.bat`在安装VS2022社区版的时候，会顺带安装上一些依赖。\n\n```bat\nvs_Community.exe --add Microsoft.VisualStudio.Workload.NativeDesktop Microsoft.VisualStudio.Workload.NativeGame Microsoft.VisualStudio.Workload.ManagedDesktop Microsoft.VisualStudio.Component.Windows10SDK.18362  Microsoft.VisualStudio.Component.VC.CMake.Project Microsoft.Net.ComponentGroup.4.8.1.DeveloperTools Microsoft.VisualStudio.Component.VC.Llvm.Clang Microsoft.VisualStudio.Component.VC.Llvm.ClangToolset Microsoft.VisualStudio.ComponentGroup.NativeDesktop.Llvm.Clang --removeProductLang Es-es --addProductLang En-us --installWhileDownloading --passive --wait\n```\n\n没有这些依赖的话，在构建CarlaUE5的时候会报错`MSB3073`，因此我们需要手动把这些依赖装到已有的VS2022专业版上：\n\n- 手动安装依赖的方法，可以参考[这个网站](https://blog.csdn.net/weixin_42205218/article/details/107829229)\n- 依赖名字到组件名字的映射，可以参考[这个网站](https://learn.microsoft.com/zh-cn/visualstudio/install/workload-component-id-vs-professional?view=vs-2022)\n\n---\n\n# 编码格式报错\n\n## 问题\n\n构建CarlaUE5时，会报以下错误：\n\n```\n[33/413] Building C object CMakeFiles\\sqlite3.dir\\_deps\\sqlite3-src\\shell.c.obj\nFAILED: CMakeFiles/sqlite3.dir/_deps/sqlite3-src/shell.c.obj\nC:\\PROGRA~1\\MICROS~4\\2022\\PROFES~1\\VC\\Tools\\MSVC\\1436~1.325\\bin\\Hostx64\\x64\\cl.exe  /nologo -D_CRT_SECURE_NO_WARNINGS -IC:\\Carla\\CarlaUE5\\Build\\_deps\\zlib-src -IC:\\Carla\\CarlaUE5\\Build\\_deps\\zlib-build -IC:\\Carla\\CarlaUE5\\Build\\_deps\\libpng-src -IC:\\Carla\\CarlaUE5\\Build\\_deps\\libpng-build /DWIN32 /D_WINDOWS /O2 /Ob2 /DNDEBUG -std:c11 -MD /wd4005 /showIncludes /FoCMakeFiles\\sqlite3.dir\\_deps\\sqlite3-src\\shell.c.obj /FdCMakeFiles\\sqlite3.dir\\ /FS -c C:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c\nC:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(1): warning C4819: 该文件包含不能在当前代码页(936)中表示的字符。请将该文件保存为 Unicode 格式以防止数据丢失\nC:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(26303): warning C4819: 该文件包含不能在当前代码页(936)中表示的字符。请将该文件保存为 Unicode 格式以防止数据丢失\nC:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(26338): error C2001: 常量中有换行符\nC:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(26339): error C2143: 语法错误: 缺少“;”(在“const”的前面)\nC:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(26353): error C2065: “zBom”: 未声明的标识符\nC:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(26353): warning C4047: “=”:“int”与“const char *”的间接级别不同\nC:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(26420): error C2065: “zBom”: 未声明的标识符\nC:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(26420): warning C4047: “函数”:“const char *”与“int”的间接级别不同\nC:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(26420): warning C4024: “oPutsUtf8”: 形参和实参 1 的类型不同\nC:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(26433): error C2065: “zBom”: 未声明的标识符\nC:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(26433): warning C4047: “函数”:“const char *”与“int”的间接级别不同\nC:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(26433): warning C4024: “oPutsUtf8”: 形参和实参 1 的类型不同\n```\n\n## 解决\n\n按[这个PR](https://github.com/carla-simulator/carla/pull/8033)的方法，在`CMake/Common.cmake`中增加一行`add_compile_options (/utf-8)`即可解决问题。\n\n修改之后重新构建，可以在`C:\\Carla\\CarlaUE5\\Build\\build.ninja`中看到编译选项中已经加上了`/utf-8`\n\n```\nbuild CMakeFiles\\sqlite3.dir\\_deps\\sqlite3-src\\shell.c.obj: C_COMPILER__sqlite3_unscanned_Release C$:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c || cmake_object_order_depends_target_sqlite3\n  DEFINES = -D_CRT_SECURE_NO_WARNINGS\n  FLAGS = /DWIN32 /D_WINDOWS /O2 /Ob2 /DNDEBUG -std:c11 -MD /utf-8 /wd4005\n  INCLUDES = -IC:\\Carla\\CarlaUE5\\Build\\_deps\\zlib-src -IC:\\Carla\\CarlaUE5\\Build\\_deps\\zlib-build -IC:\\Carla\\CarlaUE5\\Build\\_deps\\libpng-src -IC:\\Carla\\CarlaUE5\\Build\\_deps\\libpng-build\n  OBJECT_DIR = CMakeFiles\\sqlite3.dir\n  OBJECT_FILE_DIR = CMakeFiles\\sqlite3.dir\\_deps\\sqlite3-src\n  TARGET_COMPILE_PDB = CMakeFiles\\sqlite3.dir\\\n  TARGET_PDB = sqlite3.pdb\n```\n\n---\n\n# 路径过长报错\n\n## 问题\n\n构建的时候会陷入死循环，一直卡在其中一步，报错的提示指向文件路径名太长。\n\n## 解决\n\n参考[这个网站](https://blog.csdn.net/weixin_46356818/article/details/121029550)，将Windows对长路径的支持打开即可。\n\n\n<!-- https://github.com/carla-simulator/carla/pull/8033\n\nC:\\Carla\\CarlaUE5\\Build\\build.ninja\n\nbuild CMakeFiles\\sqlite3.dir\\_deps\\sqlite3-src\\shell.c.obj: C_COMPILER__sqlite3_unscanned_Release C$:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c || cmake_object_order_depends_target_sqlite3\n  DEFINES = -D_CRT_SECURE_NO_WARNINGS\n  FLAGS = /DWIN32 /D_WINDOWS /O2 /Ob2 /DNDEBUG -std:c11 -MD /utf-8 /wd4005\n  INCLUDES = -IC:\\Carla\\CarlaUE5\\Build\\_deps\\zlib-src -IC:\\Carla\\CarlaUE5\\Build\\_deps\\zlib-build -IC:\\Carla\\CarlaUE5\\Build\\_deps\\libpng-src -IC:\\Carla\\CarlaUE5\\Build\\_deps\\libpng-build\n  OBJECT_DIR = CMakeFiles\\sqlite3.dir\n  OBJECT_FILE_DIR = CMakeFiles\\sqlite3.dir\\_deps\\sqlite3-src\n  TARGET_COMPILE_PDB = CMakeFiles\\sqlite3.dir\\\n  TARGET_PDB = sqlite3.pdb\n\n\nbuild CMakeFiles\\sqlite3.dir\\_deps\\sqlite3-src\\shell.c.obj: C_COMPILER__sqlite3_unscanned_Release C$:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c || cmake_object_order_depends_target_sqlite3\n  DEFINES = -D_CRT_SECURE_NO_WARNINGS\n  FLAGS = /DWIN32 /D_WINDOWS /O2 /Ob2 /DNDEBUG -std:c11 -MD /wd4005\n  INCLUDES = -IC:\\Carla\\CarlaUE5\\Build\\_deps\\zlib-src -IC:\\Carla\\CarlaUE5\\Build\\_deps\\zlib-build -IC:\\Carla\\CarlaUE5\\Build\\_deps\\libpng-src -IC:\\Carla\\CarlaUE5\\Build\\_deps\\libpng-build\n  OBJECT_DIR = CMakeFiles\\sqlite3.dir\n  OBJECT_FILE_DIR = CMakeFiles\\sqlite3.dir\\_deps\\sqlite3-src\n  TARGET_COMPILE_PDB = CMakeFiles\\sqlite3.dir\\\n  TARGET_PDB = sqlite3.pdb\n\nhttps://www.cnblogs.com/mechanicoder/p/16894144.html\n\nMSB3073\n\nhttps://learn.microsoft.com/zh-cn/visualstudio/install/workload-component-id-vs-professional?view=vs-2022\n\n@REM echo Installing Visual Studio 2022...\n@REM curl -L -O https://aka.ms/vs/17/release/vs_community.exe || exit /b\n@REM vs_Community.exe --add Microsoft.VisualStudio.Workload.NativeDesktop Microsoft.VisualStudio.Workload.NativeGame Microsoft.VisualStudio.Workload.ManagedDesktop Microsoft.VisualStudio.Component.Windows10SDK.18362  Microsoft.VisualStudio.Component.VC.CMake.Project Microsoft.Net.ComponentGroup.4.8.1.DeveloperTools Microsoft.VisualStudio.Component.VC.Llvm.Clang Microsoft.VisualStudio.Component.VC.Llvm.ClangToolset Microsoft.VisualStudio.ComponentGroup.NativeDesktop.Llvm.Clang --removeProductLang Es-es --addProductLang En-us --installWhileDownloading --passive --wait\n@REM del vs_community.exe\n@REM curl -L -O https://aka.ms/vs/17/release/vs_professional.exe || exit /b\n@REM vs_Professional.exe --add Microsoft.VisualStudio.Workload.NativeDesktop Microsoft.VisualStudio.Workload.NativeGame Microsoft.VisualStudio.Workload.ManagedDesktop Microsoft.VisualStudio.Component.Windows10SDK.18362  Microsoft.VisualStudio.Component.VC.CMake.Project Microsoft.Net.ComponentGroup.4.8.1.DeveloperTools Microsoft.VisualStudio.Component.VC.Llvm.Clang Microsoft.VisualStudio.Component.VC.Llvm.ClangToolset Microsoft.VisualStudio.ComponentGroup.NativeDesktop.Llvm.Clang --removeProductLang Es-es --addProductLang En-us --installWhileDownloading --passive --wait\n@REM del vs_professional.exe\n@REM echo Visual Studion 2022 Installed!!!\n\nC:\\Carla\\CarlaUE5\\Setup.bat\n\nhttps://blog.csdn.net/weixin_46356818/article/details/121029550 -->","source":"_posts/tech-windows-ue5-carla-build.md","raw":"---\ntitle: 技术总结《在Win11上构建UE5版本的Carla》\ndate: 2024-08-04 23:47:02\ntags:\n\t- CarlaUE5\ncategories:\n\t- 技术总结\ndescription:\n\t- 记录在Win11上构建CarlaUE5所踩的坑\n---\n\nCarla是一个开源的自动驾驶仿真平台，其[最新版本](https://github.com/carla-simulator/carla/tree/ue5-dev)基于UE5开发，画面十分的逼真。\n\n本文主要记录在Win11上通过源码构建CarlaUE5时所碰到的问题以及解决方案，整理流程参考[官方教程](https://carla.readthedocs.io/en/latest/build_windows_ue5/)。\n\n在构建的过程中，主要碰到了以下问题：\n  \n- 本机已有的VS2022专业版，如何跳过默认的VS2022社区版安装流程，并把依赖安装到原有的VS2022专业版上；\n- 构建过程中报了一个跟编码格式相关的错；\n- 构建过程中报了一个跟路径长度相关的错。\n\n接下来分别介绍各个问题以及对应的解决方案。\n\n---\n\n# 使用已有的VS2022专业版\n\n## 修改`C:\\Carla\\CarlaUE5\\Setup.bat`\n\n- 注释掉安装VS2022社区版相关的代码\n- 将类似`C:\\Program Files\\Microsoft Visual Studio\\2022\\Community`的字段换成已有的VS2022专业版路径\n\n## 安装依赖\n\n如下所示，`C:\\Carla\\CarlaUE5\\Setup.bat`在安装VS2022社区版的时候，会顺带安装上一些依赖。\n\n```bat\nvs_Community.exe --add Microsoft.VisualStudio.Workload.NativeDesktop Microsoft.VisualStudio.Workload.NativeGame Microsoft.VisualStudio.Workload.ManagedDesktop Microsoft.VisualStudio.Component.Windows10SDK.18362  Microsoft.VisualStudio.Component.VC.CMake.Project Microsoft.Net.ComponentGroup.4.8.1.DeveloperTools Microsoft.VisualStudio.Component.VC.Llvm.Clang Microsoft.VisualStudio.Component.VC.Llvm.ClangToolset Microsoft.VisualStudio.ComponentGroup.NativeDesktop.Llvm.Clang --removeProductLang Es-es --addProductLang En-us --installWhileDownloading --passive --wait\n```\n\n没有这些依赖的话，在构建CarlaUE5的时候会报错`MSB3073`，因此我们需要手动把这些依赖装到已有的VS2022专业版上：\n\n- 手动安装依赖的方法，可以参考[这个网站](https://blog.csdn.net/weixin_42205218/article/details/107829229)\n- 依赖名字到组件名字的映射，可以参考[这个网站](https://learn.microsoft.com/zh-cn/visualstudio/install/workload-component-id-vs-professional?view=vs-2022)\n\n---\n\n# 编码格式报错\n\n## 问题\n\n构建CarlaUE5时，会报以下错误：\n\n```\n[33/413] Building C object CMakeFiles\\sqlite3.dir\\_deps\\sqlite3-src\\shell.c.obj\nFAILED: CMakeFiles/sqlite3.dir/_deps/sqlite3-src/shell.c.obj\nC:\\PROGRA~1\\MICROS~4\\2022\\PROFES~1\\VC\\Tools\\MSVC\\1436~1.325\\bin\\Hostx64\\x64\\cl.exe  /nologo -D_CRT_SECURE_NO_WARNINGS -IC:\\Carla\\CarlaUE5\\Build\\_deps\\zlib-src -IC:\\Carla\\CarlaUE5\\Build\\_deps\\zlib-build -IC:\\Carla\\CarlaUE5\\Build\\_deps\\libpng-src -IC:\\Carla\\CarlaUE5\\Build\\_deps\\libpng-build /DWIN32 /D_WINDOWS /O2 /Ob2 /DNDEBUG -std:c11 -MD /wd4005 /showIncludes /FoCMakeFiles\\sqlite3.dir\\_deps\\sqlite3-src\\shell.c.obj /FdCMakeFiles\\sqlite3.dir\\ /FS -c C:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c\nC:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(1): warning C4819: 该文件包含不能在当前代码页(936)中表示的字符。请将该文件保存为 Unicode 格式以防止数据丢失\nC:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(26303): warning C4819: 该文件包含不能在当前代码页(936)中表示的字符。请将该文件保存为 Unicode 格式以防止数据丢失\nC:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(26338): error C2001: 常量中有换行符\nC:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(26339): error C2143: 语法错误: 缺少“;”(在“const”的前面)\nC:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(26353): error C2065: “zBom”: 未声明的标识符\nC:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(26353): warning C4047: “=”:“int”与“const char *”的间接级别不同\nC:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(26420): error C2065: “zBom”: 未声明的标识符\nC:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(26420): warning C4047: “函数”:“const char *”与“int”的间接级别不同\nC:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(26420): warning C4024: “oPutsUtf8”: 形参和实参 1 的类型不同\nC:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(26433): error C2065: “zBom”: 未声明的标识符\nC:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(26433): warning C4047: “函数”:“const char *”与“int”的间接级别不同\nC:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(26433): warning C4024: “oPutsUtf8”: 形参和实参 1 的类型不同\n```\n\n## 解决\n\n按[这个PR](https://github.com/carla-simulator/carla/pull/8033)的方法，在`CMake/Common.cmake`中增加一行`add_compile_options (/utf-8)`即可解决问题。\n\n修改之后重新构建，可以在`C:\\Carla\\CarlaUE5\\Build\\build.ninja`中看到编译选项中已经加上了`/utf-8`\n\n```\nbuild CMakeFiles\\sqlite3.dir\\_deps\\sqlite3-src\\shell.c.obj: C_COMPILER__sqlite3_unscanned_Release C$:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c || cmake_object_order_depends_target_sqlite3\n  DEFINES = -D_CRT_SECURE_NO_WARNINGS\n  FLAGS = /DWIN32 /D_WINDOWS /O2 /Ob2 /DNDEBUG -std:c11 -MD /utf-8 /wd4005\n  INCLUDES = -IC:\\Carla\\CarlaUE5\\Build\\_deps\\zlib-src -IC:\\Carla\\CarlaUE5\\Build\\_deps\\zlib-build -IC:\\Carla\\CarlaUE5\\Build\\_deps\\libpng-src -IC:\\Carla\\CarlaUE5\\Build\\_deps\\libpng-build\n  OBJECT_DIR = CMakeFiles\\sqlite3.dir\n  OBJECT_FILE_DIR = CMakeFiles\\sqlite3.dir\\_deps\\sqlite3-src\n  TARGET_COMPILE_PDB = CMakeFiles\\sqlite3.dir\\\n  TARGET_PDB = sqlite3.pdb\n```\n\n---\n\n# 路径过长报错\n\n## 问题\n\n构建的时候会陷入死循环，一直卡在其中一步，报错的提示指向文件路径名太长。\n\n## 解决\n\n参考[这个网站](https://blog.csdn.net/weixin_46356818/article/details/121029550)，将Windows对长路径的支持打开即可。\n\n\n<!-- https://github.com/carla-simulator/carla/pull/8033\n\nC:\\Carla\\CarlaUE5\\Build\\build.ninja\n\nbuild CMakeFiles\\sqlite3.dir\\_deps\\sqlite3-src\\shell.c.obj: C_COMPILER__sqlite3_unscanned_Release C$:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c || cmake_object_order_depends_target_sqlite3\n  DEFINES = -D_CRT_SECURE_NO_WARNINGS\n  FLAGS = /DWIN32 /D_WINDOWS /O2 /Ob2 /DNDEBUG -std:c11 -MD /utf-8 /wd4005\n  INCLUDES = -IC:\\Carla\\CarlaUE5\\Build\\_deps\\zlib-src -IC:\\Carla\\CarlaUE5\\Build\\_deps\\zlib-build -IC:\\Carla\\CarlaUE5\\Build\\_deps\\libpng-src -IC:\\Carla\\CarlaUE5\\Build\\_deps\\libpng-build\n  OBJECT_DIR = CMakeFiles\\sqlite3.dir\n  OBJECT_FILE_DIR = CMakeFiles\\sqlite3.dir\\_deps\\sqlite3-src\n  TARGET_COMPILE_PDB = CMakeFiles\\sqlite3.dir\\\n  TARGET_PDB = sqlite3.pdb\n\n\nbuild CMakeFiles\\sqlite3.dir\\_deps\\sqlite3-src\\shell.c.obj: C_COMPILER__sqlite3_unscanned_Release C$:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c || cmake_object_order_depends_target_sqlite3\n  DEFINES = -D_CRT_SECURE_NO_WARNINGS\n  FLAGS = /DWIN32 /D_WINDOWS /O2 /Ob2 /DNDEBUG -std:c11 -MD /wd4005\n  INCLUDES = -IC:\\Carla\\CarlaUE5\\Build\\_deps\\zlib-src -IC:\\Carla\\CarlaUE5\\Build\\_deps\\zlib-build -IC:\\Carla\\CarlaUE5\\Build\\_deps\\libpng-src -IC:\\Carla\\CarlaUE5\\Build\\_deps\\libpng-build\n  OBJECT_DIR = CMakeFiles\\sqlite3.dir\n  OBJECT_FILE_DIR = CMakeFiles\\sqlite3.dir\\_deps\\sqlite3-src\n  TARGET_COMPILE_PDB = CMakeFiles\\sqlite3.dir\\\n  TARGET_PDB = sqlite3.pdb\n\nhttps://www.cnblogs.com/mechanicoder/p/16894144.html\n\nMSB3073\n\nhttps://learn.microsoft.com/zh-cn/visualstudio/install/workload-component-id-vs-professional?view=vs-2022\n\n@REM echo Installing Visual Studio 2022...\n@REM curl -L -O https://aka.ms/vs/17/release/vs_community.exe || exit /b\n@REM vs_Community.exe --add Microsoft.VisualStudio.Workload.NativeDesktop Microsoft.VisualStudio.Workload.NativeGame Microsoft.VisualStudio.Workload.ManagedDesktop Microsoft.VisualStudio.Component.Windows10SDK.18362  Microsoft.VisualStudio.Component.VC.CMake.Project Microsoft.Net.ComponentGroup.4.8.1.DeveloperTools Microsoft.VisualStudio.Component.VC.Llvm.Clang Microsoft.VisualStudio.Component.VC.Llvm.ClangToolset Microsoft.VisualStudio.ComponentGroup.NativeDesktop.Llvm.Clang --removeProductLang Es-es --addProductLang En-us --installWhileDownloading --passive --wait\n@REM del vs_community.exe\n@REM curl -L -O https://aka.ms/vs/17/release/vs_professional.exe || exit /b\n@REM vs_Professional.exe --add Microsoft.VisualStudio.Workload.NativeDesktop Microsoft.VisualStudio.Workload.NativeGame Microsoft.VisualStudio.Workload.ManagedDesktop Microsoft.VisualStudio.Component.Windows10SDK.18362  Microsoft.VisualStudio.Component.VC.CMake.Project Microsoft.Net.ComponentGroup.4.8.1.DeveloperTools Microsoft.VisualStudio.Component.VC.Llvm.Clang Microsoft.VisualStudio.Component.VC.Llvm.ClangToolset Microsoft.VisualStudio.ComponentGroup.NativeDesktop.Llvm.Clang --removeProductLang Es-es --addProductLang En-us --installWhileDownloading --passive --wait\n@REM del vs_professional.exe\n@REM echo Visual Studion 2022 Installed!!!\n\nC:\\Carla\\CarlaUE5\\Setup.bat\n\nhttps://blog.csdn.net/weixin_46356818/article/details/121029550 -->","slug":"tech-windows-ue5-carla-build","published":1,"updated":"2024-08-13T16:03:47.884Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clzvf192s002ceqwoh7c2ce4e","content":"<p>Carla是一个开源的自动驾驶仿真平台，其<a href=\"https://github.com/carla-simulator/carla/tree/ue5-dev\" target=\"_blank\" rel=\"external\">最新版本</a>基于UE5开发，画面十分的逼真。</p>\n<p>本文主要记录在Win11上通过源码构建CarlaUE5时所碰到的问题以及解决方案，整理流程参考<a href=\"https://carla.readthedocs.io/en/latest/build_windows_ue5/\" target=\"_blank\" rel=\"external\">官方教程</a>。</p>\n<p>在构建的过程中，主要碰到了以下问题：</p>\n<ul>\n<li>本机已有的VS2022专业版，如何跳过默认的VS2022社区版安装流程，并把依赖安装到原有的VS2022专业版上；</li>\n<li>构建过程中报了一个跟编码格式相关的错；</li>\n<li>构建过程中报了一个跟路径长度相关的错。</li>\n</ul>\n<p>接下来分别介绍各个问题以及对应的解决方案。</p>\n<hr>\n<h1 id=\"使用已有的VS2022专业版\"><a href=\"#使用已有的VS2022专业版\" class=\"headerlink\" title=\"使用已有的VS2022专业版\"></a>使用已有的VS2022专业版</h1><h2 id=\"修改C-Carla-CarlaUE5-Setup-bat\"><a href=\"#修改C-Carla-CarlaUE5-Setup-bat\" class=\"headerlink\" title=\"修改C:\\Carla\\CarlaUE5\\Setup.bat\"></a>修改<code>C:\\Carla\\CarlaUE5\\Setup.bat</code></h2><ul>\n<li>注释掉安装VS2022社区版相关的代码</li>\n<li>将类似<code>C:\\Program Files\\Microsoft Visual Studio\\2022\\Community</code>的字段换成已有的VS2022专业版路径</li>\n</ul>\n<h2 id=\"安装依赖\"><a href=\"#安装依赖\" class=\"headerlink\" title=\"安装依赖\"></a>安装依赖</h2><p>如下所示，<code>C:\\Carla\\CarlaUE5\\Setup.bat</code>在安装VS2022社区版的时候，会顺带安装上一些依赖。</p>\n<figure class=\"highlight bat\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">vs_Community.exe --add Microsoft.VisualStudio.Workload.NativeDesktop Microsoft.VisualStudio.Workload.NativeGame Microsoft.VisualStudio.Workload.ManagedDesktop Microsoft.VisualStudio.Component.Windows10SDK.<span class=\"number\">18362</span>  Microsoft.VisualStudio.Component.VC.CMake.Project Microsoft.<span class=\"built_in\">Net</span>.ComponentGroup.<span class=\"number\">4</span>.<span class=\"number\">8</span>.<span class=\"number\">1</span>.DeveloperTools Microsoft.VisualStudio.Component.VC.Llvm.Clang Microsoft.VisualStudio.Component.VC.Llvm.ClangToolset Microsoft.VisualStudio.ComponentGroup.NativeDesktop.Llvm.Clang --removeProductLang Es-es --addProductLang En-us --installWhileDownloading --passive --wait</div></pre></td></tr></table></figure>\n<p>没有这些依赖的话，在构建CarlaUE5的时候会报错<code>MSB3073</code>，因此我们需要手动把这些依赖装到已有的VS2022专业版上：</p>\n<ul>\n<li>手动安装依赖的方法，可以参考<a href=\"https://blog.csdn.net/weixin_42205218/article/details/107829229\" target=\"_blank\" rel=\"external\">这个网站</a></li>\n<li>依赖名字到组件名字的映射，可以参考<a href=\"https://learn.microsoft.com/zh-cn/visualstudio/install/workload-component-id-vs-professional?view=vs-2022\" target=\"_blank\" rel=\"external\">这个网站</a></li>\n</ul>\n<hr>\n<h1 id=\"编码格式报错\"><a href=\"#编码格式报错\" class=\"headerlink\" title=\"编码格式报错\"></a>编码格式报错</h1><h2 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h2><p>构建CarlaUE5时，会报以下错误：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\">[33/413] Building C object CMakeFiles\\sqlite3.dir\\_deps\\sqlite3-src\\shell.c.obj</div><div class=\"line\">FAILED: CMakeFiles/sqlite3.dir/_deps/sqlite3-src/shell.c.obj</div><div class=\"line\">C:\\PROGRA~1\\MICROS~4\\2022\\PROFES~1\\VC\\Tools\\MSVC\\1436~1.325\\bin\\Hostx64\\x64\\cl.exe  /nologo -D_CRT_SECURE_NO_WARNINGS -IC:\\Carla\\CarlaUE5\\Build\\_deps\\zlib-src -IC:\\Carla\\CarlaUE5\\Build\\_deps\\zlib-build -IC:\\Carla\\CarlaUE5\\Build\\_deps\\libpng-src -IC:\\Carla\\CarlaUE5\\Build\\_deps\\libpng-build /DWIN32 /D_WINDOWS /O2 /Ob2 /DNDEBUG -std:c11 -MD /wd4005 /showIncludes /FoCMakeFiles\\sqlite3.dir\\_deps\\sqlite3-src\\shell.c.obj /FdCMakeFiles\\sqlite3.dir\\ /FS -c C:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c</div><div class=\"line\">C:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(1): warning C4819: 该文件包含不能在当前代码页(936)中表示的字符。请将该文件保存为 Unicode 格式以防止数据丢失</div><div class=\"line\">C:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(26303): warning C4819: 该文件包含不能在当前代码页(936)中表示的字符。请将该文件保存为 Unicode 格式以防止数据丢失</div><div class=\"line\">C:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(26338): error C2001: 常量中有换行符</div><div class=\"line\">C:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(26339): error C2143: 语法错误: 缺少“;”(在“const”的前面)</div><div class=\"line\">C:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(26353): error C2065: “zBom”: 未声明的标识符</div><div class=\"line\">C:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(26353): warning C4047: “=”:“int”与“const char *”的间接级别不同</div><div class=\"line\">C:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(26420): error C2065: “zBom”: 未声明的标识符</div><div class=\"line\">C:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(26420): warning C4047: “函数”:“const char *”与“int”的间接级别不同</div><div class=\"line\">C:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(26420): warning C4024: “oPutsUtf8”: 形参和实参 1 的类型不同</div><div class=\"line\">C:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(26433): error C2065: “zBom”: 未声明的标识符</div><div class=\"line\">C:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(26433): warning C4047: “函数”:“const char *”与“int”的间接级别不同</div><div class=\"line\">C:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(26433): warning C4024: “oPutsUtf8”: 形参和实参 1 的类型不同</div></pre></td></tr></table></figure>\n<h2 id=\"解决\"><a href=\"#解决\" class=\"headerlink\" title=\"解决\"></a>解决</h2><p>按<a href=\"https://github.com/carla-simulator/carla/pull/8033\" target=\"_blank\" rel=\"external\">这个PR</a>的方法，在<code>CMake/Common.cmake</code>中增加一行<code>add_compile_options (/utf-8)</code>即可解决问题。</p>\n<p>修改之后重新构建，可以在<code>C:\\Carla\\CarlaUE5\\Build\\build.ninja</code>中看到编译选项中已经加上了<code>/utf-8</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">build CMakeFiles\\sqlite3.dir\\_deps\\sqlite3-src\\shell.c.obj: C_COMPILER__sqlite3_unscanned_Release C$:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c || cmake_object_order_depends_target_sqlite3</div><div class=\"line\">  DEFINES = -D_CRT_SECURE_NO_WARNINGS</div><div class=\"line\">  FLAGS = /DWIN32 /D_WINDOWS /O2 /Ob2 /DNDEBUG -std:c11 -MD /utf-8 /wd4005</div><div class=\"line\">  INCLUDES = -IC:\\Carla\\CarlaUE5\\Build\\_deps\\zlib-src -IC:\\Carla\\CarlaUE5\\Build\\_deps\\zlib-build -IC:\\Carla\\CarlaUE5\\Build\\_deps\\libpng-src -IC:\\Carla\\CarlaUE5\\Build\\_deps\\libpng-build</div><div class=\"line\">  OBJECT_DIR = CMakeFiles\\sqlite3.dir</div><div class=\"line\">  OBJECT_FILE_DIR = CMakeFiles\\sqlite3.dir\\_deps\\sqlite3-src</div><div class=\"line\">  TARGET_COMPILE_PDB = CMakeFiles\\sqlite3.dir\\</div><div class=\"line\">  TARGET_PDB = sqlite3.pdb</div></pre></td></tr></table></figure>\n<hr>\n<h1 id=\"路径过长报错\"><a href=\"#路径过长报错\" class=\"headerlink\" title=\"路径过长报错\"></a>路径过长报错</h1><h2 id=\"问题-1\"><a href=\"#问题-1\" class=\"headerlink\" title=\"问题\"></a>问题</h2><p>构建的时候会陷入死循环，一直卡在其中一步，报错的提示指向文件路径名太长。</p>\n<h2 id=\"解决-1\"><a href=\"#解决-1\" class=\"headerlink\" title=\"解决\"></a>解决</h2><p>参考<a href=\"https://blog.csdn.net/weixin_46356818/article/details/121029550\" target=\"_blank\" rel=\"external\">这个网站</a>，将Windows对长路径的支持打开即可。</p>\n<!-- https://github.com/carla-simulator/carla/pull/8033\n\nC:\\Carla\\CarlaUE5\\Build\\build.ninja\n\nbuild CMakeFiles\\sqlite3.dir\\_deps\\sqlite3-src\\shell.c.obj: C_COMPILER__sqlite3_unscanned_Release C$:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c || cmake_object_order_depends_target_sqlite3\n  DEFINES = -D_CRT_SECURE_NO_WARNINGS\n  FLAGS = /DWIN32 /D_WINDOWS /O2 /Ob2 /DNDEBUG -std:c11 -MD /utf-8 /wd4005\n  INCLUDES = -IC:\\Carla\\CarlaUE5\\Build\\_deps\\zlib-src -IC:\\Carla\\CarlaUE5\\Build\\_deps\\zlib-build -IC:\\Carla\\CarlaUE5\\Build\\_deps\\libpng-src -IC:\\Carla\\CarlaUE5\\Build\\_deps\\libpng-build\n  OBJECT_DIR = CMakeFiles\\sqlite3.dir\n  OBJECT_FILE_DIR = CMakeFiles\\sqlite3.dir\\_deps\\sqlite3-src\n  TARGET_COMPILE_PDB = CMakeFiles\\sqlite3.dir\\\n  TARGET_PDB = sqlite3.pdb\n\n\nbuild CMakeFiles\\sqlite3.dir\\_deps\\sqlite3-src\\shell.c.obj: C_COMPILER__sqlite3_unscanned_Release C$:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c || cmake_object_order_depends_target_sqlite3\n  DEFINES = -D_CRT_SECURE_NO_WARNINGS\n  FLAGS = /DWIN32 /D_WINDOWS /O2 /Ob2 /DNDEBUG -std:c11 -MD /wd4005\n  INCLUDES = -IC:\\Carla\\CarlaUE5\\Build\\_deps\\zlib-src -IC:\\Carla\\CarlaUE5\\Build\\_deps\\zlib-build -IC:\\Carla\\CarlaUE5\\Build\\_deps\\libpng-src -IC:\\Carla\\CarlaUE5\\Build\\_deps\\libpng-build\n  OBJECT_DIR = CMakeFiles\\sqlite3.dir\n  OBJECT_FILE_DIR = CMakeFiles\\sqlite3.dir\\_deps\\sqlite3-src\n  TARGET_COMPILE_PDB = CMakeFiles\\sqlite3.dir\\\n  TARGET_PDB = sqlite3.pdb\n\nhttps://www.cnblogs.com/mechanicoder/p/16894144.html\n\nMSB3073\n\nhttps://learn.microsoft.com/zh-cn/visualstudio/install/workload-component-id-vs-professional?view=vs-2022\n\n@REM echo Installing Visual Studio 2022...\n@REM curl -L -O https://aka.ms/vs/17/release/vs_community.exe || exit /b\n@REM vs_Community.exe --add Microsoft.VisualStudio.Workload.NativeDesktop Microsoft.VisualStudio.Workload.NativeGame Microsoft.VisualStudio.Workload.ManagedDesktop Microsoft.VisualStudio.Component.Windows10SDK.18362  Microsoft.VisualStudio.Component.VC.CMake.Project Microsoft.Net.ComponentGroup.4.8.1.DeveloperTools Microsoft.VisualStudio.Component.VC.Llvm.Clang Microsoft.VisualStudio.Component.VC.Llvm.ClangToolset Microsoft.VisualStudio.ComponentGroup.NativeDesktop.Llvm.Clang --removeProductLang Es-es --addProductLang En-us --installWhileDownloading --passive --wait\n@REM del vs_community.exe\n@REM curl -L -O https://aka.ms/vs/17/release/vs_professional.exe || exit /b\n@REM vs_Professional.exe --add Microsoft.VisualStudio.Workload.NativeDesktop Microsoft.VisualStudio.Workload.NativeGame Microsoft.VisualStudio.Workload.ManagedDesktop Microsoft.VisualStudio.Component.Windows10SDK.18362  Microsoft.VisualStudio.Component.VC.CMake.Project Microsoft.Net.ComponentGroup.4.8.1.DeveloperTools Microsoft.VisualStudio.Component.VC.Llvm.Clang Microsoft.VisualStudio.Component.VC.Llvm.ClangToolset Microsoft.VisualStudio.ComponentGroup.NativeDesktop.Llvm.Clang --removeProductLang Es-es --addProductLang En-us --installWhileDownloading --passive --wait\n@REM del vs_professional.exe\n@REM echo Visual Studion 2022 Installed!!!\n\nC:\\Carla\\CarlaUE5\\Setup.bat\n\nhttps://blog.csdn.net/weixin_46356818/article/details/121029550 -->","excerpt":"","more":"<p>Carla是一个开源的自动驾驶仿真平台，其<a href=\"https://github.com/carla-simulator/carla/tree/ue5-dev\">最新版本</a>基于UE5开发，画面十分的逼真。</p>\n<p>本文主要记录在Win11上通过源码构建CarlaUE5时所碰到的问题以及解决方案，整理流程参考<a href=\"https://carla.readthedocs.io/en/latest/build_windows_ue5/\">官方教程</a>。</p>\n<p>在构建的过程中，主要碰到了以下问题：</p>\n<ul>\n<li>本机已有的VS2022专业版，如何跳过默认的VS2022社区版安装流程，并把依赖安装到原有的VS2022专业版上；</li>\n<li>构建过程中报了一个跟编码格式相关的错；</li>\n<li>构建过程中报了一个跟路径长度相关的错。</li>\n</ul>\n<p>接下来分别介绍各个问题以及对应的解决方案。</p>\n<hr>\n<h1 id=\"使用已有的VS2022专业版\"><a href=\"#使用已有的VS2022专业版\" class=\"headerlink\" title=\"使用已有的VS2022专业版\"></a>使用已有的VS2022专业版</h1><h2 id=\"修改C-Carla-CarlaUE5-Setup-bat\"><a href=\"#修改C-Carla-CarlaUE5-Setup-bat\" class=\"headerlink\" title=\"修改C:\\Carla\\CarlaUE5\\Setup.bat\"></a>修改<code>C:\\Carla\\CarlaUE5\\Setup.bat</code></h2><ul>\n<li>注释掉安装VS2022社区版相关的代码</li>\n<li>将类似<code>C:\\Program Files\\Microsoft Visual Studio\\2022\\Community</code>的字段换成已有的VS2022专业版路径</li>\n</ul>\n<h2 id=\"安装依赖\"><a href=\"#安装依赖\" class=\"headerlink\" title=\"安装依赖\"></a>安装依赖</h2><p>如下所示，<code>C:\\Carla\\CarlaUE5\\Setup.bat</code>在安装VS2022社区版的时候，会顺带安装上一些依赖。</p>\n<figure class=\"highlight bat\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">vs_Community.exe --add Microsoft.VisualStudio.Workload.NativeDesktop Microsoft.VisualStudio.Workload.NativeGame Microsoft.VisualStudio.Workload.ManagedDesktop Microsoft.VisualStudio.Component.Windows10SDK.<span class=\"number\">18362</span>  Microsoft.VisualStudio.Component.VC.CMake.Project Microsoft.<span class=\"built_in\">Net</span>.ComponentGroup.<span class=\"number\">4</span>.<span class=\"number\">8</span>.<span class=\"number\">1</span>.DeveloperTools Microsoft.VisualStudio.Component.VC.Llvm.Clang Microsoft.VisualStudio.Component.VC.Llvm.ClangToolset Microsoft.VisualStudio.ComponentGroup.NativeDesktop.Llvm.Clang --removeProductLang Es-es --addProductLang En-us --installWhileDownloading --passive --wait</div></pre></td></tr></table></figure>\n<p>没有这些依赖的话，在构建CarlaUE5的时候会报错<code>MSB3073</code>，因此我们需要手动把这些依赖装到已有的VS2022专业版上：</p>\n<ul>\n<li>手动安装依赖的方法，可以参考<a href=\"https://blog.csdn.net/weixin_42205218/article/details/107829229\">这个网站</a></li>\n<li>依赖名字到组件名字的映射，可以参考<a href=\"https://learn.microsoft.com/zh-cn/visualstudio/install/workload-component-id-vs-professional?view=vs-2022\">这个网站</a></li>\n</ul>\n<hr>\n<h1 id=\"编码格式报错\"><a href=\"#编码格式报错\" class=\"headerlink\" title=\"编码格式报错\"></a>编码格式报错</h1><h2 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h2><p>构建CarlaUE5时，会报以下错误：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\">[33/413] Building C object CMakeFiles\\sqlite3.dir\\_deps\\sqlite3-src\\shell.c.obj</div><div class=\"line\">FAILED: CMakeFiles/sqlite3.dir/_deps/sqlite3-src/shell.c.obj</div><div class=\"line\">C:\\PROGRA~1\\MICROS~4\\2022\\PROFES~1\\VC\\Tools\\MSVC\\1436~1.325\\bin\\Hostx64\\x64\\cl.exe  /nologo -D_CRT_SECURE_NO_WARNINGS -IC:\\Carla\\CarlaUE5\\Build\\_deps\\zlib-src -IC:\\Carla\\CarlaUE5\\Build\\_deps\\zlib-build -IC:\\Carla\\CarlaUE5\\Build\\_deps\\libpng-src -IC:\\Carla\\CarlaUE5\\Build\\_deps\\libpng-build /DWIN32 /D_WINDOWS /O2 /Ob2 /DNDEBUG -std:c11 -MD /wd4005 /showIncludes /FoCMakeFiles\\sqlite3.dir\\_deps\\sqlite3-src\\shell.c.obj /FdCMakeFiles\\sqlite3.dir\\ /FS -c C:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c</div><div class=\"line\">C:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(1): warning C4819: 该文件包含不能在当前代码页(936)中表示的字符。请将该文件保存为 Unicode 格式以防止数据丢失</div><div class=\"line\">C:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(26303): warning C4819: 该文件包含不能在当前代码页(936)中表示的字符。请将该文件保存为 Unicode 格式以防止数据丢失</div><div class=\"line\">C:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(26338): error C2001: 常量中有换行符</div><div class=\"line\">C:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(26339): error C2143: 语法错误: 缺少“;”(在“const”的前面)</div><div class=\"line\">C:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(26353): error C2065: “zBom”: 未声明的标识符</div><div class=\"line\">C:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(26353): warning C4047: “=”:“int”与“const char *”的间接级别不同</div><div class=\"line\">C:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(26420): error C2065: “zBom”: 未声明的标识符</div><div class=\"line\">C:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(26420): warning C4047: “函数”:“const char *”与“int”的间接级别不同</div><div class=\"line\">C:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(26420): warning C4024: “oPutsUtf8”: 形参和实参 1 的类型不同</div><div class=\"line\">C:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(26433): error C2065: “zBom”: 未声明的标识符</div><div class=\"line\">C:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(26433): warning C4047: “函数”:“const char *”与“int”的间接级别不同</div><div class=\"line\">C:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c(26433): warning C4024: “oPutsUtf8”: 形参和实参 1 的类型不同</div></pre></td></tr></table></figure>\n<h2 id=\"解决\"><a href=\"#解决\" class=\"headerlink\" title=\"解决\"></a>解决</h2><p>按<a href=\"https://github.com/carla-simulator/carla/pull/8033\">这个PR</a>的方法，在<code>CMake/Common.cmake</code>中增加一行<code>add_compile_options (/utf-8)</code>即可解决问题。</p>\n<p>修改之后重新构建，可以在<code>C:\\Carla\\CarlaUE5\\Build\\build.ninja</code>中看到编译选项中已经加上了<code>/utf-8</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">build CMakeFiles\\sqlite3.dir\\_deps\\sqlite3-src\\shell.c.obj: C_COMPILER__sqlite3_unscanned_Release C$:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c || cmake_object_order_depends_target_sqlite3</div><div class=\"line\">  DEFINES = -D_CRT_SECURE_NO_WARNINGS</div><div class=\"line\">  FLAGS = /DWIN32 /D_WINDOWS /O2 /Ob2 /DNDEBUG -std:c11 -MD /utf-8 /wd4005</div><div class=\"line\">  INCLUDES = -IC:\\Carla\\CarlaUE5\\Build\\_deps\\zlib-src -IC:\\Carla\\CarlaUE5\\Build\\_deps\\zlib-build -IC:\\Carla\\CarlaUE5\\Build\\_deps\\libpng-src -IC:\\Carla\\CarlaUE5\\Build\\_deps\\libpng-build</div><div class=\"line\">  OBJECT_DIR = CMakeFiles\\sqlite3.dir</div><div class=\"line\">  OBJECT_FILE_DIR = CMakeFiles\\sqlite3.dir\\_deps\\sqlite3-src</div><div class=\"line\">  TARGET_COMPILE_PDB = CMakeFiles\\sqlite3.dir\\</div><div class=\"line\">  TARGET_PDB = sqlite3.pdb</div></pre></td></tr></table></figure>\n<hr>\n<h1 id=\"路径过长报错\"><a href=\"#路径过长报错\" class=\"headerlink\" title=\"路径过长报错\"></a>路径过长报错</h1><h2 id=\"问题-1\"><a href=\"#问题-1\" class=\"headerlink\" title=\"问题\"></a>问题</h2><p>构建的时候会陷入死循环，一直卡在其中一步，报错的提示指向文件路径名太长。</p>\n<h2 id=\"解决-1\"><a href=\"#解决-1\" class=\"headerlink\" title=\"解决\"></a>解决</h2><p>参考<a href=\"https://blog.csdn.net/weixin_46356818/article/details/121029550\">这个网站</a>，将Windows对长路径的支持打开即可。</p>\n<!-- https://github.com/carla-simulator/carla/pull/8033\n\nC:\\Carla\\CarlaUE5\\Build\\build.ninja\n\nbuild CMakeFiles\\sqlite3.dir\\_deps\\sqlite3-src\\shell.c.obj: C_COMPILER__sqlite3_unscanned_Release C$:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c || cmake_object_order_depends_target_sqlite3\n  DEFINES = -D_CRT_SECURE_NO_WARNINGS\n  FLAGS = /DWIN32 /D_WINDOWS /O2 /Ob2 /DNDEBUG -std:c11 -MD /utf-8 /wd4005\n  INCLUDES = -IC:\\Carla\\CarlaUE5\\Build\\_deps\\zlib-src -IC:\\Carla\\CarlaUE5\\Build\\_deps\\zlib-build -IC:\\Carla\\CarlaUE5\\Build\\_deps\\libpng-src -IC:\\Carla\\CarlaUE5\\Build\\_deps\\libpng-build\n  OBJECT_DIR = CMakeFiles\\sqlite3.dir\n  OBJECT_FILE_DIR = CMakeFiles\\sqlite3.dir\\_deps\\sqlite3-src\n  TARGET_COMPILE_PDB = CMakeFiles\\sqlite3.dir\\\n  TARGET_PDB = sqlite3.pdb\n\n\nbuild CMakeFiles\\sqlite3.dir\\_deps\\sqlite3-src\\shell.c.obj: C_COMPILER__sqlite3_unscanned_Release C$:\\Carla\\CarlaUE5\\Build\\_deps\\sqlite3-src\\shell.c || cmake_object_order_depends_target_sqlite3\n  DEFINES = -D_CRT_SECURE_NO_WARNINGS\n  FLAGS = /DWIN32 /D_WINDOWS /O2 /Ob2 /DNDEBUG -std:c11 -MD /wd4005\n  INCLUDES = -IC:\\Carla\\CarlaUE5\\Build\\_deps\\zlib-src -IC:\\Carla\\CarlaUE5\\Build\\_deps\\zlib-build -IC:\\Carla\\CarlaUE5\\Build\\_deps\\libpng-src -IC:\\Carla\\CarlaUE5\\Build\\_deps\\libpng-build\n  OBJECT_DIR = CMakeFiles\\sqlite3.dir\n  OBJECT_FILE_DIR = CMakeFiles\\sqlite3.dir\\_deps\\sqlite3-src\n  TARGET_COMPILE_PDB = CMakeFiles\\sqlite3.dir\\\n  TARGET_PDB = sqlite3.pdb\n\nhttps://www.cnblogs.com/mechanicoder/p/16894144.html\n\nMSB3073\n\nhttps://learn.microsoft.com/zh-cn/visualstudio/install/workload-component-id-vs-professional?view=vs-2022\n\n@REM echo Installing Visual Studio 2022...\n@REM curl -L -O https://aka.ms/vs/17/release/vs_community.exe || exit /b\n@REM vs_Community.exe --add Microsoft.VisualStudio.Workload.NativeDesktop Microsoft.VisualStudio.Workload.NativeGame Microsoft.VisualStudio.Workload.ManagedDesktop Microsoft.VisualStudio.Component.Windows10SDK.18362  Microsoft.VisualStudio.Component.VC.CMake.Project Microsoft.Net.ComponentGroup.4.8.1.DeveloperTools Microsoft.VisualStudio.Component.VC.Llvm.Clang Microsoft.VisualStudio.Component.VC.Llvm.ClangToolset Microsoft.VisualStudio.ComponentGroup.NativeDesktop.Llvm.Clang --removeProductLang Es-es --addProductLang En-us --installWhileDownloading --passive --wait\n@REM del vs_community.exe\n@REM curl -L -O https://aka.ms/vs/17/release/vs_professional.exe || exit /b\n@REM vs_Professional.exe --add Microsoft.VisualStudio.Workload.NativeDesktop Microsoft.VisualStudio.Workload.NativeGame Microsoft.VisualStudio.Workload.ManagedDesktop Microsoft.VisualStudio.Component.Windows10SDK.18362  Microsoft.VisualStudio.Component.VC.CMake.Project Microsoft.Net.ComponentGroup.4.8.1.DeveloperTools Microsoft.VisualStudio.Component.VC.Llvm.Clang Microsoft.VisualStudio.Component.VC.Llvm.ClangToolset Microsoft.VisualStudio.ComponentGroup.NativeDesktop.Llvm.Clang --removeProductLang Es-es --addProductLang En-us --installWhileDownloading --passive --wait\n@REM del vs_professional.exe\n@REM echo Visual Studion 2022 Installed!!!\n\nC:\\Carla\\CarlaUE5\\Setup.bat\n\nhttps://blog.csdn.net/weixin_46356818/article/details/121029550 -->"}],"PostAsset":[{"_id":"source/_posts/note-learning-how-to-learn/learning_how_to_learn.png","slug":"learning_how_to_learn.png","post":"clzvf191z000veqwodbuu30tr","modified":1,"renderable":0},{"_id":"source/_posts/note-reinforcement-learning/lec5_Model_Free_Control.png","slug":"lec5_Model_Free_Control.png","post":"clzvf19230011eqwod5y0jaoq","modified":1,"renderable":0},{"_id":"source/_posts/summary-derivative/cnn2.png","slug":"cnn2.png","post":"clzvf192h001qeqwoz7se07e4","modified":1,"renderable":0},{"_id":"source/_posts/note-linear-algebra/linear_algebra.png","slug":"linear_algebra.png","post":"clzvf1921000yeqwod4s8qyy0","modified":1,"renderable":0},{"_id":"source/_posts/summary-rl-drl/ppo_objective.png","post":"clzvf192k001xeqwom1gfasnd","slug":"ppo_objective.png","modified":1,"renderable":1},{"_id":"source/_posts/paper-prioritized-experience-replay/env.png","post":"clzvf1929001aeqwoerh2iq55","slug":"env.png","modified":1,"renderable":1},{"_id":"source/_posts/paper-prioritized-experience-replay/fig.png","post":"clzvf1929001aeqwoerh2iq55","slug":"fig.png","modified":1,"renderable":1},{"_id":"source/_posts/paper-orca/opt.png","post":"clzvf19270016eqwolnapvyjd","slug":"opt.png","modified":1,"renderable":1},{"_id":"source/_posts/paper-orca/orca_app.png","post":"clzvf19270016eqwolnapvyjd","slug":"orca_app.png","modified":1,"renderable":1},{"_id":"source/_posts/paper-orca/orca_sol.png","post":"clzvf19270016eqwolnapvyjd","slug":"orca_sol.png","modified":1,"renderable":1},{"_id":"source/_posts/paper-orca/time_interval.png","post":"clzvf19270016eqwolnapvyjd","slug":"time_interval.png","modified":1,"renderable":1},{"_id":"source/_posts/source-carlaue5-architecture/carla.png","post":"clzvf192e001keqwonw4xqcj0","slug":"carla.png","modified":1,"renderable":1},{"_id":"source/_posts/source-carlaue5-architecture/client.png","slug":"client.png","post":"clzvf192e001keqwonw4xqcj0","modified":1,"renderable":0},{"_id":"source/_posts/source-carlaue5-architecture/pythonapi.png","post":"clzvf192e001keqwonw4xqcj0","slug":"pythonapi.png","modified":1,"renderable":1},{"_id":"source/_posts/source-carlaue5-architecture/server.png","slug":"server.png","post":"clzvf192e001keqwonw4xqcj0","modified":1,"renderable":0},{"_id":"source/_posts/note-essence-of-linear-algrbra/combination.png","post":"clzvf191x000teqwor5v4pmk4","slug":"combination.png","modified":1,"renderable":1},{"_id":"source/_posts/note-essence-of-linear-algrbra/det.png","post":"clzvf191x000teqwor5v4pmk4","slug":"det.png","modified":1,"renderable":1},{"_id":"source/_posts/note-essence-of-linear-algrbra/dot_product_order.png","post":"clzvf191x000teqwor5v4pmk4","slug":"dot_product_order.png","modified":1,"renderable":1},{"_id":"source/_posts/note-essence-of-linear-algrbra/dot_product_projection.png","post":"clzvf191x000teqwor5v4pmk4","slug":"dot_product_projection.png","modified":1,"renderable":1},{"_id":"source/_posts/note-essence-of-linear-algrbra/representation.png","post":"clzvf191x000teqwor5v4pmk4","slug":"representation.png","modified":1,"renderable":1},{"_id":"source/_posts/note-essence-of-linear-algrbra/transformation.png","post":"clzvf191x000teqwor5v4pmk4","slug":"transformation.png","modified":1,"renderable":1},{"_id":"source/_posts/paper-rvo/five_agents.gif","slug":"five_agents.gif","post":"clzvf192b001deqwo96q5li2c","modified":1,"renderable":0},{"_id":"source/_posts/paper-rvo/left_right.png","post":"clzvf192b001deqwo96q5li2c","slug":"left_right.png","modified":1,"renderable":1},{"_id":"source/_posts/paper-rvo/oscillation.png","post":"clzvf192b001deqwo96q5li2c","slug":"oscillation.png","modified":1,"renderable":1},{"_id":"source/_posts/paper-rvo/prob_disc.png","post":"clzvf192b001deqwo96q5li2c","slug":"prob_disc.png","modified":1,"renderable":1},{"_id":"source/_posts/paper-rvo/prob_sol.png","post":"clzvf192b001deqwo96q5li2c","slug":"prob_sol.png","modified":1,"renderable":1},{"_id":"source/_posts/paper-rvo/rvo.png","post":"clzvf192b001deqwo96q5li2c","slug":"rvo.png","modified":1,"renderable":1},{"_id":"source/_posts/paper-rvo/vo.png","post":"clzvf192b001deqwo96q5li2c","slug":"vo.png","modified":1,"renderable":1},{"_id":"source/_posts/summary-derivative/bp1.png","post":"clzvf192h001qeqwoz7se07e4","slug":"bp1.png","modified":1,"renderable":1},{"_id":"source/_posts/summary-derivative/bp2.png","post":"clzvf192h001qeqwoz7se07e4","slug":"bp2.png","modified":1,"renderable":1},{"_id":"source/_posts/summary-derivative/bp3.png","post":"clzvf192h001qeqwoz7se07e4","slug":"bp3.png","modified":1,"renderable":1},{"_id":"source/_posts/summary-derivative/cnn1.png","post":"clzvf192h001qeqwoz7se07e4","slug":"cnn1.png","modified":1,"renderable":1},{"_id":"source/_posts/summary-derivative/rnn.png","post":"clzvf192h001qeqwoz7se07e4","slug":"rnn.png","modified":1,"renderable":1},{"_id":"source/_posts/summary-derivative/softmax.png","post":"clzvf192h001qeqwoz7se07e4","slug":"softmax.png","modified":1,"renderable":1},{"_id":"source/_posts/summary-gps/1.png","post":"clzvf192j001ueqwo9b0ueoan","slug":"1.png","modified":1,"renderable":1},{"_id":"source/_posts/summary-gps/2.png","post":"clzvf192j001ueqwo9b0ueoan","slug":"2.png","modified":1,"renderable":1},{"_id":"source/_posts/summary-gps/3.png","post":"clzvf192j001ueqwo9b0ueoan","slug":"3.png","modified":1,"renderable":1},{"_id":"source/_posts/summary-gps/3_1.png","post":"clzvf192j001ueqwo9b0ueoan","slug":"3_1.png","modified":1,"renderable":1},{"_id":"source/_posts/summary-gps/3_2.png","post":"clzvf192j001ueqwo9b0ueoan","slug":"3_2.png","modified":1,"renderable":1},{"_id":"source/_posts/summary-gps/4.png","post":"clzvf192j001ueqwo9b0ueoan","slug":"4.png","modified":1,"renderable":1},{"_id":"source/_posts/summary-gps/lqr.png","post":"clzvf192j001ueqwo9b0ueoan","slug":"lqr.png","modified":1,"renderable":1},{"_id":"source/_posts/note-reinforcement-learning/lec1_Intro_to_RL.png","post":"clzvf19230011eqwod5y0jaoq","slug":"lec1_Intro_to_RL.png","modified":1,"renderable":1},{"_id":"source/_posts/note-reinforcement-learning/lec2_MDP.png","post":"clzvf19230011eqwod5y0jaoq","slug":"lec2_MDP.png","modified":1,"renderable":1},{"_id":"source/_posts/note-reinforcement-learning/lec3_Planning_by_DP.png","post":"clzvf19230011eqwod5y0jaoq","slug":"lec3_Planning_by_DP.png","modified":1,"renderable":1},{"_id":"source/_posts/note-reinforcement-learning/lec4_Model_Free_Prediction.png","post":"clzvf19230011eqwod5y0jaoq","slug":"lec4_Model_Free_Prediction.png","modified":1,"renderable":1},{"_id":"source/_posts/note-reinforcement-learning/lec6_Value_Function_Approximation.png","post":"clzvf19230011eqwod5y0jaoq","slug":"lec6_Value_Function_Approximation.png","modified":1,"renderable":1},{"_id":"source/_posts/note-reinforcement-learning/lec7_Policy_Gradient.png","post":"clzvf19230011eqwod5y0jaoq","slug":"lec7_Policy_Gradient.png","modified":1,"renderable":1},{"_id":"source/_posts/note-reinforcement-learning/lec8_Integrating_Learning_and_Planning.png","post":"clzvf19230011eqwod5y0jaoq","slug":"lec8_Integrating_Learning_and_Planning.png","modified":1,"renderable":1},{"_id":"source/_posts/note-reinforcement-learning/lec9_Exploration_and_Exploitation.png","post":"clzvf19230011eqwod5y0jaoq","slug":"lec9_Exploration_and_Exploitation.png","modified":1,"renderable":1}],"PostCategory":[{"post_id":"clzvf190j0000eqwo4x5rnktz","category_id":"clzvf190v0003eqwovgfzelqr","_id":"clzvf191g000ceqwocrap6xw4"},{"post_id":"clzvf191c000beqwo8ml7xkus","category_id":"clzvf19170008eqwo4qjdk8wq","_id":"clzvf191o000ieqwozrgvkmwk"},{"post_id":"clzvf190s0002eqwoq82gsteh","category_id":"clzvf19170008eqwo4qjdk8wq","_id":"clzvf191r000meqwo648o0qh6"},{"post_id":"clzvf190z0005eqwoib78amfq","category_id":"clzvf19170008eqwo4qjdk8wq","_id":"clzvf191v000qeqwoa201hjh3"},{"post_id":"clzvf19120006eqwoa5tsl4g7","category_id":"clzvf19170008eqwo4qjdk8wq","_id":"clzvf1920000weqwobnf00q8z"},{"post_id":"clzvf19160007eqwo6za4exy6","category_id":"clzvf19170008eqwo4qjdk8wq","_id":"clzvf19240012eqwo5bbptyqw"},{"post_id":"clzvf191g000deqwobf58k69b","category_id":"clzvf1920000xeqwof1lqngvg","_id":"clzvf19280018eqwomy80hq9z"},{"post_id":"clzvf19250014eqwofyyfgerk","category_id":"clzvf1920000xeqwof1lqngvg","_id":"clzvf192b001ceqwo3g9s9b4w"},{"post_id":"clzvf191n000geqwo1a4ji40i","category_id":"clzvf19240013eqwoestr1vom","_id":"clzvf192c001feqwoxeze0uty"},{"post_id":"clzvf19270016eqwolnapvyjd","category_id":"clzvf1920000xeqwof1lqngvg","_id":"clzvf192e001ieqwooqa0um97"},{"post_id":"clzvf1929001aeqwoerh2iq55","category_id":"clzvf1920000xeqwof1lqngvg","_id":"clzvf192g001meqwoicpssai4"},{"post_id":"clzvf191p000jeqwozxlcc8ad","category_id":"clzvf19240013eqwoestr1vom","_id":"clzvf192h001peqwoedvzsd29"},{"post_id":"clzvf192b001deqwo96q5li2c","category_id":"clzvf1920000xeqwof1lqngvg","_id":"clzvf192j001seqwof7gxuq69"},{"post_id":"clzvf192d001heqwo26yc4qn3","category_id":"clzvf1920000xeqwof1lqngvg","_id":"clzvf192k001weqwor29libzn"},{"post_id":"clzvf191r000neqwodwng1z1c","category_id":"clzvf19240013eqwoestr1vom","_id":"clzvf192m001zeqwo4kei9nf9"},{"post_id":"clzvf191t000peqwoo01uu11x","category_id":"clzvf192g001neqwopkn8vv7k","_id":"clzvf192o0023eqwo0viitva7"},{"post_id":"clzvf191x000teqwor5v4pmk4","category_id":"clzvf192j001veqwob3q8wppv","_id":"clzvf192q0027eqwot8iwajif"},{"post_id":"clzvf191z000veqwodbuu30tr","category_id":"clzvf192j001veqwob3q8wppv","_id":"clzvf192t002deqwon9ljt691"},{"post_id":"clzvf1921000yeqwod4s8qyy0","category_id":"clzvf192j001veqwob3q8wppv","_id":"clzvf192v002geqwo4b0p4qq5"},{"post_id":"clzvf19230011eqwod5y0jaoq","category_id":"clzvf192j001veqwob3q8wppv","_id":"clzvf192w002keqwode5g8s5d"},{"post_id":"clzvf192e001keqwonw4xqcj0","category_id":"clzvf192v002ieqwoeg8wgjhp","_id":"clzvf192y002oeqwoam8m2bby"},{"post_id":"clzvf192g001oeqwojmkhperx","category_id":"clzvf192v002ieqwoeg8wgjhp","_id":"clzvf192z002seqwo4bhp8rfe"},{"post_id":"clzvf192h001qeqwoz7se07e4","category_id":"clzvf192y002peqwo8cf339nl","_id":"clzvf1931002veqwosbl859vc"},{"post_id":"clzvf192j001ueqwo9b0ueoan","category_id":"clzvf192y002peqwo8cf339nl","_id":"clzvf1936002zeqwool9w1c6e"},{"post_id":"clzvf192k001xeqwom1gfasnd","category_id":"clzvf192y002peqwo8cf339nl","_id":"clzvf19370034eqwoshn1f4sf"},{"post_id":"clzvf192m0020eqwoj3zjysjt","category_id":"clzvf19360030eqwozsf9bhwy","_id":"clzvf193a0038eqwogk5olpmr"},{"post_id":"clzvf192o0024eqwoyxd6pbvq","category_id":"clzvf19360030eqwozsf9bhwy","_id":"clzvf193c003beqwon4wr6xma"},{"post_id":"clzvf192p0026eqwoc9y7tmqf","category_id":"clzvf19360030eqwozsf9bhwy","_id":"clzvf193d003eeqwo00mghw51"},{"post_id":"clzvf192r002aeqwoyvqy18hr","category_id":"clzvf19360030eqwozsf9bhwy","_id":"clzvf193h003jeqwo0v495fav"},{"post_id":"clzvf192s002ceqwoh7c2ce4e","category_id":"clzvf19360030eqwozsf9bhwy","_id":"clzvf193i003meqwo56i0a327"}],"PostTag":[{"post_id":"clzvf190j0000eqwo4x5rnktz","tag_id":"clzvf190y0004eqwo3hzcpv0f","_id":"clzvf191b000aeqwomkbvubqn"},{"post_id":"clzvf190s0002eqwoq82gsteh","tag_id":"clzvf19170009eqwojmy9yrwy","_id":"clzvf191o000heqwo49ljseb2"},{"post_id":"clzvf190z0005eqwoib78amfq","tag_id":"clzvf191i000feqwoxed8qs8d","_id":"clzvf191t000oeqwoku6ljjz7"},{"post_id":"clzvf19120006eqwoa5tsl4g7","tag_id":"clzvf191r000leqwo0iav9bp3","_id":"clzvf191y000ueqwojbkpqtw9"},{"post_id":"clzvf19160007eqwo6za4exy6","tag_id":"clzvf191w000seqwocq8qbldc","_id":"clzvf19230010eqwoz626bfd5"},{"post_id":"clzvf191c000beqwo8ml7xkus","tag_id":"clzvf1922000zeqwo0xg0zkqp","_id":"clzvf19270017eqwoh5fsd8ic"},{"post_id":"clzvf191g000deqwobf58k69b","tag_id":"clzvf19260015eqwol19s7ixw","_id":"clzvf192c001eeqwo5hha0885"},{"post_id":"clzvf191n000geqwo1a4ji40i","tag_id":"clzvf192a001beqwoqrcifcr4","_id":"clzvf192f001leqwo62emst1r"},{"post_id":"clzvf191p000jeqwozxlcc8ad","tag_id":"clzvf192e001jeqwovchhz56m","_id":"clzvf192j001teqwoklj1jciz"},{"post_id":"clzvf191r000neqwodwng1z1c","tag_id":"clzvf192i001reqwobabpezm4","_id":"clzvf192n0021eqwok2mmsj83"},{"post_id":"clzvf191t000peqwoo01uu11x","tag_id":"clzvf192l001yeqwo1p05w96p","_id":"clzvf192q0029eqwo60tenhjb"},{"post_id":"clzvf191x000teqwor5v4pmk4","tag_id":"clzvf192p0025eqwoohkudkzo","_id":"clzvf192u002feqwolax4jlhw"},{"post_id":"clzvf191z000veqwodbuu30tr","tag_id":"clzvf192s002beqwoqa5j42oc","_id":"clzvf192v002jeqworgfjiay2"},{"post_id":"clzvf1921000yeqwod4s8qyy0","tag_id":"clzvf192v002heqwo7yucbz8x","_id":"clzvf192x002neqwosbb5nspt"},{"post_id":"clzvf19230011eqwod5y0jaoq","tag_id":"clzvf192w002leqwoz4ue4kz8","_id":"clzvf192y002reqwoti3msq6f"},{"post_id":"clzvf19250014eqwofyyfgerk","tag_id":"clzvf192y002qeqwovd61ut61","_id":"clzvf1935002yeqwo6akjsnvy"},{"post_id":"clzvf19250014eqwofyyfgerk","tag_id":"clzvf1930002ueqwohqv6okov","_id":"clzvf19360031eqwo68f3v2no"},{"post_id":"clzvf19270016eqwolnapvyjd","tag_id":"clzvf1932002xeqwo50qhe9b7","_id":"clzvf19370033eqwoo6pmu97o"},{"post_id":"clzvf1929001aeqwoerh2iq55","tag_id":"clzvf19370032eqwo341lnabw","_id":"clzvf193a0037eqwozkog3d9u"},{"post_id":"clzvf192b001deqwo96q5li2c","tag_id":"clzvf19390036eqwohuovphlp","_id":"clzvf193f003feqwoi4cup7jy"},{"post_id":"clzvf192b001deqwo96q5li2c","tag_id":"clzvf193b003aeqwoi1yfkvb2","_id":"clzvf193g003heqwolo4pg8j4"},{"post_id":"clzvf192d001heqwo26yc4qn3","tag_id":"clzvf193d003deqwozlckfnuu","_id":"clzvf193h003keqwoaj54ydj9"},{"post_id":"clzvf192e001keqwonw4xqcj0","tag_id":"clzvf193h003ieqwo8310wvxy","_id":"clzvf193i003neqwo18srihuu"},{"post_id":"clzvf192g001oeqwojmkhperx","tag_id":"clzvf193i003leqwoh6c6792i","_id":"clzvf193j003peqwoqyab9puu"},{"post_id":"clzvf192h001qeqwoz7se07e4","tag_id":"clzvf193i003oeqwojrkq360i","_id":"clzvf193m003weqwowfyepuu2"},{"post_id":"clzvf192h001qeqwoz7se07e4","tag_id":"clzvf193j003qeqwock4y4qqo","_id":"clzvf193m003xeqwoskzqju79"},{"post_id":"clzvf192h001qeqwoz7se07e4","tag_id":"clzvf193k003reqwosh6xbv1o","_id":"clzvf193n003zeqwovml7xl3o"},{"post_id":"clzvf192h001qeqwoz7se07e4","tag_id":"clzvf193l003seqwoh0l4chsc","_id":"clzvf193n0040eqwo7pbnb2ik"},{"post_id":"clzvf192h001qeqwoz7se07e4","tag_id":"clzvf193l003teqwo1tzbount","_id":"clzvf193o0042eqwouhoo1t9h"},{"post_id":"clzvf192h001qeqwoz7se07e4","tag_id":"clzvf193m003ueqwojs9t7yyq","_id":"clzvf193o0043eqworf62srte"},{"post_id":"clzvf192j001ueqwo9b0ueoan","tag_id":"clzvf193m003veqwo7zezf8ik","_id":"clzvf193p0045eqwoz8snphr6"},{"post_id":"clzvf192j001ueqwo9b0ueoan","tag_id":"clzvf193n003yeqwo9m4atl8q","_id":"clzvf193p0046eqwoxja4xcjx"},{"post_id":"clzvf192k001xeqwom1gfasnd","tag_id":"clzvf192w002leqwoz4ue4kz8","_id":"clzvf193r004eeqworxnqlsdb"},{"post_id":"clzvf192k001xeqwom1gfasnd","tag_id":"clzvf193o0044eqwoy0qvc8py","_id":"clzvf193r004feqwose8y30mu"},{"post_id":"clzvf192k001xeqwom1gfasnd","tag_id":"clzvf193p0047eqwols1kxano","_id":"clzvf193s004heqwott9934mm"},{"post_id":"clzvf192k001xeqwom1gfasnd","tag_id":"clzvf193p0048eqwowaz1rdqd","_id":"clzvf193s004ieqwol6ujpu72"},{"post_id":"clzvf192k001xeqwom1gfasnd","tag_id":"clzvf193p0049eqwo6d96hdny","_id":"clzvf193t004keqwo2xdzeb4y"},{"post_id":"clzvf192k001xeqwom1gfasnd","tag_id":"clzvf193q004aeqwocc911760","_id":"clzvf193t004leqwokpf5v99f"},{"post_id":"clzvf192k001xeqwom1gfasnd","tag_id":"clzvf193q004beqwofyjhcrm8","_id":"clzvf193u004neqwovflymqiq"},{"post_id":"clzvf192k001xeqwom1gfasnd","tag_id":"clzvf193q004ceqwo3gs7m1mj","_id":"clzvf193u004oeqwo2x90solv"},{"post_id":"clzvf192m0020eqwoj3zjysjt","tag_id":"clzvf193r004deqwo3x9sm2a6","_id":"clzvf193u004peqwoedl0fix5"},{"post_id":"clzvf192o0024eqwoyxd6pbvq","tag_id":"clzvf193s004geqwo8lw3cfdi","_id":"clzvf193v004reqwoc6l6x6eu"},{"post_id":"clzvf192p0026eqwoc9y7tmqf","tag_id":"clzvf193s004jeqwo9h047zf0","_id":"clzvf193v004seqwoeyo3rcyv"},{"post_id":"clzvf192r002aeqwoyvqy18hr","tag_id":"clzvf193u004meqwoyumof0d9","_id":"clzvf193v004teqwo2mbh8yks"},{"post_id":"clzvf192s002ceqwoh7c2ce4e","tag_id":"clzvf193h003ieqwo8310wvxy","_id":"clzvf193v004ueqwoqli6g2x7"}],"Tag":[{"name":"caffe配置","_id":"clzvf190y0004eqwo3hzcpv0f"},{"name":"caffe学习","_id":"clzvf19170009eqwojmy9yrwy"},{"name":"rnn","_id":"clzvf191i000feqwoxed8qs8d"},{"name":"s2vt data","_id":"clzvf191r000leqwo0iav9bp3"},{"name":"lstm","_id":"clzvf191w000seqwocq8qbldc"},{"name":"s2vt_captioner","_id":"clzvf1922000zeqwo0xg0zkqp"},{"name":"AlexNet","_id":"clzvf19260015eqwol19s7ixw"},{"name":"沟通的艺术","_id":"clzvf192a001beqwoqrcifcr4"},{"name":"精进","_id":"clzvf192e001jeqwovchhz56m"},{"name":"哲学家们都干了些什么","_id":"clzvf192i001reqwobabpezm4"},{"name":"A Tour of C++","_id":"clzvf192l001yeqwo1p05w96p"},{"name":"线性代数的本质","_id":"clzvf192p0025eqwoohkudkzo"},{"name":"学习方法","_id":"clzvf192s002beqwoqa5j42oc"},{"name":"线性代数","_id":"clzvf192v002heqwo7yucbz8x"},{"name":"强化学习","_id":"clzvf192w002leqwoz4ue4kz8"},{"name":"K-FAC","_id":"clzvf192y002qeqwovd61ut61"},{"name":"ACKTR","_id":"clzvf1930002ueqwohqv6okov"},{"name":"ORCA","_id":"clzvf1932002xeqwo50qhe9b7"},{"name":"Prioritized Experience Replay","_id":"clzvf19370032eqwo341lnabw"},{"name":"VO(Velocity Obstacle)","_id":"clzvf19390036eqwohuovphlp"},{"name":"RVO(Reciprocal Velocity Obstacle)","_id":"clzvf193b003aeqwoi1yfkvb2"},{"name":"rcnn","_id":"clzvf193d003deqwozlckfnuu"},{"name":"CarlaUE5","_id":"clzvf193h003ieqwo8310wvxy"},{"name":"pytorch-ppo","_id":"clzvf193i003leqwoh6c6792i"},{"name":"derivative","_id":"clzvf193i003oeqwojrkq360i"},{"name":"softmax","_id":"clzvf193j003qeqwock4y4qqo"},{"name":"backpropagation","_id":"clzvf193k003reqwosh6xbv1o"},{"name":"cnn","_id":"clzvf193l003seqwoh0l4chsc"},{"name":"bptt","_id":"clzvf193l003teqwo1tzbount"},{"name":"max pooling","_id":"clzvf193m003ueqwojs9t7yyq"},{"name":"Guided Policy Search","_id":"clzvf193m003veqwo7zezf8ik"},{"name":"GPS","_id":"clzvf193n003yeqwo9m4atl8q"},{"name":"深度强化学习","_id":"clzvf193o0044eqwoy0qvc8py"},{"name":"GAE","_id":"clzvf193p0047eqwols1kxano"},{"name":"A3C","_id":"clzvf193p0048eqwowaz1rdqd"},{"name":"DPG","_id":"clzvf193p0049eqwo6d96hdny"},{"name":"DDPG","_id":"clzvf193q004aeqwocc911760"},{"name":"TRPO","_id":"clzvf193q004beqwofyjhcrm8"},{"name":"PPO","_id":"clzvf193q004ceqwo3gs7m1mj"},{"name":"Gym","_id":"clzvf193r004deqwo3x9sm2a6"},{"name":"Ubuntu USB蓝牙适配器","_id":"clzvf193s004geqwo8lw3cfdi"},{"name":"Ubuntu to Go","_id":"clzvf193s004jeqwo9h047zf0"},{"name":"Vim","_id":"clzvf193u004meqwoyumof0d9"}]}}